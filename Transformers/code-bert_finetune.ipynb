{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_Q3_SamDonald.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS5814: Assignment 3\n",
        "\n",
        "## Problem 3"
      ],
      "metadata": {
        "id": "hxeLNPYCa93i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In problem involves creating a defect detection model that can automatically detect whether a code is insecure and may attack software systems.\n",
        "\n",
        "Work is centered on finetuning the pre-trained code-based models provided by Hugging Face package, by using the provided code_dataset.jsonl dataset."
      ],
      "metadata": {
        "id": "IKn6KNV-bBOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "j2fshHbYbl3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMpi1EtlIJXA",
        "outputId": "b8efe65d-5fe6-4db7-c53f-e10eb5527357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wAa47U8LfZ5",
        "outputId": "9ea69c45-e5c8-431f-b567-805088c386af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 122 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 133 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 9.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "dchg20BcbniV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "import pickle\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "o0_bXqE2IHl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGSheFp8bpv0",
        "outputId": "10848280-51d8-4d23-e467-92976c4f7da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Google Drive"
      ],
      "metadata": {
        "id": "VcVwZWAKbxb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCuKhaszbiJ5",
        "outputId": "2c3d2281-b0f7-4eca-d0c9-935243028ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFwcJxl6H6Pn",
        "outputId": "cd09b320-24cb-45bc-fd94-8196889a4a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/CS5814/HW3/Q3\n"
          ]
        }
      ],
      "source": [
        "%cd drive/My Drive/CS5814/HW3/Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing functions"
      ],
      "metadata": {
        "id": "v4ehzGJ8b0kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(file_loc='code_dataset.jsonl'):\n",
        "    \"\"\"\n",
        "    Loads and processing the jsonl file,\n",
        "\n",
        "    :param file_loc: location of target jsonl file\n",
        "    :param generate_histogram: Flag to display histogram of function lengths\n",
        "    :return: dataframe of preprocessed jsons\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file_loc, 'r') as json_file:\n",
        "        json_list = list(json_file)\n",
        "\n",
        "    code_list = []\n",
        "    for json_str in json_list:\n",
        "        result = json.loads(json_str)\n",
        "        code_list.append(result)\n",
        "\n",
        "    code_df = pd.DataFrame(code_list)\n",
        "\n",
        "    total = code_df['target'].sum()\n",
        "    proportion = total / code_df.shape[0]\n",
        "\n",
        "    print(\"Insecure code counts: {}, Total code counts: {}, Proportion {}\".format(total, code_df.shape[0], proportion))\n",
        "        \n",
        "    return code_df"
      ],
      "metadata": {
        "id": "JAo5HSzHISqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(input_data, attention_data, label_data, train_ratio=0.8, val_ratio=0.10, max_len=512):\n",
        "    \"\"\"\n",
        "    Splits data in accordance with provdied ratios, additionally discards functions with > max_len tokens\n",
        "        as these will not be processed by the model will (can truncate, yet may truncate the error in the code)\n",
        "\n",
        "    :param input_data: input functions\n",
        "    :param attention_data: attention map\n",
        "    :param label_data: target labels\n",
        "    :param train_ratio: ratio of data to train on\n",
        "    :param val_ratio: ratio of data to validate with (test is inferred from this and train)\n",
        "    :param max_len: max number of tokens allowed for training date\n",
        "\n",
        "    :return: 3 tuples for train val and test containing (input, attention, target)\n",
        "    \"\"\"\n",
        "    # Removing excessively long elements from dataset\n",
        "    valid_token_index = [i for i in range(len(input_data)) if len(input_data[i]) <= max_len]\n",
        "    X_data = np.array(input_data)[valid_token_index]\n",
        "    A_data = np.array(attention_data)[valid_token_index]\n",
        "    Y_data = np.array(label_data)[valid_token_index]\n",
        "\n",
        "    dataset_size = len(X_data)\n",
        "\n",
        "    # Determining index to split dataset\n",
        "    random_id = random.sample(range(dataset_size), dataset_size)\n",
        "    train_split_id = int(train_ratio * dataset_size)\n",
        "    val_split_id = int((train_ratio + val_ratio) * dataset_size)\n",
        "\n",
        "    train_ids = random_id[:train_split_id]\n",
        "    val_ids = random_id[train_split_id:val_split_id]\n",
        "    test_ids = random_id[val_split_id:]\n",
        "\n",
        "    X_train = torch.tensor(list(X_data[train_ids]))\n",
        "    A_train = torch.tensor(list(A_data[train_ids]))\n",
        "    Y_train = torch.tensor(list(Y_data[train_ids]))\n",
        "\n",
        "    X_val = torch.tensor(list(X_data[val_ids]))\n",
        "    A_val = torch.tensor(list(A_data[val_ids]))\n",
        "    Y_val = torch.tensor(list(Y_data[val_ids]))\n",
        "\n",
        "    X_test = torch.tensor(list(X_data[test_ids]))\n",
        "    A_test = torch.tensor(list(A_data[test_ids]))\n",
        "    Y_test = torch.tensor(list(Y_data[test_ids]))\n",
        "\n",
        "    return (X_train, A_train, Y_train), (X_val, A_val, Y_val), (X_test, A_test, Y_test)"
      ],
      "metadata": {
        "id": "GaIm5G0kIUHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(code_df, model_name='codebert-base'):\n",
        "    \"\"\"\n",
        "    Apply the tokenizer from the huggingface pretrained model\n",
        "\n",
        "    :param code_df: dataframe of preprocess code (from jsonl)\n",
        "    :param model_name: model name (targeting local install)\n",
        "    :return: 3 tuples for train val and test containing (input, attention, target)\n",
        "    \"\"\"\n",
        "    #tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    inputs = tokenizer(code_df['func'].tolist(), truncation=False, padding='max_length', max_length=512)\n",
        "\n",
        "    input_data = inputs['input_ids']\n",
        "    attention_data = inputs['attention_mask']\n",
        "    label_data = torch.tensor(code_df['target'].tolist())  # TODO - this can be directly converted to a np array\n",
        "\n",
        "    print(\"Data points: {}\".format(len(input_data)))\n",
        "\n",
        "    return split_data(input_data, attention_data, label_data, max_len=512)\n",
        "\n"
      ],
      "metadata": {
        "id": "KXzmOrLCIWaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_loader(run_dir):\n",
        "    data_type = ['train', 'val', 'test']\n",
        "    data_split_type = ['X', 'A', 'Y']\n",
        "\n",
        "    split_list = []\n",
        "\n",
        "    for data_type_id in data_type:\n",
        "      for split_type in data_split_type:\n",
        "          with open('{}/{}_{}.pickle'.format(run_dir,data_type_id, split_type), 'rb') as input_file:\n",
        "            object_file = pickle.load(input_file)\n",
        "          split_list.append(object_file)\n",
        "    X_train, A_train, Y_train, X_val, A_val, Y_val, X_test, A_test, Y_test = split_list\n",
        "\n",
        "    return (X_train, A_train, Y_train), (X_val, A_val, Y_val), (X_test, A_test, Y_test)"
      ],
      "metadata": {
        "id": "7OJ7SUtTOqf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "IHeJQVfVb8c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, epochs=5, batch_size=16, learning_rate=2e-5, validate_per=500,\n",
        "          dir_name=\"temp\", run_descrption=None):\n",
        "    \"\"\"\n",
        "    Main fine-tuning training loop for the provided model\n",
        "\n",
        "    :param model: model loaded with predefined weights\n",
        "    :param train_data: tuple of X_train, A_train, Y_train (X = inputs, A = attention, Y = target)\n",
        "    :param val_data: tuple X_val, A_val, Y_val\n",
        "    :param epochs: number of epochs for training\n",
        "    :param batch_size: batch size (see note below about batch_hack)\n",
        "    :param learning_rate: optimizer learning rate\n",
        "    :param validate_per: number of weight updates before validation occurs\n",
        "                            (notes: - if batch_size = 32, and validate_per = 32, validation will occur every batch\n",
        "                                    - this is wrt the start of each epoch\n",
        "                                    - validation will always occour at the start of each epoch (step 0))\n",
        "    :param run_name: name used to saving checkpoints and log files within codebert_finetune_runs\n",
        "    :param run_descrption: string that is saved to info.txt describing the run\n",
        "\n",
        "\n",
        "    :return: None (models are saved in checkpoints along with log data)\n",
        "    \"\"\"\n",
        "\n",
        "    # Saving run description.txt\n",
        "    if run_descrption is not None:\n",
        "        with open(\"{}/info.txt\".format(dir_name), \"w\") as f:\n",
        "            f.write(run_descrption)\n",
        "\n",
        "    # Unpacking data\n",
        "    X_train, A_train, Y_train = train_data\n",
        "    X_val, A_val, Y_val = val_data\n",
        "\n",
        "\n",
        "    batch_hack = batch_size  # See note below regarding limited GPU memory\n",
        "\n",
        "    # Initializing arrays for tracking loss\n",
        "    train_loss_hist = []\n",
        "    val_loss_hist = []\n",
        "    train_pred_hist = []\n",
        "    # Counter to track batches (see note below related to GPU memory)\n",
        "    batch_count = 0\n",
        "    # validate_per_batch = int(validate_per/batch_hack)\n",
        "\n",
        "    # Moving model to GPU if configured\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    validate_per = int(validate_per/batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Generating random index for manual shuffling of data each epoch as note using DataLoaders\n",
        "        permutation = torch.randperm(X_train.shape[0])\n",
        "\n",
        "        # Note here that only a single element is loaded at each iteration (batch size = 1) due to GPU memory constraint\n",
        "        for batch_id, i in enumerate(range(0, X_train.shape[0], batch_hack)):\n",
        "\n",
        "            # Loading batch and moving to device\n",
        "            indices = permutation[i:i + batch_hack]\n",
        "            batch_X, batch_Y, batch_A = X_train[indices].to(device), Y_train[indices].to(device), A_train[indices].to(device)\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X,labels=batch_Y, attention_mask=batch_A)\n",
        "            #loss = criterion(loss_clsf.float(), batch_Y_one_hot.float())\n",
        "            loss = outputs.loss\n",
        "            #print(loss)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_clsf = nn.Softmax(dim=1)(outputs.logits)\n",
        "            acc = np.average(torch.eq(batch_Y.cpu(), loss_clsf.argmax(axis=1).cpu()))\n",
        "            #rint(correct)\n",
        "\n",
        "            # Tracking loss\n",
        "            train_loss_hist.append(float(loss.item()))\n",
        "            train_pred_hist.append(acc)\n",
        "\n",
        "            # Training output\n",
        "            train_output = \"Epoch:{} Step:{} Training_loss:{:.6f}, Acc_avg:{:.2f}%\".format(epoch, i, loss.item(), np.sum(100*train_pred_hist[-50:])/min(len(train_pred_hist), 50))\n",
        "            print(train_output+\" Training_loss_avg:{:.6f}\".format(np.average(train_loss_hist[-50:])))\n",
        "            with open(\"{}/train_loss.txt\".format(dir_name), \"a+\") as f:\n",
        "                f.write(train_output+\"\\n\")\n",
        "\n",
        "            # Validation\n",
        "            if batch_id % validate_per == 0:\n",
        "                val_loss_total = 0\n",
        "                model.eval()\n",
        "                print(\"Validating:\")\n",
        "                val_acc = []\n",
        "                for val_badtch_id, j in tqdm(enumerate(range(0, X_val.shape[0], batch_hack))):\n",
        "                    # Loading singular validation data (overwrites train data as can only load 1 intp GPU)\n",
        "                    batch_X, batch_Y, batch_A = X_val[j:j+batch_hack].to(device), Y_val[j:j+batch_hack].to(device), A_val[j:j+batch_hack].to(device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        val_outputs = model(batch_X, labels=batch_Y, attention_mask=batch_A)\n",
        "                    val_loss_total += float(val_outputs['loss'].item())\n",
        "\n",
        "                    \n",
        "                    val_clsf = nn.Softmax(dim=1)(val_outputs.logits)\n",
        "                    val_acc.append(np.average(torch.eq(batch_Y.cpu(), val_clsf.argmax(axis=1).cpu())))\n",
        "\n",
        "                    del batch_X\n",
        "                    del batch_Y\n",
        "\n",
        "                # Adding average loss to tracker\n",
        "                val_average = val_loss_total / (val_badtch_id+1)\n",
        "                val_loss_hist.append(val_average)\n",
        "\n",
        "                # Validation output and logging\n",
        "                val_output = \"Epoch:{} Step:{} Val_loss:{:.6f}, Val_Acc_avg:{:.2f}%\".format(epoch, i, val_average, np.sum(100*val_acc[-50:])/min(len(val_acc), 50))\n",
        "                print(val_output)\n",
        "                with open(\"{}/val_los.txt\".format(dir_name), \"a+\") as f:\n",
        "                    f.write(val_output+\"\\n\")\n",
        "\n",
        "        # End of epoch checkpoint\n",
        "        model.save_pretrained(\"{}/epoch_{}\".format(dir_name, epoch + 1))\n"
      ],
      "metadata": {
        "id": "LxCu-823IX4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing code length, token lengths, and sample tokens (part c and d)\n"
      ],
      "metadata": {
        "id": "kaVhYtHKb-bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE that this is done on a per character basis within the function!\n",
        "\n",
        "code_df = preprocess_data(file_loc='code_dataset.jsonl')\n",
        "func_len = list(code_df['func'].str.len())\n",
        "\n",
        "print(func_len[0])\n",
        "func_len.sort()\n",
        "\n",
        "plt.hist(func_len, bins=400, range=(0,16000))\n",
        "plt.xlabel(\"Function length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(func_len, bins=100, range=(0,4000))\n",
        "plt.xlabel(\"Function length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "ratio_1000 = sum(i < 1000 for i in func_len)/len(func_len)\n",
        "print(\"\\n{}% of functions are of shorter than 1000 characters\".format(100*ratio_1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "pnm7-wFbZQdK",
        "outputId": "706c5b8e-3096-4c30-94c2-1d8b9daec44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insecure code counts: 3729, Total code counts: 8000, Proportion 0.466125\n",
            "2221\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWpklEQVR4nO3de5RlZXnn8e9PJeBtIkinp+WSVgd14cRgp0UnaoJhEhUT0TFxcE2UMUw6K+KMTsyMeBnFZDGLmHiJSQYHIxGMN7wQGTUxgKKTySg0yN0AHWhH2pbGSwSjQcFn/thvbQ5tVfWp7trnnKr6ftY6q9797n32fmpX1Xnqfd+9352qQpIkgPtMOwBJ0uwwKUiSeiYFSVLPpCBJ6pkUJEm9+007gH1x8MEH18aNG6cdhiStKJdddtnXqmrdfOtWdFLYuHEjW7dunXYYkrSiJPnSQuvsPpIk9UwKkqSeSUGS1DMpSJJ6JgVJUs+kIEnqmRQkST2TgiSpZ1KQJPVW9B3N07TxlI/35e2nP2uKkUjS8rGlIEnqmRQkST2TgiSpZ1KQJPVMCpKknklBktQzKUiSeiYFSVLPpCBJ6pkUJEk9p7lYZk5/IWkls6UgSeqZFCRJPZOCJKk3WFJIcliSTye5Lsm1SV7W6k9NsiPJFe113Mh7XpVkW5Lrkzx9qNgkSfMbcqD5LuAVVXV5kgcDlyW5oK17S1X9wejGSY4ETgAeCzwMuDDJo6rq7gFjXJLRQWRJWo0GaylU1c6quryV7wC+CByyyFuOB95fVXdW1c3ANuDooeKTJP2wiYwpJNkIPB74fKt6aZKrkpyV5MBWdwjw5ZG33cLiSUSStMwGTwpJHgR8GHh5Vd0OnAE8EjgK2Am8aYn725Jka5Ktt91227LHK0lr2aBJIcl+dAnhPVX1EYCqurWq7q6qHwDv4J4uoh3AYSNvP7TV3UtVnVlVm6tq87p164YMX5LWnCGvPgrwTuCLVfXmkfoNI5s9F7imlc8HTkiyf5KHA0cAlwwVnyTphw159dGTgRcCVye5otW9GnhBkqOAArYDvwFQVdcmORe4ju7KpZNn6cojSVoLBksKVfU3QOZZ9YlF3nMacNpQMU2a8yBJWmm8o1mS1DMpSJJ6JgVJUs+kIEnqmRQkST2TgiSp5+M4l4Gzp0paLWwpSJJ6JgVJUs+kIEnqmRQkST2TgiSpZ1KQJPVMCpKknklBktQzKUiSeiYFSVLPaS4mxKewSVoJTAp74LxGktYSu48kST2TgiSpZ1KQJPVMCpKknklBktQzKUiSeiYFSVLPpCBJ6pkUJEk9k4IkqTdYUkhyWJJPJ7kuybVJXtbqD0pyQZIb29cDW32SvC3JtiRXJdk0VGySpPkN2VK4C3hFVR0JPAk4OcmRwCnARVV1BHBRWwZ4JnBEe20BzhgwNknSPAabEK+qdgI7W/mOJF8EDgGOB45pm50NXAy8stWfU1UFfC7JQ5JsaPtZVZwxVdKsmsiYQpKNwOOBzwPrRz7ovwqsb+VDgC+PvO2WVrf7vrYk2Zpk62233TZYzJK0Fg2eFJI8CPgw8PKqun10XWsV1FL2V1VnVtXmqtq8bt26ZYxUkjRoUkiyH11CeE9VfaRV35pkQ1u/AdjV6ncAh428/dBWJ0makCGvPgrwTuCLVfXmkVXnAye28onAR0fqX9SuQnoS8K3VOJ4gSbNsyCevPRl4IXB1kita3auB04Fzk5wEfAl4flv3CeA4YBvwHeDFA8YmSZrHkFcf/Q2QBVYfO8/2BZw8VDySpD3zjmZJUs+kIEnqmRQkST2TgiSpZ1KQJPWGvCRV+8D5kSRNgy0FSVLPpCBJ6tl9NI/RrptZYFeSpEmxpSBJ6pkUJEk9k4IkqWdSkCT1xkoKSX5i6EAkSdM3bkvhfyS5JMlLkvzooBFJkqZmrKRQVU8F/h3d4zIvS/LeJD8/aGSSpIkbe0yhqm4EXgu8EvhZ4G1J/i7JvxkqOEnSZI1181qSx9E9HvNZwAXAL1XV5UkeBvxf4CPDhbi6eWOapFky7h3NfwT8KfDqqvruXGVVfSXJaweJTJI0ceMmhWcB362quwGS3Ac4oKq+U1XvHiw6SdJEjTumcCFw/5HlB7Q6SdIqMm5SOKCqvj230MoPGCYkSdK0jJsU/jHJprmFJD8FfHeR7SVJK9C4YwovBz6Y5CtAgH8O/NvBolqjZm3Kbklrz1hJoaouTfIY4NGt6vqq+v5wYUmSpmEpD9l5ArCxvWdTEqrqnEGikiRNxbg3r70beCRwBXB3qy7ApCBJq8i4LYXNwJFVVUMGoz3zDmhJQxr36qNr6AaXJUmr2LhJ4WDguiSfTHL+3GuxNyQ5K8muJNeM1J2aZEeSK9rruJF1r0qyLcn1SZ6+d9+OJGlfjNt9dOpe7PtdwB/zw+MOb6mqPxitSHIkcALwWOBhwIVJHjU3rYYkaTLGfZ7CZ4DtwH6tfClw+R7e81ngG2PGcTzw/qq6s6puBrYBR4/5XknSMhn36qNfB7YAB9FdhXQI8Hbg2L045kuTvAjYCryiqr7Z9ve5kW1uaXXzxbKlxcLhhx++F4dfPRx0lrTcxh1TOBl4MnA79A/c+bG9ON4ZdEnlKGAn8Kal7qCqzqyqzVW1ed26dXsRgiRpIeMmhTur6ntzC0nuR3efwpJU1a1VdXdV/QB4B/d0Ee2ge9TnnENbnSRpgsYdaP5MklcD92/PZn4J8L+WerAkG6pqZ1t8Lt2lrgDnA+9N8ma6geYjgEuWun/9MLuYJC3FuEnhFOAk4GrgN4BP0D2JbUFJ3gccAxyc5Bbg9cAxSY6ia2Vsb/uiqq5Nci5wHXAXcLJXHknS5I07Id5cd887xt1xVb1gnup3LrL9acBp4+5fkrT8xr366GbmGUOoqkcse0SSpKlZytxHcw4AfoXu8lTNCJ/FIGk5jHvz2tdHXjuq6q2Ao5aStMqM2320aWTxPnQth6U8i0GStAKM+8E+epPZXXRXDj1/2aORJE3VuFcfPW3oQDQ871mQtCfjdh/91mLrq+rNyxOOJGmalnL10RPo7jwG+CW6O45vHCIoSdJ0jJsUDgU2VdUd0D0sB/h4Vf3qUIFJkiZv3Anx1gPfG1n+XquTJK0i47YUzgEuSXJeW34OcPYwIUmSpmXcq49OS/KXwFNb1Yur6gvDhSVJmoal3ID2AOD2qvqzJOuSPLw9OlMrkJenSprPWGMKSV4PvBJ4VavaD/jzoYKSJE3HuAPNzwWeDfwjQFV9BXjwUEFJkqZj3KTwvaoq2vTZSR44XEiSpGkZNymcm+R/Ag9J8uvAhSzhgTuSpJVhjwPNSQJ8AHgMcDvwaOB1VXXBwLFJkiZsj0mhqirJJ6rqJwATgSStYuNeknp5kidU1aWDRqOZ5mWs0uo3blJ4IvCrSbbTXYEUukbE44YKTJI0eYsmhSSHV9X/A54+oXg0ZbYGpLVtTy2Fv6CbHfVLST5cVc+bRFCSpOnY0yWpGSk/YshAJEnTt6ekUAuUJUmr0J66j34yye10LYb7tzLcM9D8zwaNTpI0UYsmhaq676QC0ewZHXSWtDaMO82FJGkNGCwpJDkrya4k14zUHZTkgiQ3tq8HtvokeVuSbUmuSrJpqLgkSQsbsqXwLuAZu9WdAlxUVUcAF7VlgGcCR7TXFuCMAeOSJC1gsKRQVZ8FvrFb9fHc82zns+me9TxXf051Pkc3G+uGoWKTJM1vKY/jXA7rq2pnK38VWN/KhwBfHtnulla3k90k2ULXmuDwww8fLtI1xAFlSXMmnRR6bfbVJd/7UFVnAmcCbN682XsnZoBTY0irx6STwq1JNlTVztY9tKvV7wAOG9nu0FanFcxkIa08k74k9XzgxFY+EfjoSP2L2lVITwK+NdLNJEmakMFaCkneBxwDHJzkFuD1wOl0j/Y8CfgS8Py2+SeA44BtwHeAFw8Vl5bHUschbDVIK8NgSaGqXrDAqmPn2baAk4eKRZPjoLW0snlHsySpZ1KQJPVMCpKknklBktQzKUiSeiYFSVLPpCBJ6pkUJEm9qU2IJy3GO6Cl6bClIEnq2VLQxNkKkGaXLQVJUs+kIEnq2X2kqbIrSZotthQkST1bCpp5tiakybGlIEnq2VLQzPCpbdL02VKQJPVsKWjFWqhl4biDtPdMClpR7GKShmX3kSSpZ0sB//tczbycVVoak4JWHZO8tPfsPpIk9UwKkqSeSUGS1DMpSJJ6DjRLI7xaSWvdVJJCku3AHcDdwF1VtTnJQcAHgI3AduD5VfXNacSn1ckPfGnPptl99LSqOqqqNrflU4CLquoI4KK2LEmaoFnqPjoeOKaVzwYuBl45rWC0uo1zL4MtC61F02opFPDXSS5LsqXVra+qna38VWD9fG9MsiXJ1iRbb7vttknEKklrxrRaCk+pqh1Jfgy4IMnfja6sqkpS872xqs4EzgTYvHnzvNtIkvbOVFoKVbWjfd0FnAccDdyaZANA+7prGrFJ0lo28ZZCkgcC96mqO1r5F4DfAc4HTgROb18/OunYpFnheIamZRrdR+uB85LMHf+9VfVXSS4Fzk1yEvAl4PlTiE2alx/SWismnhSq6ibgJ+ep/zpw7KTjkZZq9yuXFkoSJhKtRLN0Saq0JpgsNMtMCtIUmSA0a5wQT5LUs6Ug7SOf9KbVxKQgTYCJQyuFSUGacQuNOyx1PGLo7bU6mBSkGWFrQrPAgWZJUs+WgqQ9sitp7TApSGuQH/JaiElBWsUcp9BSmRSkVWC5/vPflyTinFCrg0lBWmUm2TqwJbL6mBSkFWSID+HV8MFu62P5eEmqJKlnS0HS1IzzH/5KbAWsxJjnmBQkDWIlfzCuZSYFSUuyN2MQyzVusVwti3Hmk1rIak9wJgVJM8GWxWwwKUjSlMxiIjQpSFq1ZvFDdyGzEqtJQdKKtNRxioW235f9zHqi2RsmBUkzZ6XcUDdUnNNMPCYFSRrQviaOSScIk4IkrRCTSBBOcyFJ6pkUJEk9k4IkqWdSkCT1Zi4pJHlGkuuTbEtyyrTjkaS1ZKauPkpyX+BPgJ8HbgEuTXJ+VV233MdaKddBS9IkzVpL4WhgW1XdVFXfA94PHD/lmCRpzZiplgJwCPDlkeVbgCeObpBkC7ClLX47yfV7eayDga/t5XuHNKtxwezGZlxLY1xLM5Nx5ff2Ka4fX2jFrCWFPaqqM4Ez93U/SbZW1eZlCGlZzWpcMLuxGdfSGNfSrLW4Zq37aAdw2Mjyoa1OkjQBs5YULgWOSPLwJD8CnACcP+WYJGnNmKnuo6q6K8lLgU8C9wXOqqprBzrcPndBDWRW44LZjc24lsa4lmZNxZWqGmK/kqQVaNa6jyRJU2RSkCT11mRSmPZUGkm2J7k6yRVJtra6g5JckOTG9vXAVp8kb2uxXpVk0zLGcVaSXUmuGalbchxJTmzb35jkxIHiOjXJjnbOrkhy3Mi6V7W4rk/y9JH6Zf05JzksyaeTXJfk2iQva/VTPWeLxDXVc5bkgCSXJLmyxfWGVv/wJJ9vx/hAu6iEJPu35W1t/cY9xbvMcb0ryc0j5+uoVj+x3/22z/sm+UKSj7XlyZ6vqlpTL7oB7L8HHgH8CHAlcOSEY9gOHLxb3RuBU1r5FOD3Wvk44C+BAE8CPr+McfwMsAm4Zm/jAA4CbmpfD2zlAweI61Tgt+fZ9sj2M9wfeHj72d53iJ8zsAHY1MoPBm5ox5/qOVskrqmes/Z9P6iV9wM+387DucAJrf7twG+28kuAt7fyCcAHFot3gLjeBfzyPNtP7He/7fe3gPcCH2vLEz1fa7GlMKtTaRwPnN3KZwPPGak/pzqfAx6SZMNyHLCqPgt8Yx/jeDpwQVV9o6q+CVwAPGOAuBZyPPD+qrqzqm4GttH9jJf951xVO6vq8la+A/gi3V34Uz1ni8S1kImcs/Z9f7st7tdeBfwc8KFWv/v5mjuPHwKOTZJF4l3uuBYysd/9JIcCzwL+tC2HCZ+vtZgU5ptKY7E/oCEU8NdJLks3bQfA+qra2cpfBda38qTjXWock4zvpa35ftZcF8204mpN9cfT/Zc5M+dst7hgyuesdYVcAeyi+9D8e+AfququeY7RH7+t/xbw0EnEVVVz5+u0dr7ekmT/3ePa7fhD/BzfCvxX4Adt+aFM+HytxaQwC55SVZuAZwInJ/mZ0ZXVtQGnfq3wrMTRnAE8EjgK2Am8aVqBJHkQ8GHg5VV1++i6aZ6zeeKa+jmrqrur6ii62QmOBh4z6Rjms3tcSf4l8Cq6+J5A1yX0yknGlOQXgV1Vddkkj7u7tZgUpj6VRlXtaF93AefR/bHcOtct1L7uaptPOt6lxjGR+Krq1vaH/APgHdzTHJ5oXEn2o/vgfU9VfaRVT/2czRfXrJyzFss/AJ8G/hVd98vcjbOjx+iP39b/KPD1CcX1jNYNV1V1J/BnTP58PRl4dpLtdF13Pwf8IZM+X/syILISX3R3cd9ENwAzN5j22Ake/4HAg0fKf0vXD/n73Huw8o2t/CzuPch1yTLHs5F7D+guKQ66/6huphtoO7CVDxogrg0j5f9M12cK8FjuPah2E92A6bL/nNv3fg7w1t3qp3rOFolrqucMWAc8pJXvD/xv4BeBD3LvgdOXtPLJ3Hvg9NzF4h0grg0j5/OtwOnT+N1v+z6GewaaJ3q+lu3DZSW96K4muIGuf/M1Ez72I9oP7Erg2rnj0/UFXgTcCFw498vVfhH/pMV6NbB5GWN5H123wvfp+h1P2ps4gF+jG8zaBrx4oLje3Y57Fd18WKMfeK9pcV0PPHOonzPwFLquoauAK9rruGmfs0Ximuo5Ax4HfKEd/xrgdSN/A5e07/2DwP6t/oC2vK2tf8Se4l3muD7Vztc1wJ9zzxVKE/vdH9nvMdyTFCZ6vpzmQpLUW4tjCpKkBZgUJEk9k4IkqWdSkCT1TAqSpJ5JQStekrtHZra8YnS2yGXY93OSHDmy/DtJ/vUy7PeYuVkwl9M88V6cZOYeOq/ZNVOP45T20nerm7JgCM8BPgZcB1BVrxvoOMvlXvFKS2VLQatSumdWHNzKm5Nc3MqntsnhLk5yU5L/NPKeF7XJ0K5M8u4kPw08G/j91gJ5ZJtz/5fb9se2ee+vbvvcf+TYb0hyeVu36Hw/SR7Y3n9J29/xrf7fJ/lIkr9q8/W/ceQ9JyW5ob3nHUn+eL542+a/0ra7IclTl+sca3WypaDV4P5txkuAm6vquXvY/jHA0+iePXB9kjOARwGvBX66qr6W5KCq+kaS8+nuLP0QQDczcfegFrr594+tqhuSnAP8Jt30CABfq6pNSV4C/DbwHxaJ5zXAp6rq15I8BLgkyYVt3VF0s57e2WL9I+Bu4L/RPXPiDro7ca+sqr9dIN77VdXR6R6y83pgn7u/tHrZUtBq8N2qOqq99pQQAD5e3VzzX6ObvG493eRjH2x1VNWenufwaLoEdENbPpvu4UBz5ibLu4xuHqfF/AJwSktsF9NNX3B4W3dRVX2rqv6Jrkvox+kmavtMdfP4f59uqoPFLCUWrXG2FLRa3cU9//QcsNu6O0fKdzPM38HcMcbZf4DnVdX196pMnsjyxLqUWLTG2VLQarUd+KlWft4Y23+Kru/9odA9d7nV30HXzbS764GNSf5FW34h8Jm9jPWTwH9sT80iyeP3sP2lwM8mObBNmTz6/S0UrzQWk4JWqzcAf5hkK91/yIuqqmuB04DPJLkSeHNb9X7gv7QB4EeObP9PwIuBDya5mu5JWW/fy1h/l+6RkFclubYtLxbrDuC/082M+X/oEuC3FotXGpezpEorUJIHVdW3W0vhPOCsqjpv2nFp5bOlIK1Mp7aB6WvoHu7yF1OOR6uELQVJUs+WgiSpZ1KQJPVMCpKknklBktQzKUiSev8ffL+tAHuXmXcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "52.125% of functions are of shorter than 1000 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'codebert-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "inputs = tokenizer(code_df['func'].tolist(), truncation=False)\n",
        "input_data = inputs['input_ids']\n",
        "\n",
        "data_len = []\n",
        "for data in input_data:\n",
        "  data_len.append(len(data))\n",
        "\n",
        "data_len.sort()\n",
        "plt.hist(data_len, bins=100, range=(0,2000))\n",
        "plt.xlabel(\"Function length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "ratio_512 = sum(i < 512 for i in data_len)/len(data_len)\n",
        "print(\"{:.4f}% of tokenized functions are of shorter than 512 tokens\".format(100*ratio_512))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "HR8GsEl_ev6t",
        "outputId": "73588309-f045-4b66-ea29-60318cab8601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52.012499999999996% of tokenized functions are of shorter than 512 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'codebert-base'\n",
        "code_df = preprocess_data(file_loc='code_dataset.jsonl')\n",
        "train_data, val_data, test_data = tokenize(code_df, model_name=model_name)"
      ],
      "metadata": {
        "id": "M2frVptdjzkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_attention, _ = train_data"
      ],
      "metadata": {
        "id": "a2CKzyoXqA1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(\"Sample: {}\".format(i+1))\n",
        "  print(\"Input Data\")\n",
        "  print(train_input[i])\n",
        "  print(\"Attention Mask\")\n",
        "  print(train_attention[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP_pZaZzp-gG",
        "outputId": "8963c0d4-fe70-42d3-a51b-731bdb4c55a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 1\n",
            "Input Data\n",
            "tensor([    0, 47908, 36704,  1020,  1215, 48702,  1215,  3654,  4591,  1640,\n",
            "          846,  9211,   100,  7111,  3623,  2463,  1009,   705, 20068,     6,\n",
            "         6979,   295,    43, 50118, 50118, 45152, 50140,  1437,  1437,  1437,\n",
            "          114,    36,   282, 28696,   468, 40835,  6454,  1215,  4794,   100,\n",
            "         1215,  1864,  9162,  9162,  1215, 30187, 48200,   748, 20068, 46613,\n",
            "          705,  1343, 10975,   282,  8174,   705,  4506,     4, 45091,    43,\n",
            "        25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 13946,\n",
            "         1215, 42660,  1020,  1215, 48702,  1215,  3654,  4591,  1640,   705,\n",
            "        20068,     6,   295,     6,   359,   705, 20068, 46613,   705,  1343,\n",
            "        10975,   282, 48601, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,   748, 20068, 46613,   705,  1343, 10975,   282,  8174, 26628,\n",
            "         1215, 46234,  1640,   705, 20068,     6,   359,   705, 20068, 46613,\n",
            "          705,  1343, 10975,   282, 48601, 50140,  1437,  1437,  1437, 35524,\n",
            "        50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 2\n",
            "Input Data\n",
            "tensor([    0, 42653, 13842,   490,   338,  4473,  1215, 19017,  1215, 49345,\n",
            "         1215, 45291,  1640, 47908,  1009,  1517, 35485,     6,  6979, 10209,\n",
            "         1343,     6,  6979,   672,    43, 50118, 50118, 45152, 50140,  1437,\n",
            "         1437,  1437,  2117,   500,  1729,  3376, 16821,  1009, 49345,  5457,\n",
            "           36, 25266,   500,  1729,  3376, 16821, 49521,  1517, 35485,   131,\n",
            "        50140,  1437,  1437,  1437, 21032, 13360,  1009, 11365,  5457, 21032,\n",
            "         1640, 49345,  4397, 50140,  1437,  1437,  1437,  6979,   939,   131,\n",
            "        50140,  1437,  1437,  1437, 49315,  2881,  1215,    90, 10209,  1343,\n",
            "         1215,  5881,  5457,   112, 48188, 10209,  1343,   131, 50140, 50140,\n",
            "         1437,  1437,  1437,   114,    36,   853,  1343,  8061,  1105, 45056,\n",
            "        10209,  1343, 28696,   321,    43, 25522, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,   671,   131, 50140,  1437,  1437,  1437,\n",
            "        35524, 50140, 50140,  1437,  1437,  1437,   114,    36,  4483,    43,\n",
            "        25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 49357,\n",
            "        46613, 41124,     4,   642,  2857,   338,  1721,  5214, 10209,  1343,\n",
            "         1215,  5881,   131, 50140,  1437,  1437,  1437, 35524,  1493, 25522,\n",
            "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 49357, 46613,\n",
            "        41124,     4,   642,  2857,   338,   359,  5214, 14434,   853,  1343,\n",
            "         1215,  5881,   131, 50140,  1437,  1437,  1437, 35524, 50140, 50140,\n",
            "         1437,  1437,  1437,    13,    36,   118,  5457,   321,   131,   939,\n",
            "        28696,  2107,   131,   939, 49346, 25522, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,   114, 41006, 49345, 46613, 41124,     4,\n",
            "          642,  2857,   338, 48200,    36,   134, 48188,   939, 35122, 48200,\n",
            "           36, 49345, 46613, 41124,     4, 19017, 35685, 48200,    36,   134,\n",
            "        48188,   939, 47619, 25522, 50140,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437, 49357,  1215,  8007, 14709,\n",
            "         1640, 11365,     6, 21032,  1215, 46170,   500,  9673,   565,  1215,\n",
            "          725, 11250,  4397, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437, 35524,  1493, 25522, 50140,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437, 49357,  1215, 45703,  1215,\n",
            "         8007, 14709,  1640, 11365,     6, 21032,  1215, 46170,   500,  9673,\n",
            "          565,  1215,   725, 11250,  4397, 50140,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437, 49357, 46613, 41124,\n",
            "            4,   642,  2857,   338,   359,  5214, 14434,  1640,   134, 48188,\n",
            "          939,  4397, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "        35524, 50140,  1437,  1437,  1437, 35524, 50118, 50118, 24303, 50118,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 3\n",
            "Input Data\n",
            "tensor([    0, 47908, 48400,  1215, 20557,   877,  1215,  9996,  8231,  1215,\n",
            "        42996,  1215,  5471, 16254,  1640,   725, 29137, 48522,  1009,   298,\n",
            "           43, 25522, 50140,  1437,  1437,  1437,   256, 41191, 45780, 48522,\n",
            "         1009, 10759,   579,  5457,   359,   298, 46613,    29,   131, 50140,\n",
            "         1437,  1437,  1437, 18088,  1640,   298, 46613,  3479,  1215, 13043,\n",
            "         1215, 11432,  2055,  1368, 46613, 20263,  1215, 13043,  1215, 11432,\n",
            "        49230,  1368, 46613,    29,  3275,     4, 13043,  1215, 26061,  1215,\n",
            "        11432,  4397, 50140, 50140,  1437,  1437,  1437,  1368, 46613,  5471,\n",
            "          876,  1215, 18480,  5214,   321,   131, 50140,  1437,  1437,  1437,\n",
            "          114,  1640,   298, 46613, 20263,  1215, 13043,  1215, 11432, 48200,\n",
            "         1368, 46613,  3479,  1215, 13043,  1215, 11432,  2055,  1368, 46613,\n",
            "        20263,  1215, 13043,  1215, 11432, 45994,  1368, 46613,    29,  3275,\n",
            "            4, 13043,  1215, 26061,  1215, 11432, 48200, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 27785,\n",
            "         1640, 19095,  1215,   510, 12894, 12435, 48200, 27785,    29, 46613,\n",
            "         9502,  1215,  1399, 48200,   579, 46613, 28311,  1215, 37587,  1215,\n",
            "        43880, 46613, 45927, 35122, 25522, 50140,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1368, 46613,  5471,   876, 10975,   288,  8174,\n",
            "         1517, 20414,  5214, 24537,  6335,  1215, 10237, 12154,   176,  4154,\n",
            "         3048,  1691,   131, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1368, 46613,  5471,   876, 10975,   288,  8174, 20263,  1215,\n",
            "        19017,  1215, 42666,  5214,  1368, 46613, 20263,  1215, 13043, 10975,\n",
            "         1368, 46613, 20263,  1215, 13043,  1215, 11432,   111,   112, 27779,\n",
            "        46613, 26061,  1215, 42666,   131, 50140,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1368, 46613,  5471,   876,  1215, 18480,  5214,\n",
            "          112,   131, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "          114,    36, 19095,  1215,   510, 12894, 12435,    43, 25522, 50140,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1368, 46613,  5471,   876, 10975,   288,  8174, 20263,  1215,\n",
            "        19017,  1215, 42666,  1009,  5214,   132,   131, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1368,\n",
            "        46613,  5471,   876, 10975,   134,  8174,  1517, 20414,  5214, 24537,\n",
            "         6335,  1215, 10237, 12154,   176,  4154,  3048,  1691,   131, 50140,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1368, 46613,  5471,   876, 10975,   134,  8174, 20263,  1215,\n",
            "        19017,  1215, 42666,  5214,  1368, 46613,  5471,   876, 10975,   288,\n",
            "         8174, 20263,  1215, 19017,  1215, 42666,  2055,   112,   131, 50140,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1368, 46613,  5471,   876,  1215, 18480,  5214,   132,   131,\n",
            "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 35524, 50140,\n",
            "         1437,  1437,  1437, 35524, 50118, 50118, 24303, 50118,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 4\n",
            "Input Data\n",
            "tensor([    0, 42653, 49460,  8702,  1215, 40412,  1215, 15954,  1640,   448,\n",
            "        33836, 13360,  1009,  4339,     6, 37943, 13540, 14385,   642,    43,\n",
            "        50118, 50118, 45152, 50140,  1437,  1437,  1437,   114, 48209,   119,\n",
            "        38476,  1215, 49237,  1215, 15954, 49763,  4339, 46613, 46669, 20413,\n",
            "            6, 22379,   642, 35122, 25522, 50140,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,   671,  3950,   131, 50140,  1437,  1437,  1437,\n",
            "        35524, 50140, 50140,  1437,  1437,  1437,   671,  1528,   131, 50118,\n",
            "        50118, 24303, 50118,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 5\n",
            "Input Data\n",
            "tensor([    0, 47908,   449, 38486,  1215,    29, 27873,  1215,  1020,  1215,\n",
            "         8007, 14709,  1640,   104, 27873, 47378,  1009, 49345,     6, 49315,\n",
            "         1549,  1215,    90,  2849, 27681,  1215,   808,     6, 50140,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437, 49315,  1549,  1215,    90,  2849,\n",
            "        27681,  1215, 37643,     6, 49315,  2881,  1215,    90, 46155,  1215,\n",
            "         2544,  1215,   642,  4526,     6, 50140,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437, 49315,  2881,  1215,    90, 46155,  1215,  2544,  1215,\n",
            "        14742,    43, 50118, 50118, 45152, 50140,  1437,  1437,  1437, 49315,\n",
            "         2881,  1215,    90,  1907,   131, 50140, 50140,  1437,  1437,  1437,\n",
            "          114,    36,  1020,  1215,  2544,  1215, 14742,   359, 38266,  1215,\n",
            "        17831,  1215,   771, 11200,  1215, 15238,    43, 25522, 50140,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1907,  5457,   229, 20954,\n",
            "         1215,   104, 27873,  1215, 17831,  1215,  6454,  1640,   134,     6,\n",
            "          321,     6,   321,     6,   321,  4397, 50140,  1437,  1437,  1437,\n",
            "        35524,  1493, 25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1907,  5457, 41006, 10936, 27681,  1215,   808,   359,   321,\n",
            "        49780,   612,    43, 48188,   706,    43,  1721, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 41006,\n",
            "        10936, 27681,  1215,   808,   359,   321,  1178,   151,  2466,    43,\n",
            "        48188,   820,    43,  1721,    36, 10936, 27681,  1215, 37643, 48188,\n",
            "          545,  4397, 50140,  1437,  1437,  1437, 35524, 50140,  1437,  1437,\n",
            "         1437,   449, 38486,  1215,    29, 27873,  1215,  8007, 14709,  1215,\n",
            "        37559,  1640, 49345,     6,  1907,     6, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 41006, 47157,\n",
            "         2881,  1215,    90,    43, 10936, 27681,  1215,   808, 48188,   545,\n",
            "           43,  1721,  2849, 27681,  1215, 37643,     6, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 41006,\n",
            "        47157,  4027,  1215,    90,    43,  1020,  1215,  2544,  1215,   642,\n",
            "         4526, 48188,  2107,    43,  1721, 46155,  1215,  2544,  1215, 14742,\n",
            "            6,   112,  4397, 50118, 50118, 24303, 50118,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 6\n",
            "Input Data\n",
            "tensor([    0, 42653, 13842,  2850, 11000,  1215, 29631,  1215, 16604,  1640,\n",
            "         3632,   104,  2688,  6812,  9064,  1343,  1009,   338,    43, 50118,\n",
            "        50118, 45152, 50140,  1437,  1437,  1437,  4998,   104,  2688,  6812,\n",
            "        13360,  1009,    29,  5457, 14010,  1215,   791,  4794, 10388,  1640,\n",
            "         3632,   104,  2688,  6812, 13360,     6,  2231, 20068,     6,   910,\n",
            "        46613, 47278,     4, 20068,  4397, 50140,  1437,  1437,  1437, 49315,\n",
            "         2881,  1215,    90,   295,   131, 50140, 50140,  1437,  1437,  1437,\n",
            "        48565,   440,   414,  2937,   189,   416,    28,    11,  2017, 48404,\n",
            "        50140,  1437,  1437,  1437, 18088,  1640,   338, 46613, 47278,     4,\n",
            "         1439,  1975,   428, 45994, 48955,  4397, 50140, 50140,  1437,  1437,\n",
            "         1437,   295,  5457,   910, 46613, 32822,     4, 32822,  1215,  8476,\n",
            "         1589, 29600,   131, 50140,  1437,  1437,  1437,   114,    36,   282,\n",
            "           43, 25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         2231,   991,   257,  1215,   118,  7067,   438,  1215, 25153,  1215,\n",
            "        43166, 49763,   338, 46613,  1343, 32822,     6,   359,   338, 46613,\n",
            "        32822,     6,   112,  4397, 50140,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,   910, 46613, 47278,     4,  1439,  1975,   428,  5457,\n",
            "          741, 10232,   705,  1215,   102,  1020,  1215, 29631,   705,  1640,\n",
            "           29, 46613,  4311,     6,   910, 46613, 18658,     6,   359,   338,\n",
            "        46613,  1343, 32822,     6,   295,     6, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  2850, 11000,  1215, 29631,  1215, 27527,     6,   910,  4397,\n",
            "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   114,    36,\n",
            "          338, 46613, 47278,     4,  1439,  1975,   428, 45994, 48955,    43,\n",
            "        25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  2850, 11000,  1215, 29631,  1215, 27527,  1640,\n",
            "          338,     6,   111,   717,  6454,  4397, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437, 35524, 50140,  1437,  1437,  1437, 35524,\n",
            "         1493, 25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "        48565,  9318,  5361,  5687,  6108,     7, 23366,   414,    31,  1482,\n",
            "            4,  1437, 48404, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  2850, 11000,  1215, 29631,  1215, 27527,  1640,   338,     6,\n",
            "          321,  4397, 50140,  1437,  1437,  1437, 35524, 50118, 50118, 24303,\n",
            "        50118,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 7\n",
            "Input Data\n",
            "tensor([    0, 47908,   825,  1215, 12528,  1215,  2544,  1549,  1640, 27654,\n",
            "         7852,  1009,   705,     6,  6979,  1549,  1215,    90,  1009, 46134,\n",
            "            6, 10759, 16224,  1009, 13650,     6, 37943, 13540, 14385,   642,\n",
            "           43, 50118, 50118, 45152, 50140,  1437,  1437,  1437,  6979,  4027,\n",
            "         1215,    90,   923,   131, 50140,  1437,  1437,  1437,   114, 48209,\n",
            "        44223,  1215,   354,  1215,  8738,  1640, 14385,   642, 35122, 25522,\n",
            "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   114,    36,\n",
            "          705, 46613, 12528,  1215,  2544,  1549,    43, 25522, 50140,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "          748, 46613, 12528,  1215,  2544,  1549,  1640,   705,     6, 26907,\n",
            "            6,   766,     6, 22379,   642,  4397, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437, 35524,  1493, 25522, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   923,\n",
            "         5457,  1009, 46134,   131, 50140,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,   748, 46613, 12528,  1215,\n",
            "         2544,  1640,   705,     6,   359, 19434,     6,   766,     6, 22379,\n",
            "          642,  4397, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,   114,    36, 19434, 28696, 30497,  1549,\n",
            "         1215, 24765, 45056,   923,  8061, 30497,  1549,  1215, 30187,    43,\n",
            "        25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  5849,  1215,  8738,\n",
            "         1640, 14385,   642,     6,  1209,  2076,   500,  1215,  2444, 39766,\n",
            "         2688,  1215, 14280,  2620,  3935,  2076,  1215, 49313,     6,   766,\n",
            "        17487,   766,  4832,    22, 15755,  1297, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,    22,  2544,  1549,  1215,    90, 45751, 50140,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,   671,   131, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 35524, 50140,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "         1437,  1009, 46134,  5457,   923,   131, 50140,  1437,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437, 35524, 50140,  1437,  1437,  1437, 35524,\n",
            "        50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 8\n",
            "Input Data\n",
            "tensor([    0, 42653,  6979,   748,   466, 17884,  1215,  5016,  1215,   462,\n",
            "        24344,  1640,   846,   466, 17884, 13360,  1009,    29,     6,   468,\n",
            "          466, 17884, 34222,  1009, 22609,     6, 29916, 12377,  1009,   620,\n",
            "        48939,    43, 50118, 50118, 45152, 50140,  1437,  1437,  1437,   671,\n",
            "          579, 46613,  5090, 46613,   462, 24344, 49763,    29, 46613, 49575,\n",
            "            6,  2718, 46613, 23687,     6,  1690, 48939,  4397, 50118, 50118,\n",
            "        24303, 50118,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 9\n",
            "Input Data\n",
            "tensor([    0,  2544,  4027,  1215,    90,  2231,   991,   257,  1215,  6460,\n",
            "         1215, 17036,  1640,  1864,  5330,   791, 45918,  1009, 17036,    43,\n",
            "        50118, 50118, 45152, 50140,  1437,  1437,  1437,  5405,  1640, 17036,\n",
            "        46613, 12528,    43, 25522, 50140,  1437,  1437,  1437,   403,  1209,\n",
            "         5330,   791,  1215,   565,  3755,  2076,  1215,  4629, 18119, 28417,\n",
            "           35, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   671,\n",
            "          120,  1215, 17036, 43048,  1589,   727, 14200,   131, 50140,  1437,\n",
            "         1437,  1437,  6814,    35, 50140,  1437,  1437,  1437,   403,  1209,\n",
            "         5330,   791,  1215,   565,  3755,  2076,  1215,   846, 40835, 17710,\n",
            "           35, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   114,\n",
            "           36,  3698,  1215,   636, 12825,    43, 25522, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   671,\n",
            "        49357,  1215,  6460,  1215,   636, 12825, 47006, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437, 35524,  1493, 25522, 50140,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
            "          671, 49357,  1215,  6460,  1215, 17036, 47006, 50140,  1437,  1437,\n",
            "         1437,  1437,  1437,  1437,  1437, 35524, 50140,  1437,  1437,  1437,\n",
            "        35524, 50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample: 10\n",
            "Input Data\n",
            "tensor([    0, 42653, 13842, 45511,  1215, 10519,   268,  1640, 47908,    43,\n",
            "        50118, 50118, 45152, 50140,  1437,  1437,  1437, 45511,  1215,  6460,\n",
            "         1215, 17036, 47006, 50140,  1437,  1437,  1437,   910,    90,  1215,\n",
            "        17036,  5457,  2231,   991,   257,  1215,  4651,  1215, 17036,  1640,\n",
            "         1864,  5330,   791,  1215,   565,  3755,  2076,  1215,  4629, 18119,\n",
            "        28417,  4397, 50140,  1437,  1437,  1437, 48643,  1215, 17036,  5457,\n",
            "         2231,   991,   257,  1215,  4651,  1215, 17036,  1640,  1864,  5330,\n",
            "          791,  1215,   565,  3755,  2076,  1215,   846, 40835, 17710,  4397,\n",
            "        50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n",
            "Attention Mask\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main training configuration and running model"
      ],
      "metadata": {
        "id": "STsTgbFxssIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main configuration function for a given finetune run\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    run_name = \"Final_lr=5e-6\"\n",
        "    model_name = 'codebert-base'\n",
        "    dir_name = 'codebert_finetune_runs/{}'.format(run_name)\n",
        "\n",
        "    checkpoint_location = None\n",
        "    save_data = True\n",
        "    online = False\n",
        "\n",
        "    code_df = preprocess_data(file_loc='code_dataset.jsonl')\n",
        "    train_data, val_data, test_data = tokenize(code_df, model_name=model_name)\n",
        "\n",
        "\n",
        "    # Creating dir to save logs and checkpoints, re\n",
        "    if os.path.exists(dir_name):\n",
        "      input(\"run name already exists, press Enter to overwrite\")\n",
        "    else:\n",
        "      os.makedirs(dir_name)\n",
        "\n",
        "    if save_data:\n",
        "      print(\"saving data splits\")\n",
        "      X_train, A_train, Y_train = train_data\n",
        "      X_val, A_val, Y_val = val_data\n",
        "      X_test, A_test, Y_test = test_data\n",
        "      data_type = ['train', 'val', 'test']\n",
        "      data_split_type = ['X', 'A', 'Y']\n",
        "      data_all = [train_data, val_data, test_data]\n",
        "      for i, data in enumerate(data_all):\n",
        "        for j, split in enumerate(data):\n",
        "          with open('{}/{}_{}.pickle'.format(dir_name,data_type[i], data_split_type[j]), 'wb') as handle:\n",
        "            pickle.dump(split, handle)\n",
        "\n",
        "    # Loading model from checkpoint if location provided\n",
        "    if online:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\")\n",
        "    elif checkpoint_location is None:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "    else:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(checkpoint_location)\n",
        "\n",
        "    train(model=model,\n",
        "          train_data=train_data,\n",
        "          val_data=val_data,\n",
        "          epochs=5,\n",
        "          batch_size=8,\n",
        "          learning_rate=5e-6,\n",
        "          validate_per=100,\n",
        "          dir_name=dir_name,\n",
        "          run_descrption=\"Colab with highRam, lr=5e-6, validate per 100, batch 8, redo\")\n"
      ],
      "metadata": {
        "id": "R6O7zb14IaUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvUFgyyxcsU5",
        "outputId": "0fd3b2f8-34ac-42a2-a831-cd5a0f6e5fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insecure code counts: 3729, Total code counts: 8000, Proportion 0.466125\n",
            "Data points: 8000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving data splits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:0 Training_loss:0.589329, Acc_avg:75.00% Training_loss_avg:0.589329\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:0 Val_loss:0.681129, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:8 Training_loss:0.624261, Acc_avg:75.00% Training_loss_avg:0.606795\n",
            "Epoch:0 Step:16 Training_loss:0.771221, Acc_avg:62.50% Training_loss_avg:0.661604\n",
            "Epoch:0 Step:24 Training_loss:0.808756, Acc_avg:56.25% Training_loss_avg:0.698392\n",
            "Epoch:0 Step:32 Training_loss:0.646655, Acc_avg:60.00% Training_loss_avg:0.688045\n",
            "Epoch:0 Step:40 Training_loss:0.718900, Acc_avg:58.33% Training_loss_avg:0.693187\n",
            "Epoch:0 Step:48 Training_loss:0.679011, Acc_avg:58.93% Training_loss_avg:0.691162\n",
            "Epoch:0 Step:56 Training_loss:0.569332, Acc_avg:62.50% Training_loss_avg:0.675933\n",
            "Epoch:0 Step:64 Training_loss:0.761404, Acc_avg:61.11% Training_loss_avg:0.685430\n",
            "Epoch:0 Step:72 Training_loss:0.573385, Acc_avg:63.75% Training_loss_avg:0.674225\n",
            "Epoch:0 Step:80 Training_loss:0.627162, Acc_avg:63.64% Training_loss_avg:0.669947\n",
            "Epoch:0 Step:88 Training_loss:0.713646, Acc_avg:62.50% Training_loss_avg:0.673589\n",
            "Epoch:0 Step:96 Training_loss:0.571197, Acc_avg:63.46% Training_loss_avg:0.665712\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:96 Val_loss:0.684716, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:104 Training_loss:0.642624, Acc_avg:63.39% Training_loss_avg:0.664063\n",
            "Epoch:0 Step:112 Training_loss:0.789285, Acc_avg:60.83% Training_loss_avg:0.672411\n",
            "Epoch:0 Step:120 Training_loss:0.770315, Acc_avg:60.16% Training_loss_avg:0.678530\n",
            "Epoch:0 Step:128 Training_loss:0.592435, Acc_avg:61.03% Training_loss_avg:0.673466\n",
            "Epoch:0 Step:136 Training_loss:0.652490, Acc_avg:61.11% Training_loss_avg:0.672301\n",
            "Epoch:0 Step:144 Training_loss:0.690117, Acc_avg:60.53% Training_loss_avg:0.673238\n",
            "Epoch:0 Step:152 Training_loss:0.777899, Acc_avg:60.00% Training_loss_avg:0.678471\n",
            "Epoch:0 Step:160 Training_loss:0.828533, Acc_avg:58.33% Training_loss_avg:0.685617\n",
            "Epoch:0 Step:168 Training_loss:0.831583, Acc_avg:56.82% Training_loss_avg:0.692252\n",
            "Epoch:0 Step:176 Training_loss:0.612426, Acc_avg:57.07% Training_loss_avg:0.688781\n",
            "Epoch:0 Step:184 Training_loss:0.875740, Acc_avg:55.21% Training_loss_avg:0.696571\n",
            "Epoch:0 Step:192 Training_loss:0.625108, Acc_avg:56.00% Training_loss_avg:0.693713\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:192 Val_loss:0.680385, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:200 Training_loss:0.747016, Acc_avg:55.77% Training_loss_avg:0.695763\n",
            "Epoch:0 Step:208 Training_loss:0.599480, Acc_avg:56.94% Training_loss_avg:0.692197\n",
            "Epoch:0 Step:216 Training_loss:0.683885, Acc_avg:56.70% Training_loss_avg:0.691900\n",
            "Epoch:0 Step:224 Training_loss:0.646840, Acc_avg:56.90% Training_loss_avg:0.690346\n",
            "Epoch:0 Step:232 Training_loss:0.722198, Acc_avg:56.25% Training_loss_avg:0.691408\n",
            "Epoch:0 Step:240 Training_loss:0.638665, Acc_avg:56.45% Training_loss_avg:0.689706\n",
            "Epoch:0 Step:248 Training_loss:0.616543, Acc_avg:57.03% Training_loss_avg:0.687420\n",
            "Epoch:0 Step:256 Training_loss:0.647931, Acc_avg:57.20% Training_loss_avg:0.686223\n",
            "Epoch:0 Step:264 Training_loss:0.678447, Acc_avg:57.35% Training_loss_avg:0.685995\n",
            "Epoch:0 Step:272 Training_loss:0.654818, Acc_avg:57.50% Training_loss_avg:0.685104\n",
            "Epoch:0 Step:280 Training_loss:0.695502, Acc_avg:57.29% Training_loss_avg:0.685393\n",
            "Epoch:0 Step:288 Training_loss:0.723456, Acc_avg:57.09% Training_loss_avg:0.686422\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:288 Val_loss:0.680906, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:296 Training_loss:0.652301, Acc_avg:57.57% Training_loss_avg:0.685524\n",
            "Epoch:0 Step:304 Training_loss:0.678380, Acc_avg:57.69% Training_loss_avg:0.685340\n",
            "Epoch:0 Step:312 Training_loss:0.637371, Acc_avg:58.44% Training_loss_avg:0.684141\n",
            "Epoch:0 Step:320 Training_loss:0.629465, Acc_avg:58.84% Training_loss_avg:0.682808\n",
            "Epoch:0 Step:328 Training_loss:0.711306, Acc_avg:58.63% Training_loss_avg:0.683486\n",
            "Epoch:0 Step:336 Training_loss:0.680929, Acc_avg:58.72% Training_loss_avg:0.683427\n",
            "Epoch:0 Step:344 Training_loss:0.667706, Acc_avg:59.38% Training_loss_avg:0.683069\n",
            "Epoch:0 Step:352 Training_loss:0.668918, Acc_avg:59.44% Training_loss_avg:0.682755\n",
            "Epoch:0 Step:360 Training_loss:0.727603, Acc_avg:58.70% Training_loss_avg:0.683730\n",
            "Epoch:0 Step:368 Training_loss:0.595111, Acc_avg:59.04% Training_loss_avg:0.681844\n",
            "Epoch:0 Step:376 Training_loss:0.691362, Acc_avg:58.85% Training_loss_avg:0.682043\n",
            "Epoch:0 Step:384 Training_loss:0.678886, Acc_avg:58.93% Training_loss_avg:0.681978\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:384 Val_loss:0.680287, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:392 Training_loss:0.708608, Acc_avg:58.75% Training_loss_avg:0.682511\n",
            "Epoch:0 Step:400 Training_loss:0.697905, Acc_avg:58.50% Training_loss_avg:0.684682\n",
            "Epoch:0 Step:408 Training_loss:0.672963, Acc_avg:58.25% Training_loss_avg:0.685656\n",
            "Epoch:0 Step:416 Training_loss:0.569921, Acc_avg:59.50% Training_loss_avg:0.681630\n",
            "Epoch:0 Step:424 Training_loss:0.737138, Acc_avg:59.75% Training_loss_avg:0.680198\n",
            "Epoch:0 Step:432 Training_loss:0.716453, Acc_avg:59.00% Training_loss_avg:0.681594\n",
            "Epoch:0 Step:440 Training_loss:0.670933, Acc_avg:59.00% Training_loss_avg:0.680635\n",
            "Epoch:0 Step:448 Training_loss:0.651254, Acc_avg:59.00% Training_loss_avg:0.680080\n",
            "Epoch:0 Step:456 Training_loss:0.655005, Acc_avg:58.25% Training_loss_avg:0.681793\n",
            "Epoch:0 Step:464 Training_loss:0.620850, Acc_avg:58.75% Training_loss_avg:0.678982\n",
            "Epoch:0 Step:472 Training_loss:0.740150, Acc_avg:57.75% Training_loss_avg:0.682317\n",
            "Epoch:0 Step:480 Training_loss:0.714077, Acc_avg:57.50% Training_loss_avg:0.684056\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:480 Val_loss:0.680433, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:488 Training_loss:0.678241, Acc_avg:57.75% Training_loss_avg:0.683347\n",
            "Epoch:0 Step:496 Training_loss:0.762569, Acc_avg:57.00% Training_loss_avg:0.687175\n",
            "Epoch:0 Step:504 Training_loss:0.794815, Acc_avg:56.50% Training_loss_avg:0.690219\n",
            "Epoch:0 Step:512 Training_loss:0.643310, Acc_avg:57.25% Training_loss_avg:0.687299\n",
            "Epoch:0 Step:520 Training_loss:0.766753, Acc_avg:56.75% Training_loss_avg:0.687228\n",
            "Epoch:0 Step:528 Training_loss:0.691027, Acc_avg:56.25% Training_loss_avg:0.689200\n",
            "Epoch:0 Step:536 Training_loss:0.611007, Acc_avg:56.50% Training_loss_avg:0.688370\n",
            "Epoch:0 Step:544 Training_loss:0.751288, Acc_avg:56.25% Training_loss_avg:0.689594\n",
            "Epoch:0 Step:552 Training_loss:0.578862, Acc_avg:56.75% Training_loss_avg:0.685613\n",
            "Epoch:0 Step:560 Training_loss:0.613363, Acc_avg:57.75% Training_loss_avg:0.681309\n",
            "Epoch:0 Step:568 Training_loss:0.578549, Acc_avg:59.25% Training_loss_avg:0.676249\n",
            "Epoch:0 Step:576 Training_loss:0.750331, Acc_avg:58.75% Training_loss_avg:0.679007\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:576 Val_loss:0.679924, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:584 Training_loss:0.648141, Acc_avg:59.75% Training_loss_avg:0.674455\n",
            "Epoch:0 Step:592 Training_loss:0.594209, Acc_avg:60.00% Training_loss_avg:0.673837\n",
            "Epoch:0 Step:600 Training_loss:0.701009, Acc_avg:60.00% Training_loss_avg:0.672917\n",
            "Epoch:0 Step:608 Training_loss:0.655129, Acc_avg:59.50% Training_loss_avg:0.674030\n",
            "Epoch:0 Step:616 Training_loss:0.695579, Acc_avg:59.50% Training_loss_avg:0.674264\n",
            "Epoch:0 Step:624 Training_loss:0.626847, Acc_avg:59.75% Training_loss_avg:0.673864\n",
            "Epoch:0 Step:632 Training_loss:0.657648, Acc_avg:60.25% Training_loss_avg:0.672573\n",
            "Epoch:0 Step:640 Training_loss:0.657726, Acc_avg:60.25% Training_loss_avg:0.672954\n",
            "Epoch:0 Step:648 Training_loss:0.654702, Acc_avg:60.00% Training_loss_avg:0.673717\n",
            "Epoch:0 Step:656 Training_loss:0.686616, Acc_avg:60.00% Training_loss_avg:0.674491\n",
            "Epoch:0 Step:664 Training_loss:0.613232, Acc_avg:60.25% Training_loss_avg:0.673187\n",
            "Epoch:0 Step:672 Training_loss:0.813715, Acc_avg:59.75% Training_loss_avg:0.676364\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:672 Val_loss:0.682271, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:680 Training_loss:0.672905, Acc_avg:60.00% Training_loss_avg:0.675913\n",
            "Epoch:0 Step:688 Training_loss:0.617927, Acc_avg:60.50% Training_loss_avg:0.673802\n",
            "Epoch:0 Step:696 Training_loss:0.574800, Acc_avg:60.75% Training_loss_avg:0.672252\n",
            "Epoch:0 Step:704 Training_loss:0.755026, Acc_avg:60.50% Training_loss_avg:0.673785\n",
            "Epoch:0 Step:712 Training_loss:0.799776, Acc_avg:59.50% Training_loss_avg:0.677033\n",
            "Epoch:0 Step:720 Training_loss:0.661522, Acc_avg:59.25% Training_loss_avg:0.677674\n",
            "Epoch:0 Step:728 Training_loss:0.577947, Acc_avg:60.00% Training_loss_avg:0.675007\n",
            "Epoch:0 Step:736 Training_loss:0.886527, Acc_avg:59.25% Training_loss_avg:0.679119\n",
            "Epoch:0 Step:744 Training_loss:0.704313, Acc_avg:58.75% Training_loss_avg:0.679851\n",
            "Epoch:0 Step:752 Training_loss:0.754258, Acc_avg:58.50% Training_loss_avg:0.681558\n",
            "Epoch:0 Step:760 Training_loss:0.717334, Acc_avg:59.25% Training_loss_avg:0.681352\n",
            "Epoch:0 Step:768 Training_loss:0.904788, Acc_avg:58.00% Training_loss_avg:0.687546\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:768 Val_loss:0.683216, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:776 Training_loss:0.770410, Acc_avg:58.00% Training_loss_avg:0.689127\n",
            "Epoch:0 Step:784 Training_loss:0.667866, Acc_avg:58.00% Training_loss_avg:0.688907\n",
            "Epoch:0 Step:792 Training_loss:0.509016, Acc_avg:59.00% Training_loss_avg:0.684915\n",
            "Epoch:0 Step:800 Training_loss:0.713981, Acc_avg:58.75% Training_loss_avg:0.685236\n",
            "Epoch:0 Step:808 Training_loss:0.740125, Acc_avg:58.25% Training_loss_avg:0.686579\n",
            "Epoch:0 Step:816 Training_loss:0.658739, Acc_avg:57.50% Training_loss_avg:0.688356\n",
            "Epoch:0 Step:824 Training_loss:0.796153, Acc_avg:57.25% Training_loss_avg:0.689536\n",
            "Epoch:0 Step:832 Training_loss:0.750861, Acc_avg:57.25% Training_loss_avg:0.690224\n",
            "Epoch:0 Step:840 Training_loss:0.700586, Acc_avg:57.25% Training_loss_avg:0.690817\n",
            "Epoch:0 Step:848 Training_loss:0.804832, Acc_avg:56.25% Training_loss_avg:0.693889\n",
            "Epoch:0 Step:856 Training_loss:0.659574, Acc_avg:56.50% Training_loss_avg:0.693980\n",
            "Epoch:0 Step:864 Training_loss:0.743432, Acc_avg:55.75% Training_loss_avg:0.696432\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:864 Val_loss:0.679353, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:872 Training_loss:0.730672, Acc_avg:56.00% Training_loss_avg:0.696242\n",
            "Epoch:0 Step:880 Training_loss:0.723473, Acc_avg:56.00% Training_loss_avg:0.696430\n",
            "Epoch:0 Step:888 Training_loss:0.685705, Acc_avg:55.75% Training_loss_avg:0.696580\n",
            "Epoch:0 Step:896 Training_loss:0.721903, Acc_avg:56.25% Training_loss_avg:0.695766\n",
            "Epoch:0 Step:904 Training_loss:0.677547, Acc_avg:56.50% Training_loss_avg:0.693421\n",
            "Epoch:0 Step:912 Training_loss:0.702382, Acc_avg:56.00% Training_loss_avg:0.694602\n",
            "Epoch:0 Step:920 Training_loss:0.769358, Acc_avg:55.75% Training_loss_avg:0.694654\n",
            "Epoch:0 Step:928 Training_loss:0.651410, Acc_avg:56.50% Training_loss_avg:0.693862\n",
            "Epoch:0 Step:936 Training_loss:0.702845, Acc_avg:55.75% Training_loss_avg:0.695699\n",
            "Epoch:0 Step:944 Training_loss:0.688329, Acc_avg:56.00% Training_loss_avg:0.694440\n",
            "Epoch:0 Step:952 Training_loss:0.712083, Acc_avg:55.25% Training_loss_avg:0.697104\n",
            "Epoch:0 Step:960 Training_loss:0.708475, Acc_avg:54.50% Training_loss_avg:0.699006\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:960 Val_loss:0.686434, Val_Acc_avg:59.00%\n",
            "Epoch:0 Step:968 Training_loss:0.697691, Acc_avg:53.50% Training_loss_avg:0.701389\n",
            "Epoch:0 Step:976 Training_loss:0.704831, Acc_avg:53.75% Training_loss_avg:0.700479\n",
            "Epoch:0 Step:984 Training_loss:0.658967, Acc_avg:53.75% Training_loss_avg:0.700696\n",
            "Epoch:0 Step:992 Training_loss:0.673079, Acc_avg:53.25% Training_loss_avg:0.702273\n",
            "Epoch:0 Step:1000 Training_loss:0.643488, Acc_avg:53.75% Training_loss_avg:0.701123\n",
            "Epoch:0 Step:1008 Training_loss:0.675502, Acc_avg:53.50% Training_loss_avg:0.701530\n",
            "Epoch:0 Step:1016 Training_loss:0.745671, Acc_avg:53.25% Training_loss_avg:0.702532\n",
            "Epoch:0 Step:1024 Training_loss:0.667836, Acc_avg:53.00% Training_loss_avg:0.703352\n",
            "Epoch:0 Step:1032 Training_loss:0.669827, Acc_avg:53.25% Training_loss_avg:0.703595\n",
            "Epoch:0 Step:1040 Training_loss:0.673699, Acc_avg:53.00% Training_loss_avg:0.703915\n",
            "Epoch:0 Step:1048 Training_loss:0.640345, Acc_avg:53.25% Training_loss_avg:0.703628\n",
            "Epoch:0 Step:1056 Training_loss:0.684774, Acc_avg:53.00% Training_loss_avg:0.703591\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1056 Val_loss:0.695050, Val_Acc_avg:45.25%\n",
            "Epoch:0 Step:1064 Training_loss:0.712943, Acc_avg:52.50% Training_loss_avg:0.705585\n",
            "Epoch:0 Step:1072 Training_loss:0.687655, Acc_avg:52.50% Training_loss_avg:0.703064\n",
            "Epoch:0 Step:1080 Training_loss:0.752175, Acc_avg:51.50% Training_loss_avg:0.704649\n",
            "Epoch:0 Step:1088 Training_loss:0.751250, Acc_avg:50.50% Training_loss_avg:0.707316\n",
            "Epoch:0 Step:1096 Training_loss:0.698299, Acc_avg:49.75% Training_loss_avg:0.709786\n",
            "Epoch:0 Step:1104 Training_loss:0.628271, Acc_avg:50.00% Training_loss_avg:0.707251\n",
            "Epoch:0 Step:1112 Training_loss:0.667378, Acc_avg:50.25% Training_loss_avg:0.704603\n",
            "Epoch:0 Step:1120 Training_loss:0.726265, Acc_avg:49.75% Training_loss_avg:0.705897\n",
            "Epoch:0 Step:1128 Training_loss:0.668068, Acc_avg:49.25% Training_loss_avg:0.707700\n",
            "Epoch:0 Step:1136 Training_loss:0.771161, Acc_avg:49.75% Training_loss_avg:0.705393\n",
            "Epoch:0 Step:1144 Training_loss:0.647157, Acc_avg:50.00% Training_loss_avg:0.704249\n",
            "Epoch:0 Step:1152 Training_loss:0.677102, Acc_avg:50.50% Training_loss_avg:0.702706\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1152 Val_loss:0.692856, Val_Acc_avg:50.00%\n",
            "Epoch:0 Step:1160 Training_loss:0.681091, Acc_avg:50.75% Training_loss_avg:0.701981\n",
            "Epoch:0 Step:1168 Training_loss:0.742667, Acc_avg:51.25% Training_loss_avg:0.698739\n",
            "Epoch:0 Step:1176 Training_loss:0.655063, Acc_avg:51.25% Training_loss_avg:0.696432\n",
            "Epoch:0 Step:1184 Training_loss:0.734087, Acc_avg:51.25% Training_loss_avg:0.697756\n",
            "Epoch:0 Step:1192 Training_loss:0.707579, Acc_avg:50.50% Training_loss_avg:0.701728\n",
            "Epoch:0 Step:1200 Training_loss:0.735894, Acc_avg:50.25% Training_loss_avg:0.702166\n",
            "Epoch:0 Step:1208 Training_loss:0.686813, Acc_avg:50.75% Training_loss_avg:0.701100\n",
            "Epoch:0 Step:1216 Training_loss:0.686075, Acc_avg:50.50% Training_loss_avg:0.701646\n",
            "Epoch:0 Step:1224 Training_loss:0.725132, Acc_avg:50.75% Training_loss_avg:0.700226\n",
            "Epoch:0 Step:1232 Training_loss:0.697319, Acc_avg:51.25% Training_loss_avg:0.699155\n",
            "Epoch:0 Step:1240 Training_loss:0.613587, Acc_avg:51.75% Training_loss_avg:0.697415\n",
            "Epoch:0 Step:1248 Training_loss:0.683776, Acc_avg:52.75% Training_loss_avg:0.694994\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1248 Val_loss:0.678857, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:1256 Training_loss:0.570820, Acc_avg:53.50% Training_loss_avg:0.693219\n",
            "Epoch:0 Step:1264 Training_loss:0.746607, Acc_avg:53.25% Training_loss_avg:0.693283\n",
            "Epoch:0 Step:1272 Training_loss:0.735370, Acc_avg:53.00% Training_loss_avg:0.693376\n",
            "Epoch:0 Step:1280 Training_loss:0.581410, Acc_avg:53.50% Training_loss_avg:0.690535\n",
            "Epoch:0 Step:1288 Training_loss:0.697261, Acc_avg:53.75% Training_loss_avg:0.690766\n",
            "Epoch:0 Step:1296 Training_loss:0.779066, Acc_avg:53.00% Training_loss_avg:0.691910\n",
            "Epoch:0 Step:1304 Training_loss:0.598665, Acc_avg:53.50% Training_loss_avg:0.690332\n",
            "Epoch:0 Step:1312 Training_loss:0.588945, Acc_avg:54.50% Training_loss_avg:0.688063\n",
            "Epoch:0 Step:1320 Training_loss:0.695303, Acc_avg:55.25% Training_loss_avg:0.686582\n",
            "Epoch:0 Step:1328 Training_loss:0.629001, Acc_avg:54.75% Training_loss_avg:0.686134\n",
            "Epoch:0 Step:1336 Training_loss:0.785375, Acc_avg:54.75% Training_loss_avg:0.687785\n",
            "Epoch:0 Step:1344 Training_loss:0.665628, Acc_avg:55.00% Training_loss_avg:0.687331\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1344 Val_loss:0.684400, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:1352 Training_loss:0.848472, Acc_avg:54.75% Training_loss_avg:0.690058\n",
            "Epoch:0 Step:1360 Training_loss:0.588528, Acc_avg:55.50% Training_loss_avg:0.687659\n",
            "Epoch:0 Step:1368 Training_loss:0.602967, Acc_avg:56.00% Training_loss_avg:0.685765\n",
            "Epoch:0 Step:1376 Training_loss:0.747466, Acc_avg:56.00% Training_loss_avg:0.686618\n",
            "Epoch:0 Step:1384 Training_loss:0.664084, Acc_avg:56.00% Training_loss_avg:0.686720\n",
            "Epoch:0 Step:1392 Training_loss:0.644963, Acc_avg:56.00% Training_loss_avg:0.686158\n",
            "Epoch:0 Step:1400 Training_loss:0.742118, Acc_avg:55.50% Training_loss_avg:0.688130\n",
            "Epoch:0 Step:1408 Training_loss:0.687015, Acc_avg:55.75% Training_loss_avg:0.688360\n",
            "Epoch:0 Step:1416 Training_loss:0.596694, Acc_avg:56.50% Training_loss_avg:0.685381\n",
            "Epoch:0 Step:1424 Training_loss:0.568286, Acc_avg:56.75% Training_loss_avg:0.683390\n",
            "Epoch:0 Step:1432 Training_loss:0.645951, Acc_avg:56.50% Training_loss_avg:0.682912\n",
            "Epoch:0 Step:1440 Training_loss:0.618465, Acc_avg:57.00% Training_loss_avg:0.681808\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1440 Val_loss:0.687016, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:1448 Training_loss:0.698174, Acc_avg:56.50% Training_loss_avg:0.682964\n",
            "Epoch:0 Step:1456 Training_loss:0.755043, Acc_avg:56.50% Training_loss_avg:0.684370\n",
            "Epoch:0 Step:1464 Training_loss:0.703902, Acc_avg:56.50% Training_loss_avg:0.684189\n",
            "Epoch:0 Step:1472 Training_loss:0.719032, Acc_avg:56.75% Training_loss_avg:0.684816\n",
            "Epoch:0 Step:1480 Training_loss:0.775753, Acc_avg:57.50% Training_loss_avg:0.685288\n",
            "Epoch:0 Step:1488 Training_loss:0.807380, Acc_avg:57.75% Training_loss_avg:0.686411\n",
            "Epoch:0 Step:1496 Training_loss:0.692650, Acc_avg:57.75% Training_loss_avg:0.686298\n",
            "Epoch:0 Step:1504 Training_loss:0.523399, Acc_avg:58.25% Training_loss_avg:0.684200\n",
            "Epoch:0 Step:1512 Training_loss:0.589361, Acc_avg:58.75% Training_loss_avg:0.682640\n",
            "Epoch:0 Step:1520 Training_loss:0.558576, Acc_avg:59.50% Training_loss_avg:0.679286\n",
            "Epoch:0 Step:1528 Training_loss:0.783163, Acc_avg:59.00% Training_loss_avg:0.681588\n",
            "Epoch:0 Step:1536 Training_loss:0.630093, Acc_avg:59.50% Training_loss_avg:0.678767\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1536 Val_loss:0.684732, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:1544 Training_loss:0.663762, Acc_avg:59.25% Training_loss_avg:0.679099\n",
            "Epoch:0 Step:1552 Training_loss:0.487031, Acc_avg:59.75% Training_loss_avg:0.675297\n",
            "Epoch:0 Step:1560 Training_loss:0.566113, Acc_avg:59.75% Training_loss_avg:0.672998\n",
            "Epoch:0 Step:1568 Training_loss:0.523210, Acc_avg:60.75% Training_loss_avg:0.668609\n",
            "Epoch:0 Step:1576 Training_loss:0.800044, Acc_avg:60.50% Training_loss_avg:0.671508\n",
            "Epoch:0 Step:1584 Training_loss:0.632526, Acc_avg:60.50% Training_loss_avg:0.669477\n",
            "Epoch:0 Step:1592 Training_loss:0.770350, Acc_avg:60.25% Training_loss_avg:0.670732\n",
            "Epoch:0 Step:1600 Training_loss:0.702843, Acc_avg:60.50% Training_loss_avg:0.670071\n",
            "Epoch:0 Step:1608 Training_loss:0.760183, Acc_avg:60.25% Training_loss_avg:0.671539\n",
            "Epoch:0 Step:1616 Training_loss:0.702560, Acc_avg:60.25% Training_loss_avg:0.671868\n",
            "Epoch:0 Step:1624 Training_loss:0.573008, Acc_avg:60.75% Training_loss_avg:0.668826\n",
            "Epoch:0 Step:1632 Training_loss:0.777743, Acc_avg:60.25% Training_loss_avg:0.670434\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1632 Val_loss:0.686639, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:1640 Training_loss:0.618218, Acc_avg:60.00% Training_loss_avg:0.670527\n",
            "Epoch:0 Step:1648 Training_loss:0.620603, Acc_avg:60.25% Training_loss_avg:0.669264\n",
            "Epoch:0 Step:1656 Training_loss:0.608761, Acc_avg:59.50% Training_loss_avg:0.670022\n",
            "Epoch:0 Step:1664 Training_loss:0.798320, Acc_avg:59.75% Training_loss_avg:0.671057\n",
            "Epoch:0 Step:1672 Training_loss:0.841023, Acc_avg:59.50% Training_loss_avg:0.673170\n",
            "Epoch:0 Step:1680 Training_loss:0.742440, Acc_avg:59.00% Training_loss_avg:0.676390\n",
            "Epoch:0 Step:1688 Training_loss:0.757214, Acc_avg:58.50% Training_loss_avg:0.677589\n",
            "Epoch:0 Step:1696 Training_loss:0.737743, Acc_avg:59.00% Training_loss_avg:0.676763\n",
            "Epoch:0 Step:1704 Training_loss:0.740639, Acc_avg:58.25% Training_loss_avg:0.679602\n",
            "Epoch:0 Step:1712 Training_loss:0.577140, Acc_avg:58.00% Training_loss_avg:0.679366\n",
            "Epoch:0 Step:1720 Training_loss:0.756522, Acc_avg:57.75% Training_loss_avg:0.680591\n",
            "Epoch:0 Step:1728 Training_loss:0.753136, Acc_avg:57.25% Training_loss_avg:0.683073\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1728 Val_loss:0.678352, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:1736 Training_loss:0.707346, Acc_avg:57.75% Training_loss_avg:0.681513\n",
            "Epoch:0 Step:1744 Training_loss:0.534795, Acc_avg:58.50% Training_loss_avg:0.678896\n",
            "Epoch:0 Step:1752 Training_loss:0.703952, Acc_avg:58.75% Training_loss_avg:0.676006\n",
            "Epoch:0 Step:1760 Training_loss:0.706215, Acc_avg:58.25% Training_loss_avg:0.678359\n",
            "Epoch:0 Step:1768 Training_loss:0.660379, Acc_avg:58.00% Training_loss_avg:0.679508\n",
            "Epoch:0 Step:1776 Training_loss:0.742686, Acc_avg:57.50% Training_loss_avg:0.679412\n",
            "Epoch:0 Step:1784 Training_loss:0.660474, Acc_avg:57.75% Training_loss_avg:0.679340\n",
            "Epoch:0 Step:1792 Training_loss:0.628919, Acc_avg:57.75% Training_loss_avg:0.679019\n",
            "Epoch:0 Step:1800 Training_loss:0.691024, Acc_avg:57.50% Training_loss_avg:0.677997\n",
            "Epoch:0 Step:1808 Training_loss:0.676189, Acc_avg:57.50% Training_loss_avg:0.677781\n",
            "Epoch:0 Step:1816 Training_loss:0.729623, Acc_avg:56.75% Training_loss_avg:0.680439\n",
            "Epoch:0 Step:1824 Training_loss:0.686474, Acc_avg:56.25% Training_loss_avg:0.682803\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1824 Val_loss:0.678123, Val_Acc_avg:58.00%\n",
            "Epoch:0 Step:1832 Training_loss:0.705724, Acc_avg:56.00% Training_loss_avg:0.683998\n",
            "Epoch:0 Step:1840 Training_loss:0.674044, Acc_avg:56.00% Training_loss_avg:0.685110\n",
            "Epoch:0 Step:1848 Training_loss:0.721816, Acc_avg:55.75% Training_loss_avg:0.685583\n",
            "Epoch:0 Step:1856 Training_loss:0.692381, Acc_avg:56.00% Training_loss_avg:0.684330\n",
            "Epoch:0 Step:1864 Training_loss:0.676412, Acc_avg:56.25% Training_loss_avg:0.683780\n",
            "Epoch:0 Step:1872 Training_loss:0.731314, Acc_avg:56.00% Training_loss_avg:0.684025\n",
            "Epoch:0 Step:1880 Training_loss:0.643709, Acc_avg:56.25% Training_loss_avg:0.681385\n",
            "Epoch:0 Step:1888 Training_loss:0.651778, Acc_avg:56.75% Training_loss_avg:0.678273\n",
            "Epoch:0 Step:1896 Training_loss:0.714107, Acc_avg:56.50% Training_loss_avg:0.678702\n",
            "Epoch:0 Step:1904 Training_loss:0.660682, Acc_avg:56.25% Training_loss_avg:0.681447\n",
            "Epoch:0 Step:1912 Training_loss:0.641974, Acc_avg:56.25% Training_loss_avg:0.682500\n",
            "Epoch:0 Step:1920 Training_loss:0.661318, Acc_avg:56.25% Training_loss_avg:0.684554\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:1920 Val_loss:0.679067, Val_Acc_avg:58.75%\n",
            "Epoch:0 Step:1928 Training_loss:0.658511, Acc_avg:57.00% Training_loss_avg:0.682061\n",
            "Epoch:0 Step:1936 Training_loss:0.654924, Acc_avg:56.75% Training_loss_avg:0.682558\n",
            "Epoch:0 Step:1944 Training_loss:0.696887, Acc_avg:56.25% Training_loss_avg:0.683221\n",
            "Epoch:0 Step:1952 Training_loss:0.615371, Acc_avg:56.00% Training_loss_avg:0.685787\n",
            "Epoch:0 Step:1960 Training_loss:0.649466, Acc_avg:56.00% Training_loss_avg:0.687454\n",
            "Epoch:0 Step:1968 Training_loss:0.780676, Acc_avg:54.75% Training_loss_avg:0.692604\n",
            "Epoch:0 Step:1976 Training_loss:0.644550, Acc_avg:55.50% Training_loss_avg:0.689494\n",
            "Epoch:0 Step:1984 Training_loss:0.636992, Acc_avg:55.75% Training_loss_avg:0.689583\n",
            "Epoch:0 Step:1992 Training_loss:0.553855, Acc_avg:56.75% Training_loss_avg:0.685253\n",
            "Epoch:0 Step:2000 Training_loss:0.727490, Acc_avg:56.75% Training_loss_avg:0.685746\n",
            "Epoch:0 Step:2008 Training_loss:0.724783, Acc_avg:56.75% Training_loss_avg:0.685038\n",
            "Epoch:0 Step:2016 Training_loss:0.683370, Acc_avg:56.75% Training_loss_avg:0.684654\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2016 Val_loss:0.677010, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:2024 Training_loss:0.714758, Acc_avg:56.00% Training_loss_avg:0.687489\n",
            "Epoch:0 Step:2032 Training_loss:0.680009, Acc_avg:56.25% Training_loss_avg:0.685535\n",
            "Epoch:0 Step:2040 Training_loss:0.699343, Acc_avg:56.00% Training_loss_avg:0.687157\n",
            "Epoch:0 Step:2048 Training_loss:0.607036, Acc_avg:55.75% Training_loss_avg:0.686886\n",
            "Epoch:0 Step:2056 Training_loss:0.770922, Acc_avg:55.25% Training_loss_avg:0.690129\n",
            "Epoch:0 Step:2064 Training_loss:0.728375, Acc_avg:55.50% Training_loss_avg:0.688730\n",
            "Epoch:0 Step:2072 Training_loss:0.730209, Acc_avg:55.75% Training_loss_avg:0.686514\n",
            "Epoch:0 Step:2080 Training_loss:0.672637, Acc_avg:56.00% Training_loss_avg:0.685118\n",
            "Epoch:0 Step:2088 Training_loss:0.805608, Acc_avg:55.50% Training_loss_avg:0.686086\n",
            "Epoch:0 Step:2096 Training_loss:0.612707, Acc_avg:55.75% Training_loss_avg:0.683585\n",
            "Epoch:0 Step:2104 Training_loss:0.567615, Acc_avg:56.75% Training_loss_avg:0.680125\n",
            "Epoch:0 Step:2112 Training_loss:0.625297, Acc_avg:56.50% Training_loss_avg:0.681088\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2112 Val_loss:0.676781, Val_Acc_avg:57.75%\n",
            "Epoch:0 Step:2120 Training_loss:0.715443, Acc_avg:56.75% Training_loss_avg:0.680266\n",
            "Epoch:0 Step:2128 Training_loss:0.689012, Acc_avg:57.00% Training_loss_avg:0.678984\n",
            "Epoch:0 Step:2136 Training_loss:0.711829, Acc_avg:56.50% Training_loss_avg:0.679073\n",
            "Epoch:0 Step:2144 Training_loss:0.743527, Acc_avg:55.25% Training_loss_avg:0.683248\n",
            "Epoch:0 Step:2152 Training_loss:0.703742, Acc_avg:55.50% Training_loss_avg:0.683244\n",
            "Epoch:0 Step:2160 Training_loss:0.742531, Acc_avg:55.25% Training_loss_avg:0.683970\n",
            "Epoch:0 Step:2168 Training_loss:0.623652, Acc_avg:55.50% Training_loss_avg:0.683235\n",
            "Epoch:0 Step:2176 Training_loss:0.757899, Acc_avg:55.50% Training_loss_avg:0.683540\n",
            "Epoch:0 Step:2184 Training_loss:0.708580, Acc_avg:55.25% Training_loss_avg:0.684502\n",
            "Epoch:0 Step:2192 Training_loss:0.750915, Acc_avg:54.75% Training_loss_avg:0.686942\n",
            "Epoch:0 Step:2200 Training_loss:0.648035, Acc_avg:55.25% Training_loss_avg:0.686082\n",
            "Epoch:0 Step:2208 Training_loss:0.734797, Acc_avg:54.75% Training_loss_avg:0.687254\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2208 Val_loss:0.678408, Val_Acc_avg:59.25%\n",
            "Epoch:0 Step:2216 Training_loss:0.724637, Acc_avg:54.75% Training_loss_avg:0.687154\n",
            "Epoch:0 Step:2224 Training_loss:0.612074, Acc_avg:55.50% Training_loss_avg:0.685666\n",
            "Epoch:0 Step:2232 Training_loss:0.702692, Acc_avg:55.25% Training_loss_avg:0.685606\n",
            "Epoch:0 Step:2240 Training_loss:0.641116, Acc_avg:55.00% Training_loss_avg:0.684947\n",
            "Epoch:0 Step:2248 Training_loss:0.647508, Acc_avg:55.25% Training_loss_avg:0.683461\n",
            "Epoch:0 Step:2256 Training_loss:0.631416, Acc_avg:55.50% Training_loss_avg:0.682242\n",
            "Epoch:0 Step:2264 Training_loss:0.656820, Acc_avg:55.50% Training_loss_avg:0.681850\n",
            "Epoch:0 Step:2272 Training_loss:0.675180, Acc_avg:56.00% Training_loss_avg:0.680727\n",
            "Epoch:0 Step:2280 Training_loss:0.689856, Acc_avg:55.50% Training_loss_avg:0.681650\n",
            "Epoch:0 Step:2288 Training_loss:0.651900, Acc_avg:55.50% Training_loss_avg:0.681653\n",
            "Epoch:0 Step:2296 Training_loss:0.737260, Acc_avg:55.25% Training_loss_avg:0.682116\n",
            "Epoch:0 Step:2304 Training_loss:0.700088, Acc_avg:54.50% Training_loss_avg:0.682904\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2304 Val_loss:0.676864, Val_Acc_avg:58.75%\n",
            "Epoch:0 Step:2312 Training_loss:0.686186, Acc_avg:53.75% Training_loss_avg:0.683788\n",
            "Epoch:0 Step:2320 Training_loss:0.708499, Acc_avg:53.25% Training_loss_avg:0.684732\n",
            "Epoch:0 Step:2328 Training_loss:0.738448, Acc_avg:52.25% Training_loss_avg:0.686330\n",
            "Epoch:0 Step:2336 Training_loss:0.667226, Acc_avg:52.25% Training_loss_avg:0.686576\n",
            "Epoch:0 Step:2344 Training_loss:0.724468, Acc_avg:52.00% Training_loss_avg:0.687128\n",
            "Epoch:0 Step:2352 Training_loss:0.593282, Acc_avg:52.25% Training_loss_avg:0.686686\n",
            "Epoch:0 Step:2360 Training_loss:0.659256, Acc_avg:51.50% Training_loss_avg:0.686882\n",
            "Epoch:0 Step:2368 Training_loss:0.720467, Acc_avg:51.75% Training_loss_avg:0.685678\n",
            "Epoch:0 Step:2376 Training_loss:0.686447, Acc_avg:51.25% Training_loss_avg:0.686516\n",
            "Epoch:0 Step:2384 Training_loss:0.764599, Acc_avg:50.50% Training_loss_avg:0.689068\n",
            "Epoch:0 Step:2392 Training_loss:0.673799, Acc_avg:49.75% Training_loss_avg:0.691467\n",
            "Epoch:0 Step:2400 Training_loss:0.698635, Acc_avg:50.00% Training_loss_avg:0.690890\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2400 Val_loss:0.675799, Val_Acc_avg:59.50%\n",
            "Epoch:0 Step:2408 Training_loss:0.681424, Acc_avg:50.25% Training_loss_avg:0.690023\n",
            "Epoch:0 Step:2416 Training_loss:0.712068, Acc_avg:50.25% Training_loss_avg:0.690597\n",
            "Epoch:0 Step:2424 Training_loss:0.700440, Acc_avg:50.75% Training_loss_avg:0.690310\n",
            "Epoch:0 Step:2432 Training_loss:0.674912, Acc_avg:51.00% Training_loss_avg:0.690208\n",
            "Epoch:0 Step:2440 Training_loss:0.637054, Acc_avg:51.25% Training_loss_avg:0.688962\n",
            "Epoch:0 Step:2448 Training_loss:0.654459, Acc_avg:51.50% Training_loss_avg:0.689911\n",
            "Epoch:0 Step:2456 Training_loss:0.728747, Acc_avg:51.50% Training_loss_avg:0.689067\n",
            "Epoch:0 Step:2464 Training_loss:0.755887, Acc_avg:51.00% Training_loss_avg:0.689618\n",
            "Epoch:0 Step:2472 Training_loss:0.674483, Acc_avg:51.50% Training_loss_avg:0.688503\n",
            "Epoch:0 Step:2480 Training_loss:0.638412, Acc_avg:51.75% Training_loss_avg:0.687819\n",
            "Epoch:0 Step:2488 Training_loss:0.676562, Acc_avg:52.75% Training_loss_avg:0.685238\n",
            "Epoch:0 Step:2496 Training_loss:0.736655, Acc_avg:52.50% Training_loss_avg:0.687717\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2496 Val_loss:0.675945, Val_Acc_avg:61.50%\n",
            "Epoch:0 Step:2504 Training_loss:0.644496, Acc_avg:52.00% Training_loss_avg:0.689254\n",
            "Epoch:0 Step:2512 Training_loss:0.630943, Acc_avg:52.50% Training_loss_avg:0.689367\n",
            "Epoch:0 Step:2520 Training_loss:0.634049, Acc_avg:53.00% Training_loss_avg:0.687739\n",
            "Epoch:0 Step:2528 Training_loss:0.680416, Acc_avg:53.00% Training_loss_avg:0.687567\n",
            "Epoch:0 Step:2536 Training_loss:0.720506, Acc_avg:53.25% Training_loss_avg:0.687741\n",
            "Epoch:0 Step:2544 Training_loss:0.722981, Acc_avg:53.50% Training_loss_avg:0.687330\n",
            "Epoch:0 Step:2552 Training_loss:0.750198, Acc_avg:53.50% Training_loss_avg:0.688259\n",
            "Epoch:0 Step:2560 Training_loss:0.670075, Acc_avg:53.75% Training_loss_avg:0.686810\n",
            "Epoch:0 Step:2568 Training_loss:0.728418, Acc_avg:53.25% Training_loss_avg:0.688905\n",
            "Epoch:0 Step:2576 Training_loss:0.595438, Acc_avg:54.25% Training_loss_avg:0.685656\n",
            "Epoch:0 Step:2584 Training_loss:0.586725, Acc_avg:54.75% Training_loss_avg:0.683219\n",
            "Epoch:0 Step:2592 Training_loss:0.672741, Acc_avg:55.25% Training_loss_avg:0.681656\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2592 Val_loss:0.673553, Val_Acc_avg:60.25%\n",
            "Epoch:0 Step:2600 Training_loss:0.676234, Acc_avg:55.25% Training_loss_avg:0.682220\n",
            "Epoch:0 Step:2608 Training_loss:0.678819, Acc_avg:56.00% Training_loss_avg:0.681100\n",
            "Epoch:0 Step:2616 Training_loss:0.775073, Acc_avg:56.00% Training_loss_avg:0.682109\n",
            "Epoch:0 Step:2624 Training_loss:0.631599, Acc_avg:56.00% Training_loss_avg:0.682499\n",
            "Epoch:0 Step:2632 Training_loss:0.713852, Acc_avg:56.25% Training_loss_avg:0.682722\n",
            "Epoch:0 Step:2640 Training_loss:0.621604, Acc_avg:56.25% Training_loss_avg:0.682332\n",
            "Epoch:0 Step:2648 Training_loss:0.783587, Acc_avg:55.50% Training_loss_avg:0.685054\n",
            "Epoch:0 Step:2656 Training_loss:0.602016, Acc_avg:55.50% Training_loss_avg:0.684466\n",
            "Epoch:0 Step:2664 Training_loss:0.697644, Acc_avg:55.00% Training_loss_avg:0.685282\n",
            "Epoch:0 Step:2672 Training_loss:0.545994, Acc_avg:55.75% Training_loss_avg:0.682699\n",
            "Epoch:0 Step:2680 Training_loss:0.646877, Acc_avg:56.25% Training_loss_avg:0.681839\n",
            "Epoch:0 Step:2688 Training_loss:0.737528, Acc_avg:55.75% Training_loss_avg:0.683552\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2688 Val_loss:0.672806, Val_Acc_avg:60.25%\n",
            "Epoch:0 Step:2696 Training_loss:0.699767, Acc_avg:56.25% Training_loss_avg:0.682802\n",
            "Epoch:0 Step:2704 Training_loss:0.692798, Acc_avg:56.50% Training_loss_avg:0.682656\n",
            "Epoch:0 Step:2712 Training_loss:0.678410, Acc_avg:56.75% Training_loss_avg:0.682500\n",
            "Epoch:0 Step:2720 Training_loss:0.698217, Acc_avg:56.75% Training_loss_avg:0.682295\n",
            "Epoch:0 Step:2728 Training_loss:0.642301, Acc_avg:57.50% Training_loss_avg:0.680372\n",
            "Epoch:0 Step:2736 Training_loss:0.726706, Acc_avg:57.25% Training_loss_avg:0.681561\n",
            "Epoch:0 Step:2744 Training_loss:0.690769, Acc_avg:57.50% Training_loss_avg:0.680887\n",
            "Epoch:0 Step:2752 Training_loss:0.711867, Acc_avg:56.25% Training_loss_avg:0.683259\n",
            "Epoch:0 Step:2760 Training_loss:0.701544, Acc_avg:56.50% Training_loss_avg:0.684105\n",
            "Epoch:0 Step:2768 Training_loss:0.672547, Acc_avg:57.00% Training_loss_avg:0.683146\n",
            "Epoch:0 Step:2776 Training_loss:0.642699, Acc_avg:57.25% Training_loss_avg:0.682271\n",
            "Epoch:0 Step:2784 Training_loss:0.803887, Acc_avg:56.75% Training_loss_avg:0.683057\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2784 Val_loss:0.672613, Val_Acc_avg:61.00%\n",
            "Epoch:0 Step:2792 Training_loss:0.723585, Acc_avg:56.50% Training_loss_avg:0.684053\n",
            "Epoch:0 Step:2800 Training_loss:0.666491, Acc_avg:56.50% Training_loss_avg:0.683410\n",
            "Epoch:0 Step:2808 Training_loss:0.692362, Acc_avg:56.00% Training_loss_avg:0.683629\n",
            "Epoch:0 Step:2816 Training_loss:0.705200, Acc_avg:55.75% Training_loss_avg:0.683491\n",
            "Epoch:0 Step:2824 Training_loss:0.696152, Acc_avg:55.50% Training_loss_avg:0.683406\n",
            "Epoch:0 Step:2832 Training_loss:0.792660, Acc_avg:54.50% Training_loss_avg:0.685761\n",
            "Epoch:0 Step:2840 Training_loss:0.614924, Acc_avg:54.75% Training_loss_avg:0.685318\n",
            "Epoch:0 Step:2848 Training_loss:0.671923, Acc_avg:54.25% Training_loss_avg:0.685667\n",
            "Epoch:0 Step:2856 Training_loss:0.705340, Acc_avg:54.50% Training_loss_avg:0.685199\n",
            "Epoch:0 Step:2864 Training_loss:0.654107, Acc_avg:55.50% Training_loss_avg:0.683164\n",
            "Epoch:0 Step:2872 Training_loss:0.674400, Acc_avg:55.50% Training_loss_avg:0.683162\n",
            "Epoch:0 Step:2880 Training_loss:0.673600, Acc_avg:55.00% Training_loss_avg:0.683866\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2880 Val_loss:0.672266, Val_Acc_avg:60.50%\n",
            "Epoch:0 Step:2888 Training_loss:0.744665, Acc_avg:54.50% Training_loss_avg:0.685228\n",
            "Epoch:0 Step:2896 Training_loss:0.750064, Acc_avg:54.50% Training_loss_avg:0.685496\n",
            "Epoch:0 Step:2904 Training_loss:0.706204, Acc_avg:54.25% Training_loss_avg:0.686730\n",
            "Epoch:0 Step:2912 Training_loss:0.696163, Acc_avg:53.25% Training_loss_avg:0.688035\n",
            "Epoch:0 Step:2920 Training_loss:0.690088, Acc_avg:53.00% Training_loss_avg:0.689155\n",
            "Epoch:0 Step:2928 Training_loss:0.745765, Acc_avg:52.50% Training_loss_avg:0.690462\n",
            "Epoch:0 Step:2936 Training_loss:0.684739, Acc_avg:52.25% Training_loss_avg:0.689747\n",
            "Epoch:0 Step:2944 Training_loss:0.616119, Acc_avg:52.75% Training_loss_avg:0.687610\n",
            "Epoch:0 Step:2952 Training_loss:0.634639, Acc_avg:53.00% Training_loss_avg:0.685299\n",
            "Epoch:0 Step:2960 Training_loss:0.720799, Acc_avg:53.25% Training_loss_avg:0.686313\n",
            "Epoch:0 Step:2968 Training_loss:0.654796, Acc_avg:53.50% Training_loss_avg:0.684841\n",
            "Epoch:0 Step:2976 Training_loss:0.631811, Acc_avg:53.50% Training_loss_avg:0.685568\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:2976 Val_loss:0.681147, Val_Acc_avg:56.75%\n",
            "Epoch:0 Step:2984 Training_loss:0.631236, Acc_avg:53.00% Training_loss_avg:0.686458\n",
            "Epoch:0 Step:2992 Training_loss:0.607984, Acc_avg:53.25% Training_loss_avg:0.685163\n",
            "Epoch:0 Step:3000 Training_loss:0.619883, Acc_avg:53.25% Training_loss_avg:0.684036\n",
            "Epoch:0 Step:3008 Training_loss:0.669496, Acc_avg:53.25% Training_loss_avg:0.683850\n",
            "Epoch:0 Step:3016 Training_loss:0.717277, Acc_avg:53.75% Training_loss_avg:0.682694\n",
            "Epoch:0 Step:3024 Training_loss:0.732318, Acc_avg:53.00% Training_loss_avg:0.684708\n",
            "Epoch:0 Step:3032 Training_loss:0.682413, Acc_avg:53.25% Training_loss_avg:0.684079\n",
            "Epoch:0 Step:3040 Training_loss:0.757986, Acc_avg:52.50% Training_loss_avg:0.686807\n",
            "Epoch:0 Step:3048 Training_loss:0.716631, Acc_avg:53.50% Training_loss_avg:0.685468\n",
            "Epoch:0 Step:3056 Training_loss:0.705193, Acc_avg:53.25% Training_loss_avg:0.687531\n",
            "Epoch:0 Step:3064 Training_loss:0.641925, Acc_avg:54.00% Training_loss_avg:0.686417\n",
            "Epoch:0 Step:3072 Training_loss:0.612867, Acc_avg:53.75% Training_loss_avg:0.687754\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:3072 Val_loss:0.681002, Val_Acc_avg:56.75%\n",
            "Epoch:0 Step:3080 Training_loss:0.688653, Acc_avg:53.50% Training_loss_avg:0.688590\n",
            "Epoch:0 Step:3088 Training_loss:0.735623, Acc_avg:53.25% Training_loss_avg:0.688552\n",
            "Epoch:0 Step:3096 Training_loss:0.690940, Acc_avg:53.00% Training_loss_avg:0.688375\n",
            "Epoch:0 Step:3104 Training_loss:0.729293, Acc_avg:53.00% Training_loss_avg:0.689105\n",
            "Epoch:0 Step:3112 Training_loss:0.742096, Acc_avg:52.75% Training_loss_avg:0.690379\n",
            "Epoch:0 Step:3120 Training_loss:0.738842, Acc_avg:52.50% Training_loss_avg:0.691191\n",
            "Epoch:0 Step:3128 Training_loss:0.652422, Acc_avg:52.50% Training_loss_avg:0.691394\n",
            "Epoch:0 Step:3136 Training_loss:0.716934, Acc_avg:52.50% Training_loss_avg:0.691198\n",
            "Epoch:0 Step:3144 Training_loss:0.693490, Acc_avg:53.00% Training_loss_avg:0.691253\n",
            "Epoch:0 Step:3152 Training_loss:0.635780, Acc_avg:54.00% Training_loss_avg:0.689731\n",
            "Epoch:0 Step:3160 Training_loss:0.651299, Acc_avg:54.00% Training_loss_avg:0.688726\n",
            "Epoch:0 Step:3168 Training_loss:0.628989, Acc_avg:54.50% Training_loss_avg:0.687855\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:3168 Val_loss:0.673334, Val_Acc_avg:59.25%\n",
            "Epoch:0 Step:3176 Training_loss:0.740100, Acc_avg:53.75% Training_loss_avg:0.689803\n",
            "Epoch:0 Step:3184 Training_loss:0.651708, Acc_avg:54.50% Training_loss_avg:0.686760\n",
            "Epoch:0 Step:3192 Training_loss:0.682624, Acc_avg:54.50% Training_loss_avg:0.685940\n",
            "Epoch:0 Step:3200 Training_loss:0.731256, Acc_avg:54.00% Training_loss_avg:0.687236\n",
            "Epoch:0 Step:3208 Training_loss:0.735740, Acc_avg:54.00% Training_loss_avg:0.688103\n",
            "Epoch:0 Step:3216 Training_loss:0.752705, Acc_avg:53.75% Training_loss_avg:0.689053\n",
            "Epoch:0 Step:3224 Training_loss:0.663435, Acc_avg:54.25% Training_loss_avg:0.688399\n",
            "Epoch:0 Step:3232 Training_loss:0.656267, Acc_avg:55.25% Training_loss_avg:0.685671\n",
            "Epoch:0 Step:3240 Training_loss:0.713402, Acc_avg:54.75% Training_loss_avg:0.687641\n",
            "Epoch:0 Step:3248 Training_loss:0.643672, Acc_avg:54.50% Training_loss_avg:0.687076\n",
            "Epoch:0 Step:3256 Training_loss:0.598508, Acc_avg:55.00% Training_loss_avg:0.684939\n",
            "Epoch:0 Step:3264 Training_loss:0.690116, Acc_avg:55.25% Training_loss_avg:0.685659\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0 Step:3264 Val_loss:0.669961, Val_Acc_avg:61.75%\n",
            "Epoch:0 Step:3272 Training_loss:0.742617, Acc_avg:54.50% Training_loss_avg:0.687023\n",
            "Epoch:0 Step:3280 Training_loss:0.656904, Acc_avg:54.50% Training_loss_avg:0.686690\n",
            "Epoch:0 Step:3288 Training_loss:0.783309, Acc_avg:54.50% Training_loss_avg:0.687462\n",
            "Epoch:0 Step:3296 Training_loss:0.641883, Acc_avg:54.75% Training_loss_avg:0.685299\n",
            "Epoch:0 Step:3304 Training_loss:0.676324, Acc_avg:54.75% Training_loss_avg:0.684701\n",
            "Epoch:0 Step:3312 Training_loss:0.645252, Acc_avg:55.25% Training_loss_avg:0.683683\n",
            "Epoch:0 Step:3320 Training_loss:0.726867, Acc_avg:54.75% Training_loss_avg:0.684419\n",
            "Epoch:0 Step:3328 Training_loss:0.674193, Acc_avg:55.58% Training_loss_avg:0.682987\n",
            "Epoch:1 Step:0 Training_loss:0.690213, Acc_avg:55.83% Training_loss_avg:0.683097\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:0 Val_loss:0.668734, Val_Acc_avg:60.50%\n",
            "Epoch:1 Step:8 Training_loss:0.651958, Acc_avg:55.58% Training_loss_avg:0.683813\n",
            "Epoch:1 Step:16 Training_loss:0.722899, Acc_avg:55.08% Training_loss_avg:0.685579\n",
            "Epoch:1 Step:24 Training_loss:0.576377, Acc_avg:55.58% Training_loss_avg:0.682690\n",
            "Epoch:1 Step:32 Training_loss:0.619055, Acc_avg:55.33% Training_loss_avg:0.681975\n",
            "Epoch:1 Step:40 Training_loss:0.648033, Acc_avg:55.08% Training_loss_avg:0.682300\n",
            "Epoch:1 Step:48 Training_loss:0.567909, Acc_avg:55.33% Training_loss_avg:0.681033\n",
            "Epoch:1 Step:56 Training_loss:0.644669, Acc_avg:55.33% Training_loss_avg:0.681767\n",
            "Epoch:1 Step:64 Training_loss:0.713632, Acc_avg:55.33% Training_loss_avg:0.683642\n",
            "Epoch:1 Step:72 Training_loss:0.637187, Acc_avg:55.08% Training_loss_avg:0.682996\n",
            "Epoch:1 Step:80 Training_loss:0.699869, Acc_avg:55.08% Training_loss_avg:0.682648\n",
            "Epoch:1 Step:88 Training_loss:0.621183, Acc_avg:55.58% Training_loss_avg:0.680425\n",
            "Epoch:1 Step:96 Training_loss:0.803581, Acc_avg:54.83% Training_loss_avg:0.682848\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:96 Val_loss:0.678683, Val_Acc_avg:58.00%\n",
            "Epoch:1 Step:104 Training_loss:0.779760, Acc_avg:55.08% Training_loss_avg:0.683284\n",
            "Epoch:1 Step:112 Training_loss:0.750584, Acc_avg:54.83% Training_loss_avg:0.683963\n",
            "Epoch:1 Step:120 Training_loss:0.581824, Acc_avg:55.08% Training_loss_avg:0.681495\n",
            "Epoch:1 Step:128 Training_loss:0.695454, Acc_avg:54.58% Training_loss_avg:0.682566\n",
            "Epoch:1 Step:136 Training_loss:0.662837, Acc_avg:54.33% Training_loss_avg:0.683565\n",
            "Epoch:1 Step:144 Training_loss:0.673771, Acc_avg:54.58% Training_loss_avg:0.683268\n",
            "Epoch:1 Step:152 Training_loss:0.595497, Acc_avg:55.83% Training_loss_avg:0.680465\n",
            "Epoch:1 Step:160 Training_loss:0.572772, Acc_avg:56.58% Training_loss_avg:0.678102\n",
            "Epoch:1 Step:168 Training_loss:0.793293, Acc_avg:56.33% Training_loss_avg:0.679382\n",
            "Epoch:1 Step:176 Training_loss:0.613608, Acc_avg:57.08% Training_loss_avg:0.676812\n",
            "Epoch:1 Step:184 Training_loss:0.551793, Acc_avg:57.83% Training_loss_avg:0.673071\n",
            "Epoch:1 Step:192 Training_loss:0.628277, Acc_avg:58.08% Training_loss_avg:0.672588\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:192 Val_loss:0.672880, Val_Acc_avg:58.25%\n",
            "Epoch:1 Step:200 Training_loss:0.687613, Acc_avg:58.08% Training_loss_avg:0.672002\n",
            "Epoch:1 Step:208 Training_loss:0.721096, Acc_avg:57.83% Training_loss_avg:0.672554\n",
            "Epoch:1 Step:216 Training_loss:0.675309, Acc_avg:57.33% Training_loss_avg:0.673344\n",
            "Epoch:1 Step:224 Training_loss:0.909146, Acc_avg:56.58% Training_loss_avg:0.678501\n",
            "Epoch:1 Step:232 Training_loss:0.668948, Acc_avg:55.58% Training_loss_avg:0.679301\n",
            "Epoch:1 Step:240 Training_loss:0.596125, Acc_avg:56.58% Training_loss_avg:0.676421\n",
            "Epoch:1 Step:248 Training_loss:0.668225, Acc_avg:56.83% Training_loss_avg:0.676751\n",
            "Epoch:1 Step:256 Training_loss:0.698366, Acc_avg:56.83% Training_loss_avg:0.677066\n",
            "Epoch:1 Step:264 Training_loss:0.685320, Acc_avg:57.08% Training_loss_avg:0.676148\n",
            "Epoch:1 Step:272 Training_loss:0.564663, Acc_avg:57.83% Training_loss_avg:0.672726\n",
            "Epoch:1 Step:280 Training_loss:0.752108, Acc_avg:58.08% Training_loss_avg:0.672714\n",
            "Epoch:1 Step:288 Training_loss:0.681477, Acc_avg:57.83% Training_loss_avg:0.673075\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:288 Val_loss:0.666186, Val_Acc_avg:60.50%\n",
            "Epoch:1 Step:296 Training_loss:0.691580, Acc_avg:57.58% Training_loss_avg:0.673781\n",
            "Epoch:1 Step:304 Training_loss:0.654433, Acc_avg:57.83% Training_loss_avg:0.672602\n",
            "Epoch:1 Step:312 Training_loss:0.636101, Acc_avg:58.58% Training_loss_avg:0.672450\n",
            "Epoch:1 Step:320 Training_loss:0.616011, Acc_avg:58.58% Training_loss_avg:0.672800\n",
            "Epoch:1 Step:328 Training_loss:0.720852, Acc_avg:57.58% Training_loss_avg:0.673415\n",
            "Epoch:1 Step:336 Training_loss:0.556846, Acc_avg:58.83% Training_loss_avg:0.669700\n",
            "Epoch:1 Step:344 Training_loss:0.567666, Acc_avg:59.58% Training_loss_avg:0.667915\n",
            "Epoch:1 Step:352 Training_loss:0.658449, Acc_avg:59.83% Training_loss_avg:0.665418\n",
            "Epoch:1 Step:360 Training_loss:0.694578, Acc_avg:59.83% Training_loss_avg:0.666472\n",
            "Epoch:1 Step:368 Training_loss:0.678399, Acc_avg:59.83% Training_loss_avg:0.666513\n",
            "Epoch:1 Step:376 Training_loss:0.813154, Acc_avg:59.08% Training_loss_avg:0.669871\n",
            "Epoch:1 Step:384 Training_loss:0.672058, Acc_avg:59.08% Training_loss_avg:0.668775\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:384 Val_loss:0.663713, Val_Acc_avg:60.00%\n",
            "Epoch:1 Step:392 Training_loss:0.638192, Acc_avg:58.75% Training_loss_avg:0.668055\n",
            "Epoch:1 Step:400 Training_loss:0.691284, Acc_avg:58.50% Training_loss_avg:0.668076\n",
            "Epoch:1 Step:408 Training_loss:0.657246, Acc_avg:58.50% Training_loss_avg:0.668182\n",
            "Epoch:1 Step:416 Training_loss:0.723765, Acc_avg:58.75% Training_loss_avg:0.668199\n",
            "Epoch:1 Step:424 Training_loss:0.685638, Acc_avg:58.75% Training_loss_avg:0.670385\n",
            "Epoch:1 Step:432 Training_loss:0.728688, Acc_avg:58.50% Training_loss_avg:0.672577\n",
            "Epoch:1 Step:440 Training_loss:0.677259, Acc_avg:58.00% Training_loss_avg:0.673162\n",
            "Epoch:1 Step:448 Training_loss:0.532690, Acc_avg:58.25% Training_loss_avg:0.672458\n",
            "Epoch:1 Step:456 Training_loss:0.726867, Acc_avg:57.50% Training_loss_avg:0.674101\n",
            "Epoch:1 Step:464 Training_loss:0.666727, Acc_avg:57.50% Training_loss_avg:0.673163\n",
            "Epoch:1 Step:472 Training_loss:0.679716, Acc_avg:56.75% Training_loss_avg:0.674014\n",
            "Epoch:1 Step:480 Training_loss:0.632693, Acc_avg:56.75% Training_loss_avg:0.672670\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:480 Val_loss:0.664887, Val_Acc_avg:61.50%\n",
            "Epoch:1 Step:488 Training_loss:0.572239, Acc_avg:57.00% Training_loss_avg:0.671692\n",
            "Epoch:1 Step:496 Training_loss:0.677580, Acc_avg:57.50% Training_loss_avg:0.669172\n",
            "Epoch:1 Step:504 Training_loss:0.556623, Acc_avg:58.00% Training_loss_avg:0.664709\n",
            "Epoch:1 Step:512 Training_loss:0.674626, Acc_avg:58.00% Training_loss_avg:0.663190\n",
            "Epoch:1 Step:520 Training_loss:0.721476, Acc_avg:58.00% Training_loss_avg:0.665983\n",
            "Epoch:1 Step:528 Training_loss:0.600331, Acc_avg:58.50% Training_loss_avg:0.664080\n",
            "Epoch:1 Step:536 Training_loss:0.701760, Acc_avg:57.75% Training_loss_avg:0.664859\n",
            "Epoch:1 Step:544 Training_loss:0.715252, Acc_avg:57.25% Training_loss_avg:0.665688\n",
            "Epoch:1 Step:552 Training_loss:0.550824, Acc_avg:57.25% Training_loss_avg:0.664795\n",
            "Epoch:1 Step:560 Training_loss:0.731026, Acc_avg:56.50% Training_loss_avg:0.667960\n",
            "Epoch:1 Step:568 Training_loss:0.557834, Acc_avg:57.50% Training_loss_avg:0.663251\n",
            "Epoch:1 Step:576 Training_loss:0.568669, Acc_avg:57.50% Training_loss_avg:0.662352\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:576 Val_loss:0.669614, Val_Acc_avg:59.75%\n",
            "Epoch:1 Step:584 Training_loss:0.702509, Acc_avg:57.25% Training_loss_avg:0.665366\n",
            "Epoch:1 Step:592 Training_loss:0.709956, Acc_avg:56.50% Training_loss_avg:0.667000\n",
            "Epoch:1 Step:600 Training_loss:0.492732, Acc_avg:57.50% Training_loss_avg:0.663102\n",
            "Epoch:1 Step:608 Training_loss:0.709719, Acc_avg:57.50% Training_loss_avg:0.662875\n",
            "Epoch:1 Step:616 Training_loss:0.695225, Acc_avg:57.50% Training_loss_avg:0.663273\n",
            "Epoch:1 Step:624 Training_loss:0.722046, Acc_avg:58.00% Training_loss_avg:0.659531\n",
            "Epoch:1 Step:632 Training_loss:0.754569, Acc_avg:58.00% Training_loss_avg:0.661243\n",
            "Epoch:1 Step:640 Training_loss:0.706228, Acc_avg:57.25% Training_loss_avg:0.663445\n",
            "Epoch:1 Step:648 Training_loss:0.724252, Acc_avg:56.75% Training_loss_avg:0.664566\n",
            "Epoch:1 Step:656 Training_loss:0.538140, Acc_avg:57.75% Training_loss_avg:0.661361\n",
            "Epoch:1 Step:664 Training_loss:0.728355, Acc_avg:57.75% Training_loss_avg:0.662222\n",
            "Epoch:1 Step:672 Training_loss:0.731414, Acc_avg:57.25% Training_loss_avg:0.665557\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:672 Val_loss:0.663169, Val_Acc_avg:61.50%\n",
            "Epoch:1 Step:680 Training_loss:0.631043, Acc_avg:58.25% Training_loss_avg:0.663136\n",
            "Epoch:1 Step:688 Training_loss:0.583288, Acc_avg:58.75% Training_loss_avg:0.661172\n",
            "Epoch:1 Step:696 Training_loss:0.694353, Acc_avg:58.50% Training_loss_avg:0.661228\n",
            "Epoch:1 Step:704 Training_loss:0.674682, Acc_avg:58.50% Training_loss_avg:0.661633\n",
            "Epoch:1 Step:712 Training_loss:0.623149, Acc_avg:58.50% Training_loss_avg:0.661374\n",
            "Epoch:1 Step:720 Training_loss:0.834297, Acc_avg:57.75% Training_loss_avg:0.665739\n",
            "Epoch:1 Step:728 Training_loss:0.682869, Acc_avg:58.25% Training_loss_avg:0.664980\n",
            "Epoch:1 Step:736 Training_loss:0.650708, Acc_avg:58.00% Training_loss_avg:0.666857\n",
            "Epoch:1 Step:744 Training_loss:0.744423, Acc_avg:56.50% Training_loss_avg:0.670392\n",
            "Epoch:1 Step:752 Training_loss:0.682261, Acc_avg:56.75% Training_loss_avg:0.670868\n",
            "Epoch:1 Step:760 Training_loss:0.667111, Acc_avg:57.00% Training_loss_avg:0.670319\n",
            "Epoch:1 Step:768 Training_loss:0.619419, Acc_avg:57.75% Training_loss_avg:0.669139\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:768 Val_loss:0.669732, Val_Acc_avg:59.25%\n",
            "Epoch:1 Step:776 Training_loss:0.688802, Acc_avg:58.50% Training_loss_avg:0.666652\n",
            "Epoch:1 Step:784 Training_loss:0.554280, Acc_avg:59.25% Training_loss_avg:0.664297\n",
            "Epoch:1 Step:792 Training_loss:0.763362, Acc_avg:59.00% Training_loss_avg:0.666800\n",
            "Epoch:1 Step:800 Training_loss:0.658103, Acc_avg:59.25% Training_loss_avg:0.666136\n",
            "Epoch:1 Step:808 Training_loss:0.560991, Acc_avg:60.00% Training_loss_avg:0.664211\n",
            "Epoch:1 Step:816 Training_loss:0.727612, Acc_avg:60.00% Training_loss_avg:0.664288\n",
            "Epoch:1 Step:824 Training_loss:0.609315, Acc_avg:59.50% Training_loss_avg:0.662762\n",
            "Epoch:1 Step:832 Training_loss:0.631932, Acc_avg:59.75% Training_loss_avg:0.660827\n",
            "Epoch:1 Step:840 Training_loss:0.681954, Acc_avg:60.25% Training_loss_avg:0.660921\n",
            "Epoch:1 Step:848 Training_loss:0.561495, Acc_avg:60.50% Training_loss_avg:0.661497\n",
            "Epoch:1 Step:856 Training_loss:0.678407, Acc_avg:60.75% Training_loss_avg:0.660527\n",
            "Epoch:1 Step:864 Training_loss:0.686063, Acc_avg:60.50% Training_loss_avg:0.660914\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:864 Val_loss:0.665938, Val_Acc_avg:58.50%\n",
            "Epoch:1 Step:872 Training_loss:0.679309, Acc_avg:61.25% Training_loss_avg:0.660906\n",
            "Epoch:1 Step:880 Training_loss:0.639281, Acc_avg:61.25% Training_loss_avg:0.661038\n",
            "Epoch:1 Step:888 Training_loss:0.704734, Acc_avg:60.25% Training_loss_avg:0.663688\n",
            "Epoch:1 Step:896 Training_loss:0.581169, Acc_avg:61.00% Training_loss_avg:0.661760\n",
            "Epoch:1 Step:904 Training_loss:0.711330, Acc_avg:60.50% Training_loss_avg:0.664854\n",
            "Epoch:1 Step:912 Training_loss:0.706593, Acc_avg:60.75% Training_loss_avg:0.665493\n",
            "Epoch:1 Step:920 Training_loss:0.781735, Acc_avg:60.00% Training_loss_avg:0.666698\n",
            "Epoch:1 Step:928 Training_loss:0.570951, Acc_avg:59.75% Training_loss_avg:0.666111\n",
            "Epoch:1 Step:936 Training_loss:0.626324, Acc_avg:60.75% Training_loss_avg:0.664602\n",
            "Epoch:1 Step:944 Training_loss:0.666698, Acc_avg:61.50% Training_loss_avg:0.663631\n",
            "Epoch:1 Step:952 Training_loss:0.740564, Acc_avg:61.00% Training_loss_avg:0.667426\n",
            "Epoch:1 Step:960 Training_loss:0.616010, Acc_avg:61.75% Training_loss_avg:0.665125\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:960 Val_loss:0.662367, Val_Acc_avg:61.75%\n",
            "Epoch:1 Step:968 Training_loss:0.764092, Acc_avg:60.75% Training_loss_avg:0.669250\n",
            "Epoch:1 Step:976 Training_loss:0.585345, Acc_avg:60.50% Training_loss_avg:0.669584\n",
            "Epoch:1 Step:984 Training_loss:0.757024, Acc_avg:59.75% Training_loss_avg:0.670674\n",
            "Epoch:1 Step:992 Training_loss:0.777928, Acc_avg:59.75% Training_loss_avg:0.672034\n",
            "Epoch:1 Step:1000 Training_loss:0.731690, Acc_avg:58.50% Training_loss_avg:0.676813\n",
            "Epoch:1 Step:1008 Training_loss:0.905098, Acc_avg:58.25% Training_loss_avg:0.680720\n",
            "Epoch:1 Step:1016 Training_loss:0.633896, Acc_avg:57.75% Training_loss_avg:0.679494\n",
            "Epoch:1 Step:1024 Training_loss:0.677696, Acc_avg:58.25% Training_loss_avg:0.678607\n",
            "Epoch:1 Step:1032 Training_loss:0.736412, Acc_avg:58.25% Training_loss_avg:0.678244\n",
            "Epoch:1 Step:1040 Training_loss:0.857557, Acc_avg:58.75% Training_loss_avg:0.681270\n",
            "Epoch:1 Step:1048 Training_loss:0.593295, Acc_avg:59.50% Training_loss_avg:0.678651\n",
            "Epoch:1 Step:1056 Training_loss:0.867124, Acc_avg:58.00% Training_loss_avg:0.685231\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1056 Val_loss:0.661306, Val_Acc_avg:61.25%\n",
            "Epoch:1 Step:1064 Training_loss:0.626224, Acc_avg:58.25% Training_loss_avg:0.683188\n",
            "Epoch:1 Step:1072 Training_loss:0.677764, Acc_avg:58.00% Training_loss_avg:0.682115\n",
            "Epoch:1 Step:1080 Training_loss:0.710358, Acc_avg:57.25% Training_loss_avg:0.683702\n",
            "Epoch:1 Step:1088 Training_loss:0.579107, Acc_avg:57.00% Training_loss_avg:0.683618\n",
            "Epoch:1 Step:1096 Training_loss:0.721858, Acc_avg:57.00% Training_loss_avg:0.684168\n",
            "Epoch:1 Step:1104 Training_loss:0.756831, Acc_avg:56.25% Training_loss_avg:0.685811\n",
            "Epoch:1 Step:1112 Training_loss:0.678801, Acc_avg:55.75% Training_loss_avg:0.686924\n",
            "Epoch:1 Step:1120 Training_loss:0.645979, Acc_avg:56.00% Training_loss_avg:0.683158\n",
            "Epoch:1 Step:1128 Training_loss:0.638492, Acc_avg:56.25% Training_loss_avg:0.682270\n",
            "Epoch:1 Step:1136 Training_loss:0.675308, Acc_avg:55.75% Training_loss_avg:0.682762\n",
            "Epoch:1 Step:1144 Training_loss:0.778749, Acc_avg:56.25% Training_loss_avg:0.683449\n",
            "Epoch:1 Step:1152 Training_loss:0.632830, Acc_avg:56.50% Training_loss_avg:0.682460\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1152 Val_loss:0.660931, Val_Acc_avg:61.00%\n",
            "Epoch:1 Step:1160 Training_loss:0.654060, Acc_avg:56.25% Training_loss_avg:0.682199\n",
            "Epoch:1 Step:1168 Training_loss:0.735832, Acc_avg:55.50% Training_loss_avg:0.684527\n",
            "Epoch:1 Step:1176 Training_loss:0.690940, Acc_avg:55.25% Training_loss_avg:0.684570\n",
            "Epoch:1 Step:1184 Training_loss:0.751214, Acc_avg:54.25% Training_loss_avg:0.688509\n",
            "Epoch:1 Step:1192 Training_loss:0.623836, Acc_avg:55.00% Training_loss_avg:0.685718\n",
            "Epoch:1 Step:1200 Training_loss:0.713066, Acc_avg:54.75% Training_loss_avg:0.686817\n",
            "Epoch:1 Step:1208 Training_loss:0.718632, Acc_avg:53.75% Training_loss_avg:0.689970\n",
            "Epoch:1 Step:1216 Training_loss:0.632382, Acc_avg:54.25% Training_loss_avg:0.688066\n",
            "Epoch:1 Step:1224 Training_loss:0.692070, Acc_avg:54.00% Training_loss_avg:0.689721\n",
            "Epoch:1 Step:1232 Training_loss:0.628459, Acc_avg:54.50% Training_loss_avg:0.689651\n",
            "Epoch:1 Step:1240 Training_loss:0.688266, Acc_avg:54.25% Training_loss_avg:0.689778\n",
            "Epoch:1 Step:1248 Training_loss:0.630826, Acc_avg:53.75% Training_loss_avg:0.691164\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1248 Val_loss:0.660481, Val_Acc_avg:61.50%\n",
            "Epoch:1 Step:1256 Training_loss:0.724536, Acc_avg:53.50% Training_loss_avg:0.692087\n",
            "Epoch:1 Step:1264 Training_loss:0.680488, Acc_avg:54.00% Training_loss_avg:0.691975\n",
            "Epoch:1 Step:1272 Training_loss:0.775512, Acc_avg:53.25% Training_loss_avg:0.693899\n",
            "Epoch:1 Step:1280 Training_loss:0.705924, Acc_avg:53.00% Training_loss_avg:0.695232\n",
            "Epoch:1 Step:1288 Training_loss:0.660121, Acc_avg:53.25% Training_loss_avg:0.694340\n",
            "Epoch:1 Step:1296 Training_loss:0.616036, Acc_avg:53.00% Training_loss_avg:0.695037\n",
            "Epoch:1 Step:1304 Training_loss:0.656798, Acc_avg:53.50% Training_loss_avg:0.693947\n",
            "Epoch:1 Step:1312 Training_loss:0.589967, Acc_avg:54.25% Training_loss_avg:0.691614\n",
            "Epoch:1 Step:1320 Training_loss:0.717260, Acc_avg:54.25% Training_loss_avg:0.690325\n",
            "Epoch:1 Step:1328 Training_loss:0.614529, Acc_avg:54.25% Training_loss_avg:0.691196\n",
            "Epoch:1 Step:1336 Training_loss:0.716051, Acc_avg:53.50% Training_loss_avg:0.692991\n",
            "Epoch:1 Step:1344 Training_loss:0.751720, Acc_avg:53.00% Training_loss_avg:0.694691\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1344 Val_loss:0.661707, Val_Acc_avg:61.00%\n",
            "Epoch:1 Step:1352 Training_loss:0.562845, Acc_avg:53.50% Training_loss_avg:0.691137\n",
            "Epoch:1 Step:1360 Training_loss:0.628945, Acc_avg:53.50% Training_loss_avg:0.691395\n",
            "Epoch:1 Step:1368 Training_loss:0.661350, Acc_avg:53.75% Training_loss_avg:0.689341\n",
            "Epoch:1 Step:1376 Training_loss:0.699849, Acc_avg:53.50% Training_loss_avg:0.691631\n",
            "Epoch:1 Step:1384 Training_loss:0.730435, Acc_avg:54.00% Training_loss_avg:0.691099\n",
            "Epoch:1 Step:1392 Training_loss:0.694997, Acc_avg:54.25% Training_loss_avg:0.689440\n",
            "Epoch:1 Step:1400 Training_loss:0.635436, Acc_avg:54.75% Training_loss_avg:0.687515\n",
            "Epoch:1 Step:1408 Training_loss:0.698768, Acc_avg:55.00% Training_loss_avg:0.683389\n",
            "Epoch:1 Step:1416 Training_loss:0.692136, Acc_avg:55.25% Training_loss_avg:0.684553\n",
            "Epoch:1 Step:1424 Training_loss:0.629759, Acc_avg:55.50% Training_loss_avg:0.683595\n",
            "Epoch:1 Step:1432 Training_loss:0.684368, Acc_avg:55.75% Training_loss_avg:0.682554\n",
            "Epoch:1 Step:1440 Training_loss:0.639565, Acc_avg:56.00% Training_loss_avg:0.678194\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1440 Val_loss:0.659182, Val_Acc_avg:61.25%\n",
            "Epoch:1 Step:1448 Training_loss:0.599599, Acc_avg:56.00% Training_loss_avg:0.678320\n",
            "Epoch:1 Step:1456 Training_loss:0.736122, Acc_avg:56.50% Training_loss_avg:0.675700\n",
            "Epoch:1 Step:1464 Training_loss:0.685554, Acc_avg:56.25% Training_loss_avg:0.676887\n",
            "Epoch:1 Step:1472 Training_loss:0.703914, Acc_avg:56.50% Training_loss_avg:0.677410\n",
            "Epoch:1 Step:1480 Training_loss:0.602333, Acc_avg:57.00% Training_loss_avg:0.675249\n",
            "Epoch:1 Step:1488 Training_loss:0.585738, Acc_avg:57.00% Training_loss_avg:0.675382\n",
            "Epoch:1 Step:1496 Training_loss:0.625531, Acc_avg:57.50% Training_loss_avg:0.673455\n",
            "Epoch:1 Step:1504 Training_loss:0.781024, Acc_avg:57.75% Training_loss_avg:0.673939\n",
            "Epoch:1 Step:1512 Training_loss:0.665054, Acc_avg:57.75% Training_loss_avg:0.673664\n",
            "Epoch:1 Step:1520 Training_loss:0.605007, Acc_avg:58.50% Training_loss_avg:0.672845\n",
            "Epoch:1 Step:1528 Training_loss:0.538581, Acc_avg:58.75% Training_loss_avg:0.670846\n",
            "Epoch:1 Step:1536 Training_loss:0.675532, Acc_avg:58.75% Training_loss_avg:0.670851\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1536 Val_loss:0.657634, Val_Acc_avg:62.00%\n",
            "Epoch:1 Step:1544 Training_loss:0.585924, Acc_avg:59.75% Training_loss_avg:0.666994\n",
            "Epoch:1 Step:1552 Training_loss:0.667041, Acc_avg:59.25% Training_loss_avg:0.667679\n",
            "Epoch:1 Step:1560 Training_loss:0.670494, Acc_avg:59.25% Training_loss_avg:0.668007\n",
            "Epoch:1 Step:1568 Training_loss:0.694583, Acc_avg:59.50% Training_loss_avg:0.667182\n",
            "Epoch:1 Step:1576 Training_loss:0.674762, Acc_avg:59.75% Training_loss_avg:0.666859\n",
            "Epoch:1 Step:1584 Training_loss:0.632711, Acc_avg:60.75% Training_loss_avg:0.664489\n",
            "Epoch:1 Step:1592 Training_loss:0.681663, Acc_avg:60.50% Training_loss_avg:0.665645\n",
            "Epoch:1 Step:1600 Training_loss:0.771677, Acc_avg:60.75% Training_loss_avg:0.666817\n",
            "Epoch:1 Step:1608 Training_loss:0.696538, Acc_avg:61.00% Training_loss_avg:0.666376\n",
            "Epoch:1 Step:1616 Training_loss:0.661713, Acc_avg:60.25% Training_loss_avg:0.666962\n",
            "Epoch:1 Step:1624 Training_loss:0.660864, Acc_avg:60.00% Training_loss_avg:0.666338\n",
            "Epoch:1 Step:1632 Training_loss:0.619801, Acc_avg:60.00% Training_loss_avg:0.666165\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1632 Val_loss:0.653342, Val_Acc_avg:61.50%\n",
            "Epoch:1 Step:1640 Training_loss:0.581915, Acc_avg:60.50% Training_loss_avg:0.664038\n",
            "Epoch:1 Step:1648 Training_loss:0.657344, Acc_avg:60.00% Training_loss_avg:0.664568\n",
            "Epoch:1 Step:1656 Training_loss:0.670531, Acc_avg:60.75% Training_loss_avg:0.663488\n",
            "Epoch:1 Step:1664 Training_loss:0.584748, Acc_avg:60.50% Training_loss_avg:0.661573\n",
            "Epoch:1 Step:1672 Training_loss:0.595888, Acc_avg:61.50% Training_loss_avg:0.657981\n",
            "Epoch:1 Step:1680 Training_loss:0.517623, Acc_avg:62.25% Training_loss_avg:0.654215\n",
            "Epoch:1 Step:1688 Training_loss:0.768866, Acc_avg:61.75% Training_loss_avg:0.656390\n",
            "Epoch:1 Step:1696 Training_loss:0.612495, Acc_avg:61.50% Training_loss_avg:0.656319\n",
            "Epoch:1 Step:1704 Training_loss:0.701095, Acc_avg:61.25% Training_loss_avg:0.657205\n",
            "Epoch:1 Step:1712 Training_loss:0.668212, Acc_avg:60.50% Training_loss_avg:0.658770\n",
            "Epoch:1 Step:1720 Training_loss:0.762901, Acc_avg:60.75% Training_loss_avg:0.659683\n",
            "Epoch:1 Step:1728 Training_loss:0.720947, Acc_avg:60.25% Training_loss_avg:0.661811\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1728 Val_loss:0.652147, Val_Acc_avg:62.75%\n",
            "Epoch:1 Step:1736 Training_loss:0.542785, Acc_avg:61.00% Training_loss_avg:0.658346\n",
            "Epoch:1 Step:1744 Training_loss:0.498811, Acc_avg:61.50% Training_loss_avg:0.653287\n",
            "Epoch:1 Step:1752 Training_loss:0.650630, Acc_avg:60.75% Training_loss_avg:0.655043\n",
            "Epoch:1 Step:1760 Training_loss:0.555149, Acc_avg:61.00% Training_loss_avg:0.653567\n",
            "Epoch:1 Step:1768 Training_loss:0.705060, Acc_avg:61.25% Training_loss_avg:0.654441\n",
            "Epoch:1 Step:1776 Training_loss:0.753476, Acc_avg:61.00% Training_loss_avg:0.655514\n",
            "Epoch:1 Step:1784 Training_loss:0.602554, Acc_avg:61.25% Training_loss_avg:0.652956\n",
            "Epoch:1 Step:1792 Training_loss:0.747081, Acc_avg:61.25% Training_loss_avg:0.653998\n",
            "Epoch:1 Step:1800 Training_loss:0.697597, Acc_avg:61.00% Training_loss_avg:0.655241\n",
            "Epoch:1 Step:1808 Training_loss:0.639118, Acc_avg:61.00% Training_loss_avg:0.654048\n",
            "Epoch:1 Step:1816 Training_loss:0.656108, Acc_avg:61.50% Training_loss_avg:0.653328\n",
            "Epoch:1 Step:1824 Training_loss:0.714292, Acc_avg:61.25% Training_loss_avg:0.655018\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1824 Val_loss:0.655548, Val_Acc_avg:62.00%\n",
            "Epoch:1 Step:1832 Training_loss:0.758070, Acc_avg:61.25% Training_loss_avg:0.656492\n",
            "Epoch:1 Step:1840 Training_loss:0.644228, Acc_avg:60.75% Training_loss_avg:0.656586\n",
            "Epoch:1 Step:1848 Training_loss:0.634013, Acc_avg:60.50% Training_loss_avg:0.657274\n",
            "Epoch:1 Step:1856 Training_loss:0.717449, Acc_avg:60.75% Training_loss_avg:0.656901\n",
            "Epoch:1 Step:1864 Training_loss:0.667547, Acc_avg:61.00% Training_loss_avg:0.656540\n",
            "Epoch:1 Step:1872 Training_loss:0.536570, Acc_avg:61.50% Training_loss_avg:0.653194\n",
            "Epoch:1 Step:1880 Training_loss:0.630811, Acc_avg:61.00% Training_loss_avg:0.653763\n",
            "Epoch:1 Step:1888 Training_loss:0.670688, Acc_avg:60.50% Training_loss_avg:0.655462\n",
            "Epoch:1 Step:1896 Training_loss:0.630568, Acc_avg:60.50% Training_loss_avg:0.655563\n",
            "Epoch:1 Step:1904 Training_loss:0.627578, Acc_avg:61.25% Training_loss_avg:0.652494\n",
            "Epoch:1 Step:1912 Training_loss:0.545484, Acc_avg:61.75% Training_loss_avg:0.650103\n",
            "Epoch:1 Step:1920 Training_loss:0.594843, Acc_avg:61.25% Training_loss_avg:0.649899\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:1920 Val_loss:0.653996, Val_Acc_avg:61.50%\n",
            "Epoch:1 Step:1928 Training_loss:0.625806, Acc_avg:60.50% Training_loss_avg:0.651644\n",
            "Epoch:1 Step:1936 Training_loss:0.616010, Acc_avg:61.00% Training_loss_avg:0.650453\n",
            "Epoch:1 Step:1944 Training_loss:0.585812, Acc_avg:60.75% Training_loss_avg:0.650451\n",
            "Epoch:1 Step:1952 Training_loss:0.544457, Acc_avg:61.25% Training_loss_avg:0.647999\n",
            "Epoch:1 Step:1960 Training_loss:0.654723, Acc_avg:61.25% Training_loss_avg:0.647684\n",
            "Epoch:1 Step:1968 Training_loss:0.615301, Acc_avg:61.25% Training_loss_avg:0.646098\n",
            "Epoch:1 Step:1976 Training_loss:0.751710, Acc_avg:61.00% Training_loss_avg:0.647637\n",
            "Epoch:1 Step:1984 Training_loss:0.598076, Acc_avg:61.00% Training_loss_avg:0.646945\n",
            "Epoch:1 Step:1992 Training_loss:0.688019, Acc_avg:61.25% Training_loss_avg:0.647072\n",
            "Epoch:1 Step:2000 Training_loss:0.694647, Acc_avg:61.00% Training_loss_avg:0.645531\n",
            "Epoch:1 Step:2008 Training_loss:0.754828, Acc_avg:60.50% Training_loss_avg:0.646697\n",
            "Epoch:1 Step:2016 Training_loss:0.798382, Acc_avg:60.25% Training_loss_avg:0.649430\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2016 Val_loss:0.648251, Val_Acc_avg:62.50%\n",
            "Epoch:1 Step:2024 Training_loss:0.563524, Acc_avg:61.25% Training_loss_avg:0.647483\n",
            "Epoch:1 Step:2032 Training_loss:0.643739, Acc_avg:61.00% Training_loss_avg:0.647962\n",
            "Epoch:1 Step:2040 Training_loss:0.778326, Acc_avg:60.50% Training_loss_avg:0.651890\n",
            "Epoch:1 Step:2048 Training_loss:0.600704, Acc_avg:60.75% Training_loss_avg:0.650758\n",
            "Epoch:1 Step:2056 Training_loss:0.911821, Acc_avg:59.25% Training_loss_avg:0.655583\n",
            "Epoch:1 Step:2064 Training_loss:0.874877, Acc_avg:58.25% Training_loss_avg:0.661386\n",
            "Epoch:1 Step:2072 Training_loss:0.551271, Acc_avg:58.50% Training_loss_avg:0.660494\n",
            "Epoch:1 Step:2080 Training_loss:0.706545, Acc_avg:57.50% Training_loss_avg:0.664272\n",
            "Epoch:1 Step:2088 Training_loss:0.699510, Acc_avg:58.25% Training_loss_avg:0.662885\n",
            "Epoch:1 Step:2096 Training_loss:0.567598, Acc_avg:58.50% Training_loss_avg:0.661987\n",
            "Epoch:1 Step:2104 Training_loss:0.707006, Acc_avg:58.25% Training_loss_avg:0.662105\n",
            "Epoch:1 Step:2112 Training_loss:0.575448, Acc_avg:58.75% Training_loss_avg:0.660250\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2112 Val_loss:0.647105, Val_Acc_avg:63.00%\n",
            "Epoch:1 Step:2120 Training_loss:0.742662, Acc_avg:58.50% Training_loss_avg:0.659845\n",
            "Epoch:1 Step:2128 Training_loss:0.665091, Acc_avg:59.00% Training_loss_avg:0.658728\n",
            "Epoch:1 Step:2136 Training_loss:0.562022, Acc_avg:59.00% Training_loss_avg:0.659113\n",
            "Epoch:1 Step:2144 Training_loss:0.625489, Acc_avg:59.00% Training_loss_avg:0.661646\n",
            "Epoch:1 Step:2152 Training_loss:0.601039, Acc_avg:59.75% Training_loss_avg:0.660655\n",
            "Epoch:1 Step:2160 Training_loss:0.645428, Acc_avg:59.25% Training_loss_avg:0.662460\n",
            "Epoch:1 Step:2168 Training_loss:0.501146, Acc_avg:60.00% Training_loss_avg:0.658382\n",
            "Epoch:1 Step:2176 Training_loss:0.734025, Acc_avg:60.50% Training_loss_avg:0.657993\n",
            "Epoch:1 Step:2184 Training_loss:0.590444, Acc_avg:60.75% Training_loss_avg:0.657751\n",
            "Epoch:1 Step:2192 Training_loss:0.704026, Acc_avg:61.00% Training_loss_avg:0.656890\n",
            "Epoch:1 Step:2200 Training_loss:0.851298, Acc_avg:60.50% Training_loss_avg:0.659964\n",
            "Epoch:1 Step:2208 Training_loss:0.829837, Acc_avg:60.50% Training_loss_avg:0.663778\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2208 Val_loss:0.677607, Val_Acc_avg:61.75%\n",
            "Epoch:1 Step:2216 Training_loss:0.803160, Acc_avg:59.75% Training_loss_avg:0.666719\n",
            "Epoch:1 Step:2224 Training_loss:0.752393, Acc_avg:59.75% Training_loss_avg:0.667481\n",
            "Epoch:1 Step:2232 Training_loss:0.814366, Acc_avg:59.50% Training_loss_avg:0.668607\n",
            "Epoch:1 Step:2240 Training_loss:0.580537, Acc_avg:59.75% Training_loss_avg:0.667333\n",
            "Epoch:1 Step:2248 Training_loss:0.662694, Acc_avg:59.75% Training_loss_avg:0.667907\n",
            "Epoch:1 Step:2256 Training_loss:0.670409, Acc_avg:59.75% Training_loss_avg:0.666966\n",
            "Epoch:1 Step:2264 Training_loss:0.624320, Acc_avg:59.75% Training_loss_avg:0.666101\n",
            "Epoch:1 Step:2272 Training_loss:0.717296, Acc_avg:59.50% Training_loss_avg:0.669716\n",
            "Epoch:1 Step:2280 Training_loss:0.571191, Acc_avg:60.00% Training_loss_avg:0.668524\n",
            "Epoch:1 Step:2288 Training_loss:0.512023, Acc_avg:60.75% Training_loss_avg:0.665350\n",
            "Epoch:1 Step:2296 Training_loss:0.671920, Acc_avg:60.50% Training_loss_avg:0.666177\n",
            "Epoch:1 Step:2304 Training_loss:0.786673, Acc_avg:59.50% Training_loss_avg:0.669359\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2304 Val_loss:0.652728, Val_Acc_avg:62.75%\n",
            "Epoch:1 Step:2312 Training_loss:0.686355, Acc_avg:59.25% Training_loss_avg:0.672177\n",
            "Epoch:1 Step:2320 Training_loss:0.796658, Acc_avg:59.00% Training_loss_avg:0.676213\n",
            "Epoch:1 Step:2328 Training_loss:0.615380, Acc_avg:59.50% Training_loss_avg:0.676004\n",
            "Epoch:1 Step:2336 Training_loss:0.618868, Acc_avg:59.25% Training_loss_avg:0.676062\n",
            "Epoch:1 Step:2344 Training_loss:0.609812, Acc_avg:59.50% Training_loss_avg:0.676542\n",
            "Epoch:1 Step:2352 Training_loss:0.587804, Acc_avg:59.50% Training_loss_avg:0.677408\n",
            "Epoch:1 Step:2360 Training_loss:0.701876, Acc_avg:59.25% Training_loss_avg:0.678352\n",
            "Epoch:1 Step:2368 Training_loss:0.619129, Acc_avg:59.50% Training_loss_avg:0.678428\n",
            "Epoch:1 Step:2376 Training_loss:0.659158, Acc_avg:60.00% Training_loss_avg:0.676577\n",
            "Epoch:1 Step:2384 Training_loss:0.713695, Acc_avg:59.75% Training_loss_avg:0.678889\n",
            "Epoch:1 Step:2392 Training_loss:0.590737, Acc_avg:59.50% Training_loss_avg:0.676944\n",
            "Epoch:1 Step:2400 Training_loss:0.728188, Acc_avg:59.50% Training_loss_avg:0.677615\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2400 Val_loss:0.653970, Val_Acc_avg:62.50%\n",
            "Epoch:1 Step:2408 Training_loss:0.635987, Acc_avg:60.00% Training_loss_avg:0.675238\n",
            "Epoch:1 Step:2416 Training_loss:0.625258, Acc_avg:60.75% Training_loss_avg:0.671775\n",
            "Epoch:1 Step:2424 Training_loss:0.700808, Acc_avg:59.75% Training_loss_avg:0.674521\n",
            "Epoch:1 Step:2432 Training_loss:0.859960, Acc_avg:58.75% Training_loss_avg:0.678845\n",
            "Epoch:1 Step:2440 Training_loss:0.575608, Acc_avg:59.25% Training_loss_avg:0.674791\n",
            "Epoch:1 Step:2448 Training_loss:0.615167, Acc_avg:59.25% Training_loss_avg:0.675080\n",
            "Epoch:1 Step:2456 Training_loss:0.571115, Acc_avg:60.75% Training_loss_avg:0.668266\n",
            "Epoch:1 Step:2464 Training_loss:0.718300, Acc_avg:61.25% Training_loss_avg:0.665135\n",
            "Epoch:1 Step:2472 Training_loss:0.602154, Acc_avg:61.00% Training_loss_avg:0.666152\n",
            "Epoch:1 Step:2480 Training_loss:0.594838, Acc_avg:61.75% Training_loss_avg:0.663918\n",
            "Epoch:1 Step:2488 Training_loss:0.606986, Acc_avg:61.75% Training_loss_avg:0.662068\n",
            "Epoch:1 Step:2496 Training_loss:0.569957, Acc_avg:61.75% Training_loss_avg:0.662115\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2496 Val_loss:0.646861, Val_Acc_avg:63.00%\n",
            "Epoch:1 Step:2504 Training_loss:0.783504, Acc_avg:62.00% Training_loss_avg:0.663645\n",
            "Epoch:1 Step:2512 Training_loss:0.631271, Acc_avg:61.75% Training_loss_avg:0.664761\n",
            "Epoch:1 Step:2520 Training_loss:0.627552, Acc_avg:62.50% Training_loss_avg:0.662459\n",
            "Epoch:1 Step:2528 Training_loss:0.761130, Acc_avg:62.25% Training_loss_avg:0.664380\n",
            "Epoch:1 Step:2536 Training_loss:0.605146, Acc_avg:62.00% Training_loss_avg:0.665242\n",
            "Epoch:1 Step:2544 Training_loss:0.637474, Acc_avg:62.00% Training_loss_avg:0.665482\n",
            "Epoch:1 Step:2552 Training_loss:0.651386, Acc_avg:61.25% Training_loss_avg:0.666489\n",
            "Epoch:1 Step:2560 Training_loss:0.734046, Acc_avg:60.75% Training_loss_avg:0.668261\n",
            "Epoch:1 Step:2568 Training_loss:0.819637, Acc_avg:59.50% Training_loss_avg:0.674631\n",
            "Epoch:1 Step:2576 Training_loss:0.630081, Acc_avg:59.75% Training_loss_avg:0.672552\n",
            "Epoch:1 Step:2584 Training_loss:0.629731, Acc_avg:59.50% Training_loss_avg:0.673338\n",
            "Epoch:1 Step:2592 Training_loss:0.695209, Acc_avg:59.25% Training_loss_avg:0.673162\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2592 Val_loss:0.643632, Val_Acc_avg:63.00%\n",
            "Epoch:1 Step:2600 Training_loss:0.704447, Acc_avg:59.75% Training_loss_avg:0.670225\n",
            "Epoch:1 Step:2608 Training_loss:0.707551, Acc_avg:59.50% Training_loss_avg:0.667779\n",
            "Epoch:1 Step:2616 Training_loss:0.599133, Acc_avg:60.25% Training_loss_avg:0.663698\n",
            "Epoch:1 Step:2624 Training_loss:0.581849, Acc_avg:61.00% Training_loss_avg:0.660287\n",
            "Epoch:1 Step:2632 Training_loss:0.648527, Acc_avg:61.50% Training_loss_avg:0.656971\n",
            "Epoch:1 Step:2640 Training_loss:0.738558, Acc_avg:61.00% Training_loss_avg:0.660131\n",
            "Epoch:1 Step:2648 Training_loss:0.676194, Acc_avg:60.75% Training_loss_avg:0.660401\n",
            "Epoch:1 Step:2656 Training_loss:0.741807, Acc_avg:60.50% Training_loss_avg:0.661829\n",
            "Epoch:1 Step:2664 Training_loss:0.653239, Acc_avg:60.75% Training_loss_avg:0.662407\n",
            "Epoch:1 Step:2672 Training_loss:0.713685, Acc_avg:60.75% Training_loss_avg:0.662335\n",
            "Epoch:1 Step:2680 Training_loss:0.594100, Acc_avg:60.75% Training_loss_avg:0.662793\n",
            "Epoch:1 Step:2688 Training_loss:0.767918, Acc_avg:59.75% Training_loss_avg:0.667911\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2688 Val_loss:0.642840, Val_Acc_avg:63.00%\n",
            "Epoch:1 Step:2696 Training_loss:0.681504, Acc_avg:59.75% Training_loss_avg:0.668103\n",
            "Epoch:1 Step:2704 Training_loss:0.690020, Acc_avg:60.50% Training_loss_avg:0.666170\n",
            "Epoch:1 Step:2712 Training_loss:0.689907, Acc_avg:60.50% Training_loss_avg:0.666241\n",
            "Epoch:1 Step:2720 Training_loss:0.673087, Acc_avg:60.50% Training_loss_avg:0.663770\n",
            "Epoch:1 Step:2728 Training_loss:0.721883, Acc_avg:60.00% Training_loss_avg:0.665900\n",
            "Epoch:1 Step:2736 Training_loss:0.718491, Acc_avg:59.75% Training_loss_avg:0.667892\n",
            "Epoch:1 Step:2744 Training_loss:0.660105, Acc_avg:59.50% Training_loss_avg:0.668898\n",
            "Epoch:1 Step:2752 Training_loss:0.651954, Acc_avg:59.25% Training_loss_avg:0.670181\n",
            "Epoch:1 Step:2760 Training_loss:0.541386, Acc_avg:59.75% Training_loss_avg:0.666971\n",
            "Epoch:1 Step:2768 Training_loss:0.669907, Acc_avg:59.50% Training_loss_avg:0.667987\n",
            "Epoch:1 Step:2776 Training_loss:0.698670, Acc_avg:59.00% Training_loss_avg:0.668777\n",
            "Epoch:1 Step:2784 Training_loss:0.677093, Acc_avg:59.00% Training_loss_avg:0.668045\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2784 Val_loss:0.645385, Val_Acc_avg:63.25%\n",
            "Epoch:1 Step:2792 Training_loss:0.607485, Acc_avg:58.75% Training_loss_avg:0.668380\n",
            "Epoch:1 Step:2800 Training_loss:0.629773, Acc_avg:59.25% Training_loss_avg:0.666412\n",
            "Epoch:1 Step:2808 Training_loss:0.729949, Acc_avg:58.50% Training_loss_avg:0.668291\n",
            "Epoch:1 Step:2816 Training_loss:0.721722, Acc_avg:57.75% Training_loss_avg:0.670220\n",
            "Epoch:1 Step:2824 Training_loss:0.681840, Acc_avg:58.00% Training_loss_avg:0.669841\n",
            "Epoch:1 Step:2832 Training_loss:0.665210, Acc_avg:59.00% Training_loss_avg:0.665946\n",
            "Epoch:1 Step:2840 Training_loss:0.657605, Acc_avg:58.50% Training_loss_avg:0.667586\n",
            "Epoch:1 Step:2848 Training_loss:0.698568, Acc_avg:58.25% Training_loss_avg:0.669254\n",
            "Epoch:1 Step:2856 Training_loss:0.716295, Acc_avg:57.75% Training_loss_avg:0.672157\n",
            "Epoch:1 Step:2864 Training_loss:0.532260, Acc_avg:58.50% Training_loss_avg:0.668436\n",
            "Epoch:1 Step:2872 Training_loss:0.641286, Acc_avg:58.25% Training_loss_avg:0.669219\n",
            "Epoch:1 Step:2880 Training_loss:0.708998, Acc_avg:58.25% Training_loss_avg:0.671502\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2880 Val_loss:0.642833, Val_Acc_avg:62.75%\n",
            "Epoch:1 Step:2888 Training_loss:0.717792, Acc_avg:58.25% Training_loss_avg:0.673718\n",
            "Epoch:1 Step:2896 Training_loss:0.624450, Acc_avg:58.00% Training_loss_avg:0.674808\n",
            "Epoch:1 Step:2904 Training_loss:0.573042, Acc_avg:58.50% Training_loss_avg:0.670599\n",
            "Epoch:1 Step:2912 Training_loss:0.564979, Acc_avg:58.75% Training_loss_avg:0.669273\n",
            "Epoch:1 Step:2920 Training_loss:0.552203, Acc_avg:59.00% Training_loss_avg:0.667766\n",
            "Epoch:1 Step:2928 Training_loss:0.673355, Acc_avg:59.00% Training_loss_avg:0.666011\n",
            "Epoch:1 Step:2936 Training_loss:0.631079, Acc_avg:58.75% Training_loss_avg:0.666529\n",
            "Epoch:1 Step:2944 Training_loss:0.612465, Acc_avg:58.50% Training_loss_avg:0.666029\n",
            "Epoch:1 Step:2952 Training_loss:0.698206, Acc_avg:58.50% Training_loss_avg:0.666966\n",
            "Epoch:1 Step:2960 Training_loss:0.746091, Acc_avg:58.50% Training_loss_avg:0.667207\n",
            "Epoch:1 Step:2968 Training_loss:0.596900, Acc_avg:59.00% Training_loss_avg:0.662752\n",
            "Epoch:1 Step:2976 Training_loss:0.711279, Acc_avg:58.50% Training_loss_avg:0.664376\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:2976 Val_loss:0.641676, Val_Acc_avg:62.75%\n",
            "Epoch:1 Step:2984 Training_loss:0.650167, Acc_avg:59.00% Training_loss_avg:0.664784\n",
            "Epoch:1 Step:2992 Training_loss:0.478254, Acc_avg:60.00% Training_loss_avg:0.660445\n",
            "Epoch:1 Step:3000 Training_loss:0.772499, Acc_avg:59.50% Training_loss_avg:0.661806\n",
            "Epoch:1 Step:3008 Training_loss:0.722013, Acc_avg:59.75% Training_loss_avg:0.662096\n",
            "Epoch:1 Step:3016 Training_loss:0.638386, Acc_avg:59.25% Training_loss_avg:0.662881\n",
            "Epoch:1 Step:3024 Training_loss:0.627055, Acc_avg:58.25% Training_loss_avg:0.663785\n",
            "Epoch:1 Step:3032 Training_loss:0.700920, Acc_avg:58.00% Training_loss_avg:0.664833\n",
            "Epoch:1 Step:3040 Training_loss:0.810439, Acc_avg:57.75% Training_loss_avg:0.666270\n",
            "Epoch:1 Step:3048 Training_loss:0.600034, Acc_avg:58.25% Training_loss_avg:0.664747\n",
            "Epoch:1 Step:3056 Training_loss:0.835337, Acc_avg:57.75% Training_loss_avg:0.666618\n",
            "Epoch:1 Step:3064 Training_loss:0.604967, Acc_avg:57.75% Training_loss_avg:0.665652\n",
            "Epoch:1 Step:3072 Training_loss:0.754234, Acc_avg:57.25% Training_loss_avg:0.666463\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:3072 Val_loss:0.638546, Val_Acc_avg:62.75%\n",
            "Epoch:1 Step:3080 Training_loss:0.666182, Acc_avg:57.00% Training_loss_avg:0.667905\n",
            "Epoch:1 Step:3088 Training_loss:0.555292, Acc_avg:58.25% Training_loss_avg:0.663652\n",
            "Epoch:1 Step:3096 Training_loss:0.578849, Acc_avg:58.25% Training_loss_avg:0.661599\n",
            "Epoch:1 Step:3104 Training_loss:0.515164, Acc_avg:58.75% Training_loss_avg:0.658102\n",
            "Epoch:1 Step:3112 Training_loss:0.705805, Acc_avg:58.25% Training_loss_avg:0.658420\n",
            "Epoch:1 Step:3120 Training_loss:0.680663, Acc_avg:58.50% Training_loss_avg:0.658572\n",
            "Epoch:1 Step:3128 Training_loss:0.638313, Acc_avg:58.75% Training_loss_avg:0.656900\n",
            "Epoch:1 Step:3136 Training_loss:0.722679, Acc_avg:58.75% Training_loss_avg:0.656984\n",
            "Epoch:1 Step:3144 Training_loss:0.715725, Acc_avg:58.50% Training_loss_avg:0.658096\n",
            "Epoch:1 Step:3152 Training_loss:0.858961, Acc_avg:57.75% Training_loss_avg:0.662237\n",
            "Epoch:1 Step:3160 Training_loss:0.634014, Acc_avg:57.75% Training_loss_avg:0.664089\n",
            "Epoch:1 Step:3168 Training_loss:0.777700, Acc_avg:57.25% Training_loss_avg:0.666245\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:3168 Val_loss:0.644608, Val_Acc_avg:63.25%\n",
            "Epoch:1 Step:3176 Training_loss:0.633377, Acc_avg:57.75% Training_loss_avg:0.664939\n",
            "Epoch:1 Step:3184 Training_loss:0.645258, Acc_avg:57.75% Training_loss_avg:0.664302\n",
            "Epoch:1 Step:3192 Training_loss:0.621795, Acc_avg:58.25% Training_loss_avg:0.664589\n",
            "Epoch:1 Step:3200 Training_loss:0.786289, Acc_avg:57.75% Training_loss_avg:0.667719\n",
            "Epoch:1 Step:3208 Training_loss:0.670768, Acc_avg:58.50% Training_loss_avg:0.666535\n",
            "Epoch:1 Step:3216 Training_loss:0.660117, Acc_avg:59.50% Training_loss_avg:0.665303\n",
            "Epoch:1 Step:3224 Training_loss:0.685687, Acc_avg:59.50% Training_loss_avg:0.665380\n",
            "Epoch:1 Step:3232 Training_loss:0.500814, Acc_avg:59.75% Training_loss_avg:0.662092\n",
            "Epoch:1 Step:3240 Training_loss:0.695183, Acc_avg:59.75% Training_loss_avg:0.662844\n",
            "Epoch:1 Step:3248 Training_loss:0.598738, Acc_avg:60.00% Training_loss_avg:0.660847\n",
            "Epoch:1 Step:3256 Training_loss:0.618270, Acc_avg:60.50% Training_loss_avg:0.658887\n",
            "Epoch:1 Step:3264 Training_loss:0.560575, Acc_avg:60.75% Training_loss_avg:0.659453\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:3264 Val_loss:0.652453, Val_Acc_avg:62.75%\n",
            "Epoch:1 Step:3272 Training_loss:0.656168, Acc_avg:60.50% Training_loss_avg:0.659751\n",
            "Epoch:1 Step:3280 Training_loss:0.619096, Acc_avg:60.50% Training_loss_avg:0.657953\n",
            "Epoch:1 Step:3288 Training_loss:0.574076, Acc_avg:60.75% Training_loss_avg:0.655078\n",
            "Epoch:1 Step:3296 Training_loss:0.823870, Acc_avg:60.50% Training_loss_avg:0.659067\n",
            "Epoch:1 Step:3304 Training_loss:0.609259, Acc_avg:60.50% Training_loss_avg:0.659791\n",
            "Epoch:1 Step:3312 Training_loss:0.800906, Acc_avg:59.75% Training_loss_avg:0.664510\n",
            "Epoch:1 Step:3320 Training_loss:0.710488, Acc_avg:59.00% Training_loss_avg:0.667675\n",
            "Epoch:1 Step:3328 Training_loss:0.580859, Acc_avg:59.33% Training_loss_avg:0.665825\n",
            "Epoch:2 Step:0 Training_loss:0.698581, Acc_avg:59.58% Training_loss_avg:0.667175\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:0 Val_loss:0.657284, Val_Acc_avg:62.75%\n",
            "Epoch:2 Step:8 Training_loss:0.693689, Acc_avg:59.58% Training_loss_avg:0.668800\n",
            "Epoch:2 Step:16 Training_loss:0.479853, Acc_avg:60.33% Training_loss_avg:0.664433\n",
            "Epoch:2 Step:24 Training_loss:0.710226, Acc_avg:60.58% Training_loss_avg:0.663715\n",
            "Epoch:2 Step:32 Training_loss:0.617646, Acc_avg:60.58% Training_loss_avg:0.664130\n",
            "Epoch:2 Step:40 Training_loss:0.546466, Acc_avg:60.83% Training_loss_avg:0.660834\n",
            "Epoch:2 Step:48 Training_loss:0.712099, Acc_avg:60.08% Training_loss_avg:0.662073\n",
            "Epoch:2 Step:56 Training_loss:0.580828, Acc_avg:59.83% Training_loss_avg:0.664124\n",
            "Epoch:2 Step:64 Training_loss:0.632764, Acc_avg:60.33% Training_loss_avg:0.661330\n",
            "Epoch:2 Step:72 Training_loss:0.522938, Acc_avg:60.83% Training_loss_avg:0.657348\n",
            "Epoch:2 Step:80 Training_loss:0.733998, Acc_avg:60.83% Training_loss_avg:0.659260\n",
            "Epoch:2 Step:88 Training_loss:0.626871, Acc_avg:61.08% Training_loss_avg:0.659257\n",
            "Epoch:2 Step:96 Training_loss:0.673788, Acc_avg:61.33% Training_loss_avg:0.658714\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:96 Val_loss:0.650196, Val_Acc_avg:62.75%\n",
            "Epoch:2 Step:104 Training_loss:0.843013, Acc_avg:61.58% Training_loss_avg:0.659365\n",
            "Epoch:2 Step:112 Training_loss:0.653840, Acc_avg:61.58% Training_loss_avg:0.660442\n",
            "Epoch:2 Step:120 Training_loss:0.818414, Acc_avg:61.58% Training_loss_avg:0.660103\n",
            "Epoch:2 Step:128 Training_loss:0.551030, Acc_avg:61.58% Training_loss_avg:0.659024\n",
            "Epoch:2 Step:136 Training_loss:0.835222, Acc_avg:61.58% Training_loss_avg:0.660644\n",
            "Epoch:2 Step:144 Training_loss:0.698828, Acc_avg:61.58% Training_loss_avg:0.661297\n",
            "Epoch:2 Step:152 Training_loss:0.785256, Acc_avg:60.33% Training_loss_avg:0.665896\n",
            "Epoch:2 Step:160 Training_loss:0.664188, Acc_avg:60.33% Training_loss_avg:0.667603\n",
            "Epoch:2 Step:168 Training_loss:0.597137, Acc_avg:59.83% Training_loss_avg:0.669242\n",
            "Epoch:2 Step:176 Training_loss:0.773818, Acc_avg:59.58% Training_loss_avg:0.670603\n",
            "Epoch:2 Step:184 Training_loss:0.654306, Acc_avg:59.83% Training_loss_avg:0.670076\n",
            "Epoch:2 Step:192 Training_loss:0.617950, Acc_avg:60.08% Training_loss_avg:0.669668\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:192 Val_loss:0.638512, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:200 Training_loss:0.640638, Acc_avg:60.33% Training_loss_avg:0.668028\n",
            "Epoch:2 Step:208 Training_loss:0.562624, Acc_avg:60.33% Training_loss_avg:0.664966\n",
            "Epoch:2 Step:216 Training_loss:0.617787, Acc_avg:61.08% Training_loss_avg:0.660142\n",
            "Epoch:2 Step:224 Training_loss:0.656178, Acc_avg:60.58% Training_loss_avg:0.660585\n",
            "Epoch:2 Step:232 Training_loss:0.740243, Acc_avg:60.58% Training_loss_avg:0.659836\n",
            "Epoch:2 Step:240 Training_loss:0.623558, Acc_avg:60.58% Training_loss_avg:0.659640\n",
            "Epoch:2 Step:248 Training_loss:0.665323, Acc_avg:60.58% Training_loss_avg:0.660041\n",
            "Epoch:2 Step:256 Training_loss:0.595363, Acc_avg:60.83% Training_loss_avg:0.659512\n",
            "Epoch:2 Step:264 Training_loss:0.677845, Acc_avg:61.33% Training_loss_avg:0.657344\n",
            "Epoch:2 Step:272 Training_loss:0.591069, Acc_avg:61.83% Training_loss_avg:0.655750\n",
            "Epoch:2 Step:280 Training_loss:0.698446, Acc_avg:61.08% Training_loss_avg:0.656516\n",
            "Epoch:2 Step:288 Training_loss:0.684278, Acc_avg:61.33% Training_loss_avg:0.656488\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:288 Val_loss:0.637818, Val_Acc_avg:63.75%\n",
            "Epoch:2 Step:296 Training_loss:0.648055, Acc_avg:60.83% Training_loss_avg:0.659433\n",
            "Epoch:2 Step:304 Training_loss:0.540474, Acc_avg:61.83% Training_loss_avg:0.656339\n",
            "Epoch:2 Step:312 Training_loss:0.696975, Acc_avg:61.33% Training_loss_avg:0.658303\n",
            "Epoch:2 Step:320 Training_loss:0.676110, Acc_avg:61.08% Training_loss_avg:0.659460\n",
            "Epoch:2 Step:328 Training_loss:0.749152, Acc_avg:60.33% Training_loss_avg:0.663232\n",
            "Epoch:2 Step:336 Training_loss:0.619612, Acc_avg:60.83% Training_loss_avg:0.662501\n",
            "Epoch:2 Step:344 Training_loss:0.495757, Acc_avg:61.08% Training_loss_avg:0.660034\n",
            "Epoch:2 Step:352 Training_loss:0.641632, Acc_avg:60.83% Training_loss_avg:0.661385\n",
            "Epoch:2 Step:360 Training_loss:0.644654, Acc_avg:61.33% Training_loss_avg:0.657801\n",
            "Epoch:2 Step:368 Training_loss:0.746174, Acc_avg:60.58% Training_loss_avg:0.660539\n",
            "Epoch:2 Step:376 Training_loss:0.553471, Acc_avg:60.83% Training_loss_avg:0.655590\n",
            "Epoch:2 Step:384 Training_loss:0.695882, Acc_avg:60.83% Training_loss_avg:0.655298\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:384 Val_loss:0.636009, Val_Acc_avg:62.75%\n",
            "Epoch:2 Step:392 Training_loss:0.687930, Acc_avg:60.75% Training_loss_avg:0.657439\n",
            "Epoch:2 Step:400 Training_loss:0.556321, Acc_avg:60.75% Training_loss_avg:0.654594\n",
            "Epoch:2 Step:408 Training_loss:0.680974, Acc_avg:60.50% Training_loss_avg:0.654340\n",
            "Epoch:2 Step:416 Training_loss:0.680408, Acc_avg:60.00% Training_loss_avg:0.658351\n",
            "Epoch:2 Step:424 Training_loss:0.638583, Acc_avg:60.50% Training_loss_avg:0.656918\n",
            "Epoch:2 Step:432 Training_loss:0.719537, Acc_avg:60.00% Training_loss_avg:0.658956\n",
            "Epoch:2 Step:440 Training_loss:0.577237, Acc_avg:60.25% Training_loss_avg:0.659571\n",
            "Epoch:2 Step:448 Training_loss:0.611368, Acc_avg:60.75% Training_loss_avg:0.657557\n",
            "Epoch:2 Step:456 Training_loss:0.595141, Acc_avg:60.75% Training_loss_avg:0.657843\n",
            "Epoch:2 Step:464 Training_loss:0.700571, Acc_avg:60.75% Training_loss_avg:0.659199\n",
            "Epoch:2 Step:472 Training_loss:0.651509, Acc_avg:60.25% Training_loss_avg:0.661771\n",
            "Epoch:2 Step:480 Training_loss:0.826919, Acc_avg:60.00% Training_loss_avg:0.663629\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:480 Val_loss:0.637006, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:488 Training_loss:0.698436, Acc_avg:60.00% Training_loss_avg:0.665060\n",
            "Epoch:2 Step:496 Training_loss:0.461388, Acc_avg:60.75% Training_loss_avg:0.660812\n",
            "Epoch:2 Step:504 Training_loss:0.668698, Acc_avg:61.25% Training_loss_avg:0.657326\n",
            "Epoch:2 Step:512 Training_loss:0.621056, Acc_avg:61.25% Training_loss_avg:0.656670\n",
            "Epoch:2 Step:520 Training_loss:0.569620, Acc_avg:62.00% Training_loss_avg:0.651695\n",
            "Epoch:2 Step:528 Training_loss:0.650286, Acc_avg:61.50% Training_loss_avg:0.653680\n",
            "Epoch:2 Step:536 Training_loss:0.691231, Acc_avg:62.00% Training_loss_avg:0.650800\n",
            "Epoch:2 Step:544 Training_loss:0.784816, Acc_avg:61.75% Training_loss_avg:0.652520\n",
            "Epoch:2 Step:552 Training_loss:0.687762, Acc_avg:62.25% Training_loss_avg:0.650570\n",
            "Epoch:2 Step:560 Training_loss:0.766178, Acc_avg:62.25% Training_loss_avg:0.652610\n",
            "Epoch:2 Step:568 Training_loss:0.906515, Acc_avg:61.25% Training_loss_avg:0.658797\n",
            "Epoch:2 Step:576 Training_loss:0.650827, Acc_avg:61.75% Training_loss_avg:0.656337\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:576 Val_loss:0.635860, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:584 Training_loss:0.433657, Acc_avg:62.00% Training_loss_avg:0.651924\n",
            "Epoch:2 Step:592 Training_loss:0.613655, Acc_avg:61.50% Training_loss_avg:0.651838\n",
            "Epoch:2 Step:600 Training_loss:0.505423, Acc_avg:62.25% Training_loss_avg:0.649134\n",
            "Epoch:2 Step:608 Training_loss:0.721798, Acc_avg:62.00% Training_loss_avg:0.652318\n",
            "Epoch:2 Step:616 Training_loss:0.572640, Acc_avg:62.25% Training_loss_avg:0.651415\n",
            "Epoch:2 Step:624 Training_loss:0.816243, Acc_avg:62.25% Training_loss_avg:0.654616\n",
            "Epoch:2 Step:632 Training_loss:0.539355, Acc_avg:63.00% Training_loss_avg:0.650598\n",
            "Epoch:2 Step:640 Training_loss:0.494619, Acc_avg:63.25% Training_loss_avg:0.648019\n",
            "Epoch:2 Step:648 Training_loss:0.691430, Acc_avg:62.75% Training_loss_avg:0.648542\n",
            "Epoch:2 Step:656 Training_loss:0.691721, Acc_avg:62.25% Training_loss_avg:0.650469\n",
            "Epoch:2 Step:664 Training_loss:0.637481, Acc_avg:62.50% Training_loss_avg:0.649661\n",
            "Epoch:2 Step:672 Training_loss:0.580538, Acc_avg:62.25% Training_loss_avg:0.649451\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:672 Val_loss:0.645713, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:680 Training_loss:0.670768, Acc_avg:62.50% Training_loss_avg:0.648897\n",
            "Epoch:2 Step:688 Training_loss:0.472766, Acc_avg:63.25% Training_loss_avg:0.644667\n",
            "Epoch:2 Step:696 Training_loss:0.565277, Acc_avg:63.50% Training_loss_avg:0.643011\n",
            "Epoch:2 Step:704 Training_loss:0.830738, Acc_avg:62.25% Training_loss_avg:0.648817\n",
            "Epoch:2 Step:712 Training_loss:0.598559, Acc_avg:62.75% Training_loss_avg:0.646848\n",
            "Epoch:2 Step:720 Training_loss:0.562168, Acc_avg:63.00% Training_loss_avg:0.644570\n",
            "Epoch:2 Step:728 Training_loss:0.856109, Acc_avg:62.75% Training_loss_avg:0.646709\n",
            "Epoch:2 Step:736 Training_loss:0.779032, Acc_avg:62.00% Training_loss_avg:0.649897\n",
            "Epoch:2 Step:744 Training_loss:0.585295, Acc_avg:61.75% Training_loss_avg:0.651688\n",
            "Epoch:2 Step:752 Training_loss:0.523048, Acc_avg:62.25% Training_loss_avg:0.649316\n",
            "Epoch:2 Step:760 Training_loss:0.551563, Acc_avg:62.00% Training_loss_avg:0.647454\n",
            "Epoch:2 Step:768 Training_loss:0.745363, Acc_avg:62.25% Training_loss_avg:0.647438\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:768 Val_loss:0.647802, Val_Acc_avg:63.00%\n",
            "Epoch:2 Step:776 Training_loss:0.826597, Acc_avg:61.50% Training_loss_avg:0.652901\n",
            "Epoch:2 Step:784 Training_loss:0.650729, Acc_avg:61.75% Training_loss_avg:0.651998\n",
            "Epoch:2 Step:792 Training_loss:0.486989, Acc_avg:62.50% Training_loss_avg:0.647979\n",
            "Epoch:2 Step:800 Training_loss:0.745066, Acc_avg:61.75% Training_loss_avg:0.651754\n",
            "Epoch:2 Step:808 Training_loss:0.737348, Acc_avg:61.50% Training_loss_avg:0.652881\n",
            "Epoch:2 Step:816 Training_loss:0.550244, Acc_avg:62.00% Training_loss_avg:0.650278\n",
            "Epoch:2 Step:824 Training_loss:0.686054, Acc_avg:61.25% Training_loss_avg:0.651227\n",
            "Epoch:2 Step:832 Training_loss:0.668999, Acc_avg:61.50% Training_loss_avg:0.650217\n",
            "Epoch:2 Step:840 Training_loss:0.878026, Acc_avg:60.50% Training_loss_avg:0.656232\n",
            "Epoch:2 Step:848 Training_loss:0.515989, Acc_avg:60.75% Training_loss_avg:0.654325\n",
            "Epoch:2 Step:856 Training_loss:0.764433, Acc_avg:59.75% Training_loss_avg:0.657711\n",
            "Epoch:2 Step:864 Training_loss:0.518206, Acc_avg:60.25% Training_loss_avg:0.654063\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:864 Val_loss:0.630926, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:872 Training_loss:0.707457, Acc_avg:60.25% Training_loss_avg:0.655182\n",
            "Epoch:2 Step:880 Training_loss:0.610910, Acc_avg:61.25% Training_loss_avg:0.650862\n",
            "Epoch:2 Step:888 Training_loss:0.718061, Acc_avg:60.75% Training_loss_avg:0.651255\n",
            "Epoch:2 Step:896 Training_loss:0.671749, Acc_avg:60.00% Training_loss_avg:0.655462\n",
            "Epoch:2 Step:904 Training_loss:0.614827, Acc_avg:60.00% Training_loss_avg:0.654384\n",
            "Epoch:2 Step:912 Training_loss:0.669176, Acc_avg:59.50% Training_loss_avg:0.655347\n",
            "Epoch:2 Step:920 Training_loss:0.697133, Acc_avg:58.75% Training_loss_avg:0.657897\n",
            "Epoch:2 Step:928 Training_loss:0.731695, Acc_avg:58.75% Training_loss_avg:0.659525\n",
            "Epoch:2 Step:936 Training_loss:0.525124, Acc_avg:59.00% Training_loss_avg:0.656203\n",
            "Epoch:2 Step:944 Training_loss:0.733200, Acc_avg:58.75% Training_loss_avg:0.655171\n",
            "Epoch:2 Step:952 Training_loss:0.616355, Acc_avg:59.00% Training_loss_avg:0.653743\n",
            "Epoch:2 Step:960 Training_loss:0.713477, Acc_avg:59.00% Training_loss_avg:0.652689\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:960 Val_loss:0.632686, Val_Acc_avg:63.75%\n",
            "Epoch:2 Step:968 Training_loss:0.675826, Acc_avg:60.00% Training_loss_avg:0.648075\n",
            "Epoch:2 Step:976 Training_loss:0.648922, Acc_avg:60.50% Training_loss_avg:0.648037\n",
            "Epoch:2 Step:984 Training_loss:0.573657, Acc_avg:60.25% Training_loss_avg:0.650837\n",
            "Epoch:2 Step:992 Training_loss:0.592359, Acc_avg:60.75% Training_loss_avg:0.650411\n",
            "Epoch:2 Step:1000 Training_loss:0.649724, Acc_avg:60.00% Training_loss_avg:0.653297\n",
            "Epoch:2 Step:1008 Training_loss:0.729755, Acc_avg:59.75% Training_loss_avg:0.653456\n",
            "Epoch:2 Step:1016 Training_loss:0.576371, Acc_avg:59.50% Training_loss_avg:0.653531\n",
            "Epoch:2 Step:1024 Training_loss:0.489289, Acc_avg:60.25% Training_loss_avg:0.646992\n",
            "Epoch:2 Step:1032 Training_loss:0.565930, Acc_avg:60.50% Training_loss_avg:0.647523\n",
            "Epoch:2 Step:1040 Training_loss:0.795092, Acc_avg:59.75% Training_loss_avg:0.653533\n",
            "Epoch:2 Step:1048 Training_loss:0.654315, Acc_avg:60.25% Training_loss_avg:0.652790\n",
            "Epoch:2 Step:1056 Training_loss:0.618293, Acc_avg:60.50% Training_loss_avg:0.651322\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1056 Val_loss:0.638764, Val_Acc_avg:61.75%\n",
            "Epoch:2 Step:1064 Training_loss:0.511743, Acc_avg:60.50% Training_loss_avg:0.648807\n",
            "Epoch:2 Step:1072 Training_loss:0.699261, Acc_avg:59.75% Training_loss_avg:0.651181\n",
            "Epoch:2 Step:1080 Training_loss:0.710905, Acc_avg:60.00% Training_loss_avg:0.651984\n",
            "Epoch:2 Step:1088 Training_loss:0.644353, Acc_avg:59.25% Training_loss_avg:0.655416\n",
            "Epoch:2 Step:1096 Training_loss:0.594188, Acc_avg:59.25% Training_loss_avg:0.655994\n",
            "Epoch:2 Step:1104 Training_loss:0.652364, Acc_avg:59.50% Training_loss_avg:0.652427\n",
            "Epoch:2 Step:1112 Training_loss:0.707696, Acc_avg:59.00% Training_loss_avg:0.654609\n",
            "Epoch:2 Step:1120 Training_loss:0.573566, Acc_avg:59.00% Training_loss_avg:0.654837\n",
            "Epoch:2 Step:1128 Training_loss:0.666501, Acc_avg:59.25% Training_loss_avg:0.651045\n",
            "Epoch:2 Step:1136 Training_loss:0.628554, Acc_avg:60.25% Training_loss_avg:0.648036\n",
            "Epoch:2 Step:1144 Training_loss:0.619442, Acc_avg:59.75% Training_loss_avg:0.648718\n",
            "Epoch:2 Step:1152 Training_loss:0.817498, Acc_avg:58.75% Training_loss_avg:0.654607\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1152 Val_loss:0.635078, Val_Acc_avg:62.75%\n",
            "Epoch:2 Step:1160 Training_loss:0.706370, Acc_avg:58.50% Training_loss_avg:0.657704\n",
            "Epoch:2 Step:1168 Training_loss:0.712088, Acc_avg:58.75% Training_loss_avg:0.657038\n",
            "Epoch:2 Step:1176 Training_loss:0.565387, Acc_avg:59.50% Training_loss_avg:0.651814\n",
            "Epoch:2 Step:1184 Training_loss:0.590668, Acc_avg:59.50% Training_loss_avg:0.650613\n",
            "Epoch:2 Step:1192 Training_loss:0.578257, Acc_avg:58.75% Training_loss_avg:0.652438\n",
            "Epoch:2 Step:1200 Training_loss:0.660586, Acc_avg:59.25% Training_loss_avg:0.650748\n",
            "Epoch:2 Step:1208 Training_loss:0.816877, Acc_avg:59.25% Training_loss_avg:0.652339\n",
            "Epoch:2 Step:1216 Training_loss:0.555125, Acc_avg:59.00% Training_loss_avg:0.652437\n",
            "Epoch:2 Step:1224 Training_loss:0.611686, Acc_avg:59.50% Training_loss_avg:0.650949\n",
            "Epoch:2 Step:1232 Training_loss:0.690051, Acc_avg:59.75% Training_loss_avg:0.651370\n",
            "Epoch:2 Step:1240 Training_loss:0.643444, Acc_avg:60.00% Training_loss_avg:0.646679\n",
            "Epoch:2 Step:1248 Training_loss:0.626908, Acc_avg:59.50% Training_loss_avg:0.648897\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1248 Val_loss:0.632295, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:1256 Training_loss:0.649299, Acc_avg:60.00% Training_loss_avg:0.646594\n",
            "Epoch:2 Step:1264 Training_loss:0.598612, Acc_avg:59.75% Training_loss_avg:0.648203\n",
            "Epoch:2 Step:1272 Training_loss:0.604749, Acc_avg:60.00% Training_loss_avg:0.646148\n",
            "Epoch:2 Step:1280 Training_loss:0.599037, Acc_avg:59.50% Training_loss_avg:0.645911\n",
            "Epoch:2 Step:1288 Training_loss:0.623526, Acc_avg:60.50% Training_loss_avg:0.644020\n",
            "Epoch:2 Step:1296 Training_loss:0.717798, Acc_avg:60.50% Training_loss_avg:0.644941\n",
            "Epoch:2 Step:1304 Training_loss:0.596073, Acc_avg:60.50% Training_loss_avg:0.644566\n",
            "Epoch:2 Step:1312 Training_loss:0.609569, Acc_avg:60.75% Training_loss_avg:0.643374\n",
            "Epoch:2 Step:1320 Training_loss:0.706512, Acc_avg:61.50% Training_loss_avg:0.643562\n",
            "Epoch:2 Step:1328 Training_loss:0.581564, Acc_avg:62.00% Training_loss_avg:0.640559\n",
            "Epoch:2 Step:1336 Training_loss:0.744141, Acc_avg:61.25% Training_loss_avg:0.644939\n",
            "Epoch:2 Step:1344 Training_loss:0.663775, Acc_avg:61.75% Training_loss_avg:0.643551\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1344 Val_loss:0.632224, Val_Acc_avg:63.75%\n",
            "Epoch:2 Step:1352 Training_loss:0.658061, Acc_avg:61.75% Training_loss_avg:0.644385\n",
            "Epoch:2 Step:1360 Training_loss:0.571864, Acc_avg:62.50% Training_loss_avg:0.641553\n",
            "Epoch:2 Step:1368 Training_loss:0.673511, Acc_avg:62.00% Training_loss_avg:0.641506\n",
            "Epoch:2 Step:1376 Training_loss:0.847112, Acc_avg:61.00% Training_loss_avg:0.645470\n",
            "Epoch:2 Step:1384 Training_loss:0.698968, Acc_avg:60.50% Training_loss_avg:0.647976\n",
            "Epoch:2 Step:1392 Training_loss:0.572399, Acc_avg:60.25% Training_loss_avg:0.647577\n",
            "Epoch:2 Step:1400 Training_loss:0.590819, Acc_avg:60.25% Training_loss_avg:0.646399\n",
            "Epoch:2 Step:1408 Training_loss:0.548316, Acc_avg:61.00% Training_loss_avg:0.642770\n",
            "Epoch:2 Step:1416 Training_loss:0.661364, Acc_avg:61.25% Training_loss_avg:0.644470\n",
            "Epoch:2 Step:1424 Training_loss:0.762890, Acc_avg:60.50% Training_loss_avg:0.649942\n",
            "Epoch:2 Step:1432 Training_loss:0.578496, Acc_avg:60.50% Training_loss_avg:0.650193\n",
            "Epoch:2 Step:1440 Training_loss:0.598044, Acc_avg:61.00% Training_loss_avg:0.646252\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1440 Val_loss:0.637604, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:1448 Training_loss:0.600550, Acc_avg:61.00% Training_loss_avg:0.645177\n",
            "Epoch:2 Step:1456 Training_loss:0.599052, Acc_avg:61.00% Training_loss_avg:0.644792\n",
            "Epoch:2 Step:1464 Training_loss:0.626601, Acc_avg:60.75% Training_loss_avg:0.647090\n",
            "Epoch:2 Step:1472 Training_loss:0.659911, Acc_avg:61.25% Training_loss_avg:0.646303\n",
            "Epoch:2 Step:1480 Training_loss:0.874045, Acc_avg:60.50% Training_loss_avg:0.649565\n",
            "Epoch:2 Step:1488 Training_loss:0.659827, Acc_avg:60.50% Training_loss_avg:0.649875\n",
            "Epoch:2 Step:1496 Training_loss:0.719141, Acc_avg:60.25% Training_loss_avg:0.652374\n",
            "Epoch:2 Step:1504 Training_loss:0.568663, Acc_avg:60.50% Training_loss_avg:0.650700\n",
            "Epoch:2 Step:1512 Training_loss:0.558503, Acc_avg:61.25% Training_loss_avg:0.647716\n",
            "Epoch:2 Step:1520 Training_loss:0.569066, Acc_avg:61.25% Training_loss_avg:0.647626\n",
            "Epoch:2 Step:1528 Training_loss:0.473254, Acc_avg:61.75% Training_loss_avg:0.643761\n",
            "Epoch:2 Step:1536 Training_loss:0.650366, Acc_avg:61.25% Training_loss_avg:0.644197\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1536 Val_loss:0.640999, Val_Acc_avg:63.00%\n",
            "Epoch:2 Step:1544 Training_loss:0.714086, Acc_avg:61.50% Training_loss_avg:0.646090\n",
            "Epoch:2 Step:1552 Training_loss:0.746229, Acc_avg:61.75% Training_loss_avg:0.644665\n",
            "Epoch:2 Step:1560 Training_loss:0.554162, Acc_avg:62.25% Training_loss_avg:0.641621\n",
            "Epoch:2 Step:1568 Training_loss:0.538608, Acc_avg:62.25% Training_loss_avg:0.638151\n",
            "Epoch:2 Step:1576 Training_loss:0.660580, Acc_avg:62.25% Training_loss_avg:0.640055\n",
            "Epoch:2 Step:1584 Training_loss:0.551336, Acc_avg:62.50% Training_loss_avg:0.639268\n",
            "Epoch:2 Step:1592 Training_loss:0.536568, Acc_avg:63.00% Training_loss_avg:0.638434\n",
            "Epoch:2 Step:1600 Training_loss:0.643719, Acc_avg:63.00% Training_loss_avg:0.638097\n",
            "Epoch:2 Step:1608 Training_loss:0.706726, Acc_avg:63.50% Training_loss_avg:0.635894\n",
            "Epoch:2 Step:1616 Training_loss:0.659083, Acc_avg:63.25% Training_loss_avg:0.637973\n",
            "Epoch:2 Step:1624 Training_loss:0.820324, Acc_avg:62.75% Training_loss_avg:0.642146\n",
            "Epoch:2 Step:1632 Training_loss:0.594155, Acc_avg:62.50% Training_loss_avg:0.640228\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1632 Val_loss:0.632065, Val_Acc_avg:63.50%\n",
            "Epoch:2 Step:1640 Training_loss:0.572622, Acc_avg:63.00% Training_loss_avg:0.638812\n",
            "Epoch:2 Step:1648 Training_loss:0.784417, Acc_avg:62.50% Training_loss_avg:0.641962\n",
            "Epoch:2 Step:1656 Training_loss:0.520029, Acc_avg:62.75% Training_loss_avg:0.639376\n",
            "Epoch:2 Step:1664 Training_loss:0.540716, Acc_avg:63.25% Training_loss_avg:0.638218\n",
            "Epoch:2 Step:1672 Training_loss:0.758376, Acc_avg:62.75% Training_loss_avg:0.641291\n",
            "Epoch:2 Step:1680 Training_loss:0.587574, Acc_avg:63.00% Training_loss_avg:0.641062\n",
            "Epoch:2 Step:1688 Training_loss:0.560576, Acc_avg:62.50% Training_loss_avg:0.639803\n",
            "Epoch:2 Step:1696 Training_loss:0.606294, Acc_avg:62.75% Training_loss_avg:0.637573\n",
            "Epoch:2 Step:1704 Training_loss:0.617415, Acc_avg:63.00% Training_loss_avg:0.638000\n",
            "Epoch:2 Step:1712 Training_loss:0.597250, Acc_avg:63.00% Training_loss_avg:0.637753\n",
            "Epoch:2 Step:1720 Training_loss:0.613099, Acc_avg:63.00% Training_loss_avg:0.635885\n",
            "Epoch:2 Step:1728 Training_loss:0.589911, Acc_avg:63.25% Training_loss_avg:0.636052\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1728 Val_loss:0.634118, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:1736 Training_loss:0.689583, Acc_avg:63.50% Training_loss_avg:0.634961\n",
            "Epoch:2 Step:1744 Training_loss:0.499123, Acc_avg:64.00% Training_loss_avg:0.631668\n",
            "Epoch:2 Step:1752 Training_loss:0.651289, Acc_avg:63.50% Training_loss_avg:0.631532\n",
            "Epoch:2 Step:1760 Training_loss:0.597950, Acc_avg:62.75% Training_loss_avg:0.632054\n",
            "Epoch:2 Step:1768 Training_loss:0.596036, Acc_avg:63.75% Training_loss_avg:0.630504\n",
            "Epoch:2 Step:1776 Training_loss:0.575423, Acc_avg:64.50% Training_loss_avg:0.625071\n",
            "Epoch:2 Step:1784 Training_loss:0.444777, Acc_avg:65.50% Training_loss_avg:0.619987\n",
            "Epoch:2 Step:1792 Training_loss:0.601456, Acc_avg:65.50% Training_loss_avg:0.620568\n",
            "Epoch:2 Step:1800 Training_loss:0.732474, Acc_avg:65.25% Training_loss_avg:0.623401\n",
            "Epoch:2 Step:1808 Training_loss:0.493644, Acc_avg:65.25% Training_loss_avg:0.622308\n",
            "Epoch:2 Step:1816 Training_loss:0.689249, Acc_avg:64.75% Training_loss_avg:0.622865\n",
            "Epoch:2 Step:1824 Training_loss:0.464850, Acc_avg:65.50% Training_loss_avg:0.616904\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1824 Val_loss:0.640663, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:1832 Training_loss:0.723818, Acc_avg:64.50% Training_loss_avg:0.619811\n",
            "Epoch:2 Step:1840 Training_loss:0.743575, Acc_avg:63.75% Training_loss_avg:0.622722\n",
            "Epoch:2 Step:1848 Training_loss:0.588337, Acc_avg:63.75% Training_loss_avg:0.622477\n",
            "Epoch:2 Step:1856 Training_loss:0.597432, Acc_avg:63.75% Training_loss_avg:0.622445\n",
            "Epoch:2 Step:1864 Training_loss:0.641317, Acc_avg:63.75% Training_loss_avg:0.622739\n",
            "Epoch:2 Step:1872 Training_loss:0.478751, Acc_avg:64.00% Training_loss_avg:0.619116\n",
            "Epoch:2 Step:1880 Training_loss:0.562058, Acc_avg:65.00% Training_loss_avg:0.612876\n",
            "Epoch:2 Step:1888 Training_loss:0.711050, Acc_avg:64.50% Training_loss_avg:0.613901\n",
            "Epoch:2 Step:1896 Training_loss:0.672062, Acc_avg:64.75% Training_loss_avg:0.612959\n",
            "Epoch:2 Step:1904 Training_loss:0.777704, Acc_avg:64.25% Training_loss_avg:0.617140\n",
            "Epoch:2 Step:1912 Training_loss:0.587443, Acc_avg:63.75% Training_loss_avg:0.617719\n",
            "Epoch:2 Step:1920 Training_loss:0.499227, Acc_avg:63.75% Training_loss_avg:0.616322\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:1920 Val_loss:0.640630, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:1928 Training_loss:0.443129, Acc_avg:64.00% Training_loss_avg:0.615720\n",
            "Epoch:2 Step:1936 Training_loss:0.626835, Acc_avg:64.25% Training_loss_avg:0.615249\n",
            "Epoch:2 Step:1944 Training_loss:0.681485, Acc_avg:64.25% Training_loss_avg:0.614597\n",
            "Epoch:2 Step:1952 Training_loss:0.578004, Acc_avg:64.25% Training_loss_avg:0.611232\n",
            "Epoch:2 Step:1960 Training_loss:0.676918, Acc_avg:64.00% Training_loss_avg:0.613687\n",
            "Epoch:2 Step:1968 Training_loss:0.765303, Acc_avg:63.50% Training_loss_avg:0.618221\n",
            "Epoch:2 Step:1976 Training_loss:0.564786, Acc_avg:63.50% Training_loss_avg:0.616306\n",
            "Epoch:2 Step:1984 Training_loss:0.742406, Acc_avg:62.75% Training_loss_avg:0.620127\n",
            "Epoch:2 Step:1992 Training_loss:0.596558, Acc_avg:62.50% Training_loss_avg:0.621327\n",
            "Epoch:2 Step:2000 Training_loss:0.619805, Acc_avg:62.75% Training_loss_avg:0.620848\n",
            "Epoch:2 Step:2008 Training_loss:0.532564, Acc_avg:62.75% Training_loss_avg:0.617365\n",
            "Epoch:2 Step:2016 Training_loss:0.657384, Acc_avg:62.75% Training_loss_avg:0.617331\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:2016 Val_loss:0.627454, Val_Acc_avg:64.00%\n",
            "Epoch:2 Step:2024 Training_loss:0.505306, Acc_avg:63.75% Training_loss_avg:0.611031\n",
            "Epoch:2 Step:2032 Training_loss:0.780750, Acc_avg:63.75% Training_loss_avg:0.614763\n",
            "Epoch:2 Step:2040 Training_loss:0.639057, Acc_avg:63.75% Training_loss_avg:0.616091\n",
            "Epoch:2 Step:2048 Training_loss:0.602522, Acc_avg:64.50% Training_loss_avg:0.612454\n",
            "Epoch:2 Step:2056 Training_loss:0.616216, Acc_avg:64.25% Training_loss_avg:0.614377\n",
            "Epoch:2 Step:2064 Training_loss:0.688610, Acc_avg:63.50% Training_loss_avg:0.617335\n",
            "Epoch:2 Step:2072 Training_loss:0.774733, Acc_avg:63.50% Training_loss_avg:0.617662\n",
            "Epoch:2 Step:2080 Training_loss:0.564132, Acc_avg:63.75% Training_loss_avg:0.617194\n",
            "Epoch:2 Step:2088 Training_loss:0.707071, Acc_avg:63.25% Training_loss_avg:0.620123\n",
            "Epoch:2 Step:2096 Training_loss:0.545379, Acc_avg:63.25% Training_loss_avg:0.618905\n",
            "Epoch:2 Step:2104 Training_loss:0.578608, Acc_avg:63.00% Training_loss_avg:0.618129\n",
            "Epoch:2 Step:2112 Training_loss:0.429923, Acc_avg:63.50% Training_loss_avg:0.614782\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:2112 Val_loss:0.629610, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:2120 Training_loss:0.588635, Acc_avg:64.00% Training_loss_avg:0.614293\n",
            "Epoch:2 Step:2128 Training_loss:0.612624, Acc_avg:63.75% Training_loss_avg:0.614747\n",
            "Epoch:2 Step:2136 Training_loss:0.622840, Acc_avg:64.00% Training_loss_avg:0.613413\n",
            "Epoch:2 Step:2144 Training_loss:0.483885, Acc_avg:64.00% Training_loss_avg:0.613108\n",
            "Epoch:2 Step:2152 Training_loss:0.676061, Acc_avg:64.00% Training_loss_avg:0.613603\n",
            "Epoch:2 Step:2160 Training_loss:0.759144, Acc_avg:64.00% Training_loss_avg:0.616827\n",
            "Epoch:2 Step:2168 Training_loss:0.661021, Acc_avg:63.50% Training_loss_avg:0.618127\n",
            "Epoch:2 Step:2176 Training_loss:0.804613, Acc_avg:63.25% Training_loss_avg:0.622711\n",
            "Epoch:2 Step:2184 Training_loss:0.484355, Acc_avg:63.00% Training_loss_avg:0.623502\n",
            "Epoch:2 Step:2192 Training_loss:0.555564, Acc_avg:63.25% Training_loss_avg:0.622584\n",
            "Epoch:2 Step:2200 Training_loss:0.470429, Acc_avg:64.00% Training_loss_avg:0.617343\n",
            "Epoch:2 Step:2208 Training_loss:0.763497, Acc_avg:63.50% Training_loss_avg:0.622740\n",
            "Validating:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2 Step:2208 Val_loss:0.665806, Val_Acc_avg:62.75%\n",
            "Epoch:2 Step:2216 Training_loss:0.635877, Acc_avg:63.75% Training_loss_avg:0.621673\n",
            "Epoch:2 Step:2224 Training_loss:0.755449, Acc_avg:62.75% Training_loss_avg:0.627485\n",
            "Epoch:2 Step:2232 Training_loss:0.619218, Acc_avg:63.25% Training_loss_avg:0.625393\n",
            "Epoch:2 Step:2240 Training_loss:0.613279, Acc_avg:64.00% Training_loss_avg:0.622787\n",
            "Epoch:2 Step:2248 Training_loss:0.690312, Acc_avg:63.75% Training_loss_avg:0.624827\n",
            "Epoch:2 Step:2256 Training_loss:0.749855, Acc_avg:63.25% Training_loss_avg:0.627875\n",
            "Epoch:2 Step:2264 Training_loss:0.472656, Acc_avg:63.50% Training_loss_avg:0.624502\n",
            "Epoch:2 Step:2272 Training_loss:0.777108, Acc_avg:63.25% Training_loss_avg:0.630469\n",
            "Epoch:2 Step:2280 Training_loss:0.678632, Acc_avg:62.75% Training_loss_avg:0.632801\n",
            "Epoch:2 Step:2288 Training_loss:0.795532, Acc_avg:62.75% Training_loss_avg:0.634490\n",
            "Epoch:2 Step:2296 Training_loss:0.640585, Acc_avg:62.75% Training_loss_avg:0.633861\n",
            "Epoch:2 Step:2304 Training_loss:0.509490, Acc_avg:63.75% Training_loss_avg:0.628496\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2304 Val_loss:0.637292, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:2312 Training_loss:0.553730, Acc_avg:64.00% Training_loss_avg:0.627822\n",
            "Epoch:2 Step:2320 Training_loss:0.683880, Acc_avg:63.75% Training_loss_avg:0.631515\n",
            "Epoch:2 Step:2328 Training_loss:0.629045, Acc_avg:63.25% Training_loss_avg:0.635233\n",
            "Epoch:2 Step:2336 Training_loss:0.752653, Acc_avg:62.50% Training_loss_avg:0.637750\n",
            "Epoch:2 Step:2344 Training_loss:0.633835, Acc_avg:62.50% Training_loss_avg:0.636797\n",
            "Epoch:2 Step:2352 Training_loss:0.511374, Acc_avg:63.25% Training_loss_avg:0.635464\n",
            "Epoch:2 Step:2360 Training_loss:0.569062, Acc_avg:63.00% Training_loss_avg:0.633307\n",
            "Epoch:2 Step:2368 Training_loss:0.551702, Acc_avg:63.50% Training_loss_avg:0.629035\n",
            "Epoch:2 Step:2376 Training_loss:0.687357, Acc_avg:63.25% Training_loss_avg:0.631487\n",
            "Epoch:2 Step:2384 Training_loss:0.548393, Acc_avg:64.25% Training_loss_avg:0.627606\n",
            "Epoch:2 Step:2392 Training_loss:0.705488, Acc_avg:64.00% Training_loss_avg:0.629785\n",
            "Epoch:2 Step:2400 Training_loss:0.755800, Acc_avg:63.00% Training_loss_avg:0.632505\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2400 Val_loss:0.625426, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:2408 Training_loss:0.604183, Acc_avg:62.75% Training_loss_avg:0.633937\n",
            "Epoch:2 Step:2416 Training_loss:0.634265, Acc_avg:62.75% Training_loss_avg:0.633475\n",
            "Epoch:2 Step:2424 Training_loss:0.567928, Acc_avg:62.25% Training_loss_avg:0.634727\n",
            "Epoch:2 Step:2432 Training_loss:0.532508, Acc_avg:62.75% Training_loss_avg:0.629762\n",
            "Epoch:2 Step:2440 Training_loss:0.636584, Acc_avg:62.75% Training_loss_avg:0.629713\n",
            "Epoch:2 Step:2448 Training_loss:0.732366, Acc_avg:61.75% Training_loss_avg:0.632310\n",
            "Epoch:2 Step:2456 Training_loss:0.527908, Acc_avg:62.25% Training_loss_avg:0.630544\n",
            "Epoch:2 Step:2464 Training_loss:0.750607, Acc_avg:62.25% Training_loss_avg:0.631784\n",
            "Epoch:2 Step:2472 Training_loss:0.551350, Acc_avg:62.75% Training_loss_avg:0.627316\n",
            "Epoch:2 Step:2480 Training_loss:0.613908, Acc_avg:62.50% Training_loss_avg:0.628311\n",
            "Epoch:2 Step:2488 Training_loss:0.629771, Acc_avg:63.00% Training_loss_avg:0.626765\n",
            "Epoch:2 Step:2496 Training_loss:0.722859, Acc_avg:62.50% Training_loss_avg:0.630315\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2496 Val_loss:0.623581, Val_Acc_avg:63.75%\n",
            "Epoch:2 Step:2504 Training_loss:0.722752, Acc_avg:62.00% Training_loss_avg:0.633198\n",
            "Epoch:2 Step:2512 Training_loss:0.720045, Acc_avg:61.00% Training_loss_avg:0.639000\n",
            "Epoch:2 Step:2520 Training_loss:0.686601, Acc_avg:60.25% Training_loss_avg:0.640960\n",
            "Epoch:2 Step:2528 Training_loss:0.645222, Acc_avg:60.00% Training_loss_avg:0.641612\n",
            "Epoch:2 Step:2536 Training_loss:0.654089, Acc_avg:59.75% Training_loss_avg:0.642237\n",
            "Epoch:2 Step:2544 Training_loss:0.714965, Acc_avg:58.75% Training_loss_avg:0.646858\n",
            "Epoch:2 Step:2552 Training_loss:0.497088, Acc_avg:59.25% Training_loss_avg:0.643279\n",
            "Epoch:2 Step:2560 Training_loss:0.556717, Acc_avg:60.00% Training_loss_avg:0.639230\n",
            "Epoch:2 Step:2568 Training_loss:0.643153, Acc_avg:60.00% Training_loss_avg:0.638873\n",
            "Epoch:2 Step:2576 Training_loss:0.820919, Acc_avg:60.00% Training_loss_avg:0.639199\n",
            "Epoch:2 Step:2584 Training_loss:0.659229, Acc_avg:59.50% Training_loss_avg:0.642696\n",
            "Epoch:2 Step:2592 Training_loss:0.654878, Acc_avg:59.25% Training_loss_avg:0.644683\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2592 Val_loss:0.623659, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:2600 Training_loss:0.633321, Acc_avg:58.50% Training_loss_avg:0.647941\n",
            "Epoch:2 Step:2608 Training_loss:0.694285, Acc_avg:59.00% Training_loss_avg:0.646556\n",
            "Epoch:2 Step:2616 Training_loss:0.622324, Acc_avg:59.00% Training_loss_avg:0.646285\n",
            "Epoch:2 Step:2624 Training_loss:0.702829, Acc_avg:59.25% Training_loss_avg:0.645233\n",
            "Epoch:2 Step:2632 Training_loss:0.719803, Acc_avg:59.00% Training_loss_avg:0.647245\n",
            "Epoch:2 Step:2640 Training_loss:0.810822, Acc_avg:58.50% Training_loss_avg:0.651195\n",
            "Epoch:2 Step:2648 Training_loss:0.621706, Acc_avg:58.75% Training_loss_avg:0.649823\n",
            "Epoch:2 Step:2656 Training_loss:0.645282, Acc_avg:59.00% Training_loss_avg:0.647732\n",
            "Epoch:2 Step:2664 Training_loss:0.482354, Acc_avg:59.25% Training_loss_avg:0.647926\n",
            "Epoch:2 Step:2672 Training_loss:0.590001, Acc_avg:59.00% Training_loss_avg:0.644184\n",
            "Epoch:2 Step:2680 Training_loss:0.870544, Acc_avg:58.75% Training_loss_avg:0.648022\n",
            "Epoch:2 Step:2688 Training_loss:0.733474, Acc_avg:59.00% Training_loss_avg:0.646781\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2688 Val_loss:0.623644, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:2696 Training_loss:0.469653, Acc_avg:59.25% Training_loss_avg:0.643362\n",
            "Epoch:2 Step:2704 Training_loss:0.675965, Acc_avg:58.50% Training_loss_avg:0.646692\n",
            "Epoch:2 Step:2712 Training_loss:0.533305, Acc_avg:59.00% Training_loss_avg:0.646283\n",
            "Epoch:2 Step:2720 Training_loss:0.586042, Acc_avg:59.00% Training_loss_avg:0.644326\n",
            "Epoch:2 Step:2728 Training_loss:0.461187, Acc_avg:59.50% Training_loss_avg:0.640969\n",
            "Epoch:2 Step:2736 Training_loss:0.661657, Acc_avg:59.75% Training_loss_avg:0.639149\n",
            "Epoch:2 Step:2744 Training_loss:0.630408, Acc_avg:59.75% Training_loss_avg:0.639081\n",
            "Epoch:2 Step:2752 Training_loss:0.643099, Acc_avg:59.50% Training_loss_avg:0.641715\n",
            "Epoch:2 Step:2760 Training_loss:0.714536, Acc_avg:59.25% Training_loss_avg:0.644625\n",
            "Epoch:2 Step:2768 Training_loss:0.540777, Acc_avg:59.50% Training_loss_avg:0.644406\n",
            "Epoch:2 Step:2776 Training_loss:0.549498, Acc_avg:59.75% Training_loss_avg:0.641649\n",
            "Epoch:2 Step:2784 Training_loss:0.665035, Acc_avg:59.00% Training_loss_avg:0.643982\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2784 Val_loss:0.622379, Val_Acc_avg:64.50%\n",
            "Epoch:2 Step:2792 Training_loss:0.767852, Acc_avg:59.00% Training_loss_avg:0.645229\n",
            "Epoch:2 Step:2800 Training_loss:0.580688, Acc_avg:60.00% Training_loss_avg:0.641727\n",
            "Epoch:2 Step:2808 Training_loss:0.840171, Acc_avg:59.25% Training_loss_avg:0.646447\n",
            "Epoch:2 Step:2816 Training_loss:0.540385, Acc_avg:59.50% Training_loss_avg:0.644569\n",
            "Epoch:2 Step:2824 Training_loss:0.547343, Acc_avg:59.75% Training_loss_avg:0.644157\n",
            "Epoch:2 Step:2832 Training_loss:0.682222, Acc_avg:59.50% Training_loss_avg:0.647152\n",
            "Epoch:2 Step:2840 Training_loss:0.522272, Acc_avg:60.00% Training_loss_avg:0.644865\n",
            "Epoch:2 Step:2848 Training_loss:0.521979, Acc_avg:60.50% Training_loss_avg:0.640658\n",
            "Epoch:2 Step:2856 Training_loss:0.732853, Acc_avg:59.50% Training_loss_avg:0.644757\n",
            "Epoch:2 Step:2864 Training_loss:0.520387, Acc_avg:60.00% Training_loss_avg:0.640152\n",
            "Epoch:2 Step:2872 Training_loss:0.615080, Acc_avg:60.25% Training_loss_avg:0.641427\n",
            "Epoch:2 Step:2880 Training_loss:0.602826, Acc_avg:60.25% Training_loss_avg:0.641205\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2880 Val_loss:0.624038, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:2888 Training_loss:0.780918, Acc_avg:59.75% Training_loss_avg:0.644228\n",
            "Epoch:2 Step:2896 Training_loss:0.583685, Acc_avg:60.00% Training_loss_avg:0.641445\n",
            "Epoch:2 Step:2904 Training_loss:0.433126, Acc_avg:61.25% Training_loss_avg:0.635652\n",
            "Epoch:2 Step:2912 Training_loss:0.601840, Acc_avg:61.75% Training_loss_avg:0.633288\n",
            "Epoch:2 Step:2920 Training_loss:0.637202, Acc_avg:62.00% Training_loss_avg:0.632300\n",
            "Epoch:2 Step:2928 Training_loss:0.557268, Acc_avg:62.25% Training_loss_avg:0.630541\n",
            "Epoch:2 Step:2936 Training_loss:0.632449, Acc_avg:62.50% Training_loss_avg:0.630108\n",
            "Epoch:2 Step:2944 Training_loss:0.615458, Acc_avg:63.00% Training_loss_avg:0.628118\n",
            "Epoch:2 Step:2952 Training_loss:0.643661, Acc_avg:62.75% Training_loss_avg:0.631049\n",
            "Epoch:2 Step:2960 Training_loss:0.760054, Acc_avg:61.75% Training_loss_avg:0.635116\n",
            "Epoch:2 Step:2968 Training_loss:0.744202, Acc_avg:62.00% Training_loss_avg:0.637137\n",
            "Epoch:2 Step:2976 Training_loss:0.544585, Acc_avg:62.50% Training_loss_avg:0.631610\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2976 Val_loss:0.627243, Val_Acc_avg:64.25%\n",
            "Epoch:2 Step:2984 Training_loss:0.567260, Acc_avg:62.50% Training_loss_avg:0.629771\n",
            "Epoch:2 Step:2992 Training_loss:0.735486, Acc_avg:62.50% Training_loss_avg:0.631383\n",
            "Epoch:2 Step:3000 Training_loss:0.775620, Acc_avg:62.50% Training_loss_avg:0.634229\n",
            "Epoch:2 Step:3008 Training_loss:0.580586, Acc_avg:62.25% Training_loss_avg:0.631955\n",
            "Epoch:2 Step:3016 Training_loss:0.471857, Acc_avg:62.75% Training_loss_avg:0.628946\n",
            "Epoch:2 Step:3024 Training_loss:0.467767, Acc_avg:63.25% Training_loss_avg:0.624245\n",
            "Epoch:2 Step:3032 Training_loss:0.464408, Acc_avg:63.50% Training_loss_avg:0.619137\n",
            "Epoch:2 Step:3040 Training_loss:0.681804, Acc_avg:63.50% Training_loss_avg:0.616556\n",
            "Epoch:2 Step:3048 Training_loss:0.513129, Acc_avg:63.50% Training_loss_avg:0.614385\n",
            "Epoch:2 Step:3056 Training_loss:0.713657, Acc_avg:63.75% Training_loss_avg:0.615752\n",
            "Epoch:2 Step:3064 Training_loss:0.854671, Acc_avg:62.75% Training_loss_avg:0.623199\n",
            "Epoch:2 Step:3072 Training_loss:0.614579, Acc_avg:63.00% Training_loss_avg:0.623690\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:3072 Val_loss:0.619507, Val_Acc_avg:64.00%\n",
            "Epoch:2 Step:3080 Training_loss:0.506884, Acc_avg:63.75% Training_loss_avg:0.616417\n",
            "Epoch:2 Step:3088 Training_loss:0.625837, Acc_avg:64.00% Training_loss_avg:0.614264\n",
            "Epoch:2 Step:3096 Training_loss:0.744827, Acc_avg:63.50% Training_loss_avg:0.619768\n",
            "Epoch:2 Step:3104 Training_loss:0.609787, Acc_avg:63.75% Training_loss_avg:0.618444\n",
            "Epoch:2 Step:3112 Training_loss:0.741441, Acc_avg:63.00% Training_loss_avg:0.622607\n",
            "Epoch:2 Step:3120 Training_loss:0.559639, Acc_avg:63.50% Training_loss_avg:0.622079\n",
            "Epoch:2 Step:3128 Training_loss:0.589229, Acc_avg:63.50% Training_loss_avg:0.624640\n",
            "Epoch:2 Step:3136 Training_loss:0.518200, Acc_avg:64.25% Training_loss_avg:0.621771\n",
            "Epoch:2 Step:3144 Training_loss:0.522331, Acc_avg:64.75% Training_loss_avg:0.619609\n",
            "Epoch:2 Step:3152 Training_loss:0.573722, Acc_avg:64.50% Training_loss_avg:0.618221\n",
            "Epoch:2 Step:3160 Training_loss:0.670576, Acc_avg:65.00% Training_loss_avg:0.617342\n",
            "Epoch:2 Step:3168 Training_loss:0.556874, Acc_avg:64.75% Training_loss_avg:0.617664\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:3168 Val_loss:0.620180, Val_Acc_avg:63.25%\n",
            "Epoch:2 Step:3176 Training_loss:0.704453, Acc_avg:64.50% Training_loss_avg:0.620763\n",
            "Epoch:2 Step:3184 Training_loss:0.543292, Acc_avg:64.50% Training_loss_avg:0.618328\n",
            "Epoch:2 Step:3192 Training_loss:0.649166, Acc_avg:64.50% Training_loss_avg:0.615955\n",
            "Epoch:2 Step:3200 Training_loss:0.595440, Acc_avg:64.50% Training_loss_avg:0.616250\n",
            "Epoch:2 Step:3208 Training_loss:0.675659, Acc_avg:65.75% Training_loss_avg:0.612960\n",
            "Epoch:2 Step:3216 Training_loss:0.516820, Acc_avg:65.75% Training_loss_avg:0.612488\n",
            "Epoch:2 Step:3224 Training_loss:0.675342, Acc_avg:65.25% Training_loss_avg:0.615048\n",
            "Epoch:2 Step:3232 Training_loss:0.504059, Acc_avg:65.75% Training_loss_avg:0.611485\n",
            "Epoch:2 Step:3240 Training_loss:0.517612, Acc_avg:65.50% Training_loss_avg:0.611392\n",
            "Epoch:2 Step:3248 Training_loss:0.539807, Acc_avg:65.75% Training_loss_avg:0.611748\n",
            "Epoch:2 Step:3256 Training_loss:0.865953, Acc_avg:66.00% Training_loss_avg:0.614410\n",
            "Epoch:2 Step:3264 Training_loss:0.598505, Acc_avg:65.75% Training_loss_avg:0.615973\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "27it [00:04,  6.54it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Training Analysis"
      ],
      "metadata": {
        "id": "eDX7MNXrs9gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation loss vs epochs plot"
      ],
      "metadata": {
        "id": "5Au6fzpFCVYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Messy code to extract information from the dumped .txt files\n",
        "# Could be significantly improved + streamlined\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "with open(\"{}/train_loss.txt\".format(dir_name)) as f:\n",
        "    contents = f.readlines()\n",
        "\n",
        "train_loss = [i.split(' ')[-2].split(':')[-1] for i in contents]\n",
        "train_loss = [float(i.split(',')[0]) for i in train_loss]\n",
        "\n",
        "train_step = [int(i.split(' ')[1].split(':')[-1]) for i in contents]\n",
        "train_epoch = [int(i.split(' ')[0].split(':')[-1]) for i in contents]\n",
        "\n",
        "train_total_step = []\n",
        "\n",
        "steps_per_epoch = max(train_step)\n",
        "for i in range(len(train_step)):\n",
        "    train_total_step.append(steps_per_epoch*train_epoch[i]+train_step[i])\n",
        "\n",
        "\n",
        "\n",
        "with open(\"{}/val_loss.txt\".format(dir_name)) as f:\n",
        "    contents = f.readlines()\n",
        "\n",
        "val_loss = [i.split(' ')[-2].split(':')[-1] for i in contents]\n",
        "val_loss = [float(i.split(',')[0]) for i in val_loss]\n",
        "\n",
        "val_step = [int(i.split(' ')[1].split(':')[-1]) for i in contents]\n",
        "val_epoch = [int(i.split(' ')[0].split(':')[-1]) for i in contents]\n",
        "\n",
        "val_total_step = []\n",
        "\n",
        "for i in range(len(val_step)):\n",
        "    val_total_step.append(steps_per_epoch*val_epoch[i]+val_step[i])\n",
        "\n",
        "\n",
        "train_epochs = np.array(train_total_step)/steps_per_epoch\n",
        "val_epochs = np.array(val_total_step)/steps_per_epoch\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(train_epochs,train_loss, label='Training')\n",
        "plt.plot(val_epochs, val_loss, label='Validation')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "train_epochs = np.array(train_total_step[49:-50])/steps_per_epoch\n",
        "val_epochs = np.array(val_total_step[2:-3])/steps_per_epoch\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(train_epochs, moving_average(train_loss,100), label='Training')\n",
        "plt.plot(val_epochs, moving_average(val_loss,6), label='Validation')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "pyDXqGa5CU3f",
        "outputId": "c9b20b32-e2ff-46ce-f6a7-2b0f3cff7666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model performance and confusion matrix"
      ],
      "metadata": {
        "id": "2pjaEPmtCRqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading finetuned model\n",
        "run_name = \"Final_lr=5e-6\"\n",
        "model_name = 'codebert-base'\n",
        "dir_name = 'codebert_finetune_runs/{}'.format(run_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"codebert_finetune_runs/Final_lr=5e-6/epoch_5\").to(device)\n",
        "\n",
        "test_acc = []\n",
        "test_loss_total = 0\n",
        "(X_train, A_train, Y_train), (X_val, A_val, Y_val), (X_test, A_test, Y_test) = split_loader(dir_name)\n",
        "\n",
        "pred_list = []\n",
        "truth_list = []\n",
        "\n",
        "for test_badtch_id, j in tqdm(enumerate(range(0, X_test.shape[0]))):\n",
        "                    # Loading singular validation data (overwrites train data as can only load 1 intp GPU)\n",
        "                    batch_X, batch_Y, batch_A = X_test[j:j+1].to(device), Y_test[j:j+1].to(device), A_test[j:j+1].to(device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        test_outputs = model(batch_X, labels=batch_Y, attention_mask=batch_A)\n",
        "                    test_loss_total += float(test_outputs['loss'].item())\n",
        "\n",
        "                    \n",
        "                    test_clsf = nn.Softmax(dim=1)(test_outputs.logits)\n",
        "\n",
        "                    pred_list.append(test_clsf.argmax(axis=1).cpu()[0].item())\n",
        "                    truth_list.append(batch_Y.cpu()[0].item())\n",
        "\n",
        "                    test_acc.append(np.average(torch.eq(batch_Y.cpu(), test_clsf.argmax(axis=1).cpu())))\n",
        "\n",
        "test_loss_total /= (j+1)\n",
        "test_acc = np.average(test_acc)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(truth_list, pred_list).ravel()\n",
        "\n",
        "print(\"\\n\\nConfusion Matrix:\")\n",
        "print(\"TP: {}, FP:{}\\nFN:{}, TN:{}\".format(tp, fp, fn, tn))\n",
        "print(\"\\nAccuracy {:.4f}\".format(test_acc))\n",
        "print(\"Precision: {:.4f}\".format(tp/(tp+fp)))\n",
        "print(\"Recall: {:.4f}\".format(tp/(tp+fn)))\n"
      ],
      "metadata": {
        "id": "nCFAxXRkuCxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1f9753-50db-44ee-c0a6-585a86cf996d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "417it [00:09, 44.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "TP: 47, FP:6\n",
            "FN:155, TN:209\n",
            "\n",
            "Accuracy 0.6139\n",
            "Precision: 0.8868\n",
            "Recall: 0.2327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified BERT architechture with additional FNN layers"
      ],
      "metadata": {
        "id": "UpeLP0AZcSxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bellow there are experiments with a modified BERT architechture, this has not been cleaned as the results were worse than above. For similar reasons it was not included within the report"
      ],
      "metadata": {
        "id": "UHhtBCuDci52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(512,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "      x = self.fc1(cls_hs.logits)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "1YzMHJ__gASY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Main configuration function for a given finetune run\n",
        ":return: None\n",
        "\"\"\"\n",
        "run_name = \"lr_5e-5 redo, 512 split Full unfreeze\"\n",
        "run_dir = \"codebert_finetune_runs/{}\".format(run_name)\n",
        "model_name = 'codebert-base'\n",
        "checkpoint_location = None\n",
        "online = False\n",
        "load_splits = False\n",
        "save_data = True\n",
        "\n",
        "print(\"generating data splits\")\n",
        "\n",
        "code_df = preprocess_data(file_loc='code_dataset.jsonl')\n",
        "train_data, val_data, test_data = tokenize(code_df, model_name=model_name)\n",
        "\n",
        "X_train, A_train, Y_train = train_data\n",
        "X_val, A_val, Y_val = val_data\n",
        "X_test, A_test, Y_test = test_data\n",
        "\n",
        "data_type = ['train', 'val', 'test']\n",
        "data_split_type = ['X', 'A', 'Y']\n",
        "\n",
        "\n",
        "# Creating dir to save logs and checkpoints, re\n",
        "dir_name = \"{}\".format(run_dir)\n",
        "if os.path.exists(dir_name):\n",
        "  input(\"run name already exists, press Enter to overwrite\")\n",
        "else:\n",
        "  os.makedirs(dir_name)\n",
        "\n",
        "if save_data:\n",
        "  print(\"saving data splits\")\n",
        "\n",
        "  data_all = [train_data, val_data, test_data]\n",
        "  for i, data in enumerate(data_all):\n",
        "    for j, split in enumerate(data):\n",
        "      with open('{}/{}_{}.pickle'.format(run_dir,data_type[i], data_split_type[j]), 'wb') as handle:\n",
        "        pickle.dump(split, handle)\n",
        "\n",
        "# Loading model from checkpoint if location provided\n",
        "if online:\n",
        "  print(\"loading model from online\")\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\")\n",
        "elif checkpoint_location is None:\n",
        "  print(\"loading model from local repo\")\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=512)\n",
        "else:\n",
        "  print(\"loading model from checkpoint: {}\".format(checkpoint_location))\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(checkpoint_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAaxK3INearK",
        "outputId": "e8e3dfc4-a772-48c5-8f63-d703383615bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating data splits\n",
            "Insecure code counts: 3729, Total code counts: 8000, Proportion 0.466125\n",
            "Data points: 8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving data splits\n",
            "loading model from local repo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "kzyyeN-ogL5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = BERT_Arch(model)"
      ],
      "metadata": {
        "id": "SLPhcojUu6ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = custom_model.to(device)"
      ],
      "metadata": {
        "id": "pdyLbDQlgbyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_custom(model, train_data, val_data, epochs=5, batch_size=16, learning_rate=2e-5, validate_per=500,\n",
        "          run_name=\"temp\", run_descrption=None):\n",
        "    \"\"\"\n",
        "    Main fine-tuning training loop for the provided model\n",
        "\n",
        "    :param model: model loaded with predefined weights\n",
        "    :param train_data: tuple of X_train, A_train, Y_train (X = inputs, A = attention, Y = target)\n",
        "    :param val_data: tuple X_val, A_val, Y_val\n",
        "    :param epochs: number of epochs for training\n",
        "    :param batch_size: batch size (see note below about batch_hack)\n",
        "    :param learning_rate: optimizer learning rate\n",
        "    :param validate_per: number of weight updates before validation occurs\n",
        "                            (notes: - if batch_size = 32, and validate_per = 32, validation will occur every batch\n",
        "                                    - this is wrt the start of each epoch\n",
        "                                    - validation will always occour at the start of each epoch (step 0))\n",
        "    :param run_name: name used to saving checkpoints and log files within codebert_finetune_runs\n",
        "    :param run_descrption: string that is saved to info.txt describing the run\n",
        "\n",
        "\n",
        "    :return: None (models are saved in checkpoints along with log data)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Saving run description.txt\n",
        "    if run_descrption is not None:\n",
        "        with open(\"{}/info.txt\".format(dir_name), \"a+\") as f:\n",
        "            f.write(run_descrption)\n",
        "\n",
        "    # Unpacking data\n",
        "    X_train, A_train, Y_train = train_data\n",
        "    X_val, A_val, Y_val = val_data\n",
        "\n",
        "\n",
        "    batch_hack = batch_size  # See note below regarding limited GPU memory\n",
        "\n",
        "    # Initializing arrays for tracking loss\n",
        "    train_loss_hist = []\n",
        "    val_loss_hist = []\n",
        "    train_pred_hist = []\n",
        "    # Counter to track batches (see note below related to GPU memory)\n",
        "    batch_count = 0\n",
        "    # validate_per_batch = int(validate_per/batch_hack)\n",
        "\n",
        "    # Moving model to GPU if configured\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    validate_per = int(validate_per/batch_size)\n",
        "\n",
        "    cross_entropy  = nn.NLLLoss() \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Generating random index for manual shuffling of data each epoch as note using DataLoaders\n",
        "        permutation = torch.randperm(X_train.shape[0])\n",
        "\n",
        "        # Note here that only a single element is loaded at each iteration (batch size = 1) due to GPU memory constraint\n",
        "        for batch_id, i in enumerate(range(0, X_train.shape[0], batch_hack)):\n",
        "\n",
        "            # Loading batch and moving to device\n",
        "            indices = permutation[i:i + batch_hack]\n",
        "            batch_X, batch_Y, batch_A = X_train[indices].to(device), Y_train[indices].to(device), A_train[indices].to(device)\n",
        "\n",
        "\n",
        "            batch_Y_one_hot = torch.nn.functional.one_hot(batch_Y, num_classes= 2)\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            # Forward pass\n",
        "            #outputs = model(batch_X,labels=batch_Y, attention_mask=batch_A)\n",
        "            outputs = model(batch_X, batch_A)\n",
        "\n",
        "            #loss = criterion(loss_clsf.float(), batch_Y_one_hot.float())\n",
        "            #loss = outputs.loss\n",
        "\n",
        "            loss = cross_entropy(outputs, batch_Y)\n",
        "\n",
        "\n",
        "            # Clip params\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_clsf = nn.Softmax(dim=1)(outputs)\n",
        "            acc = np.average(torch.eq(batch_Y.cpu(), loss_clsf.argmax(axis=1).cpu()))\n",
        "            #rint(correct)\n",
        "\n",
        "            # Tracking loss\n",
        "            train_loss_hist.append(float(loss.item()))\n",
        "            train_pred_hist.append(acc)\n",
        "\n",
        "            # Training output\n",
        "            train_output = \"Epoch:{} Step:{} Training_loss:{:.6f}, Acc_avg:{:.2f}%\".format(epoch, i, loss.item(), np.sum(100*train_pred_hist[-50:])/min(len(train_pred_hist), 50))\n",
        "            print(train_output+\" Training_loss_avg:{:.6f}\".format(np.average(train_loss_hist[-50:])))\n",
        "            with open(\"{}/train_loss.txt\".format(dir_name), \"a+\") as f:\n",
        "                f.write(train_output+\"\\n\")\n",
        "\n",
        "            # Validation\n",
        "            if batch_id % validate_per == 0:\n",
        "                val_loss_total = 0\n",
        "                model.eval()\n",
        "                print(\"Validating:\")\n",
        "                val_acc = []\n",
        "                for val_badtch_id, j in tqdm(enumerate(range(0, X_val.shape[0], batch_hack))):\n",
        "                    # Loading singular validation data (overwrites train data as can only load 1 intp GPU)\n",
        "                    batch_X, batch_Y, batch_A = X_val[j:j+batch_hack].to(device), Y_val[j:j+batch_hack].to(device), A_val[j:j+batch_hack].to(device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(batch_X, batch_A)\n",
        "\n",
        "                    val_loss = cross_entropy(outputs, batch_Y)\n",
        "                    val_loss_total += float(val_loss)\n",
        "\n",
        "                    \n",
        "                    val_clsf = nn.Softmax(dim=1)(outputs)\n",
        "                    val_acc.append(np.average(torch.eq(batch_Y.cpu(), val_clsf.argmax(axis=1).cpu())))\n",
        "\n",
        "                    del batch_X\n",
        "                    del batch_Y\n",
        "\n",
        "                # Adding average loss to tracker\n",
        "                val_average = val_loss_total / (val_badtch_id+1)\n",
        "                val_loss_hist.append(val_average)\n",
        "\n",
        "                # Validation output and logging\n",
        "                val_output = \"Epoch:{} Step:{} Val_loss:{:.6f}, Val_Acc_avg:{:.2f}%\".format(epoch, i, val_average, np.sum(100*val_acc[-50:])/min(len(val_acc), 50))\n",
        "                print(val_output)\n",
        "                with open(\"{}/val_los.txt\".format(dir_name), \"a+\") as f:\n",
        "                    f.write(val_output+\"\\n\")\n",
        "\n",
        "        # End of epoch checkpoint\n",
        "        #model.save_pretrained(\"{}/epoch_{}\".format(dir_name, epoch + 1))\n",
        "        torch.save(model, \"{}/epoch_{}\".format(dir_name, epoch + 1))\n"
      ],
      "metadata": {
        "id": "K9PZIMx4gkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_custom(model=custom_model,\n",
        "      train_data=train_data,\n",
        "      val_data=val_data,\n",
        "      epochs=10,\n",
        "      batch_size=8,\n",
        "      learning_rate=5e-5,\n",
        "      validate_per=250,\n",
        "      run_name=run_name,\n",
        "      run_descrption=\"lr_5e-5 redo\")"
      ],
      "metadata": {
        "id": "z9XcxQb1gJH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec69e422-ef10-4290-b902-34d2bc3c4c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:0 Training_loss:0.690187, Acc_avg:62.50% Training_loss_avg:0.690187\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:0 Val_loss:0.694344, Val_Acc_avg:45.25%\n",
            "Epoch:0 Step:8 Training_loss:0.680802, Acc_avg:56.25% Training_loss_avg:0.685494\n",
            "Epoch:0 Step:16 Training_loss:0.673006, Acc_avg:58.33% Training_loss_avg:0.681332\n",
            "Epoch:0 Step:24 Training_loss:0.697169, Acc_avg:56.25% Training_loss_avg:0.685291\n",
            "Epoch:0 Step:32 Training_loss:0.741785, Acc_avg:50.00% Training_loss_avg:0.696590\n",
            "Epoch:0 Step:40 Training_loss:0.683279, Acc_avg:52.08% Training_loss_avg:0.694371\n",
            "Epoch:0 Step:48 Training_loss:0.709840, Acc_avg:51.79% Training_loss_avg:0.696581\n",
            "Epoch:0 Step:56 Training_loss:0.716756, Acc_avg:50.00% Training_loss_avg:0.699103\n",
            "Epoch:0 Step:64 Training_loss:0.698136, Acc_avg:48.61% Training_loss_avg:0.698996\n",
            "Epoch:0 Step:72 Training_loss:0.681654, Acc_avg:51.25% Training_loss_avg:0.697261\n",
            "Epoch:0 Step:80 Training_loss:0.666886, Acc_avg:52.27% Training_loss_avg:0.694500\n",
            "Epoch:0 Step:88 Training_loss:0.753497, Acc_avg:50.00% Training_loss_avg:0.699416\n",
            "Epoch:0 Step:96 Training_loss:0.744714, Acc_avg:49.04% Training_loss_avg:0.702901\n",
            "Epoch:0 Step:104 Training_loss:0.721307, Acc_avg:49.11% Training_loss_avg:0.704216\n",
            "Epoch:0 Step:112 Training_loss:0.691221, Acc_avg:49.17% Training_loss_avg:0.703349\n",
            "Epoch:0 Step:120 Training_loss:0.645314, Acc_avg:50.78% Training_loss_avg:0.699722\n",
            "Epoch:0 Step:128 Training_loss:0.692669, Acc_avg:50.74% Training_loss_avg:0.699307\n",
            "Epoch:0 Step:136 Training_loss:0.690068, Acc_avg:50.69% Training_loss_avg:0.698794\n",
            "Epoch:0 Step:144 Training_loss:0.760189, Acc_avg:49.34% Training_loss_avg:0.702025\n",
            "Epoch:0 Step:152 Training_loss:0.661865, Acc_avg:50.00% Training_loss_avg:0.700017\n",
            "Epoch:0 Step:160 Training_loss:0.661982, Acc_avg:50.60% Training_loss_avg:0.698206\n",
            "Epoch:0 Step:168 Training_loss:0.725857, Acc_avg:50.00% Training_loss_avg:0.699463\n",
            "Epoch:0 Step:176 Training_loss:0.732834, Acc_avg:49.46% Training_loss_avg:0.700914\n",
            "Epoch:0 Step:184 Training_loss:0.688293, Acc_avg:49.48% Training_loss_avg:0.700388\n",
            "Epoch:0 Step:192 Training_loss:0.738334, Acc_avg:49.00% Training_loss_avg:0.701906\n",
            "Epoch:0 Step:200 Training_loss:0.725251, Acc_avg:48.08% Training_loss_avg:0.702804\n",
            "Epoch:0 Step:208 Training_loss:0.663542, Acc_avg:49.07% Training_loss_avg:0.701350\n",
            "Epoch:0 Step:216 Training_loss:0.695921, Acc_avg:48.66% Training_loss_avg:0.701156\n",
            "Epoch:0 Step:224 Training_loss:0.698186, Acc_avg:48.71% Training_loss_avg:0.701053\n",
            "Epoch:0 Step:232 Training_loss:0.663973, Acc_avg:50.00% Training_loss_avg:0.699817\n",
            "Epoch:0 Step:240 Training_loss:0.680461, Acc_avg:50.81% Training_loss_avg:0.699193\n",
            "Epoch:0 Step:248 Training_loss:0.677290, Acc_avg:50.78% Training_loss_avg:0.698508\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:248 Val_loss:0.690676, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:256 Training_loss:0.666537, Acc_avg:51.52% Training_loss_avg:0.697540\n",
            "Epoch:0 Step:264 Training_loss:0.680447, Acc_avg:51.84% Training_loss_avg:0.697037\n",
            "Epoch:0 Step:272 Training_loss:0.720582, Acc_avg:51.07% Training_loss_avg:0.697710\n",
            "Epoch:0 Step:280 Training_loss:0.702439, Acc_avg:50.69% Training_loss_avg:0.697841\n",
            "Epoch:0 Step:288 Training_loss:0.675730, Acc_avg:51.35% Training_loss_avg:0.697243\n",
            "Epoch:0 Step:296 Training_loss:0.689450, Acc_avg:50.99% Training_loss_avg:0.697038\n",
            "Epoch:0 Step:304 Training_loss:0.664400, Acc_avg:51.60% Training_loss_avg:0.696201\n",
            "Epoch:0 Step:312 Training_loss:0.696716, Acc_avg:51.56% Training_loss_avg:0.696214\n",
            "Epoch:0 Step:320 Training_loss:0.642353, Acc_avg:52.13% Training_loss_avg:0.694901\n",
            "Epoch:0 Step:328 Training_loss:0.637699, Acc_avg:52.98% Training_loss_avg:0.693539\n",
            "Epoch:0 Step:336 Training_loss:0.654247, Acc_avg:53.20% Training_loss_avg:0.692625\n",
            "Epoch:0 Step:344 Training_loss:0.679312, Acc_avg:53.41% Training_loss_avg:0.692322\n",
            "Epoch:0 Step:352 Training_loss:0.654241, Acc_avg:53.61% Training_loss_avg:0.691476\n",
            "Epoch:0 Step:360 Training_loss:0.749308, Acc_avg:53.53% Training_loss_avg:0.692733\n",
            "Epoch:0 Step:368 Training_loss:0.584409, Acc_avg:54.26% Training_loss_avg:0.690428\n",
            "Epoch:0 Step:376 Training_loss:0.715137, Acc_avg:54.17% Training_loss_avg:0.690943\n",
            "Epoch:0 Step:384 Training_loss:0.716415, Acc_avg:54.08% Training_loss_avg:0.691463\n",
            "Epoch:0 Step:392 Training_loss:0.888163, Acc_avg:53.50% Training_loss_avg:0.695397\n",
            "Epoch:0 Step:400 Training_loss:0.718678, Acc_avg:53.25% Training_loss_avg:0.695967\n",
            "Epoch:0 Step:408 Training_loss:0.680742, Acc_avg:53.25% Training_loss_avg:0.695966\n",
            "Epoch:0 Step:416 Training_loss:0.657705, Acc_avg:53.50% Training_loss_avg:0.695660\n",
            "Epoch:0 Step:424 Training_loss:0.761603, Acc_avg:53.25% Training_loss_avg:0.696948\n",
            "Epoch:0 Step:432 Training_loss:0.666756, Acc_avg:53.75% Training_loss_avg:0.695448\n",
            "Epoch:0 Step:440 Training_loss:0.721200, Acc_avg:53.50% Training_loss_avg:0.696206\n",
            "Epoch:0 Step:448 Training_loss:0.693312, Acc_avg:53.50% Training_loss_avg:0.695876\n",
            "Epoch:0 Step:456 Training_loss:0.673411, Acc_avg:54.00% Training_loss_avg:0.695009\n",
            "Epoch:0 Step:464 Training_loss:0.673614, Acc_avg:54.50% Training_loss_avg:0.694518\n",
            "Epoch:0 Step:472 Training_loss:0.664243, Acc_avg:54.25% Training_loss_avg:0.694170\n",
            "Epoch:0 Step:480 Training_loss:0.770902, Acc_avg:53.50% Training_loss_avg:0.696250\n",
            "Epoch:0 Step:488 Training_loss:0.719758, Acc_avg:54.00% Training_loss_avg:0.695576\n",
            "Epoch:0 Step:496 Training_loss:0.658796, Acc_avg:54.50% Training_loss_avg:0.693857\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:496 Val_loss:0.689451, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:504 Training_loss:0.728552, Acc_avg:54.00% Training_loss_avg:0.694002\n",
            "Epoch:0 Step:512 Training_loss:0.655941, Acc_avg:54.50% Training_loss_avg:0.693297\n",
            "Epoch:0 Step:520 Training_loss:0.705081, Acc_avg:54.00% Training_loss_avg:0.694492\n",
            "Epoch:0 Step:528 Training_loss:0.673421, Acc_avg:54.25% Training_loss_avg:0.694107\n",
            "Epoch:0 Step:536 Training_loss:0.738257, Acc_avg:53.50% Training_loss_avg:0.695071\n",
            "Epoch:0 Step:544 Training_loss:0.687615, Acc_avg:54.25% Training_loss_avg:0.693619\n",
            "Epoch:0 Step:552 Training_loss:0.706785, Acc_avg:53.75% Training_loss_avg:0.694518\n",
            "Epoch:0 Step:560 Training_loss:0.722193, Acc_avg:52.75% Training_loss_avg:0.695722\n",
            "Epoch:0 Step:568 Training_loss:0.713471, Acc_avg:52.75% Training_loss_avg:0.695474\n",
            "Epoch:0 Step:576 Training_loss:0.694515, Acc_avg:53.25% Training_loss_avg:0.694708\n",
            "Epoch:0 Step:584 Training_loss:0.709620, Acc_avg:52.75% Training_loss_avg:0.695134\n",
            "Epoch:0 Step:592 Training_loss:0.687865, Acc_avg:53.75% Training_loss_avg:0.694125\n",
            "Epoch:0 Step:600 Training_loss:0.693733, Acc_avg:54.50% Training_loss_avg:0.693495\n",
            "Epoch:0 Step:608 Training_loss:0.704814, Acc_avg:53.50% Training_loss_avg:0.694320\n",
            "Epoch:0 Step:616 Training_loss:0.723881, Acc_avg:53.25% Training_loss_avg:0.694879\n",
            "Epoch:0 Step:624 Training_loss:0.696286, Acc_avg:53.00% Training_loss_avg:0.694841\n",
            "Epoch:0 Step:632 Training_loss:0.688121, Acc_avg:52.25% Training_loss_avg:0.695324\n",
            "Epoch:0 Step:640 Training_loss:0.675868, Acc_avg:52.00% Training_loss_avg:0.695232\n",
            "Epoch:0 Step:648 Training_loss:0.689434, Acc_avg:52.00% Training_loss_avg:0.695475\n",
            "Epoch:0 Step:656 Training_loss:0.733065, Acc_avg:50.50% Training_loss_avg:0.696806\n",
            "Epoch:0 Step:664 Training_loss:0.694715, Acc_avg:50.25% Training_loss_avg:0.697091\n",
            "Epoch:0 Step:672 Training_loss:0.701573, Acc_avg:50.75% Training_loss_avg:0.696711\n",
            "Epoch:0 Step:680 Training_loss:0.689014, Acc_avg:51.50% Training_loss_avg:0.696442\n",
            "Epoch:0 Step:688 Training_loss:0.705904, Acc_avg:50.50% Training_loss_avg:0.697046\n",
            "Epoch:0 Step:696 Training_loss:0.702465, Acc_avg:50.50% Training_loss_avg:0.697306\n",
            "Epoch:0 Step:704 Training_loss:0.690746, Acc_avg:50.25% Training_loss_avg:0.697833\n",
            "Epoch:0 Step:712 Training_loss:0.692609, Acc_avg:50.00% Training_loss_avg:0.697751\n",
            "Epoch:0 Step:720 Training_loss:0.674156, Acc_avg:50.00% Training_loss_avg:0.698387\n",
            "Epoch:0 Step:728 Training_loss:0.676867, Acc_avg:49.25% Training_loss_avg:0.699170\n",
            "Epoch:0 Step:736 Training_loss:0.682994, Acc_avg:49.75% Training_loss_avg:0.699745\n",
            "Epoch:0 Step:744 Training_loss:0.689043, Acc_avg:49.25% Training_loss_avg:0.699940\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:744 Val_loss:0.690865, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:752 Training_loss:0.691318, Acc_avg:49.25% Training_loss_avg:0.700681\n",
            "Epoch:0 Step:760 Training_loss:0.710777, Acc_avg:49.00% Training_loss_avg:0.699911\n",
            "Epoch:0 Step:768 Training_loss:0.701909, Acc_avg:48.00% Training_loss_avg:0.702261\n",
            "Epoch:0 Step:776 Training_loss:0.656889, Acc_avg:48.50% Training_loss_avg:0.701096\n",
            "Epoch:0 Step:784 Training_loss:0.669000, Acc_avg:48.75% Training_loss_avg:0.700148\n",
            "Epoch:0 Step:792 Training_loss:0.702417, Acc_avg:49.25% Training_loss_avg:0.696433\n",
            "Epoch:0 Step:800 Training_loss:0.694154, Acc_avg:49.25% Training_loss_avg:0.695942\n",
            "Epoch:0 Step:808 Training_loss:0.722732, Acc_avg:49.25% Training_loss_avg:0.696782\n",
            "Epoch:0 Step:816 Training_loss:0.679268, Acc_avg:48.50% Training_loss_avg:0.697213\n",
            "Epoch:0 Step:824 Training_loss:0.688930, Acc_avg:49.00% Training_loss_avg:0.695760\n",
            "Epoch:0 Step:832 Training_loss:0.697173, Acc_avg:48.75% Training_loss_avg:0.696368\n",
            "Epoch:0 Step:840 Training_loss:0.672894, Acc_avg:49.00% Training_loss_avg:0.695402\n",
            "Epoch:0 Step:848 Training_loss:0.647253, Acc_avg:49.50% Training_loss_avg:0.694481\n",
            "Epoch:0 Step:856 Training_loss:0.655860, Acc_avg:49.75% Training_loss_avg:0.694130\n",
            "Epoch:0 Step:864 Training_loss:0.700680, Acc_avg:49.50% Training_loss_avg:0.694671\n",
            "Epoch:0 Step:872 Training_loss:0.733984, Acc_avg:49.00% Training_loss_avg:0.696066\n",
            "Epoch:0 Step:880 Training_loss:0.745465, Acc_avg:48.75% Training_loss_avg:0.695557\n",
            "Epoch:0 Step:888 Training_loss:0.734158, Acc_avg:48.50% Training_loss_avg:0.695845\n",
            "Epoch:0 Step:896 Training_loss:0.705944, Acc_avg:48.25% Training_loss_avg:0.696788\n",
            "Epoch:0 Step:904 Training_loss:0.682380, Acc_avg:49.00% Training_loss_avg:0.695865\n",
            "Epoch:0 Step:912 Training_loss:0.690402, Acc_avg:48.25% Training_loss_avg:0.696554\n",
            "Epoch:0 Step:920 Training_loss:0.688733, Acc_avg:48.25% Training_loss_avg:0.696227\n",
            "Epoch:0 Step:928 Training_loss:0.698135, Acc_avg:47.75% Training_loss_avg:0.696721\n",
            "Epoch:0 Step:936 Training_loss:0.687940, Acc_avg:48.75% Training_loss_avg:0.695715\n",
            "Epoch:0 Step:944 Training_loss:0.751101, Acc_avg:48.25% Training_loss_avg:0.696985\n",
            "Epoch:0 Step:952 Training_loss:0.674164, Acc_avg:48.75% Training_loss_avg:0.696332\n",
            "Epoch:0 Step:960 Training_loss:0.710325, Acc_avg:49.25% Training_loss_avg:0.696095\n",
            "Epoch:0 Step:968 Training_loss:0.702741, Acc_avg:49.25% Training_loss_avg:0.695880\n",
            "Epoch:0 Step:976 Training_loss:0.710222, Acc_avg:49.00% Training_loss_avg:0.696194\n",
            "Epoch:0 Step:984 Training_loss:0.688745, Acc_avg:50.00% Training_loss_avg:0.695777\n",
            "Epoch:0 Step:992 Training_loss:0.691460, Acc_avg:49.25% Training_loss_avg:0.695849\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:992 Val_loss:0.693227, Val_Acc_avg:51.25%\n",
            "Epoch:0 Step:1000 Training_loss:0.714614, Acc_avg:49.00% Training_loss_avg:0.696266\n",
            "Epoch:0 Step:1008 Training_loss:0.706624, Acc_avg:49.25% Training_loss_avg:0.696303\n",
            "Epoch:0 Step:1016 Training_loss:0.692806, Acc_avg:49.75% Training_loss_avg:0.695681\n",
            "Epoch:0 Step:1024 Training_loss:0.696425, Acc_avg:49.75% Training_loss_avg:0.695684\n",
            "Epoch:0 Step:1032 Training_loss:0.700209, Acc_avg:49.50% Training_loss_avg:0.695926\n",
            "Epoch:0 Step:1040 Training_loss:0.683811, Acc_avg:49.50% Training_loss_avg:0.696085\n",
            "Epoch:0 Step:1048 Training_loss:0.690085, Acc_avg:49.25% Training_loss_avg:0.696098\n",
            "Epoch:0 Step:1056 Training_loss:0.697493, Acc_avg:50.00% Training_loss_avg:0.695386\n",
            "Epoch:0 Step:1064 Training_loss:0.682435, Acc_avg:50.25% Training_loss_avg:0.695141\n",
            "Epoch:0 Step:1072 Training_loss:0.665634, Acc_avg:51.00% Training_loss_avg:0.694422\n",
            "Epoch:0 Step:1080 Training_loss:0.703195, Acc_avg:50.50% Training_loss_avg:0.694705\n",
            "Epoch:0 Step:1088 Training_loss:0.703190, Acc_avg:50.75% Training_loss_avg:0.694651\n",
            "Epoch:0 Step:1096 Training_loss:0.699045, Acc_avg:51.00% Training_loss_avg:0.694583\n",
            "Epoch:0 Step:1104 Training_loss:0.651916, Acc_avg:51.50% Training_loss_avg:0.693806\n",
            "Epoch:0 Step:1112 Training_loss:0.630594, Acc_avg:52.25% Training_loss_avg:0.692566\n",
            "Epoch:0 Step:1120 Training_loss:0.649597, Acc_avg:52.25% Training_loss_avg:0.692075\n",
            "Epoch:0 Step:1128 Training_loss:0.642134, Acc_avg:52.75% Training_loss_avg:0.691380\n",
            "Epoch:0 Step:1136 Training_loss:0.721291, Acc_avg:51.75% Training_loss_avg:0.692146\n",
            "Epoch:0 Step:1144 Training_loss:0.639189, Acc_avg:52.25% Training_loss_avg:0.691149\n",
            "Epoch:0 Step:1152 Training_loss:0.607228, Acc_avg:52.50% Training_loss_avg:0.689467\n",
            "Epoch:0 Step:1160 Training_loss:0.769996, Acc_avg:52.25% Training_loss_avg:0.690651\n",
            "Epoch:0 Step:1168 Training_loss:0.670038, Acc_avg:52.75% Training_loss_avg:0.690014\n",
            "Epoch:0 Step:1176 Training_loss:0.678233, Acc_avg:52.25% Training_loss_avg:0.690441\n",
            "Epoch:0 Step:1184 Training_loss:0.820898, Acc_avg:51.50% Training_loss_avg:0.693479\n",
            "Epoch:0 Step:1192 Training_loss:0.813054, Acc_avg:51.00% Training_loss_avg:0.695692\n",
            "Epoch:0 Step:1200 Training_loss:0.751586, Acc_avg:50.75% Training_loss_avg:0.696840\n",
            "Epoch:0 Step:1208 Training_loss:0.659744, Acc_avg:51.25% Training_loss_avg:0.695580\n",
            "Epoch:0 Step:1216 Training_loss:0.794789, Acc_avg:51.00% Training_loss_avg:0.697891\n",
            "Epoch:0 Step:1224 Training_loss:0.716482, Acc_avg:50.50% Training_loss_avg:0.698442\n",
            "Epoch:0 Step:1232 Training_loss:0.700051, Acc_avg:50.75% Training_loss_avg:0.698499\n",
            "Epoch:0 Step:1240 Training_loss:0.639026, Acc_avg:51.00% Training_loss_avg:0.697822\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:1240 Val_loss:0.689155, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:1248 Training_loss:0.717662, Acc_avg:50.25% Training_loss_avg:0.699230\n",
            "Epoch:0 Step:1256 Training_loss:0.687631, Acc_avg:49.75% Training_loss_avg:0.699866\n",
            "Epoch:0 Step:1264 Training_loss:0.640316, Acc_avg:50.25% Training_loss_avg:0.698658\n",
            "Epoch:0 Step:1272 Training_loss:0.731873, Acc_avg:50.50% Training_loss_avg:0.698616\n",
            "Epoch:0 Step:1280 Training_loss:0.667151, Acc_avg:51.50% Training_loss_avg:0.697050\n",
            "Epoch:0 Step:1288 Training_loss:0.706316, Acc_avg:52.00% Training_loss_avg:0.696493\n",
            "Epoch:0 Step:1296 Training_loss:0.756635, Acc_avg:51.25% Training_loss_avg:0.697507\n",
            "Epoch:0 Step:1304 Training_loss:0.712083, Acc_avg:51.00% Training_loss_avg:0.698101\n",
            "Epoch:0 Step:1312 Training_loss:0.611016, Acc_avg:51.75% Training_loss_avg:0.696513\n",
            "Epoch:0 Step:1320 Training_loss:0.704283, Acc_avg:51.75% Training_loss_avg:0.696824\n",
            "Epoch:0 Step:1328 Training_loss:0.686676, Acc_avg:52.00% Training_loss_avg:0.696595\n",
            "Epoch:0 Step:1336 Training_loss:0.694206, Acc_avg:51.75% Training_loss_avg:0.696720\n",
            "Epoch:0 Step:1344 Training_loss:0.688478, Acc_avg:52.25% Training_loss_avg:0.695468\n",
            "Epoch:0 Step:1352 Training_loss:0.726266, Acc_avg:51.75% Training_loss_avg:0.696510\n",
            "Epoch:0 Step:1360 Training_loss:0.685727, Acc_avg:52.50% Training_loss_avg:0.696018\n",
            "Epoch:0 Step:1368 Training_loss:0.637408, Acc_avg:53.50% Training_loss_avg:0.694711\n",
            "Epoch:0 Step:1376 Training_loss:0.696813, Acc_avg:53.50% Training_loss_avg:0.694443\n",
            "Epoch:0 Step:1384 Training_loss:0.696309, Acc_avg:53.00% Training_loss_avg:0.694594\n",
            "Epoch:0 Step:1392 Training_loss:0.679362, Acc_avg:53.00% Training_loss_avg:0.694352\n",
            "Epoch:0 Step:1400 Training_loss:0.711181, Acc_avg:52.75% Training_loss_avg:0.694284\n",
            "Epoch:0 Step:1408 Training_loss:0.670028, Acc_avg:53.00% Training_loss_avg:0.693552\n",
            "Epoch:0 Step:1416 Training_loss:0.676304, Acc_avg:53.00% Training_loss_avg:0.693222\n",
            "Epoch:0 Step:1424 Training_loss:0.694966, Acc_avg:53.50% Training_loss_avg:0.693193\n",
            "Epoch:0 Step:1432 Training_loss:0.703914, Acc_avg:54.00% Training_loss_avg:0.693267\n",
            "Epoch:0 Step:1440 Training_loss:0.731660, Acc_avg:53.50% Training_loss_avg:0.694224\n",
            "Epoch:0 Step:1448 Training_loss:0.736347, Acc_avg:53.50% Training_loss_avg:0.695149\n",
            "Epoch:0 Step:1456 Training_loss:0.698474, Acc_avg:53.50% Training_loss_avg:0.695169\n",
            "Epoch:0 Step:1464 Training_loss:0.700443, Acc_avg:52.75% Training_loss_avg:0.695529\n",
            "Epoch:0 Step:1472 Training_loss:0.689402, Acc_avg:52.50% Training_loss_avg:0.696004\n",
            "Epoch:0 Step:1480 Training_loss:0.716262, Acc_avg:52.50% Training_loss_avg:0.696265\n",
            "Epoch:0 Step:1488 Training_loss:0.719374, Acc_avg:52.50% Training_loss_avg:0.696589\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:1488 Val_loss:0.692784, Val_Acc_avg:55.00%\n",
            "Epoch:0 Step:1496 Training_loss:0.713372, Acc_avg:52.25% Training_loss_avg:0.696876\n",
            "Epoch:0 Step:1504 Training_loss:0.680884, Acc_avg:52.25% Training_loss_avg:0.697455\n",
            "Epoch:0 Step:1512 Training_loss:0.702530, Acc_avg:51.50% Training_loss_avg:0.698894\n",
            "Epoch:0 Step:1520 Training_loss:0.686602, Acc_avg:51.00% Training_loss_avg:0.699634\n",
            "Epoch:0 Step:1528 Training_loss:0.697565, Acc_avg:50.25% Training_loss_avg:0.700742\n",
            "Epoch:0 Step:1536 Training_loss:0.711924, Acc_avg:50.00% Training_loss_avg:0.700555\n",
            "Epoch:0 Step:1544 Training_loss:0.696498, Acc_avg:49.75% Training_loss_avg:0.701701\n",
            "Epoch:0 Step:1552 Training_loss:0.700407, Acc_avg:49.00% Training_loss_avg:0.703565\n",
            "Epoch:0 Step:1560 Training_loss:0.675557, Acc_avg:49.75% Training_loss_avg:0.701676\n",
            "Epoch:0 Step:1568 Training_loss:0.692506, Acc_avg:49.50% Training_loss_avg:0.702125\n",
            "Epoch:0 Step:1576 Training_loss:0.683433, Acc_avg:49.75% Training_loss_avg:0.702229\n",
            "Epoch:0 Step:1584 Training_loss:0.683001, Acc_avg:50.50% Training_loss_avg:0.699472\n",
            "Epoch:0 Step:1592 Training_loss:0.691017, Acc_avg:51.25% Training_loss_avg:0.697031\n",
            "Epoch:0 Step:1600 Training_loss:0.659211, Acc_avg:52.00% Training_loss_avg:0.695183\n",
            "Epoch:0 Step:1608 Training_loss:0.648654, Acc_avg:52.00% Training_loss_avg:0.694962\n",
            "Epoch:0 Step:1616 Training_loss:0.735737, Acc_avg:52.00% Training_loss_avg:0.693780\n",
            "Epoch:0 Step:1624 Training_loss:0.676570, Acc_avg:52.50% Training_loss_avg:0.692982\n",
            "Epoch:0 Step:1632 Training_loss:0.687188, Acc_avg:52.50% Training_loss_avg:0.692725\n",
            "Epoch:0 Step:1640 Training_loss:0.702848, Acc_avg:52.00% Training_loss_avg:0.694001\n",
            "Epoch:0 Step:1648 Training_loss:0.696930, Acc_avg:52.25% Training_loss_avg:0.693587\n",
            "Epoch:0 Step:1656 Training_loss:0.663742, Acc_avg:52.25% Training_loss_avg:0.693109\n",
            "Epoch:0 Step:1664 Training_loss:0.705537, Acc_avg:51.75% Training_loss_avg:0.694413\n",
            "Epoch:0 Step:1672 Training_loss:0.661017, Acc_avg:52.25% Training_loss_avg:0.692996\n",
            "Epoch:0 Step:1680 Training_loss:0.642060, Acc_avg:52.50% Training_loss_avg:0.692494\n",
            "Epoch:0 Step:1688 Training_loss:0.652680, Acc_avg:52.75% Training_loss_avg:0.691422\n",
            "Epoch:0 Step:1696 Training_loss:0.738157, Acc_avg:53.25% Training_loss_avg:0.691052\n",
            "Epoch:0 Step:1704 Training_loss:0.699505, Acc_avg:53.25% Training_loss_avg:0.690801\n",
            "Epoch:0 Step:1712 Training_loss:0.648196, Acc_avg:53.25% Training_loss_avg:0.691544\n",
            "Epoch:0 Step:1720 Training_loss:0.770807, Acc_avg:52.75% Training_loss_avg:0.692875\n",
            "Epoch:0 Step:1728 Training_loss:0.623550, Acc_avg:53.25% Training_loss_avg:0.691612\n",
            "Epoch:0 Step:1736 Training_loss:0.663103, Acc_avg:53.50% Training_loss_avg:0.690990\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:1736 Val_loss:0.689789, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:1744 Training_loss:0.667858, Acc_avg:53.50% Training_loss_avg:0.690578\n",
            "Epoch:0 Step:1752 Training_loss:0.670912, Acc_avg:54.00% Training_loss_avg:0.689471\n",
            "Epoch:0 Step:1760 Training_loss:0.722182, Acc_avg:53.25% Training_loss_avg:0.690200\n",
            "Epoch:0 Step:1768 Training_loss:0.657721, Acc_avg:52.75% Training_loss_avg:0.690606\n",
            "Epoch:0 Step:1776 Training_loss:0.740686, Acc_avg:52.50% Training_loss_avg:0.691483\n",
            "Epoch:0 Step:1784 Training_loss:0.657467, Acc_avg:52.75% Training_loss_avg:0.690707\n",
            "Epoch:0 Step:1792 Training_loss:0.614626, Acc_avg:53.25% Training_loss_avg:0.689412\n",
            "Epoch:0 Step:1800 Training_loss:0.562730, Acc_avg:54.50% Training_loss_avg:0.686443\n",
            "Epoch:0 Step:1808 Training_loss:0.707965, Acc_avg:54.50% Training_loss_avg:0.687202\n",
            "Epoch:0 Step:1816 Training_loss:0.676999, Acc_avg:54.75% Training_loss_avg:0.687215\n",
            "Epoch:0 Step:1824 Training_loss:0.571864, Acc_avg:55.50% Training_loss_avg:0.684753\n",
            "Epoch:0 Step:1832 Training_loss:0.617209, Acc_avg:55.75% Training_loss_avg:0.683019\n",
            "Epoch:0 Step:1840 Training_loss:0.770825, Acc_avg:55.75% Training_loss_avg:0.683803\n",
            "Epoch:0 Step:1848 Training_loss:0.744654, Acc_avg:56.00% Training_loss_avg:0.683969\n",
            "Epoch:0 Step:1856 Training_loss:0.739621, Acc_avg:56.00% Training_loss_avg:0.684792\n",
            "Epoch:0 Step:1864 Training_loss:0.720859, Acc_avg:56.75% Training_loss_avg:0.685200\n",
            "Epoch:0 Step:1872 Training_loss:0.653184, Acc_avg:56.50% Training_loss_avg:0.684476\n",
            "Epoch:0 Step:1880 Training_loss:0.704598, Acc_avg:56.75% Training_loss_avg:0.684242\n",
            "Epoch:0 Step:1888 Training_loss:0.546216, Acc_avg:57.75% Training_loss_avg:0.680779\n",
            "Epoch:0 Step:1896 Training_loss:0.782967, Acc_avg:57.75% Training_loss_avg:0.682171\n",
            "Epoch:0 Step:1904 Training_loss:0.770441, Acc_avg:57.00% Training_loss_avg:0.683962\n",
            "Epoch:0 Step:1912 Training_loss:0.656802, Acc_avg:57.50% Training_loss_avg:0.683048\n",
            "Epoch:0 Step:1920 Training_loss:0.709653, Acc_avg:57.75% Training_loss_avg:0.683509\n",
            "Epoch:0 Step:1928 Training_loss:0.654957, Acc_avg:58.25% Training_loss_avg:0.682657\n",
            "Epoch:0 Step:1936 Training_loss:0.699461, Acc_avg:58.75% Training_loss_avg:0.682407\n",
            "Epoch:0 Step:1944 Training_loss:0.845761, Acc_avg:58.25% Training_loss_avg:0.685393\n",
            "Epoch:0 Step:1952 Training_loss:0.653744, Acc_avg:58.75% Training_loss_avg:0.684459\n",
            "Epoch:0 Step:1960 Training_loss:0.678258, Acc_avg:58.75% Training_loss_avg:0.684513\n",
            "Epoch:0 Step:1968 Training_loss:0.655610, Acc_avg:59.00% Training_loss_avg:0.683775\n",
            "Epoch:0 Step:1976 Training_loss:0.744475, Acc_avg:58.50% Training_loss_avg:0.684996\n",
            "Epoch:0 Step:1984 Training_loss:0.725454, Acc_avg:58.25% Training_loss_avg:0.685845\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:1984 Val_loss:0.690180, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:1992 Training_loss:0.733718, Acc_avg:57.75% Training_loss_avg:0.686699\n",
            "Epoch:0 Step:2000 Training_loss:0.660284, Acc_avg:57.75% Training_loss_avg:0.686721\n",
            "Epoch:0 Step:2008 Training_loss:0.690024, Acc_avg:57.25% Training_loss_avg:0.687548\n",
            "Epoch:0 Step:2016 Training_loss:0.697006, Acc_avg:57.75% Training_loss_avg:0.686774\n",
            "Epoch:0 Step:2024 Training_loss:0.662936, Acc_avg:57.75% Training_loss_avg:0.686501\n",
            "Epoch:0 Step:2032 Training_loss:0.640414, Acc_avg:58.25% Training_loss_avg:0.685565\n",
            "Epoch:0 Step:2040 Training_loss:0.675602, Acc_avg:58.50% Training_loss_avg:0.685020\n",
            "Epoch:0 Step:2048 Training_loss:0.668633, Acc_avg:58.75% Training_loss_avg:0.684455\n",
            "Epoch:0 Step:2056 Training_loss:0.674682, Acc_avg:59.00% Training_loss_avg:0.684673\n",
            "Epoch:0 Step:2064 Training_loss:0.676014, Acc_avg:59.25% Training_loss_avg:0.684083\n",
            "Epoch:0 Step:2072 Training_loss:0.729344, Acc_avg:58.75% Training_loss_avg:0.685449\n",
            "Epoch:0 Step:2080 Training_loss:0.601620, Acc_avg:59.00% Training_loss_avg:0.684641\n",
            "Epoch:0 Step:2088 Training_loss:0.776076, Acc_avg:58.00% Training_loss_avg:0.687109\n",
            "Epoch:0 Step:2096 Training_loss:0.735587, Acc_avg:58.00% Training_loss_avg:0.687057\n",
            "Epoch:0 Step:2104 Training_loss:0.635147, Acc_avg:58.50% Training_loss_avg:0.685770\n",
            "Epoch:0 Step:2112 Training_loss:0.676322, Acc_avg:58.25% Training_loss_avg:0.686333\n",
            "Epoch:0 Step:2120 Training_loss:0.591407, Acc_avg:59.50% Training_loss_avg:0.682745\n",
            "Epoch:0 Step:2128 Training_loss:0.706243, Acc_avg:59.00% Training_loss_avg:0.684398\n",
            "Epoch:0 Step:2136 Training_loss:0.630674, Acc_avg:59.25% Training_loss_avg:0.683750\n",
            "Epoch:0 Step:2144 Training_loss:0.679863, Acc_avg:59.00% Training_loss_avg:0.683990\n",
            "Epoch:0 Step:2152 Training_loss:0.835261, Acc_avg:58.00% Training_loss_avg:0.687277\n",
            "Epoch:0 Step:2160 Training_loss:0.718170, Acc_avg:58.25% Training_loss_avg:0.687197\n",
            "Epoch:0 Step:2168 Training_loss:0.618182, Acc_avg:58.50% Training_loss_avg:0.686406\n",
            "Epoch:0 Step:2176 Training_loss:0.672370, Acc_avg:59.00% Training_loss_avg:0.685040\n",
            "Epoch:0 Step:2184 Training_loss:0.659601, Acc_avg:59.25% Training_loss_avg:0.685082\n",
            "Epoch:0 Step:2192 Training_loss:0.678161, Acc_avg:58.75% Training_loss_avg:0.686353\n",
            "Epoch:0 Step:2200 Training_loss:0.712342, Acc_avg:57.75% Training_loss_avg:0.689345\n",
            "Epoch:0 Step:2208 Training_loss:0.636586, Acc_avg:58.25% Training_loss_avg:0.687918\n",
            "Epoch:0 Step:2216 Training_loss:0.600696, Acc_avg:58.75% Training_loss_avg:0.686392\n",
            "Epoch:0 Step:2224 Training_loss:0.747883, Acc_avg:57.75% Training_loss_avg:0.689912\n",
            "Epoch:0 Step:2232 Training_loss:0.667321, Acc_avg:57.25% Training_loss_avg:0.690914\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:2232 Val_loss:0.692831, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:2240 Training_loss:0.624778, Acc_avg:58.00% Training_loss_avg:0.687993\n",
            "Epoch:0 Step:2248 Training_loss:0.676481, Acc_avg:58.00% Training_loss_avg:0.686630\n",
            "Epoch:0 Step:2256 Training_loss:0.694115, Acc_avg:58.50% Training_loss_avg:0.685720\n",
            "Epoch:0 Step:2264 Training_loss:0.706340, Acc_avg:58.25% Training_loss_avg:0.685429\n",
            "Epoch:0 Step:2272 Training_loss:0.685847, Acc_avg:58.00% Training_loss_avg:0.686083\n",
            "Epoch:0 Step:2280 Training_loss:0.790069, Acc_avg:57.50% Training_loss_avg:0.687792\n",
            "Epoch:0 Step:2288 Training_loss:0.591203, Acc_avg:57.50% Training_loss_avg:0.688692\n",
            "Epoch:0 Step:2296 Training_loss:0.672169, Acc_avg:58.00% Training_loss_avg:0.686476\n",
            "Epoch:0 Step:2304 Training_loss:0.657899, Acc_avg:58.25% Training_loss_avg:0.684225\n",
            "Epoch:0 Step:2312 Training_loss:0.747400, Acc_avg:57.75% Training_loss_avg:0.686037\n",
            "Epoch:0 Step:2320 Training_loss:0.619553, Acc_avg:58.00% Training_loss_avg:0.684235\n",
            "Epoch:0 Step:2328 Training_loss:0.706298, Acc_avg:57.75% Training_loss_avg:0.685262\n",
            "Epoch:0 Step:2336 Training_loss:0.718550, Acc_avg:57.75% Training_loss_avg:0.685643\n",
            "Epoch:0 Step:2344 Training_loss:0.704313, Acc_avg:58.25% Training_loss_avg:0.682814\n",
            "Epoch:0 Step:2352 Training_loss:0.676996, Acc_avg:58.25% Training_loss_avg:0.683280\n",
            "Epoch:0 Step:2360 Training_loss:0.740895, Acc_avg:57.75% Training_loss_avg:0.684532\n",
            "Epoch:0 Step:2368 Training_loss:0.667703, Acc_avg:57.75% Training_loss_avg:0.684774\n",
            "Epoch:0 Step:2376 Training_loss:0.690811, Acc_avg:58.00% Training_loss_avg:0.683701\n",
            "Epoch:0 Step:2384 Training_loss:0.747410, Acc_avg:57.75% Training_loss_avg:0.684140\n",
            "Epoch:0 Step:2392 Training_loss:0.681753, Acc_avg:58.00% Training_loss_avg:0.683101\n",
            "Epoch:0 Step:2400 Training_loss:0.733748, Acc_avg:57.50% Training_loss_avg:0.684570\n",
            "Epoch:0 Step:2408 Training_loss:0.665153, Acc_avg:57.75% Training_loss_avg:0.684073\n",
            "Epoch:0 Step:2416 Training_loss:0.672527, Acc_avg:58.00% Training_loss_avg:0.683583\n",
            "Epoch:0 Step:2424 Training_loss:0.751418, Acc_avg:57.25% Training_loss_avg:0.685353\n",
            "Epoch:0 Step:2432 Training_loss:0.707875, Acc_avg:56.75% Training_loss_avg:0.686702\n",
            "Epoch:0 Step:2440 Training_loss:0.624917, Acc_avg:57.25% Training_loss_avg:0.685688\n",
            "Epoch:0 Step:2448 Training_loss:0.655831, Acc_avg:57.75% Training_loss_avg:0.685432\n",
            "Epoch:0 Step:2456 Training_loss:0.742367, Acc_avg:57.00% Training_loss_avg:0.686786\n",
            "Epoch:0 Step:2464 Training_loss:0.701384, Acc_avg:56.75% Training_loss_avg:0.687293\n",
            "Epoch:0 Step:2472 Training_loss:0.695773, Acc_avg:56.75% Training_loss_avg:0.686622\n",
            "Epoch:0 Step:2480 Training_loss:0.713437, Acc_avg:56.00% Training_loss_avg:0.688858\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:2480 Val_loss:0.689398, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:2488 Training_loss:0.672953, Acc_avg:56.75% Training_loss_avg:0.686796\n",
            "Epoch:0 Step:2496 Training_loss:0.732289, Acc_avg:56.75% Training_loss_avg:0.686730\n",
            "Epoch:0 Step:2504 Training_loss:0.661141, Acc_avg:56.50% Training_loss_avg:0.687250\n",
            "Epoch:0 Step:2512 Training_loss:0.701096, Acc_avg:56.25% Training_loss_avg:0.687745\n",
            "Epoch:0 Step:2520 Training_loss:0.713584, Acc_avg:55.50% Training_loss_avg:0.690189\n",
            "Epoch:0 Step:2528 Training_loss:0.716832, Acc_avg:55.25% Training_loss_avg:0.690400\n",
            "Epoch:0 Step:2536 Training_loss:0.660574, Acc_avg:55.25% Training_loss_avg:0.690998\n",
            "Epoch:0 Step:2544 Training_loss:0.657001, Acc_avg:55.75% Training_loss_avg:0.690541\n",
            "Epoch:0 Step:2552 Training_loss:0.656324, Acc_avg:57.00% Training_loss_avg:0.686962\n",
            "Epoch:0 Step:2560 Training_loss:0.717269, Acc_avg:57.00% Training_loss_avg:0.686944\n",
            "Epoch:0 Step:2568 Training_loss:0.688413, Acc_avg:56.75% Training_loss_avg:0.688349\n",
            "Epoch:0 Step:2576 Training_loss:0.649031, Acc_avg:57.00% Training_loss_avg:0.687882\n",
            "Epoch:0 Step:2584 Training_loss:0.718785, Acc_avg:56.25% Training_loss_avg:0.689066\n",
            "Epoch:0 Step:2592 Training_loss:0.683891, Acc_avg:56.50% Training_loss_avg:0.689181\n",
            "Epoch:0 Step:2600 Training_loss:0.692438, Acc_avg:56.50% Training_loss_avg:0.688782\n",
            "Epoch:0 Step:2608 Training_loss:0.615047, Acc_avg:56.75% Training_loss_avg:0.688352\n",
            "Epoch:0 Step:2616 Training_loss:0.702098, Acc_avg:55.75% Training_loss_avg:0.690380\n",
            "Epoch:0 Step:2624 Training_loss:0.741332, Acc_avg:55.25% Training_loss_avg:0.690249\n",
            "Epoch:0 Step:2632 Training_loss:0.620756, Acc_avg:56.00% Training_loss_avg:0.689317\n",
            "Epoch:0 Step:2640 Training_loss:0.640207, Acc_avg:56.00% Training_loss_avg:0.689626\n",
            "Epoch:0 Step:2648 Training_loss:0.667006, Acc_avg:56.25% Training_loss_avg:0.689436\n",
            "Epoch:0 Step:2656 Training_loss:0.640568, Acc_avg:56.50% Training_loss_avg:0.688366\n",
            "Epoch:0 Step:2664 Training_loss:0.608665, Acc_avg:57.00% Training_loss_avg:0.686412\n",
            "Epoch:0 Step:2672 Training_loss:0.663199, Acc_avg:57.25% Training_loss_avg:0.685959\n",
            "Epoch:0 Step:2680 Training_loss:0.667684, Acc_avg:57.75% Training_loss_avg:0.683511\n",
            "Epoch:0 Step:2688 Training_loss:0.688160, Acc_avg:57.00% Training_loss_avg:0.685451\n",
            "Epoch:0 Step:2696 Training_loss:0.595166, Acc_avg:57.50% Training_loss_avg:0.683910\n",
            "Epoch:0 Step:2704 Training_loss:0.697105, Acc_avg:57.25% Training_loss_avg:0.684695\n",
            "Epoch:0 Step:2712 Training_loss:0.769219, Acc_avg:57.25% Training_loss_avg:0.685131\n",
            "Epoch:0 Step:2720 Training_loss:0.575320, Acc_avg:57.25% Training_loss_avg:0.684246\n",
            "Epoch:0 Step:2728 Training_loss:0.762501, Acc_avg:57.00% Training_loss_avg:0.685370\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:2728 Val_loss:0.702151, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:2736 Training_loss:0.655666, Acc_avg:57.25% Training_loss_avg:0.684113\n",
            "Epoch:0 Step:2744 Training_loss:0.600003, Acc_avg:57.75% Training_loss_avg:0.682026\n",
            "Epoch:0 Step:2752 Training_loss:0.790610, Acc_avg:57.25% Training_loss_avg:0.684299\n",
            "Epoch:0 Step:2760 Training_loss:0.716397, Acc_avg:57.50% Training_loss_avg:0.683809\n",
            "Epoch:0 Step:2768 Training_loss:0.599597, Acc_avg:57.75% Training_loss_avg:0.682447\n",
            "Epoch:0 Step:2776 Training_loss:0.721443, Acc_avg:57.75% Training_loss_avg:0.683059\n",
            "Epoch:0 Step:2784 Training_loss:0.589316, Acc_avg:58.50% Training_loss_avg:0.679897\n",
            "Epoch:0 Step:2792 Training_loss:0.603580, Acc_avg:59.00% Training_loss_avg:0.678334\n",
            "Epoch:0 Step:2800 Training_loss:0.774922, Acc_avg:58.75% Training_loss_avg:0.679157\n",
            "Epoch:0 Step:2808 Training_loss:0.555429, Acc_avg:59.25% Training_loss_avg:0.676963\n",
            "Epoch:0 Step:2816 Training_loss:0.694086, Acc_avg:59.00% Training_loss_avg:0.677394\n",
            "Epoch:0 Step:2824 Training_loss:0.842692, Acc_avg:59.00% Training_loss_avg:0.679220\n",
            "Epoch:0 Step:2832 Training_loss:0.654487, Acc_avg:59.00% Training_loss_avg:0.678152\n",
            "Epoch:0 Step:2840 Training_loss:0.665765, Acc_avg:58.50% Training_loss_avg:0.678969\n",
            "Epoch:0 Step:2848 Training_loss:0.612248, Acc_avg:58.25% Training_loss_avg:0.678097\n",
            "Epoch:0 Step:2856 Training_loss:0.822040, Acc_avg:58.25% Training_loss_avg:0.679691\n",
            "Epoch:0 Step:2864 Training_loss:0.710182, Acc_avg:58.25% Training_loss_avg:0.679867\n",
            "Epoch:0 Step:2872 Training_loss:0.600424, Acc_avg:58.75% Training_loss_avg:0.677960\n",
            "Epoch:0 Step:2880 Training_loss:0.723657, Acc_avg:58.75% Training_loss_avg:0.678164\n",
            "Epoch:0 Step:2888 Training_loss:0.711062, Acc_avg:58.50% Training_loss_avg:0.678926\n",
            "Epoch:0 Step:2896 Training_loss:0.683039, Acc_avg:58.75% Training_loss_avg:0.677941\n",
            "Epoch:0 Step:2904 Training_loss:0.759163, Acc_avg:58.25% Training_loss_avg:0.679902\n",
            "Epoch:0 Step:2912 Training_loss:0.749340, Acc_avg:58.00% Training_loss_avg:0.680866\n",
            "Epoch:0 Step:2920 Training_loss:0.697880, Acc_avg:58.25% Training_loss_avg:0.680552\n",
            "Epoch:0 Step:2928 Training_loss:0.725715, Acc_avg:58.50% Training_loss_avg:0.680730\n",
            "Epoch:0 Step:2936 Training_loss:0.683877, Acc_avg:58.00% Training_loss_avg:0.681196\n",
            "Epoch:0 Step:2944 Training_loss:0.757632, Acc_avg:57.00% Training_loss_avg:0.683209\n",
            "Epoch:0 Step:2952 Training_loss:0.730663, Acc_avg:56.50% Training_loss_avg:0.684696\n",
            "Epoch:0 Step:2960 Training_loss:0.696753, Acc_avg:56.50% Training_loss_avg:0.684285\n",
            "Epoch:0 Step:2968 Training_loss:0.672778, Acc_avg:56.50% Training_loss_avg:0.683972\n",
            "Epoch:0 Step:2976 Training_loss:0.675669, Acc_avg:56.25% Training_loss_avg:0.684505\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:2976 Val_loss:0.689770, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:2984 Training_loss:0.668998, Acc_avg:56.75% Training_loss_avg:0.683509\n",
            "Epoch:0 Step:2992 Training_loss:0.694852, Acc_avg:56.50% Training_loss_avg:0.683729\n",
            "Epoch:0 Step:3000 Training_loss:0.697067, Acc_avg:56.25% Training_loss_avg:0.683821\n",
            "Epoch:0 Step:3008 Training_loss:0.691123, Acc_avg:55.75% Training_loss_avg:0.685343\n",
            "Epoch:0 Step:3016 Training_loss:0.676391, Acc_avg:56.25% Training_loss_avg:0.684829\n",
            "Epoch:0 Step:3024 Training_loss:0.685539, Acc_avg:56.75% Training_loss_avg:0.683713\n",
            "Epoch:0 Step:3032 Training_loss:0.692612, Acc_avg:56.00% Training_loss_avg:0.685150\n",
            "Epoch:0 Step:3040 Training_loss:0.717217, Acc_avg:55.00% Training_loss_avg:0.686690\n",
            "Epoch:0 Step:3048 Training_loss:0.694569, Acc_avg:54.75% Training_loss_avg:0.687241\n",
            "Epoch:0 Step:3056 Training_loss:0.701690, Acc_avg:54.00% Training_loss_avg:0.688464\n",
            "Epoch:0 Step:3064 Training_loss:0.670736, Acc_avg:54.25% Training_loss_avg:0.689705\n",
            "Epoch:0 Step:3072 Training_loss:0.678394, Acc_avg:54.50% Training_loss_avg:0.690009\n",
            "Epoch:0 Step:3080 Training_loss:0.702268, Acc_avg:54.00% Training_loss_avg:0.690701\n",
            "Epoch:0 Step:3088 Training_loss:0.691773, Acc_avg:54.00% Training_loss_avg:0.690773\n",
            "Epoch:0 Step:3096 Training_loss:0.674114, Acc_avg:54.00% Training_loss_avg:0.692352\n",
            "Epoch:0 Step:3104 Training_loss:0.682959, Acc_avg:54.25% Training_loss_avg:0.692069\n",
            "Epoch:0 Step:3112 Training_loss:0.704464, Acc_avg:54.50% Training_loss_avg:0.690774\n",
            "Epoch:0 Step:3120 Training_loss:0.700070, Acc_avg:54.00% Training_loss_avg:0.693269\n",
            "Epoch:0 Step:3128 Training_loss:0.690191, Acc_avg:54.25% Training_loss_avg:0.691823\n",
            "Epoch:0 Step:3136 Training_loss:0.691921, Acc_avg:54.25% Training_loss_avg:0.692548\n",
            "Epoch:0 Step:3144 Training_loss:0.661102, Acc_avg:54.25% Training_loss_avg:0.693770\n",
            "Epoch:0 Step:3152 Training_loss:0.690068, Acc_avg:54.75% Training_loss_avg:0.691759\n",
            "Epoch:0 Step:3160 Training_loss:0.710941, Acc_avg:54.25% Training_loss_avg:0.691650\n",
            "Epoch:0 Step:3168 Training_loss:0.708005, Acc_avg:53.50% Training_loss_avg:0.693818\n",
            "Epoch:0 Step:3176 Training_loss:0.684493, Acc_avg:53.75% Training_loss_avg:0.693079\n",
            "Epoch:0 Step:3184 Training_loss:0.680121, Acc_avg:53.50% Training_loss_avg:0.694895\n",
            "Epoch:0 Step:3192 Training_loss:0.682699, Acc_avg:53.00% Training_loss_avg:0.696478\n",
            "Epoch:0 Step:3200 Training_loss:0.680430, Acc_avg:53.25% Training_loss_avg:0.694588\n",
            "Epoch:0 Step:3208 Training_loss:0.662608, Acc_avg:53.25% Training_loss_avg:0.696731\n",
            "Epoch:0 Step:3216 Training_loss:0.714718, Acc_avg:53.00% Training_loss_avg:0.697144\n",
            "Epoch:0 Step:3224 Training_loss:0.706249, Acc_avg:53.50% Training_loss_avg:0.694415\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 Step:3224 Val_loss:0.689523, Val_Acc_avg:54.75%\n",
            "Epoch:0 Step:3232 Training_loss:0.696144, Acc_avg:53.75% Training_loss_avg:0.695248\n",
            "Epoch:0 Step:3240 Training_loss:0.654708, Acc_avg:54.00% Training_loss_avg:0.695027\n",
            "Epoch:0 Step:3248 Training_loss:0.636326, Acc_avg:54.25% Training_loss_avg:0.695509\n",
            "Epoch:0 Step:3256 Training_loss:0.678839, Acc_avg:55.00% Training_loss_avg:0.692645\n",
            "Epoch:0 Step:3264 Training_loss:0.661039, Acc_avg:55.50% Training_loss_avg:0.691662\n",
            "Epoch:0 Step:3272 Training_loss:0.674975, Acc_avg:55.25% Training_loss_avg:0.693153\n",
            "Epoch:0 Step:3280 Training_loss:0.667766, Acc_avg:55.50% Training_loss_avg:0.692035\n",
            "Epoch:0 Step:3288 Training_loss:0.807302, Acc_avg:55.00% Training_loss_avg:0.693960\n",
            "Epoch:0 Step:3296 Training_loss:0.626782, Acc_avg:55.75% Training_loss_avg:0.692835\n",
            "Epoch:0 Step:3304 Training_loss:0.668977, Acc_avg:56.25% Training_loss_avg:0.691031\n",
            "Epoch:0 Step:3312 Training_loss:0.739475, Acc_avg:56.25% Training_loss_avg:0.690834\n",
            "Epoch:0 Step:3320 Training_loss:0.814151, Acc_avg:55.25% Training_loss_avg:0.693159\n",
            "Epoch:0 Step:3328 Training_loss:0.655753, Acc_avg:55.58% Training_loss_avg:0.691760\n",
            "Epoch:1 Step:0 Training_loss:0.660128, Acc_avg:55.83% Training_loss_avg:0.691285\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:0 Val_loss:0.690072, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:8 Training_loss:0.682009, Acc_avg:56.33% Training_loss_avg:0.689772\n",
            "Epoch:1 Step:16 Training_loss:0.680851, Acc_avg:56.58% Training_loss_avg:0.688776\n",
            "Epoch:1 Step:24 Training_loss:0.689244, Acc_avg:56.58% Training_loss_avg:0.688626\n",
            "Epoch:1 Step:32 Training_loss:0.724989, Acc_avg:56.08% Training_loss_avg:0.689670\n",
            "Epoch:1 Step:40 Training_loss:0.703208, Acc_avg:55.83% Training_loss_avg:0.690221\n",
            "Epoch:1 Step:48 Training_loss:0.798657, Acc_avg:54.83% Training_loss_avg:0.692814\n",
            "Epoch:1 Step:56 Training_loss:0.652369, Acc_avg:55.33% Training_loss_avg:0.691964\n",
            "Epoch:1 Step:64 Training_loss:0.680933, Acc_avg:55.58% Training_loss_avg:0.691642\n",
            "Epoch:1 Step:72 Training_loss:0.721750, Acc_avg:55.08% Training_loss_avg:0.692254\n",
            "Epoch:1 Step:80 Training_loss:0.682205, Acc_avg:55.08% Training_loss_avg:0.692371\n",
            "Epoch:1 Step:88 Training_loss:0.617236, Acc_avg:55.83% Training_loss_avg:0.691005\n",
            "Epoch:1 Step:96 Training_loss:0.686916, Acc_avg:56.08% Training_loss_avg:0.690891\n",
            "Epoch:1 Step:104 Training_loss:0.630249, Acc_avg:57.33% Training_loss_avg:0.689151\n",
            "Epoch:1 Step:112 Training_loss:0.680267, Acc_avg:57.58% Training_loss_avg:0.688865\n",
            "Epoch:1 Step:120 Training_loss:0.722738, Acc_avg:57.58% Training_loss_avg:0.689286\n",
            "Epoch:1 Step:128 Training_loss:0.717478, Acc_avg:56.58% Training_loss_avg:0.690221\n",
            "Epoch:1 Step:136 Training_loss:0.716555, Acc_avg:55.83% Training_loss_avg:0.690984\n",
            "Epoch:1 Step:144 Training_loss:0.681134, Acc_avg:56.33% Training_loss_avg:0.690562\n",
            "Epoch:1 Step:152 Training_loss:0.678519, Acc_avg:56.83% Training_loss_avg:0.690297\n",
            "Epoch:1 Step:160 Training_loss:0.693782, Acc_avg:56.08% Training_loss_avg:0.690690\n",
            "Epoch:1 Step:168 Training_loss:0.690554, Acc_avg:55.83% Training_loss_avg:0.690842\n",
            "Epoch:1 Step:176 Training_loss:0.696759, Acc_avg:55.83% Training_loss_avg:0.690688\n",
            "Epoch:1 Step:184 Training_loss:0.763519, Acc_avg:55.33% Training_loss_avg:0.691957\n",
            "Epoch:1 Step:192 Training_loss:0.694785, Acc_avg:55.33% Training_loss_avg:0.692049\n",
            "Epoch:1 Step:200 Training_loss:0.640860, Acc_avg:55.58% Training_loss_avg:0.691027\n",
            "Epoch:1 Step:208 Training_loss:0.645348, Acc_avg:55.83% Training_loss_avg:0.690712\n",
            "Epoch:1 Step:216 Training_loss:0.703376, Acc_avg:55.58% Training_loss_avg:0.690978\n",
            "Epoch:1 Step:224 Training_loss:0.688893, Acc_avg:56.08% Training_loss_avg:0.690537\n",
            "Epoch:1 Step:232 Training_loss:0.674622, Acc_avg:56.58% Training_loss_avg:0.689870\n",
            "Epoch:1 Step:240 Training_loss:0.721721, Acc_avg:56.08% Training_loss_avg:0.690614\n",
            "Epoch:1 Step:248 Training_loss:0.692167, Acc_avg:55.83% Training_loss_avg:0.690855\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:248 Val_loss:0.689412, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:256 Training_loss:0.691442, Acc_avg:55.83% Training_loss_avg:0.691030\n",
            "Epoch:1 Step:264 Training_loss:0.733696, Acc_avg:55.33% Training_loss_avg:0.692095\n",
            "Epoch:1 Step:272 Training_loss:0.706248, Acc_avg:54.58% Training_loss_avg:0.692968\n",
            "Epoch:1 Step:280 Training_loss:0.728563, Acc_avg:54.33% Training_loss_avg:0.693245\n",
            "Epoch:1 Step:288 Training_loss:0.685498, Acc_avg:54.58% Training_loss_avg:0.692830\n",
            "Epoch:1 Step:296 Training_loss:0.718774, Acc_avg:54.08% Training_loss_avg:0.693283\n",
            "Epoch:1 Step:304 Training_loss:0.687873, Acc_avg:53.58% Training_loss_avg:0.693946\n",
            "Epoch:1 Step:312 Training_loss:0.691298, Acc_avg:52.83% Training_loss_avg:0.695045\n",
            "Epoch:1 Step:320 Training_loss:0.691454, Acc_avg:52.83% Training_loss_avg:0.695298\n",
            "Epoch:1 Step:328 Training_loss:0.723955, Acc_avg:52.08% Training_loss_avg:0.696556\n",
            "Epoch:1 Step:336 Training_loss:0.731609, Acc_avg:51.08% Training_loss_avg:0.697689\n",
            "Epoch:1 Step:344 Training_loss:0.689023, Acc_avg:51.33% Training_loss_avg:0.698114\n",
            "Epoch:1 Step:352 Training_loss:0.655393, Acc_avg:52.58% Training_loss_avg:0.695076\n",
            "Epoch:1 Step:360 Training_loss:0.705730, Acc_avg:51.33% Training_loss_avg:0.696655\n",
            "Epoch:1 Step:368 Training_loss:0.691716, Acc_avg:51.08% Training_loss_avg:0.697109\n",
            "Epoch:1 Step:376 Training_loss:0.703049, Acc_avg:51.08% Training_loss_avg:0.696381\n",
            "Epoch:1 Step:384 Training_loss:0.683614, Acc_avg:52.08% Training_loss_avg:0.693770\n",
            "Epoch:1 Step:392 Training_loss:0.697144, Acc_avg:51.75% Training_loss_avg:0.694598\n",
            "Epoch:1 Step:400 Training_loss:0.688034, Acc_avg:51.50% Training_loss_avg:0.695156\n",
            "Epoch:1 Step:408 Training_loss:0.687459, Acc_avg:51.75% Training_loss_avg:0.695265\n",
            "Epoch:1 Step:416 Training_loss:0.706386, Acc_avg:51.50% Training_loss_avg:0.695776\n",
            "Epoch:1 Step:424 Training_loss:0.697209, Acc_avg:51.50% Training_loss_avg:0.695935\n",
            "Epoch:1 Step:432 Training_loss:0.695247, Acc_avg:51.50% Training_loss_avg:0.695340\n",
            "Epoch:1 Step:440 Training_loss:0.689378, Acc_avg:51.75% Training_loss_avg:0.695064\n",
            "Epoch:1 Step:448 Training_loss:0.697829, Acc_avg:52.50% Training_loss_avg:0.693047\n",
            "Epoch:1 Step:456 Training_loss:0.707158, Acc_avg:51.50% Training_loss_avg:0.694143\n",
            "Epoch:1 Step:464 Training_loss:0.672868, Acc_avg:52.25% Training_loss_avg:0.693982\n",
            "Epoch:1 Step:472 Training_loss:0.702767, Acc_avg:52.25% Training_loss_avg:0.693602\n",
            "Epoch:1 Step:480 Training_loss:0.701379, Acc_avg:52.00% Training_loss_avg:0.693985\n",
            "Epoch:1 Step:488 Training_loss:0.711882, Acc_avg:51.00% Training_loss_avg:0.695878\n",
            "Epoch:1 Step:496 Training_loss:0.705983, Acc_avg:50.25% Training_loss_avg:0.696260\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:496 Val_loss:0.691591, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:504 Training_loss:0.696092, Acc_avg:49.25% Training_loss_avg:0.697577\n",
            "Epoch:1 Step:512 Training_loss:0.674716, Acc_avg:49.75% Training_loss_avg:0.697466\n",
            "Epoch:1 Step:520 Training_loss:0.700106, Acc_avg:50.00% Training_loss_avg:0.697013\n",
            "Epoch:1 Step:528 Training_loss:0.686539, Acc_avg:50.25% Training_loss_avg:0.696394\n",
            "Epoch:1 Step:536 Training_loss:0.701227, Acc_avg:50.25% Training_loss_avg:0.696088\n",
            "Epoch:1 Step:544 Training_loss:0.691290, Acc_avg:50.25% Training_loss_avg:0.696291\n",
            "Epoch:1 Step:552 Training_loss:0.696896, Acc_avg:49.75% Training_loss_avg:0.696658\n",
            "Epoch:1 Step:560 Training_loss:0.690051, Acc_avg:49.75% Training_loss_avg:0.696584\n",
            "Epoch:1 Step:568 Training_loss:0.692537, Acc_avg:49.75% Training_loss_avg:0.696623\n",
            "Epoch:1 Step:576 Training_loss:0.679122, Acc_avg:50.00% Training_loss_avg:0.696271\n",
            "Epoch:1 Step:584 Training_loss:0.690608, Acc_avg:50.25% Training_loss_avg:0.694812\n",
            "Epoch:1 Step:592 Training_loss:0.694914, Acc_avg:50.25% Training_loss_avg:0.694815\n",
            "Epoch:1 Step:600 Training_loss:0.669114, Acc_avg:50.25% Training_loss_avg:0.695380\n",
            "Epoch:1 Step:608 Training_loss:0.699582, Acc_avg:49.25% Training_loss_avg:0.696465\n",
            "Epoch:1 Step:616 Training_loss:0.671907, Acc_avg:49.75% Training_loss_avg:0.695835\n",
            "Epoch:1 Step:624 Training_loss:0.688992, Acc_avg:49.75% Training_loss_avg:0.695837\n",
            "Epoch:1 Step:632 Training_loss:0.668694, Acc_avg:50.00% Training_loss_avg:0.695719\n",
            "Epoch:1 Step:640 Training_loss:0.657916, Acc_avg:50.75% Training_loss_avg:0.694443\n",
            "Epoch:1 Step:648 Training_loss:0.662571, Acc_avg:51.25% Training_loss_avg:0.693851\n",
            "Epoch:1 Step:656 Training_loss:0.671997, Acc_avg:51.50% Training_loss_avg:0.693462\n",
            "Epoch:1 Step:664 Training_loss:0.648905, Acc_avg:52.50% Training_loss_avg:0.691766\n",
            "Epoch:1 Step:672 Training_loss:0.684861, Acc_avg:52.50% Training_loss_avg:0.691338\n",
            "Epoch:1 Step:680 Training_loss:0.666316, Acc_avg:53.75% Training_loss_avg:0.690093\n",
            "Epoch:1 Step:688 Training_loss:0.726645, Acc_avg:53.25% Training_loss_avg:0.690916\n",
            "Epoch:1 Step:696 Training_loss:0.677245, Acc_avg:53.75% Training_loss_avg:0.690086\n",
            "Epoch:1 Step:704 Training_loss:0.705024, Acc_avg:53.50% Training_loss_avg:0.690429\n",
            "Epoch:1 Step:712 Training_loss:0.667699, Acc_avg:53.50% Training_loss_avg:0.689957\n",
            "Epoch:1 Step:720 Training_loss:0.678209, Acc_avg:53.50% Training_loss_avg:0.689692\n",
            "Epoch:1 Step:728 Training_loss:0.671540, Acc_avg:54.00% Training_loss_avg:0.688643\n",
            "Epoch:1 Step:736 Training_loss:0.768708, Acc_avg:54.50% Training_loss_avg:0.689385\n",
            "Epoch:1 Step:744 Training_loss:0.769332, Acc_avg:53.75% Training_loss_avg:0.690992\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:744 Val_loss:0.693428, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:752 Training_loss:0.653056, Acc_avg:53.25% Training_loss_avg:0.690945\n",
            "Epoch:1 Step:760 Training_loss:0.628677, Acc_avg:54.25% Training_loss_avg:0.689404\n",
            "Epoch:1 Step:768 Training_loss:0.763015, Acc_avg:54.25% Training_loss_avg:0.690830\n",
            "Epoch:1 Step:776 Training_loss:0.598144, Acc_avg:55.00% Training_loss_avg:0.688732\n",
            "Epoch:1 Step:784 Training_loss:0.727583, Acc_avg:54.50% Training_loss_avg:0.689611\n",
            "Epoch:1 Step:792 Training_loss:0.707133, Acc_avg:54.50% Training_loss_avg:0.689811\n",
            "Epoch:1 Step:800 Training_loss:0.729049, Acc_avg:54.50% Training_loss_avg:0.690631\n",
            "Epoch:1 Step:808 Training_loss:0.636508, Acc_avg:54.75% Training_loss_avg:0.689612\n",
            "Epoch:1 Step:816 Training_loss:0.757233, Acc_avg:54.50% Training_loss_avg:0.690629\n",
            "Epoch:1 Step:824 Training_loss:0.582089, Acc_avg:55.25% Training_loss_avg:0.688327\n",
            "Epoch:1 Step:832 Training_loss:0.632143, Acc_avg:56.00% Training_loss_avg:0.687065\n",
            "Epoch:1 Step:840 Training_loss:0.870961, Acc_avg:55.00% Training_loss_avg:0.690696\n",
            "Epoch:1 Step:848 Training_loss:0.642992, Acc_avg:55.25% Training_loss_avg:0.689599\n",
            "Epoch:1 Step:856 Training_loss:0.709808, Acc_avg:56.00% Training_loss_avg:0.689652\n",
            "Epoch:1 Step:864 Training_loss:0.764477, Acc_avg:54.75% Training_loss_avg:0.691485\n",
            "Epoch:1 Step:872 Training_loss:0.705041, Acc_avg:55.00% Training_loss_avg:0.691530\n",
            "Epoch:1 Step:880 Training_loss:0.655189, Acc_avg:55.50% Training_loss_avg:0.690606\n",
            "Epoch:1 Step:888 Training_loss:0.643919, Acc_avg:56.00% Training_loss_avg:0.689247\n",
            "Epoch:1 Step:896 Training_loss:0.693360, Acc_avg:56.50% Training_loss_avg:0.688995\n",
            "Epoch:1 Step:904 Training_loss:0.702452, Acc_avg:56.75% Training_loss_avg:0.689122\n",
            "Epoch:1 Step:912 Training_loss:0.620186, Acc_avg:56.75% Training_loss_avg:0.688031\n",
            "Epoch:1 Step:920 Training_loss:0.704194, Acc_avg:56.75% Training_loss_avg:0.688113\n",
            "Epoch:1 Step:928 Training_loss:0.696800, Acc_avg:56.75% Training_loss_avg:0.688318\n",
            "Epoch:1 Step:936 Training_loss:0.657064, Acc_avg:57.25% Training_loss_avg:0.687435\n",
            "Epoch:1 Step:944 Training_loss:0.689698, Acc_avg:57.00% Training_loss_avg:0.687403\n",
            "Epoch:1 Step:952 Training_loss:0.695231, Acc_avg:57.25% Training_loss_avg:0.687370\n",
            "Epoch:1 Step:960 Training_loss:0.666481, Acc_avg:57.50% Training_loss_avg:0.686898\n",
            "Epoch:1 Step:968 Training_loss:0.688195, Acc_avg:57.50% Training_loss_avg:0.686812\n",
            "Epoch:1 Step:976 Training_loss:0.731565, Acc_avg:57.25% Training_loss_avg:0.687860\n",
            "Epoch:1 Step:984 Training_loss:0.757468, Acc_avg:57.00% Training_loss_avg:0.689198\n",
            "Epoch:1 Step:992 Training_loss:0.622799, Acc_avg:57.75% Training_loss_avg:0.687755\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:992 Val_loss:0.689733, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:1000 Training_loss:0.717705, Acc_avg:57.25% Training_loss_avg:0.688727\n",
            "Epoch:1 Step:1008 Training_loss:0.715496, Acc_avg:57.25% Training_loss_avg:0.689045\n",
            "Epoch:1 Step:1016 Training_loss:0.652318, Acc_avg:57.25% Training_loss_avg:0.688654\n",
            "Epoch:1 Step:1024 Training_loss:0.729212, Acc_avg:56.75% Training_loss_avg:0.689458\n",
            "Epoch:1 Step:1032 Training_loss:0.680759, Acc_avg:56.50% Training_loss_avg:0.689699\n",
            "Epoch:1 Step:1040 Training_loss:0.684820, Acc_avg:56.25% Training_loss_avg:0.690237\n",
            "Epoch:1 Step:1048 Training_loss:0.738624, Acc_avg:55.50% Training_loss_avg:0.691758\n",
            "Epoch:1 Step:1056 Training_loss:0.655438, Acc_avg:55.50% Training_loss_avg:0.691427\n",
            "Epoch:1 Step:1064 Training_loss:0.711086, Acc_avg:55.00% Training_loss_avg:0.692671\n",
            "Epoch:1 Step:1072 Training_loss:0.674698, Acc_avg:55.25% Training_loss_avg:0.692468\n",
            "Epoch:1 Step:1080 Training_loss:0.700764, Acc_avg:54.50% Training_loss_avg:0.693157\n",
            "Epoch:1 Step:1088 Training_loss:0.682398, Acc_avg:55.00% Training_loss_avg:0.692272\n",
            "Epoch:1 Step:1096 Training_loss:0.658874, Acc_avg:55.25% Training_loss_avg:0.691904\n",
            "Epoch:1 Step:1104 Training_loss:0.711607, Acc_avg:55.25% Training_loss_avg:0.692036\n",
            "Epoch:1 Step:1112 Training_loss:0.701273, Acc_avg:55.25% Training_loss_avg:0.692707\n",
            "Epoch:1 Step:1120 Training_loss:0.662980, Acc_avg:55.50% Training_loss_avg:0.692403\n",
            "Epoch:1 Step:1128 Training_loss:0.669022, Acc_avg:55.50% Training_loss_avg:0.692352\n",
            "Epoch:1 Step:1136 Training_loss:0.679519, Acc_avg:55.75% Training_loss_avg:0.690569\n",
            "Epoch:1 Step:1144 Training_loss:0.682262, Acc_avg:56.25% Training_loss_avg:0.688827\n",
            "Epoch:1 Step:1152 Training_loss:0.697356, Acc_avg:56.00% Training_loss_avg:0.689713\n",
            "Epoch:1 Step:1160 Training_loss:0.692624, Acc_avg:55.50% Training_loss_avg:0.690992\n",
            "Epoch:1 Step:1168 Training_loss:0.610777, Acc_avg:56.25% Training_loss_avg:0.687947\n",
            "Epoch:1 Step:1176 Training_loss:0.690241, Acc_avg:55.75% Training_loss_avg:0.689789\n",
            "Epoch:1 Step:1184 Training_loss:0.662698, Acc_avg:56.50% Training_loss_avg:0.688492\n",
            "Epoch:1 Step:1192 Training_loss:0.689853, Acc_avg:56.50% Training_loss_avg:0.688146\n",
            "Epoch:1 Step:1200 Training_loss:0.712391, Acc_avg:56.50% Training_loss_avg:0.687813\n",
            "Epoch:1 Step:1208 Training_loss:0.677091, Acc_avg:56.25% Training_loss_avg:0.688625\n",
            "Epoch:1 Step:1216 Training_loss:0.635328, Acc_avg:57.00% Training_loss_avg:0.686186\n",
            "Epoch:1 Step:1224 Training_loss:0.715421, Acc_avg:56.25% Training_loss_avg:0.688853\n",
            "Epoch:1 Step:1232 Training_loss:0.707089, Acc_avg:55.75% Training_loss_avg:0.690352\n",
            "Epoch:1 Step:1240 Training_loss:0.675808, Acc_avg:56.75% Training_loss_avg:0.686449\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:1240 Val_loss:0.689868, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:1248 Training_loss:0.659882, Acc_avg:57.00% Training_loss_avg:0.686787\n",
            "Epoch:1 Step:1256 Training_loss:0.761358, Acc_avg:56.25% Training_loss_avg:0.687818\n",
            "Epoch:1 Step:1264 Training_loss:0.649499, Acc_avg:57.25% Training_loss_avg:0.685518\n",
            "Epoch:1 Step:1272 Training_loss:0.670485, Acc_avg:57.50% Training_loss_avg:0.684827\n",
            "Epoch:1 Step:1280 Training_loss:0.634299, Acc_avg:57.50% Training_loss_avg:0.684409\n",
            "Epoch:1 Step:1288 Training_loss:0.734403, Acc_avg:57.00% Training_loss_avg:0.686219\n",
            "Epoch:1 Step:1296 Training_loss:0.656124, Acc_avg:57.50% Training_loss_avg:0.685474\n",
            "Epoch:1 Step:1304 Training_loss:0.761549, Acc_avg:57.25% Training_loss_avg:0.686656\n",
            "Epoch:1 Step:1312 Training_loss:0.658361, Acc_avg:57.00% Training_loss_avg:0.687420\n",
            "Epoch:1 Step:1320 Training_loss:0.574880, Acc_avg:57.75% Training_loss_avg:0.684833\n",
            "Epoch:1 Step:1328 Training_loss:0.673642, Acc_avg:58.00% Training_loss_avg:0.684370\n",
            "Epoch:1 Step:1336 Training_loss:0.661877, Acc_avg:58.25% Training_loss_avg:0.684467\n",
            "Epoch:1 Step:1344 Training_loss:0.737062, Acc_avg:58.00% Training_loss_avg:0.685414\n",
            "Epoch:1 Step:1352 Training_loss:0.623295, Acc_avg:58.25% Training_loss_avg:0.683975\n",
            "Epoch:1 Step:1360 Training_loss:0.670983, Acc_avg:58.25% Training_loss_avg:0.684065\n",
            "Epoch:1 Step:1368 Training_loss:0.699314, Acc_avg:58.25% Training_loss_avg:0.684288\n",
            "Epoch:1 Step:1376 Training_loss:0.588397, Acc_avg:58.75% Training_loss_avg:0.681424\n",
            "Epoch:1 Step:1384 Training_loss:0.704903, Acc_avg:59.25% Training_loss_avg:0.680373\n",
            "Epoch:1 Step:1392 Training_loss:0.658793, Acc_avg:58.75% Training_loss_avg:0.681093\n",
            "Epoch:1 Step:1400 Training_loss:0.665294, Acc_avg:59.00% Training_loss_avg:0.680045\n",
            "Epoch:1 Step:1408 Training_loss:0.738471, Acc_avg:59.00% Training_loss_avg:0.680504\n",
            "Epoch:1 Step:1416 Training_loss:0.631756, Acc_avg:58.75% Training_loss_avg:0.680093\n",
            "Epoch:1 Step:1424 Training_loss:0.757129, Acc_avg:59.00% Training_loss_avg:0.680651\n",
            "Epoch:1 Step:1432 Training_loss:0.736737, Acc_avg:58.75% Training_loss_avg:0.681771\n",
            "Epoch:1 Step:1440 Training_loss:0.850733, Acc_avg:58.00% Training_loss_avg:0.685089\n",
            "Epoch:1 Step:1448 Training_loss:0.672219, Acc_avg:58.50% Training_loss_avg:0.683761\n",
            "Epoch:1 Step:1456 Training_loss:0.671553, Acc_avg:58.50% Training_loss_avg:0.684083\n",
            "Epoch:1 Step:1464 Training_loss:0.738701, Acc_avg:58.25% Training_loss_avg:0.684635\n",
            "Epoch:1 Step:1472 Training_loss:0.685115, Acc_avg:58.25% Training_loss_avg:0.684844\n",
            "Epoch:1 Step:1480 Training_loss:0.642184, Acc_avg:58.75% Training_loss_avg:0.683672\n",
            "Epoch:1 Step:1488 Training_loss:0.585756, Acc_avg:59.25% Training_loss_avg:0.681739\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:1488 Val_loss:0.691186, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:1496 Training_loss:0.821093, Acc_avg:58.00% Training_loss_avg:0.684984\n",
            "Epoch:1 Step:1504 Training_loss:0.676563, Acc_avg:58.50% Training_loss_avg:0.684283\n",
            "Epoch:1 Step:1512 Training_loss:0.717124, Acc_avg:58.50% Training_loss_avg:0.684600\n",
            "Epoch:1 Step:1520 Training_loss:0.729210, Acc_avg:57.75% Training_loss_avg:0.685925\n",
            "Epoch:1 Step:1528 Training_loss:0.693635, Acc_avg:57.50% Training_loss_avg:0.686417\n",
            "Epoch:1 Step:1536 Training_loss:0.699660, Acc_avg:57.50% Training_loss_avg:0.686820\n",
            "Epoch:1 Step:1544 Training_loss:0.640642, Acc_avg:58.00% Training_loss_avg:0.685987\n",
            "Epoch:1 Step:1552 Training_loss:0.661713, Acc_avg:58.25% Training_loss_avg:0.685274\n",
            "Epoch:1 Step:1560 Training_loss:0.686300, Acc_avg:58.25% Training_loss_avg:0.685148\n",
            "Epoch:1 Step:1568 Training_loss:0.727454, Acc_avg:57.50% Training_loss_avg:0.687481\n",
            "Epoch:1 Step:1576 Training_loss:0.687310, Acc_avg:57.50% Training_loss_avg:0.687423\n",
            "Epoch:1 Step:1584 Training_loss:0.691068, Acc_avg:57.00% Training_loss_avg:0.687990\n",
            "Epoch:1 Step:1592 Training_loss:0.708507, Acc_avg:56.75% Training_loss_avg:0.688363\n",
            "Epoch:1 Step:1600 Training_loss:0.681845, Acc_avg:56.75% Training_loss_avg:0.687752\n",
            "Epoch:1 Step:1608 Training_loss:0.719519, Acc_avg:56.25% Training_loss_avg:0.688601\n",
            "Epoch:1 Step:1616 Training_loss:0.699133, Acc_avg:55.75% Training_loss_avg:0.689877\n",
            "Epoch:1 Step:1624 Training_loss:0.663604, Acc_avg:56.25% Training_loss_avg:0.688841\n",
            "Epoch:1 Step:1632 Training_loss:0.711797, Acc_avg:56.00% Training_loss_avg:0.688935\n",
            "Epoch:1 Step:1640 Training_loss:0.651961, Acc_avg:56.75% Training_loss_avg:0.688458\n",
            "Epoch:1 Step:1648 Training_loss:0.676000, Acc_avg:56.50% Training_loss_avg:0.688780\n",
            "Epoch:1 Step:1656 Training_loss:0.712980, Acc_avg:56.75% Training_loss_avg:0.687813\n",
            "Epoch:1 Step:1664 Training_loss:0.692552, Acc_avg:56.00% Training_loss_avg:0.688674\n",
            "Epoch:1 Step:1672 Training_loss:0.713014, Acc_avg:55.25% Training_loss_avg:0.689524\n",
            "Epoch:1 Step:1680 Training_loss:0.710305, Acc_avg:54.50% Training_loss_avg:0.691044\n",
            "Epoch:1 Step:1688 Training_loss:0.657375, Acc_avg:55.25% Training_loss_avg:0.689504\n",
            "Epoch:1 Step:1696 Training_loss:0.721299, Acc_avg:54.00% Training_loss_avg:0.690807\n",
            "Epoch:1 Step:1704 Training_loss:0.707655, Acc_avg:54.00% Training_loss_avg:0.689730\n",
            "Epoch:1 Step:1712 Training_loss:0.702435, Acc_avg:53.25% Training_loss_avg:0.690611\n",
            "Epoch:1 Step:1720 Training_loss:0.688363, Acc_avg:52.50% Training_loss_avg:0.692881\n",
            "Epoch:1 Step:1728 Training_loss:0.682432, Acc_avg:52.50% Training_loss_avg:0.693056\n",
            "Epoch:1 Step:1736 Training_loss:0.698486, Acc_avg:51.75% Training_loss_avg:0.693789\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:1736 Val_loss:0.693910, Val_Acc_avg:45.25%\n",
            "Epoch:1 Step:1744 Training_loss:0.687233, Acc_avg:52.25% Training_loss_avg:0.692792\n",
            "Epoch:1 Step:1752 Training_loss:0.687925, Acc_avg:52.00% Training_loss_avg:0.694085\n",
            "Epoch:1 Step:1760 Training_loss:0.693581, Acc_avg:52.00% Training_loss_avg:0.694537\n",
            "Epoch:1 Step:1768 Training_loss:0.731357, Acc_avg:51.25% Training_loss_avg:0.695177\n",
            "Epoch:1 Step:1776 Training_loss:0.704039, Acc_avg:50.75% Training_loss_avg:0.697490\n",
            "Epoch:1 Step:1784 Training_loss:0.719204, Acc_avg:50.50% Training_loss_avg:0.697776\n",
            "Epoch:1 Step:1792 Training_loss:0.706865, Acc_avg:50.00% Training_loss_avg:0.698738\n",
            "Epoch:1 Step:1800 Training_loss:0.685802, Acc_avg:49.75% Training_loss_avg:0.699148\n",
            "Epoch:1 Step:1808 Training_loss:0.717254, Acc_avg:49.50% Training_loss_avg:0.698724\n",
            "Epoch:1 Step:1816 Training_loss:0.718382, Acc_avg:48.75% Training_loss_avg:0.700456\n",
            "Epoch:1 Step:1824 Training_loss:0.706733, Acc_avg:48.50% Training_loss_avg:0.699448\n",
            "Epoch:1 Step:1832 Training_loss:0.685098, Acc_avg:48.50% Training_loss_avg:0.698415\n",
            "Epoch:1 Step:1840 Training_loss:0.700304, Acc_avg:48.75% Training_loss_avg:0.695407\n",
            "Epoch:1 Step:1848 Training_loss:0.676454, Acc_avg:49.00% Training_loss_avg:0.695492\n",
            "Epoch:1 Step:1856 Training_loss:0.681178, Acc_avg:49.25% Training_loss_avg:0.695684\n",
            "Epoch:1 Step:1864 Training_loss:0.675865, Acc_avg:50.00% Training_loss_avg:0.694427\n",
            "Epoch:1 Step:1872 Training_loss:0.690218, Acc_avg:50.00% Training_loss_avg:0.694529\n",
            "Epoch:1 Step:1880 Training_loss:0.727111, Acc_avg:49.25% Training_loss_avg:0.696228\n",
            "Epoch:1 Step:1888 Training_loss:0.684260, Acc_avg:48.75% Training_loss_avg:0.698198\n",
            "Epoch:1 Step:1896 Training_loss:0.684334, Acc_avg:49.75% Training_loss_avg:0.695463\n",
            "Epoch:1 Step:1904 Training_loss:0.672112, Acc_avg:49.75% Training_loss_avg:0.695374\n",
            "Epoch:1 Step:1912 Training_loss:0.718924, Acc_avg:49.50% Training_loss_avg:0.695410\n",
            "Epoch:1 Step:1920 Training_loss:0.684938, Acc_avg:49.75% Training_loss_avg:0.694524\n",
            "Epoch:1 Step:1928 Training_loss:0.716876, Acc_avg:49.50% Training_loss_avg:0.694989\n",
            "Epoch:1 Step:1936 Training_loss:0.661844, Acc_avg:49.75% Training_loss_avg:0.694233\n",
            "Epoch:1 Step:1944 Training_loss:0.723205, Acc_avg:48.75% Training_loss_avg:0.695884\n",
            "Epoch:1 Step:1952 Training_loss:0.764867, Acc_avg:48.25% Training_loss_avg:0.697947\n",
            "Epoch:1 Step:1960 Training_loss:0.747595, Acc_avg:48.00% Training_loss_avg:0.699173\n",
            "Epoch:1 Step:1968 Training_loss:0.623723, Acc_avg:48.50% Training_loss_avg:0.697098\n",
            "Epoch:1 Step:1976 Training_loss:0.655367, Acc_avg:48.75% Training_loss_avg:0.696460\n",
            "Epoch:1 Step:1984 Training_loss:0.668254, Acc_avg:49.00% Training_loss_avg:0.696003\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:1984 Val_loss:0.689883, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:1992 Training_loss:0.707875, Acc_avg:49.00% Training_loss_avg:0.695991\n",
            "Epoch:1 Step:2000 Training_loss:0.714183, Acc_avg:48.75% Training_loss_avg:0.696637\n",
            "Epoch:1 Step:2008 Training_loss:0.674640, Acc_avg:49.25% Training_loss_avg:0.695740\n",
            "Epoch:1 Step:2016 Training_loss:0.659623, Acc_avg:49.50% Training_loss_avg:0.694950\n",
            "Epoch:1 Step:2024 Training_loss:0.761721, Acc_avg:48.50% Training_loss_avg:0.696912\n",
            "Epoch:1 Step:2032 Training_loss:0.750165, Acc_avg:48.25% Training_loss_avg:0.697679\n",
            "Epoch:1 Step:2040 Training_loss:0.673482, Acc_avg:47.25% Training_loss_avg:0.698110\n",
            "Epoch:1 Step:2048 Training_loss:0.658465, Acc_avg:47.25% Training_loss_avg:0.697759\n",
            "Epoch:1 Step:2056 Training_loss:0.673116, Acc_avg:47.75% Training_loss_avg:0.696962\n",
            "Epoch:1 Step:2064 Training_loss:0.664082, Acc_avg:48.50% Training_loss_avg:0.696392\n",
            "Epoch:1 Step:2072 Training_loss:0.722272, Acc_avg:48.50% Training_loss_avg:0.696577\n",
            "Epoch:1 Step:2080 Training_loss:0.754833, Acc_avg:48.00% Training_loss_avg:0.697468\n",
            "Epoch:1 Step:2088 Training_loss:0.699882, Acc_avg:47.50% Training_loss_avg:0.698318\n",
            "Epoch:1 Step:2096 Training_loss:0.704098, Acc_avg:48.25% Training_loss_avg:0.697974\n",
            "Epoch:1 Step:2104 Training_loss:0.694600, Acc_avg:48.75% Training_loss_avg:0.697713\n",
            "Epoch:1 Step:2112 Training_loss:0.727483, Acc_avg:48.75% Training_loss_avg:0.698214\n",
            "Epoch:1 Step:2120 Training_loss:0.676906, Acc_avg:49.25% Training_loss_avg:0.697985\n",
            "Epoch:1 Step:2128 Training_loss:0.694922, Acc_avg:49.00% Training_loss_avg:0.698235\n",
            "Epoch:1 Step:2136 Training_loss:0.727640, Acc_avg:48.50% Training_loss_avg:0.698818\n",
            "Epoch:1 Step:2144 Training_loss:0.669167, Acc_avg:48.75% Training_loss_avg:0.698456\n",
            "Epoch:1 Step:2152 Training_loss:0.657892, Acc_avg:49.00% Training_loss_avg:0.697856\n",
            "Epoch:1 Step:2160 Training_loss:0.669009, Acc_avg:49.25% Training_loss_avg:0.697364\n",
            "Epoch:1 Step:2168 Training_loss:0.659534, Acc_avg:50.75% Training_loss_avg:0.695928\n",
            "Epoch:1 Step:2176 Training_loss:0.685313, Acc_avg:51.00% Training_loss_avg:0.695553\n",
            "Epoch:1 Step:2184 Training_loss:0.707945, Acc_avg:50.75% Training_loss_avg:0.695328\n",
            "Epoch:1 Step:2192 Training_loss:0.694872, Acc_avg:51.00% Training_loss_avg:0.695088\n",
            "Epoch:1 Step:2200 Training_loss:0.710567, Acc_avg:51.00% Training_loss_avg:0.695584\n",
            "Epoch:1 Step:2208 Training_loss:0.718535, Acc_avg:51.00% Training_loss_avg:0.695609\n",
            "Epoch:1 Step:2216 Training_loss:0.672702, Acc_avg:52.00% Training_loss_avg:0.694696\n",
            "Epoch:1 Step:2224 Training_loss:0.683909, Acc_avg:52.75% Training_loss_avg:0.694239\n",
            "Epoch:1 Step:2232 Training_loss:0.689424, Acc_avg:52.75% Training_loss_avg:0.694326\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:2232 Val_loss:0.690354, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:2240 Training_loss:0.681989, Acc_avg:53.25% Training_loss_avg:0.693959\n",
            "Epoch:1 Step:2248 Training_loss:0.681253, Acc_avg:53.00% Training_loss_avg:0.694055\n",
            "Epoch:1 Step:2256 Training_loss:0.685650, Acc_avg:52.75% Training_loss_avg:0.694145\n",
            "Epoch:1 Step:2264 Training_loss:0.704441, Acc_avg:52.50% Training_loss_avg:0.694716\n",
            "Epoch:1 Step:2272 Training_loss:0.665086, Acc_avg:52.75% Training_loss_avg:0.694214\n",
            "Epoch:1 Step:2280 Training_loss:0.691852, Acc_avg:53.00% Training_loss_avg:0.693509\n",
            "Epoch:1 Step:2288 Training_loss:0.669717, Acc_avg:53.00% Training_loss_avg:0.693218\n",
            "Epoch:1 Step:2296 Training_loss:0.716572, Acc_avg:52.50% Training_loss_avg:0.693862\n",
            "Epoch:1 Step:2304 Training_loss:0.724002, Acc_avg:52.00% Training_loss_avg:0.694900\n",
            "Epoch:1 Step:2312 Training_loss:0.729329, Acc_avg:52.00% Training_loss_avg:0.695108\n",
            "Epoch:1 Step:2320 Training_loss:0.697960, Acc_avg:52.00% Training_loss_avg:0.695369\n",
            "Epoch:1 Step:2328 Training_loss:0.675269, Acc_avg:52.75% Training_loss_avg:0.694537\n",
            "Epoch:1 Step:2336 Training_loss:0.657312, Acc_avg:53.00% Training_loss_avg:0.694446\n",
            "Epoch:1 Step:2344 Training_loss:0.651954, Acc_avg:54.00% Training_loss_avg:0.693021\n",
            "Epoch:1 Step:2352 Training_loss:0.648600, Acc_avg:55.00% Training_loss_avg:0.690696\n",
            "Epoch:1 Step:2360 Training_loss:0.661331, Acc_avg:55.75% Training_loss_avg:0.688970\n",
            "Epoch:1 Step:2368 Training_loss:0.722303, Acc_avg:55.00% Training_loss_avg:0.690942\n",
            "Epoch:1 Step:2376 Training_loss:0.669920, Acc_avg:55.00% Training_loss_avg:0.691233\n",
            "Epoch:1 Step:2384 Training_loss:0.671309, Acc_avg:54.75% Training_loss_avg:0.691294\n",
            "Epoch:1 Step:2392 Training_loss:0.648111, Acc_avg:55.50% Training_loss_avg:0.690099\n",
            "Epoch:1 Step:2400 Training_loss:0.668167, Acc_avg:56.00% Training_loss_avg:0.689179\n",
            "Epoch:1 Step:2408 Training_loss:0.702860, Acc_avg:55.75% Training_loss_avg:0.689743\n",
            "Epoch:1 Step:2416 Training_loss:0.693304, Acc_avg:55.75% Training_loss_avg:0.690417\n",
            "Epoch:1 Step:2424 Training_loss:0.751551, Acc_avg:55.75% Training_loss_avg:0.690213\n",
            "Epoch:1 Step:2432 Training_loss:0.733605, Acc_avg:56.00% Training_loss_avg:0.689882\n",
            "Epoch:1 Step:2440 Training_loss:0.677216, Acc_avg:56.25% Training_loss_avg:0.689957\n",
            "Epoch:1 Step:2448 Training_loss:0.772243, Acc_avg:55.50% Training_loss_avg:0.692232\n",
            "Epoch:1 Step:2456 Training_loss:0.607348, Acc_avg:55.75% Training_loss_avg:0.690917\n",
            "Epoch:1 Step:2464 Training_loss:0.677431, Acc_avg:55.25% Training_loss_avg:0.691184\n",
            "Epoch:1 Step:2472 Training_loss:0.696273, Acc_avg:56.00% Training_loss_avg:0.690664\n",
            "Epoch:1 Step:2480 Training_loss:0.625257, Acc_avg:57.25% Training_loss_avg:0.688072\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:2480 Val_loss:0.689887, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:2488 Training_loss:0.658777, Acc_avg:57.50% Training_loss_avg:0.687250\n",
            "Epoch:1 Step:2496 Training_loss:0.689685, Acc_avg:57.50% Training_loss_avg:0.686962\n",
            "Epoch:1 Step:2504 Training_loss:0.712870, Acc_avg:57.00% Training_loss_avg:0.687327\n",
            "Epoch:1 Step:2512 Training_loss:0.731748, Acc_avg:57.25% Training_loss_avg:0.687413\n",
            "Epoch:1 Step:2520 Training_loss:0.752986, Acc_avg:56.25% Training_loss_avg:0.688934\n",
            "Epoch:1 Step:2528 Training_loss:0.701414, Acc_avg:56.25% Training_loss_avg:0.689064\n",
            "Epoch:1 Step:2536 Training_loss:0.725322, Acc_avg:56.75% Training_loss_avg:0.689018\n",
            "Epoch:1 Step:2544 Training_loss:0.619727, Acc_avg:56.75% Training_loss_avg:0.688029\n",
            "Epoch:1 Step:2552 Training_loss:0.629938, Acc_avg:56.75% Training_loss_avg:0.687470\n",
            "Epoch:1 Step:2560 Training_loss:0.581994, Acc_avg:57.25% Training_loss_avg:0.685730\n",
            "Epoch:1 Step:2568 Training_loss:0.724756, Acc_avg:56.75% Training_loss_avg:0.687034\n",
            "Epoch:1 Step:2576 Training_loss:0.698765, Acc_avg:56.50% Training_loss_avg:0.687303\n",
            "Epoch:1 Step:2584 Training_loss:0.680494, Acc_avg:57.00% Training_loss_avg:0.686754\n",
            "Epoch:1 Step:2592 Training_loss:0.665080, Acc_avg:57.25% Training_loss_avg:0.686158\n",
            "Epoch:1 Step:2600 Training_loss:0.649116, Acc_avg:57.75% Training_loss_avg:0.684929\n",
            "Epoch:1 Step:2608 Training_loss:0.658000, Acc_avg:58.50% Training_loss_avg:0.683718\n",
            "Epoch:1 Step:2616 Training_loss:0.608129, Acc_avg:58.25% Training_loss_avg:0.682427\n",
            "Epoch:1 Step:2624 Training_loss:0.743314, Acc_avg:58.00% Training_loss_avg:0.683615\n",
            "Epoch:1 Step:2632 Training_loss:0.793198, Acc_avg:57.25% Training_loss_avg:0.685691\n",
            "Epoch:1 Step:2640 Training_loss:0.690636, Acc_avg:57.00% Training_loss_avg:0.685864\n",
            "Epoch:1 Step:2648 Training_loss:0.613897, Acc_avg:57.25% Training_loss_avg:0.684516\n",
            "Epoch:1 Step:2656 Training_loss:0.697413, Acc_avg:57.00% Training_loss_avg:0.684752\n",
            "Epoch:1 Step:2664 Training_loss:0.668854, Acc_avg:57.00% Training_loss_avg:0.684040\n",
            "Epoch:1 Step:2672 Training_loss:0.715070, Acc_avg:56.50% Training_loss_avg:0.685040\n",
            "Epoch:1 Step:2680 Training_loss:0.619680, Acc_avg:57.00% Training_loss_avg:0.683596\n",
            "Epoch:1 Step:2688 Training_loss:0.646286, Acc_avg:57.25% Training_loss_avg:0.683128\n",
            "Epoch:1 Step:2696 Training_loss:0.610392, Acc_avg:58.00% Training_loss_avg:0.681004\n",
            "Epoch:1 Step:2704 Training_loss:0.749994, Acc_avg:58.00% Training_loss_avg:0.681524\n",
            "Epoch:1 Step:2712 Training_loss:0.790667, Acc_avg:57.75% Training_loss_avg:0.682751\n",
            "Epoch:1 Step:2720 Training_loss:0.696124, Acc_avg:57.75% Training_loss_avg:0.682714\n",
            "Epoch:1 Step:2728 Training_loss:0.741453, Acc_avg:57.25% Training_loss_avg:0.684038\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:2728 Val_loss:0.691591, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:2736 Training_loss:0.671998, Acc_avg:57.00% Training_loss_avg:0.684331\n",
            "Epoch:1 Step:2744 Training_loss:0.805842, Acc_avg:55.75% Training_loss_avg:0.687409\n",
            "Epoch:1 Step:2752 Training_loss:0.670754, Acc_avg:55.25% Training_loss_avg:0.687852\n",
            "Epoch:1 Step:2760 Training_loss:0.674184, Acc_avg:54.75% Training_loss_avg:0.688109\n",
            "Epoch:1 Step:2768 Training_loss:0.668298, Acc_avg:55.25% Training_loss_avg:0.687029\n",
            "Epoch:1 Step:2776 Training_loss:0.586067, Acc_avg:55.75% Training_loss_avg:0.685352\n",
            "Epoch:1 Step:2784 Training_loss:0.688838, Acc_avg:55.50% Training_loss_avg:0.685703\n",
            "Epoch:1 Step:2792 Training_loss:0.590551, Acc_avg:55.50% Training_loss_avg:0.684551\n",
            "Epoch:1 Step:2800 Training_loss:0.682762, Acc_avg:55.25% Training_loss_avg:0.684843\n",
            "Epoch:1 Step:2808 Training_loss:0.688088, Acc_avg:55.25% Training_loss_avg:0.684548\n",
            "Epoch:1 Step:2816 Training_loss:0.732422, Acc_avg:54.75% Training_loss_avg:0.685330\n",
            "Epoch:1 Step:2824 Training_loss:0.654874, Acc_avg:55.75% Training_loss_avg:0.683397\n",
            "Epoch:1 Step:2832 Training_loss:0.708117, Acc_avg:56.00% Training_loss_avg:0.682887\n",
            "Epoch:1 Step:2840 Training_loss:0.734954, Acc_avg:56.00% Training_loss_avg:0.684042\n",
            "Epoch:1 Step:2848 Training_loss:0.669481, Acc_avg:56.75% Training_loss_avg:0.681986\n",
            "Epoch:1 Step:2856 Training_loss:0.683410, Acc_avg:56.50% Training_loss_avg:0.683508\n",
            "Epoch:1 Step:2864 Training_loss:0.742513, Acc_avg:56.50% Training_loss_avg:0.684809\n",
            "Epoch:1 Step:2872 Training_loss:0.666909, Acc_avg:56.50% Training_loss_avg:0.684222\n",
            "Epoch:1 Step:2880 Training_loss:0.695293, Acc_avg:56.00% Training_loss_avg:0.685623\n",
            "Epoch:1 Step:2888 Training_loss:0.703759, Acc_avg:55.75% Training_loss_avg:0.686522\n",
            "Epoch:1 Step:2896 Training_loss:0.617778, Acc_avg:56.50% Training_loss_avg:0.685084\n",
            "Epoch:1 Step:2904 Training_loss:0.723560, Acc_avg:56.50% Training_loss_avg:0.685298\n",
            "Epoch:1 Step:2912 Training_loss:0.688546, Acc_avg:56.75% Training_loss_avg:0.684434\n",
            "Epoch:1 Step:2920 Training_loss:0.703114, Acc_avg:57.25% Training_loss_avg:0.683437\n",
            "Epoch:1 Step:2928 Training_loss:0.704056, Acc_avg:57.25% Training_loss_avg:0.683489\n",
            "Epoch:1 Step:2936 Training_loss:0.768560, Acc_avg:57.00% Training_loss_avg:0.684354\n",
            "Epoch:1 Step:2944 Training_loss:0.628212, Acc_avg:57.25% Training_loss_avg:0.684524\n",
            "Epoch:1 Step:2952 Training_loss:0.608495, Acc_avg:57.75% Training_loss_avg:0.684095\n",
            "Epoch:1 Step:2960 Training_loss:0.703830, Acc_avg:56.75% Training_loss_avg:0.686532\n",
            "Epoch:1 Step:2968 Training_loss:0.704711, Acc_avg:56.50% Training_loss_avg:0.686131\n",
            "Epoch:1 Step:2976 Training_loss:0.655297, Acc_avg:56.75% Training_loss_avg:0.685261\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:2976 Val_loss:0.689709, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:2984 Training_loss:0.786107, Acc_avg:56.25% Training_loss_avg:0.687374\n",
            "Epoch:1 Step:2992 Training_loss:0.671563, Acc_avg:56.00% Training_loss_avg:0.687503\n",
            "Epoch:1 Step:3000 Training_loss:0.627448, Acc_avg:56.00% Training_loss_avg:0.687070\n",
            "Epoch:1 Step:3008 Training_loss:0.695153, Acc_avg:55.75% Training_loss_avg:0.687813\n",
            "Epoch:1 Step:3016 Training_loss:0.728727, Acc_avg:55.50% Training_loss_avg:0.690225\n",
            "Epoch:1 Step:3024 Training_loss:0.621992, Acc_avg:56.25% Training_loss_avg:0.687799\n",
            "Epoch:1 Step:3032 Training_loss:0.676590, Acc_avg:57.25% Training_loss_avg:0.685466\n",
            "Epoch:1 Step:3040 Training_loss:0.676676, Acc_avg:57.25% Training_loss_avg:0.685187\n",
            "Epoch:1 Step:3048 Training_loss:0.722736, Acc_avg:56.50% Training_loss_avg:0.687364\n",
            "Epoch:1 Step:3056 Training_loss:0.758577, Acc_avg:56.00% Training_loss_avg:0.688587\n",
            "Epoch:1 Step:3064 Training_loss:0.699017, Acc_avg:55.75% Training_loss_avg:0.689191\n",
            "Epoch:1 Step:3072 Training_loss:0.653548, Acc_avg:56.00% Training_loss_avg:0.687960\n",
            "Epoch:1 Step:3080 Training_loss:0.724974, Acc_avg:55.25% Training_loss_avg:0.690066\n",
            "Epoch:1 Step:3088 Training_loss:0.647262, Acc_avg:55.00% Training_loss_avg:0.690085\n",
            "Epoch:1 Step:3096 Training_loss:0.678739, Acc_avg:54.75% Training_loss_avg:0.691452\n",
            "Epoch:1 Step:3104 Training_loss:0.721582, Acc_avg:54.75% Training_loss_avg:0.690884\n",
            "Epoch:1 Step:3112 Training_loss:0.645510, Acc_avg:55.75% Training_loss_avg:0.687981\n",
            "Epoch:1 Step:3120 Training_loss:0.660081, Acc_avg:56.00% Training_loss_avg:0.687260\n",
            "Epoch:1 Step:3128 Training_loss:0.707241, Acc_avg:56.00% Training_loss_avg:0.686576\n",
            "Epoch:1 Step:3136 Training_loss:0.686830, Acc_avg:55.75% Training_loss_avg:0.686873\n",
            "Epoch:1 Step:3144 Training_loss:0.641309, Acc_avg:56.75% Training_loss_avg:0.683582\n",
            "Epoch:1 Step:3152 Training_loss:0.703152, Acc_avg:56.50% Training_loss_avg:0.684230\n",
            "Epoch:1 Step:3160 Training_loss:0.658280, Acc_avg:56.75% Training_loss_avg:0.683912\n",
            "Epoch:1 Step:3168 Training_loss:0.754955, Acc_avg:56.25% Training_loss_avg:0.685645\n",
            "Epoch:1 Step:3176 Training_loss:0.727417, Acc_avg:55.25% Training_loss_avg:0.688472\n",
            "Epoch:1 Step:3184 Training_loss:0.642310, Acc_avg:56.00% Training_loss_avg:0.687541\n",
            "Epoch:1 Step:3192 Training_loss:0.608056, Acc_avg:56.25% Training_loss_avg:0.687891\n",
            "Epoch:1 Step:3200 Training_loss:0.629852, Acc_avg:56.75% Training_loss_avg:0.686833\n",
            "Epoch:1 Step:3208 Training_loss:0.695727, Acc_avg:56.75% Training_loss_avg:0.686986\n",
            "Epoch:1 Step:3216 Training_loss:0.627166, Acc_avg:57.50% Training_loss_avg:0.684881\n",
            "Epoch:1 Step:3224 Training_loss:0.733822, Acc_avg:56.75% Training_loss_avg:0.686460\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Step:3224 Val_loss:0.690433, Val_Acc_avg:54.75%\n",
            "Epoch:1 Step:3232 Training_loss:0.628554, Acc_avg:57.25% Training_loss_avg:0.684869\n",
            "Epoch:1 Step:3240 Training_loss:0.716417, Acc_avg:57.00% Training_loss_avg:0.684498\n",
            "Epoch:1 Step:3248 Training_loss:0.653213, Acc_avg:57.00% Training_loss_avg:0.684173\n",
            "Epoch:1 Step:3256 Training_loss:0.750495, Acc_avg:56.75% Training_loss_avg:0.685514\n",
            "Epoch:1 Step:3264 Training_loss:0.738826, Acc_avg:56.75% Training_loss_avg:0.685440\n",
            "Epoch:1 Step:3272 Training_loss:0.641282, Acc_avg:56.75% Training_loss_avg:0.684928\n",
            "Epoch:1 Step:3280 Training_loss:0.766388, Acc_avg:56.25% Training_loss_avg:0.686350\n",
            "Epoch:1 Step:3288 Training_loss:0.750429, Acc_avg:56.00% Training_loss_avg:0.687283\n",
            "Epoch:1 Step:3296 Training_loss:0.712698, Acc_avg:55.25% Training_loss_avg:0.689182\n",
            "Epoch:1 Step:3304 Training_loss:0.666629, Acc_avg:55.75% Training_loss_avg:0.688043\n",
            "Epoch:1 Step:3312 Training_loss:0.615455, Acc_avg:56.00% Training_loss_avg:0.686581\n",
            "Epoch:1 Step:3320 Training_loss:0.656607, Acc_avg:56.25% Training_loss_avg:0.685651\n",
            "Epoch:1 Step:3328 Training_loss:0.738396, Acc_avg:55.92% Training_loss_avg:0.686338\n",
            "Epoch:2 Step:0 Training_loss:0.818923, Acc_avg:55.92% Training_loss_avg:0.687345\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:0 Val_loss:0.689678, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:8 Training_loss:0.696189, Acc_avg:55.17% Training_loss_avg:0.688705\n",
            "Epoch:2 Step:16 Training_loss:0.632581, Acc_avg:54.67% Training_loss_avg:0.689186\n",
            "Epoch:2 Step:24 Training_loss:0.682463, Acc_avg:54.67% Training_loss_avg:0.688759\n",
            "Epoch:2 Step:32 Training_loss:0.701211, Acc_avg:54.67% Training_loss_avg:0.688689\n",
            "Epoch:2 Step:40 Training_loss:0.701367, Acc_avg:54.42% Training_loss_avg:0.689610\n",
            "Epoch:2 Step:48 Training_loss:0.737642, Acc_avg:54.67% Training_loss_avg:0.688641\n",
            "Epoch:2 Step:56 Training_loss:0.639866, Acc_avg:55.17% Training_loss_avg:0.688007\n",
            "Epoch:2 Step:64 Training_loss:0.716373, Acc_avg:54.67% Training_loss_avg:0.689786\n",
            "Epoch:2 Step:72 Training_loss:0.716569, Acc_avg:54.42% Training_loss_avg:0.690214\n",
            "Epoch:2 Step:80 Training_loss:0.657661, Acc_avg:54.92% Training_loss_avg:0.688793\n",
            "Epoch:2 Step:88 Training_loss:0.653828, Acc_avg:54.67% Training_loss_avg:0.689429\n",
            "Epoch:2 Step:96 Training_loss:0.681602, Acc_avg:54.67% Training_loss_avg:0.689530\n",
            "Epoch:2 Step:104 Training_loss:0.692676, Acc_avg:54.67% Training_loss_avg:0.689850\n",
            "Epoch:2 Step:112 Training_loss:0.699819, Acc_avg:54.67% Training_loss_avg:0.689391\n",
            "Epoch:2 Step:120 Training_loss:0.742939, Acc_avg:54.92% Training_loss_avg:0.689079\n",
            "Epoch:2 Step:128 Training_loss:0.726245, Acc_avg:54.67% Training_loss_avg:0.689623\n",
            "Epoch:2 Step:136 Training_loss:0.690149, Acc_avg:54.42% Training_loss_avg:0.690355\n",
            "Epoch:2 Step:144 Training_loss:0.651331, Acc_avg:54.92% Training_loss_avg:0.688882\n",
            "Epoch:2 Step:152 Training_loss:0.678866, Acc_avg:54.92% Training_loss_avg:0.689514\n",
            "Epoch:2 Step:160 Training_loss:0.672287, Acc_avg:54.67% Training_loss_avg:0.689385\n",
            "Epoch:2 Step:168 Training_loss:0.670322, Acc_avg:55.42% Training_loss_avg:0.688360\n",
            "Epoch:2 Step:176 Training_loss:0.700075, Acc_avg:55.17% Training_loss_avg:0.689451\n",
            "Epoch:2 Step:184 Training_loss:0.673717, Acc_avg:55.17% Training_loss_avg:0.689724\n",
            "Epoch:2 Step:192 Training_loss:0.666099, Acc_avg:55.42% Training_loss_avg:0.688901\n",
            "Epoch:2 Step:200 Training_loss:0.667394, Acc_avg:55.67% Training_loss_avg:0.688513\n",
            "Epoch:2 Step:208 Training_loss:0.715921, Acc_avg:55.17% Training_loss_avg:0.690005\n",
            "Epoch:2 Step:216 Training_loss:0.650360, Acc_avg:55.42% Training_loss_avg:0.688949\n",
            "Epoch:2 Step:224 Training_loss:0.637687, Acc_avg:55.67% Training_loss_avg:0.688537\n",
            "Epoch:2 Step:232 Training_loss:0.617144, Acc_avg:56.42% Training_loss_avg:0.685781\n",
            "Epoch:2 Step:240 Training_loss:0.681073, Acc_avg:56.92% Training_loss_avg:0.684854\n",
            "Epoch:2 Step:248 Training_loss:0.727366, Acc_avg:56.42% Training_loss_avg:0.686555\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:248 Val_loss:0.689678, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:256 Training_loss:0.689449, Acc_avg:55.67% Training_loss_avg:0.688183\n",
            "Epoch:2 Step:264 Training_loss:0.719927, Acc_avg:55.17% Training_loss_avg:0.689985\n",
            "Epoch:2 Step:272 Training_loss:0.748491, Acc_avg:54.92% Training_loss_avg:0.691040\n",
            "Epoch:2 Step:280 Training_loss:0.726097, Acc_avg:54.42% Training_loss_avg:0.693018\n",
            "Epoch:2 Step:288 Training_loss:0.649543, Acc_avg:54.92% Training_loss_avg:0.691333\n",
            "Epoch:2 Step:296 Training_loss:0.660155, Acc_avg:54.67% Training_loss_avg:0.691965\n",
            "Epoch:2 Step:304 Training_loss:0.728855, Acc_avg:54.42% Training_loss_avg:0.692214\n",
            "Epoch:2 Step:312 Training_loss:0.651436, Acc_avg:54.42% Training_loss_avg:0.692178\n",
            "Epoch:2 Step:320 Training_loss:0.609603, Acc_avg:54.92% Training_loss_avg:0.689360\n",
            "Epoch:2 Step:328 Training_loss:0.686396, Acc_avg:54.92% Training_loss_avg:0.688312\n",
            "Epoch:2 Step:336 Training_loss:0.646859, Acc_avg:55.17% Training_loss_avg:0.688423\n",
            "Epoch:2 Step:344 Training_loss:0.662786, Acc_avg:55.92% Training_loss_avg:0.686351\n",
            "Epoch:2 Step:352 Training_loss:0.683334, Acc_avg:56.17% Training_loss_avg:0.685009\n",
            "Epoch:2 Step:360 Training_loss:0.637891, Acc_avg:56.42% Training_loss_avg:0.683513\n",
            "Epoch:2 Step:368 Training_loss:0.680392, Acc_avg:56.42% Training_loss_avg:0.683788\n",
            "Epoch:2 Step:376 Training_loss:0.622171, Acc_avg:56.17% Training_loss_avg:0.683923\n",
            "Epoch:2 Step:384 Training_loss:0.717641, Acc_avg:55.92% Training_loss_avg:0.685143\n",
            "Epoch:2 Step:392 Training_loss:0.644723, Acc_avg:56.50% Training_loss_avg:0.683270\n",
            "Epoch:2 Step:400 Training_loss:0.734312, Acc_avg:56.75% Training_loss_avg:0.681578\n",
            "Epoch:2 Step:408 Training_loss:0.744608, Acc_avg:56.75% Training_loss_avg:0.682546\n",
            "Epoch:2 Step:416 Training_loss:0.615727, Acc_avg:56.75% Training_loss_avg:0.682209\n",
            "Epoch:2 Step:424 Training_loss:0.677629, Acc_avg:57.00% Training_loss_avg:0.682112\n",
            "Epoch:2 Step:432 Training_loss:0.606270, Acc_avg:57.50% Training_loss_avg:0.680213\n",
            "Epoch:2 Step:440 Training_loss:0.677664, Acc_avg:57.50% Training_loss_avg:0.679739\n",
            "Epoch:2 Step:448 Training_loss:0.650431, Acc_avg:58.00% Training_loss_avg:0.677995\n",
            "Epoch:2 Step:456 Training_loss:0.638063, Acc_avg:58.00% Training_loss_avg:0.677959\n",
            "Epoch:2 Step:464 Training_loss:0.717669, Acc_avg:58.00% Training_loss_avg:0.677985\n",
            "Epoch:2 Step:472 Training_loss:0.705048, Acc_avg:58.25% Training_loss_avg:0.677755\n",
            "Epoch:2 Step:480 Training_loss:0.811429, Acc_avg:57.25% Training_loss_avg:0.680830\n",
            "Epoch:2 Step:488 Training_loss:0.656855, Acc_avg:57.25% Training_loss_avg:0.680891\n",
            "Epoch:2 Step:496 Training_loss:0.673861, Acc_avg:57.25% Training_loss_avg:0.680736\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:496 Val_loss:0.691755, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:504 Training_loss:0.744354, Acc_avg:57.00% Training_loss_avg:0.681769\n",
            "Epoch:2 Step:512 Training_loss:0.612641, Acc_avg:57.75% Training_loss_avg:0.680026\n",
            "Epoch:2 Step:520 Training_loss:0.706097, Acc_avg:58.00% Training_loss_avg:0.679289\n",
            "Epoch:2 Step:528 Training_loss:0.690839, Acc_avg:58.50% Training_loss_avg:0.678581\n",
            "Epoch:2 Step:536 Training_loss:0.743532, Acc_avg:58.25% Training_loss_avg:0.679648\n",
            "Epoch:2 Step:544 Training_loss:0.744109, Acc_avg:58.00% Training_loss_avg:0.681504\n",
            "Epoch:2 Step:552 Training_loss:0.738496, Acc_avg:57.50% Training_loss_avg:0.682697\n",
            "Epoch:2 Step:560 Training_loss:0.604785, Acc_avg:58.25% Training_loss_avg:0.681346\n",
            "Epoch:2 Step:568 Training_loss:0.701740, Acc_avg:57.75% Training_loss_avg:0.681975\n",
            "Epoch:2 Step:576 Training_loss:0.660343, Acc_avg:57.50% Training_loss_avg:0.681180\n",
            "Epoch:2 Step:584 Training_loss:0.779133, Acc_avg:56.75% Training_loss_avg:0.683289\n",
            "Epoch:2 Step:592 Training_loss:0.672985, Acc_avg:56.75% Training_loss_avg:0.683426\n",
            "Epoch:2 Step:600 Training_loss:0.628318, Acc_avg:57.00% Training_loss_avg:0.682645\n",
            "Epoch:2 Step:608 Training_loss:0.612016, Acc_avg:57.75% Training_loss_avg:0.680567\n",
            "Epoch:2 Step:616 Training_loss:0.661270, Acc_avg:57.75% Training_loss_avg:0.680785\n",
            "Epoch:2 Step:624 Training_loss:0.654633, Acc_avg:57.75% Training_loss_avg:0.681124\n",
            "Epoch:2 Step:632 Training_loss:0.674435, Acc_avg:57.50% Training_loss_avg:0.682270\n",
            "Epoch:2 Step:640 Training_loss:0.638757, Acc_avg:57.50% Training_loss_avg:0.681423\n",
            "Epoch:2 Step:648 Training_loss:0.697929, Acc_avg:57.50% Training_loss_avg:0.680835\n",
            "Epoch:2 Step:656 Training_loss:0.662739, Acc_avg:57.75% Training_loss_avg:0.680300\n",
            "Epoch:2 Step:664 Training_loss:0.624869, Acc_avg:58.25% Training_loss_avg:0.678399\n",
            "Epoch:2 Step:672 Training_loss:0.669656, Acc_avg:58.50% Training_loss_avg:0.676822\n",
            "Epoch:2 Step:680 Training_loss:0.707309, Acc_avg:58.25% Training_loss_avg:0.676447\n",
            "Epoch:2 Step:688 Training_loss:0.691060, Acc_avg:58.00% Training_loss_avg:0.677277\n",
            "Epoch:2 Step:696 Training_loss:0.836818, Acc_avg:57.25% Training_loss_avg:0.680810\n",
            "Epoch:2 Step:704 Training_loss:0.760595, Acc_avg:57.00% Training_loss_avg:0.681445\n",
            "Epoch:2 Step:712 Training_loss:0.650629, Acc_avg:57.00% Training_loss_avg:0.681429\n",
            "Epoch:2 Step:720 Training_loss:0.700688, Acc_avg:56.50% Training_loss_avg:0.683251\n",
            "Epoch:2 Step:728 Training_loss:0.793346, Acc_avg:55.75% Training_loss_avg:0.685390\n",
            "Epoch:2 Step:736 Training_loss:0.759146, Acc_avg:55.00% Training_loss_avg:0.687635\n",
            "Epoch:2 Step:744 Training_loss:0.675255, Acc_avg:55.25% Training_loss_avg:0.687885\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:744 Val_loss:0.689435, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:752 Training_loss:0.744375, Acc_avg:54.75% Training_loss_avg:0.689106\n",
            "Epoch:2 Step:760 Training_loss:0.650416, Acc_avg:55.00% Training_loss_avg:0.689356\n",
            "Epoch:2 Step:768 Training_loss:0.742884, Acc_avg:54.25% Training_loss_avg:0.690606\n",
            "Epoch:2 Step:776 Training_loss:0.651511, Acc_avg:54.50% Training_loss_avg:0.691193\n",
            "Epoch:2 Step:784 Training_loss:0.735982, Acc_avg:54.00% Training_loss_avg:0.691560\n",
            "Epoch:2 Step:792 Training_loss:0.641420, Acc_avg:54.50% Training_loss_avg:0.691494\n",
            "Epoch:2 Step:800 Training_loss:0.662982, Acc_avg:55.25% Training_loss_avg:0.690067\n",
            "Epoch:2 Step:808 Training_loss:0.661833, Acc_avg:55.75% Training_loss_avg:0.688411\n",
            "Epoch:2 Step:816 Training_loss:0.706601, Acc_avg:55.00% Training_loss_avg:0.690229\n",
            "Epoch:2 Step:824 Training_loss:0.721832, Acc_avg:54.50% Training_loss_avg:0.691113\n",
            "Epoch:2 Step:832 Training_loss:0.692030, Acc_avg:54.00% Training_loss_avg:0.692828\n",
            "Epoch:2 Step:840 Training_loss:0.660869, Acc_avg:54.50% Training_loss_avg:0.692492\n",
            "Epoch:2 Step:848 Training_loss:0.710684, Acc_avg:54.25% Training_loss_avg:0.693697\n",
            "Epoch:2 Step:856 Training_loss:0.705246, Acc_avg:53.50% Training_loss_avg:0.695041\n",
            "Epoch:2 Step:864 Training_loss:0.701507, Acc_avg:53.75% Training_loss_avg:0.694718\n",
            "Epoch:2 Step:872 Training_loss:0.725182, Acc_avg:53.25% Training_loss_avg:0.695120\n",
            "Epoch:2 Step:880 Training_loss:0.660963, Acc_avg:54.50% Training_loss_avg:0.692111\n",
            "Epoch:2 Step:888 Training_loss:0.718202, Acc_avg:53.50% Training_loss_avg:0.693338\n",
            "Epoch:2 Step:896 Training_loss:0.672993, Acc_avg:53.50% Training_loss_avg:0.693321\n",
            "Epoch:2 Step:904 Training_loss:0.682195, Acc_avg:53.75% Training_loss_avg:0.692077\n",
            "Epoch:2 Step:912 Training_loss:0.681040, Acc_avg:53.50% Training_loss_avg:0.693445\n",
            "Epoch:2 Step:920 Training_loss:0.692548, Acc_avg:53.75% Training_loss_avg:0.693174\n",
            "Epoch:2 Step:928 Training_loss:0.689549, Acc_avg:53.50% Training_loss_avg:0.693149\n",
            "Epoch:2 Step:936 Training_loss:0.673114, Acc_avg:54.00% Training_loss_avg:0.691740\n",
            "Epoch:2 Step:944 Training_loss:0.699843, Acc_avg:54.00% Training_loss_avg:0.690855\n",
            "Epoch:2 Step:952 Training_loss:0.671805, Acc_avg:54.75% Training_loss_avg:0.689521\n",
            "Epoch:2 Step:960 Training_loss:0.689421, Acc_avg:54.00% Training_loss_avg:0.691214\n",
            "Epoch:2 Step:968 Training_loss:0.664764, Acc_avg:54.50% Training_loss_avg:0.690474\n",
            "Epoch:2 Step:976 Training_loss:0.698749, Acc_avg:54.25% Training_loss_avg:0.691242\n",
            "Epoch:2 Step:984 Training_loss:0.664968, Acc_avg:55.00% Training_loss_avg:0.688959\n",
            "Epoch:2 Step:992 Training_loss:0.669775, Acc_avg:55.25% Training_loss_avg:0.688895\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:992 Val_loss:0.689683, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:1000 Training_loss:0.672785, Acc_avg:55.00% Training_loss_avg:0.689784\n",
            "Epoch:2 Step:1008 Training_loss:0.716620, Acc_avg:54.00% Training_loss_avg:0.691876\n",
            "Epoch:2 Step:1016 Training_loss:0.712740, Acc_avg:53.50% Training_loss_avg:0.692906\n",
            "Epoch:2 Step:1024 Training_loss:0.687575, Acc_avg:53.25% Training_loss_avg:0.693565\n",
            "Epoch:2 Step:1032 Training_loss:0.733015, Acc_avg:52.50% Training_loss_avg:0.694736\n",
            "Epoch:2 Step:1040 Training_loss:0.698353, Acc_avg:52.25% Training_loss_avg:0.695928\n",
            "Epoch:2 Step:1048 Training_loss:0.610090, Acc_avg:53.00% Training_loss_avg:0.694171\n",
            "Epoch:2 Step:1056 Training_loss:0.808439, Acc_avg:52.25% Training_loss_avg:0.697085\n",
            "Epoch:2 Step:1064 Training_loss:0.697467, Acc_avg:52.00% Training_loss_avg:0.698537\n",
            "Epoch:2 Step:1072 Training_loss:0.718301, Acc_avg:51.75% Training_loss_avg:0.699510\n",
            "Epoch:2 Step:1080 Training_loss:0.682180, Acc_avg:52.25% Training_loss_avg:0.699008\n",
            "Epoch:2 Step:1088 Training_loss:0.679503, Acc_avg:52.50% Training_loss_avg:0.698776\n",
            "Epoch:2 Step:1096 Training_loss:0.621520, Acc_avg:53.75% Training_loss_avg:0.694471\n",
            "Epoch:2 Step:1104 Training_loss:0.700416, Acc_avg:54.25% Training_loss_avg:0.693267\n",
            "Epoch:2 Step:1112 Training_loss:0.710155, Acc_avg:54.00% Training_loss_avg:0.694457\n",
            "Epoch:2 Step:1120 Training_loss:0.631557, Acc_avg:54.50% Training_loss_avg:0.693075\n",
            "Epoch:2 Step:1128 Training_loss:0.728179, Acc_avg:54.75% Training_loss_avg:0.691772\n",
            "Epoch:2 Step:1136 Training_loss:0.626371, Acc_avg:55.50% Training_loss_avg:0.689116\n",
            "Epoch:2 Step:1144 Training_loss:0.678421, Acc_avg:55.50% Training_loss_avg:0.689179\n",
            "Epoch:2 Step:1152 Training_loss:0.686782, Acc_avg:56.25% Training_loss_avg:0.688027\n",
            "Epoch:2 Step:1160 Training_loss:0.695359, Acc_avg:55.75% Training_loss_avg:0.688926\n",
            "Epoch:2 Step:1168 Training_loss:0.635975, Acc_avg:57.00% Training_loss_avg:0.686788\n",
            "Epoch:2 Step:1176 Training_loss:0.631442, Acc_avg:57.00% Training_loss_avg:0.686387\n",
            "Epoch:2 Step:1184 Training_loss:0.687575, Acc_avg:57.50% Training_loss_avg:0.685419\n",
            "Epoch:2 Step:1192 Training_loss:0.704204, Acc_avg:56.75% Training_loss_avg:0.686674\n",
            "Epoch:2 Step:1200 Training_loss:0.742449, Acc_avg:55.75% Training_loss_avg:0.688264\n",
            "Epoch:2 Step:1208 Training_loss:0.725653, Acc_avg:55.00% Training_loss_avg:0.689540\n",
            "Epoch:2 Step:1216 Training_loss:0.728430, Acc_avg:55.00% Training_loss_avg:0.689977\n",
            "Epoch:2 Step:1224 Training_loss:0.653497, Acc_avg:55.50% Training_loss_avg:0.688610\n",
            "Epoch:2 Step:1232 Training_loss:0.676707, Acc_avg:55.75% Training_loss_avg:0.688304\n",
            "Epoch:2 Step:1240 Training_loss:0.619616, Acc_avg:55.75% Training_loss_avg:0.687478\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:1240 Val_loss:0.689490, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:1248 Training_loss:0.673598, Acc_avg:56.25% Training_loss_avg:0.686737\n",
            "Epoch:2 Step:1256 Training_loss:0.791773, Acc_avg:56.25% Training_loss_avg:0.688467\n",
            "Epoch:2 Step:1264 Training_loss:0.746047, Acc_avg:55.50% Training_loss_avg:0.689358\n",
            "Epoch:2 Step:1272 Training_loss:0.672713, Acc_avg:56.25% Training_loss_avg:0.688309\n",
            "Epoch:2 Step:1280 Training_loss:0.705975, Acc_avg:55.50% Training_loss_avg:0.689209\n",
            "Epoch:2 Step:1288 Training_loss:0.675780, Acc_avg:56.25% Training_loss_avg:0.688361\n",
            "Epoch:2 Step:1296 Training_loss:0.690233, Acc_avg:56.00% Training_loss_avg:0.688705\n",
            "Epoch:2 Step:1304 Training_loss:0.641236, Acc_avg:56.50% Training_loss_avg:0.687886\n",
            "Epoch:2 Step:1312 Training_loss:0.704985, Acc_avg:56.00% Training_loss_avg:0.688365\n",
            "Epoch:2 Step:1320 Training_loss:0.665937, Acc_avg:56.00% Training_loss_avg:0.687833\n",
            "Epoch:2 Step:1328 Training_loss:0.742556, Acc_avg:55.75% Training_loss_avg:0.688893\n",
            "Epoch:2 Step:1336 Training_loss:0.677687, Acc_avg:55.50% Training_loss_avg:0.688984\n",
            "Epoch:2 Step:1344 Training_loss:0.716009, Acc_avg:55.25% Training_loss_avg:0.689308\n",
            "Epoch:2 Step:1352 Training_loss:0.638722, Acc_avg:55.25% Training_loss_avg:0.688646\n",
            "Epoch:2 Step:1360 Training_loss:0.703485, Acc_avg:55.25% Training_loss_avg:0.688927\n",
            "Epoch:2 Step:1368 Training_loss:0.672323, Acc_avg:55.00% Training_loss_avg:0.689079\n",
            "Epoch:2 Step:1376 Training_loss:0.716174, Acc_avg:55.25% Training_loss_avg:0.689427\n",
            "Epoch:2 Step:1384 Training_loss:0.703290, Acc_avg:55.00% Training_loss_avg:0.690194\n",
            "Epoch:2 Step:1392 Training_loss:0.677731, Acc_avg:54.50% Training_loss_avg:0.690353\n",
            "Epoch:2 Step:1400 Training_loss:0.736267, Acc_avg:53.75% Training_loss_avg:0.691622\n",
            "Epoch:2 Step:1408 Training_loss:0.684419, Acc_avg:54.25% Training_loss_avg:0.690978\n",
            "Epoch:2 Step:1416 Training_loss:0.754580, Acc_avg:54.00% Training_loss_avg:0.691815\n",
            "Epoch:2 Step:1424 Training_loss:0.645277, Acc_avg:54.25% Training_loss_avg:0.690969\n",
            "Epoch:2 Step:1432 Training_loss:0.663096, Acc_avg:55.25% Training_loss_avg:0.689571\n",
            "Epoch:2 Step:1440 Training_loss:0.683806, Acc_avg:55.25% Training_loss_avg:0.689280\n",
            "Epoch:2 Step:1448 Training_loss:0.675328, Acc_avg:54.75% Training_loss_avg:0.690585\n",
            "Epoch:2 Step:1456 Training_loss:0.672121, Acc_avg:55.75% Training_loss_avg:0.687858\n",
            "Epoch:2 Step:1464 Training_loss:0.681103, Acc_avg:55.75% Training_loss_avg:0.687531\n",
            "Epoch:2 Step:1472 Training_loss:0.731479, Acc_avg:55.75% Training_loss_avg:0.687794\n",
            "Epoch:2 Step:1480 Training_loss:0.745240, Acc_avg:55.00% Training_loss_avg:0.689056\n",
            "Epoch:2 Step:1488 Training_loss:0.700347, Acc_avg:55.00% Training_loss_avg:0.689473\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:1488 Val_loss:0.689631, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:1496 Training_loss:0.736560, Acc_avg:54.00% Training_loss_avg:0.691773\n",
            "Epoch:2 Step:1504 Training_loss:0.697538, Acc_avg:53.75% Training_loss_avg:0.691716\n",
            "Epoch:2 Step:1512 Training_loss:0.662046, Acc_avg:54.25% Training_loss_avg:0.690754\n",
            "Epoch:2 Step:1520 Training_loss:0.681868, Acc_avg:54.00% Training_loss_avg:0.691760\n",
            "Epoch:2 Step:1528 Training_loss:0.722854, Acc_avg:54.25% Training_loss_avg:0.691653\n",
            "Epoch:2 Step:1536 Training_loss:0.703241, Acc_avg:53.75% Training_loss_avg:0.693191\n",
            "Epoch:2 Step:1544 Training_loss:0.703219, Acc_avg:53.25% Training_loss_avg:0.693687\n",
            "Epoch:2 Step:1552 Training_loss:0.672051, Acc_avg:53.50% Training_loss_avg:0.693392\n",
            "Epoch:2 Step:1560 Training_loss:0.660132, Acc_avg:54.00% Training_loss_avg:0.692688\n",
            "Epoch:2 Step:1568 Training_loss:0.692823, Acc_avg:53.25% Training_loss_avg:0.693824\n",
            "Epoch:2 Step:1576 Training_loss:0.658759, Acc_avg:53.00% Training_loss_avg:0.694371\n",
            "Epoch:2 Step:1584 Training_loss:0.685709, Acc_avg:53.25% Training_loss_avg:0.694333\n",
            "Epoch:2 Step:1592 Training_loss:0.665693, Acc_avg:53.50% Training_loss_avg:0.693563\n",
            "Epoch:2 Step:1600 Training_loss:0.681754, Acc_avg:54.25% Training_loss_avg:0.692349\n",
            "Epoch:2 Step:1608 Training_loss:0.679601, Acc_avg:54.75% Training_loss_avg:0.691428\n",
            "Epoch:2 Step:1616 Training_loss:0.646291, Acc_avg:55.50% Training_loss_avg:0.689786\n",
            "Epoch:2 Step:1624 Training_loss:0.713259, Acc_avg:55.25% Training_loss_avg:0.690981\n",
            "Epoch:2 Step:1632 Training_loss:0.712111, Acc_avg:55.00% Training_loss_avg:0.691689\n",
            "Epoch:2 Step:1640 Training_loss:0.672731, Acc_avg:54.75% Training_loss_avg:0.692751\n",
            "Epoch:2 Step:1648 Training_loss:0.712919, Acc_avg:54.00% Training_loss_avg:0.693538\n",
            "Epoch:2 Step:1656 Training_loss:0.740193, Acc_avg:54.00% Training_loss_avg:0.692506\n",
            "Epoch:2 Step:1664 Training_loss:0.701054, Acc_avg:54.25% Training_loss_avg:0.691606\n",
            "Epoch:2 Step:1672 Training_loss:0.696597, Acc_avg:53.75% Training_loss_avg:0.692084\n",
            "Epoch:2 Step:1680 Training_loss:0.658550, Acc_avg:54.00% Training_loss_avg:0.691135\n",
            "Epoch:2 Step:1688 Training_loss:0.645667, Acc_avg:54.25% Training_loss_avg:0.690533\n",
            "Epoch:2 Step:1696 Training_loss:0.673430, Acc_avg:54.50% Training_loss_avg:0.690197\n",
            "Epoch:2 Step:1704 Training_loss:0.709125, Acc_avg:53.75% Training_loss_avg:0.691555\n",
            "Epoch:2 Step:1712 Training_loss:0.679848, Acc_avg:54.00% Training_loss_avg:0.691052\n",
            "Epoch:2 Step:1720 Training_loss:0.710748, Acc_avg:53.50% Training_loss_avg:0.691948\n",
            "Epoch:2 Step:1728 Training_loss:0.740441, Acc_avg:53.50% Training_loss_avg:0.691906\n",
            "Epoch:2 Step:1736 Training_loss:0.745287, Acc_avg:53.00% Training_loss_avg:0.693258\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:1736 Val_loss:0.689403, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:1744 Training_loss:0.763252, Acc_avg:53.00% Training_loss_avg:0.694203\n",
            "Epoch:2 Step:1752 Training_loss:0.678379, Acc_avg:52.50% Training_loss_avg:0.694996\n",
            "Epoch:2 Step:1760 Training_loss:0.678535, Acc_avg:52.75% Training_loss_avg:0.694497\n",
            "Epoch:2 Step:1768 Training_loss:0.686842, Acc_avg:52.75% Training_loss_avg:0.694787\n",
            "Epoch:2 Step:1776 Training_loss:0.702843, Acc_avg:52.50% Training_loss_avg:0.694521\n",
            "Epoch:2 Step:1784 Training_loss:0.697520, Acc_avg:52.50% Training_loss_avg:0.694405\n",
            "Epoch:2 Step:1792 Training_loss:0.665308, Acc_avg:53.00% Training_loss_avg:0.694157\n",
            "Epoch:2 Step:1800 Training_loss:0.678645, Acc_avg:53.75% Training_loss_avg:0.693004\n",
            "Epoch:2 Step:1808 Training_loss:0.678798, Acc_avg:54.00% Training_loss_avg:0.692892\n",
            "Epoch:2 Step:1816 Training_loss:0.668830, Acc_avg:54.75% Training_loss_avg:0.691177\n",
            "Epoch:2 Step:1824 Training_loss:0.719294, Acc_avg:54.00% Training_loss_avg:0.692657\n",
            "Epoch:2 Step:1832 Training_loss:0.691261, Acc_avg:53.75% Training_loss_avg:0.693221\n",
            "Epoch:2 Step:1840 Training_loss:0.670423, Acc_avg:54.00% Training_loss_avg:0.692953\n",
            "Epoch:2 Step:1848 Training_loss:0.710903, Acc_avg:53.50% Training_loss_avg:0.693664\n",
            "Epoch:2 Step:1856 Training_loss:0.684766, Acc_avg:53.25% Training_loss_avg:0.693917\n",
            "Epoch:2 Step:1864 Training_loss:0.722356, Acc_avg:52.25% Training_loss_avg:0.694742\n",
            "Epoch:2 Step:1872 Training_loss:0.675566, Acc_avg:52.75% Training_loss_avg:0.693624\n",
            "Epoch:2 Step:1880 Training_loss:0.667259, Acc_avg:53.50% Training_loss_avg:0.692064\n",
            "Epoch:2 Step:1888 Training_loss:0.694833, Acc_avg:53.25% Training_loss_avg:0.691954\n",
            "Epoch:2 Step:1896 Training_loss:0.694718, Acc_avg:53.50% Training_loss_avg:0.691117\n",
            "Epoch:2 Step:1904 Training_loss:0.657646, Acc_avg:54.25% Training_loss_avg:0.690320\n",
            "Epoch:2 Step:1912 Training_loss:0.679822, Acc_avg:53.75% Training_loss_avg:0.690675\n",
            "Epoch:2 Step:1920 Training_loss:0.685137, Acc_avg:53.75% Training_loss_avg:0.690740\n",
            "Epoch:2 Step:1928 Training_loss:0.704640, Acc_avg:54.00% Training_loss_avg:0.690376\n",
            "Epoch:2 Step:1936 Training_loss:0.697833, Acc_avg:54.00% Training_loss_avg:0.690268\n",
            "Epoch:2 Step:1944 Training_loss:0.680581, Acc_avg:54.25% Training_loss_avg:0.689815\n",
            "Epoch:2 Step:1952 Training_loss:0.694233, Acc_avg:53.50% Training_loss_avg:0.690259\n",
            "Epoch:2 Step:1960 Training_loss:0.624478, Acc_avg:53.50% Training_loss_avg:0.689546\n",
            "Epoch:2 Step:1968 Training_loss:0.687635, Acc_avg:53.75% Training_loss_avg:0.689442\n",
            "Epoch:2 Step:1976 Training_loss:0.676114, Acc_avg:53.75% Training_loss_avg:0.689789\n",
            "Epoch:2 Step:1984 Training_loss:0.711480, Acc_avg:53.25% Training_loss_avg:0.690305\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:1984 Val_loss:0.689585, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:1992 Training_loss:0.678926, Acc_avg:53.25% Training_loss_avg:0.690569\n",
            "Epoch:2 Step:2000 Training_loss:0.643779, Acc_avg:53.50% Training_loss_avg:0.689810\n",
            "Epoch:2 Step:2008 Training_loss:0.721654, Acc_avg:53.00% Training_loss_avg:0.690651\n",
            "Epoch:2 Step:2016 Training_loss:0.709974, Acc_avg:52.25% Training_loss_avg:0.691924\n",
            "Epoch:2 Step:2024 Training_loss:0.805743, Acc_avg:51.75% Training_loss_avg:0.693774\n",
            "Epoch:2 Step:2032 Training_loss:0.718684, Acc_avg:51.50% Training_loss_avg:0.693906\n",
            "Epoch:2 Step:2040 Training_loss:0.755998, Acc_avg:50.50% Training_loss_avg:0.695571\n",
            "Epoch:2 Step:2048 Training_loss:0.648976, Acc_avg:51.25% Training_loss_avg:0.694292\n",
            "Epoch:2 Step:2056 Training_loss:0.696129, Acc_avg:51.50% Training_loss_avg:0.693411\n",
            "Epoch:2 Step:2064 Training_loss:0.735199, Acc_avg:51.25% Training_loss_avg:0.694094\n",
            "Epoch:2 Step:2072 Training_loss:0.691939, Acc_avg:51.75% Training_loss_avg:0.694001\n",
            "Epoch:2 Step:2080 Training_loss:0.695225, Acc_avg:51.50% Training_loss_avg:0.694734\n",
            "Epoch:2 Step:2088 Training_loss:0.715243, Acc_avg:50.75% Training_loss_avg:0.696126\n",
            "Epoch:2 Step:2096 Training_loss:0.643144, Acc_avg:51.00% Training_loss_avg:0.695520\n",
            "Epoch:2 Step:2104 Training_loss:0.690430, Acc_avg:51.25% Training_loss_avg:0.695146\n",
            "Epoch:2 Step:2112 Training_loss:0.688890, Acc_avg:51.25% Training_loss_avg:0.695327\n",
            "Epoch:2 Step:2120 Training_loss:0.660952, Acc_avg:52.00% Training_loss_avg:0.694331\n",
            "Epoch:2 Step:2128 Training_loss:0.681965, Acc_avg:52.50% Training_loss_avg:0.693161\n",
            "Epoch:2 Step:2136 Training_loss:0.685155, Acc_avg:53.25% Training_loss_avg:0.691959\n",
            "Epoch:2 Step:2144 Training_loss:0.693179, Acc_avg:53.25% Training_loss_avg:0.690557\n",
            "Epoch:2 Step:2152 Training_loss:0.676090, Acc_avg:53.50% Training_loss_avg:0.690511\n",
            "Epoch:2 Step:2160 Training_loss:0.644605, Acc_avg:54.00% Training_loss_avg:0.689833\n",
            "Epoch:2 Step:2168 Training_loss:0.655373, Acc_avg:54.00% Training_loss_avg:0.689203\n",
            "Epoch:2 Step:2176 Training_loss:0.648757, Acc_avg:55.00% Training_loss_avg:0.688122\n",
            "Epoch:2 Step:2184 Training_loss:0.692856, Acc_avg:55.00% Training_loss_avg:0.688029\n",
            "Epoch:2 Step:2192 Training_loss:0.674261, Acc_avg:54.50% Training_loss_avg:0.688208\n",
            "Epoch:2 Step:2200 Training_loss:0.669755, Acc_avg:54.50% Training_loss_avg:0.688030\n",
            "Epoch:2 Step:2208 Training_loss:0.702052, Acc_avg:54.00% Training_loss_avg:0.688495\n",
            "Epoch:2 Step:2216 Training_loss:0.639121, Acc_avg:54.25% Training_loss_avg:0.687901\n",
            "Epoch:2 Step:2224 Training_loss:0.698309, Acc_avg:54.50% Training_loss_avg:0.687481\n",
            "Epoch:2 Step:2232 Training_loss:0.739061, Acc_avg:54.25% Training_loss_avg:0.688437\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2232 Val_loss:0.689861, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:2240 Training_loss:0.721870, Acc_avg:53.75% Training_loss_avg:0.689466\n",
            "Epoch:2 Step:2248 Training_loss:0.752506, Acc_avg:53.50% Training_loss_avg:0.690298\n",
            "Epoch:2 Step:2256 Training_loss:0.713031, Acc_avg:53.25% Training_loss_avg:0.690863\n",
            "Epoch:2 Step:2264 Training_loss:0.664873, Acc_avg:54.50% Training_loss_avg:0.689714\n",
            "Epoch:2 Step:2272 Training_loss:0.678905, Acc_avg:54.25% Training_loss_avg:0.689780\n",
            "Epoch:2 Step:2280 Training_loss:0.638072, Acc_avg:54.50% Training_loss_avg:0.689197\n",
            "Epoch:2 Step:2288 Training_loss:0.672786, Acc_avg:54.75% Training_loss_avg:0.688756\n",
            "Epoch:2 Step:2296 Training_loss:0.796936, Acc_avg:54.75% Training_loss_avg:0.690800\n",
            "Epoch:2 Step:2304 Training_loss:0.653636, Acc_avg:54.00% Training_loss_avg:0.690720\n",
            "Epoch:2 Step:2312 Training_loss:0.681118, Acc_avg:54.00% Training_loss_avg:0.690746\n",
            "Epoch:2 Step:2320 Training_loss:0.706693, Acc_avg:53.50% Training_loss_avg:0.691177\n",
            "Epoch:2 Step:2328 Training_loss:0.707685, Acc_avg:53.50% Training_loss_avg:0.691238\n",
            "Epoch:2 Step:2336 Training_loss:0.647823, Acc_avg:54.00% Training_loss_avg:0.690238\n",
            "Epoch:2 Step:2344 Training_loss:0.730045, Acc_avg:53.50% Training_loss_avg:0.691227\n",
            "Epoch:2 Step:2352 Training_loss:0.714647, Acc_avg:53.50% Training_loss_avg:0.691635\n",
            "Epoch:2 Step:2360 Training_loss:0.685994, Acc_avg:53.25% Training_loss_avg:0.692865\n",
            "Epoch:2 Step:2368 Training_loss:0.677361, Acc_avg:53.25% Training_loss_avg:0.692660\n",
            "Epoch:2 Step:2376 Training_loss:0.712554, Acc_avg:53.00% Training_loss_avg:0.693389\n",
            "Epoch:2 Step:2384 Training_loss:0.689894, Acc_avg:53.25% Training_loss_avg:0.692957\n",
            "Epoch:2 Step:2392 Training_loss:0.640462, Acc_avg:53.25% Training_loss_avg:0.692188\n",
            "Epoch:2 Step:2400 Training_loss:0.596283, Acc_avg:53.50% Training_loss_avg:0.691238\n",
            "Epoch:2 Step:2408 Training_loss:0.668957, Acc_avg:54.25% Training_loss_avg:0.690184\n",
            "Epoch:2 Step:2416 Training_loss:0.690524, Acc_avg:54.50% Training_loss_avg:0.689795\n",
            "Epoch:2 Step:2424 Training_loss:0.700302, Acc_avg:55.00% Training_loss_avg:0.687686\n",
            "Epoch:2 Step:2432 Training_loss:0.676653, Acc_avg:55.50% Training_loss_avg:0.686845\n",
            "Epoch:2 Step:2440 Training_loss:0.668774, Acc_avg:56.25% Training_loss_avg:0.685101\n",
            "Epoch:2 Step:2448 Training_loss:0.668552, Acc_avg:56.00% Training_loss_avg:0.685493\n",
            "Epoch:2 Step:2456 Training_loss:0.647442, Acc_avg:56.25% Training_loss_avg:0.684519\n",
            "Epoch:2 Step:2464 Training_loss:0.645732, Acc_avg:57.25% Training_loss_avg:0.682729\n",
            "Epoch:2 Step:2472 Training_loss:0.708655, Acc_avg:56.75% Training_loss_avg:0.683064\n",
            "Epoch:2 Step:2480 Training_loss:0.697229, Acc_avg:57.00% Training_loss_avg:0.683104\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2480 Val_loss:0.690607, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:2488 Training_loss:0.602675, Acc_avg:57.75% Training_loss_avg:0.680852\n",
            "Epoch:2 Step:2496 Training_loss:0.643989, Acc_avg:57.75% Training_loss_avg:0.680869\n",
            "Epoch:2 Step:2504 Training_loss:0.617912, Acc_avg:58.25% Training_loss_avg:0.679419\n",
            "Epoch:2 Step:2512 Training_loss:0.679738, Acc_avg:58.25% Training_loss_avg:0.679236\n",
            "Epoch:2 Step:2520 Training_loss:0.682435, Acc_avg:58.00% Training_loss_avg:0.679666\n",
            "Epoch:2 Step:2528 Training_loss:0.666259, Acc_avg:58.00% Training_loss_avg:0.679351\n",
            "Epoch:2 Step:2536 Training_loss:0.726110, Acc_avg:57.50% Training_loss_avg:0.680171\n",
            "Epoch:2 Step:2544 Training_loss:0.862691, Acc_avg:57.25% Training_loss_avg:0.683561\n",
            "Epoch:2 Step:2552 Training_loss:0.600403, Acc_avg:57.50% Training_loss_avg:0.682047\n",
            "Epoch:2 Step:2560 Training_loss:0.774638, Acc_avg:56.25% Training_loss_avg:0.684648\n",
            "Epoch:2 Step:2568 Training_loss:0.706463, Acc_avg:56.00% Training_loss_avg:0.685670\n",
            "Epoch:2 Step:2576 Training_loss:0.684329, Acc_avg:55.25% Training_loss_avg:0.686381\n",
            "Epoch:2 Step:2584 Training_loss:0.694892, Acc_avg:55.25% Training_loss_avg:0.686422\n",
            "Epoch:2 Step:2592 Training_loss:0.835004, Acc_avg:54.50% Training_loss_avg:0.689637\n",
            "Epoch:2 Step:2600 Training_loss:0.635769, Acc_avg:54.75% Training_loss_avg:0.688957\n",
            "Epoch:2 Step:2608 Training_loss:0.715993, Acc_avg:54.75% Training_loss_avg:0.689236\n",
            "Epoch:2 Step:2616 Training_loss:0.656781, Acc_avg:54.75% Training_loss_avg:0.689589\n",
            "Epoch:2 Step:2624 Training_loss:0.662445, Acc_avg:54.75% Training_loss_avg:0.688872\n",
            "Epoch:2 Step:2632 Training_loss:0.710412, Acc_avg:54.75% Training_loss_avg:0.688299\n",
            "Epoch:2 Step:2640 Training_loss:0.677467, Acc_avg:55.00% Training_loss_avg:0.687411\n",
            "Epoch:2 Step:2648 Training_loss:0.659207, Acc_avg:55.75% Training_loss_avg:0.685545\n",
            "Epoch:2 Step:2656 Training_loss:0.715178, Acc_avg:55.50% Training_loss_avg:0.685587\n",
            "Epoch:2 Step:2664 Training_loss:0.670257, Acc_avg:55.00% Training_loss_avg:0.685695\n",
            "Epoch:2 Step:2672 Training_loss:0.621042, Acc_avg:55.75% Training_loss_avg:0.684538\n",
            "Epoch:2 Step:2680 Training_loss:0.663948, Acc_avg:55.25% Training_loss_avg:0.685055\n",
            "Epoch:2 Step:2688 Training_loss:0.626436, Acc_avg:55.50% Training_loss_avg:0.684128\n",
            "Epoch:2 Step:2696 Training_loss:0.653578, Acc_avg:56.00% Training_loss_avg:0.681261\n",
            "Epoch:2 Step:2704 Training_loss:0.675661, Acc_avg:56.50% Training_loss_avg:0.681702\n",
            "Epoch:2 Step:2712 Training_loss:0.669688, Acc_avg:56.75% Training_loss_avg:0.681473\n",
            "Epoch:2 Step:2720 Training_loss:0.727704, Acc_avg:56.75% Training_loss_avg:0.681893\n",
            "Epoch:2 Step:2728 Training_loss:0.701724, Acc_avg:57.00% Training_loss_avg:0.681774\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2728 Val_loss:0.690016, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:2736 Training_loss:0.679814, Acc_avg:56.75% Training_loss_avg:0.682414\n",
            "Epoch:2 Step:2744 Training_loss:0.678105, Acc_avg:57.00% Training_loss_avg:0.681375\n",
            "Epoch:2 Step:2752 Training_loss:0.708332, Acc_avg:57.00% Training_loss_avg:0.681249\n",
            "Epoch:2 Step:2760 Training_loss:0.698713, Acc_avg:56.75% Training_loss_avg:0.681503\n",
            "Epoch:2 Step:2768 Training_loss:0.704549, Acc_avg:56.50% Training_loss_avg:0.682047\n",
            "Epoch:2 Step:2776 Training_loss:0.665801, Acc_avg:57.00% Training_loss_avg:0.681112\n",
            "Epoch:2 Step:2784 Training_loss:0.689097, Acc_avg:57.25% Training_loss_avg:0.681096\n",
            "Epoch:2 Step:2792 Training_loss:0.727955, Acc_avg:57.00% Training_loss_avg:0.682846\n",
            "Epoch:2 Step:2800 Training_loss:0.732436, Acc_avg:55.75% Training_loss_avg:0.685569\n",
            "Epoch:2 Step:2808 Training_loss:0.605215, Acc_avg:55.75% Training_loss_avg:0.684294\n",
            "Epoch:2 Step:2816 Training_loss:0.759926, Acc_avg:55.25% Training_loss_avg:0.685682\n",
            "Epoch:2 Step:2824 Training_loss:0.777713, Acc_avg:55.00% Training_loss_avg:0.687230\n",
            "Epoch:2 Step:2832 Training_loss:0.740713, Acc_avg:54.75% Training_loss_avg:0.688512\n",
            "Epoch:2 Step:2840 Training_loss:0.650073, Acc_avg:55.25% Training_loss_avg:0.688138\n",
            "Epoch:2 Step:2848 Training_loss:0.677754, Acc_avg:55.25% Training_loss_avg:0.688322\n",
            "Epoch:2 Step:2856 Training_loss:0.810805, Acc_avg:54.25% Training_loss_avg:0.691589\n",
            "Epoch:2 Step:2864 Training_loss:0.641466, Acc_avg:54.50% Training_loss_avg:0.691504\n",
            "Epoch:2 Step:2872 Training_loss:0.675112, Acc_avg:55.00% Training_loss_avg:0.690833\n",
            "Epoch:2 Step:2880 Training_loss:0.689064, Acc_avg:54.75% Training_loss_avg:0.690669\n",
            "Epoch:2 Step:2888 Training_loss:0.665604, Acc_avg:54.25% Training_loss_avg:0.691928\n",
            "Epoch:2 Step:2896 Training_loss:0.648917, Acc_avg:54.25% Training_loss_avg:0.692027\n",
            "Epoch:2 Step:2904 Training_loss:0.658201, Acc_avg:54.25% Training_loss_avg:0.692832\n",
            "Epoch:2 Step:2912 Training_loss:0.638202, Acc_avg:55.00% Training_loss_avg:0.692002\n",
            "Epoch:2 Step:2920 Training_loss:0.665957, Acc_avg:55.25% Training_loss_avg:0.691672\n",
            "Epoch:2 Step:2928 Training_loss:0.657577, Acc_avg:55.50% Training_loss_avg:0.691498\n",
            "Epoch:2 Step:2936 Training_loss:0.678482, Acc_avg:56.25% Training_loss_avg:0.690546\n",
            "Epoch:2 Step:2944 Training_loss:0.673266, Acc_avg:57.00% Training_loss_avg:0.686757\n",
            "Epoch:2 Step:2952 Training_loss:0.704023, Acc_avg:56.75% Training_loss_avg:0.688830\n",
            "Epoch:2 Step:2960 Training_loss:0.712987, Acc_avg:57.00% Training_loss_avg:0.687597\n",
            "Epoch:2 Step:2968 Training_loss:0.655427, Acc_avg:57.25% Training_loss_avg:0.686576\n",
            "Epoch:2 Step:2976 Training_loss:0.643006, Acc_avg:57.50% Training_loss_avg:0.685750\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:2976 Val_loss:0.690188, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:2984 Training_loss:0.564663, Acc_avg:58.50% Training_loss_avg:0.683145\n",
            "Epoch:2 Step:2992 Training_loss:0.756511, Acc_avg:58.75% Training_loss_avg:0.681575\n",
            "Epoch:2 Step:3000 Training_loss:0.637981, Acc_avg:58.75% Training_loss_avg:0.681619\n",
            "Epoch:2 Step:3008 Training_loss:0.740618, Acc_avg:58.75% Training_loss_avg:0.682112\n",
            "Epoch:2 Step:3016 Training_loss:0.735960, Acc_avg:58.00% Training_loss_avg:0.683695\n",
            "Epoch:2 Step:3024 Training_loss:0.664075, Acc_avg:58.25% Training_loss_avg:0.683728\n",
            "Epoch:2 Step:3032 Training_loss:0.675266, Acc_avg:58.50% Training_loss_avg:0.683025\n",
            "Epoch:2 Step:3040 Training_loss:0.696586, Acc_avg:58.50% Training_loss_avg:0.683408\n",
            "Epoch:2 Step:3048 Training_loss:0.684902, Acc_avg:58.50% Training_loss_avg:0.683921\n",
            "Epoch:2 Step:3056 Training_loss:0.714274, Acc_avg:59.00% Training_loss_avg:0.683903\n",
            "Epoch:2 Step:3064 Training_loss:0.761887, Acc_avg:58.75% Training_loss_avg:0.685736\n",
            "Epoch:2 Step:3072 Training_loss:0.659105, Acc_avg:58.25% Training_loss_avg:0.686497\n",
            "Epoch:2 Step:3080 Training_loss:0.804414, Acc_avg:57.75% Training_loss_avg:0.689306\n",
            "Epoch:2 Step:3088 Training_loss:0.685137, Acc_avg:57.25% Training_loss_avg:0.690481\n",
            "Epoch:2 Step:3096 Training_loss:0.604022, Acc_avg:57.25% Training_loss_avg:0.689489\n",
            "Epoch:2 Step:3104 Training_loss:0.681063, Acc_avg:57.25% Training_loss_avg:0.689597\n",
            "Epoch:2 Step:3112 Training_loss:0.668109, Acc_avg:57.25% Training_loss_avg:0.689566\n",
            "Epoch:2 Step:3120 Training_loss:0.718407, Acc_avg:57.25% Training_loss_avg:0.689380\n",
            "Epoch:2 Step:3128 Training_loss:0.686316, Acc_avg:57.00% Training_loss_avg:0.689072\n",
            "Epoch:2 Step:3136 Training_loss:0.725688, Acc_avg:56.75% Training_loss_avg:0.689989\n",
            "Epoch:2 Step:3144 Training_loss:0.707933, Acc_avg:56.75% Training_loss_avg:0.690586\n",
            "Epoch:2 Step:3152 Training_loss:0.679119, Acc_avg:57.25% Training_loss_avg:0.690001\n",
            "Epoch:2 Step:3160 Training_loss:0.704025, Acc_avg:57.50% Training_loss_avg:0.690108\n",
            "Epoch:2 Step:3168 Training_loss:0.716803, Acc_avg:57.25% Training_loss_avg:0.690353\n",
            "Epoch:2 Step:3176 Training_loss:0.700131, Acc_avg:56.75% Training_loss_avg:0.691039\n",
            "Epoch:2 Step:3184 Training_loss:0.681699, Acc_avg:56.50% Training_loss_avg:0.690891\n",
            "Epoch:2 Step:3192 Training_loss:0.635346, Acc_avg:57.00% Training_loss_avg:0.689039\n",
            "Epoch:2 Step:3200 Training_loss:0.647504, Acc_avg:58.25% Training_loss_avg:0.687341\n",
            "Epoch:2 Step:3208 Training_loss:0.685594, Acc_avg:58.00% Training_loss_avg:0.688948\n",
            "Epoch:2 Step:3216 Training_loss:0.667424, Acc_avg:58.75% Training_loss_avg:0.687098\n",
            "Epoch:2 Step:3224 Training_loss:0.627048, Acc_avg:59.50% Training_loss_avg:0.684085\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:2 Step:3224 Val_loss:0.689519, Val_Acc_avg:54.75%\n",
            "Epoch:2 Step:3232 Training_loss:0.705650, Acc_avg:59.50% Training_loss_avg:0.683384\n",
            "Epoch:2 Step:3240 Training_loss:0.660432, Acc_avg:59.00% Training_loss_avg:0.683591\n",
            "Epoch:2 Step:3248 Training_loss:0.700537, Acc_avg:58.75% Training_loss_avg:0.684046\n",
            "Epoch:2 Step:3256 Training_loss:0.696962, Acc_avg:59.50% Training_loss_avg:0.681770\n",
            "Epoch:2 Step:3264 Training_loss:0.728328, Acc_avg:58.50% Training_loss_avg:0.683507\n",
            "Epoch:2 Step:3272 Training_loss:0.667756, Acc_avg:58.50% Training_loss_avg:0.683360\n",
            "Epoch:2 Step:3280 Training_loss:0.691938, Acc_avg:58.50% Training_loss_avg:0.683417\n",
            "Epoch:2 Step:3288 Training_loss:0.658242, Acc_avg:58.75% Training_loss_avg:0.683270\n",
            "Epoch:2 Step:3296 Training_loss:0.719250, Acc_avg:58.00% Training_loss_avg:0.684677\n",
            "Epoch:2 Step:3304 Training_loss:0.703125, Acc_avg:57.50% Training_loss_avg:0.685575\n",
            "Epoch:2 Step:3312 Training_loss:0.688327, Acc_avg:57.00% Training_loss_avg:0.686578\n",
            "Epoch:2 Step:3320 Training_loss:0.743846, Acc_avg:56.25% Training_loss_avg:0.688135\n",
            "Epoch:2 Step:3328 Training_loss:0.735655, Acc_avg:55.42% Training_loss_avg:0.689697\n",
            "Epoch:3 Step:0 Training_loss:0.584273, Acc_avg:55.67% Training_loss_avg:0.687813\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:0 Val_loss:0.689552, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:8 Training_loss:0.630056, Acc_avg:55.92% Training_loss_avg:0.686949\n",
            "Epoch:3 Step:16 Training_loss:0.666231, Acc_avg:55.92% Training_loss_avg:0.686193\n",
            "Epoch:3 Step:24 Training_loss:0.729109, Acc_avg:55.92% Training_loss_avg:0.686515\n",
            "Epoch:3 Step:32 Training_loss:0.678267, Acc_avg:55.92% Training_loss_avg:0.686972\n",
            "Epoch:3 Step:40 Training_loss:0.650525, Acc_avg:55.92% Training_loss_avg:0.687122\n",
            "Epoch:3 Step:48 Training_loss:0.620574, Acc_avg:55.67% Training_loss_avg:0.688241\n",
            "Epoch:3 Step:56 Training_loss:0.596751, Acc_avg:56.92% Training_loss_avg:0.685045\n",
            "Epoch:3 Step:64 Training_loss:0.653019, Acc_avg:56.92% Training_loss_avg:0.685346\n",
            "Epoch:3 Step:72 Training_loss:0.764051, Acc_avg:56.42% Training_loss_avg:0.685815\n",
            "Epoch:3 Step:80 Training_loss:0.648366, Acc_avg:56.92% Training_loss_avg:0.684063\n",
            "Epoch:3 Step:88 Training_loss:0.649350, Acc_avg:57.17% Training_loss_avg:0.683768\n",
            "Epoch:3 Step:96 Training_loss:0.660269, Acc_avg:57.17% Training_loss_avg:0.683468\n",
            "Epoch:3 Step:104 Training_loss:0.646080, Acc_avg:57.42% Training_loss_avg:0.682458\n",
            "Epoch:3 Step:112 Training_loss:0.649409, Acc_avg:57.42% Training_loss_avg:0.681748\n",
            "Epoch:3 Step:120 Training_loss:0.572531, Acc_avg:57.67% Training_loss_avg:0.678914\n",
            "Epoch:3 Step:128 Training_loss:0.671586, Acc_avg:58.17% Training_loss_avg:0.677108\n",
            "Epoch:3 Step:136 Training_loss:0.750840, Acc_avg:57.67% Training_loss_avg:0.678942\n",
            "Epoch:3 Step:144 Training_loss:0.771724, Acc_avg:57.67% Training_loss_avg:0.678289\n",
            "Epoch:3 Step:152 Training_loss:0.719089, Acc_avg:57.42% Training_loss_avg:0.678968\n",
            "Epoch:3 Step:160 Training_loss:0.718057, Acc_avg:57.17% Training_loss_avg:0.681248\n",
            "Epoch:3 Step:168 Training_loss:0.820395, Acc_avg:56.42% Training_loss_avg:0.684035\n",
            "Epoch:3 Step:176 Training_loss:0.727237, Acc_avg:55.92% Training_loss_avg:0.685218\n",
            "Epoch:3 Step:184 Training_loss:0.569474, Acc_avg:56.92% Training_loss_avg:0.682239\n",
            "Epoch:3 Step:192 Training_loss:0.761551, Acc_avg:56.92% Training_loss_avg:0.683744\n",
            "Epoch:3 Step:200 Training_loss:0.689429, Acc_avg:56.92% Training_loss_avg:0.683018\n",
            "Epoch:3 Step:208 Training_loss:0.661157, Acc_avg:57.17% Training_loss_avg:0.682083\n",
            "Epoch:3 Step:216 Training_loss:0.663904, Acc_avg:57.42% Training_loss_avg:0.681779\n",
            "Epoch:3 Step:224 Training_loss:0.632992, Acc_avg:57.67% Training_loss_avg:0.680358\n",
            "Epoch:3 Step:232 Training_loss:0.719882, Acc_avg:58.17% Training_loss_avg:0.680419\n",
            "Epoch:3 Step:240 Training_loss:0.677598, Acc_avg:58.17% Training_loss_avg:0.679969\n",
            "Epoch:3 Step:248 Training_loss:0.657284, Acc_avg:58.42% Training_loss_avg:0.679481\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:248 Val_loss:0.690707, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:256 Training_loss:0.631342, Acc_avg:58.42% Training_loss_avg:0.679400\n",
            "Epoch:3 Step:264 Training_loss:0.686041, Acc_avg:58.17% Training_loss_avg:0.680171\n",
            "Epoch:3 Step:272 Training_loss:0.695883, Acc_avg:57.92% Training_loss_avg:0.680377\n",
            "Epoch:3 Step:280 Training_loss:0.733364, Acc_avg:57.67% Training_loss_avg:0.681696\n",
            "Epoch:3 Step:288 Training_loss:0.600312, Acc_avg:57.92% Training_loss_avg:0.681161\n",
            "Epoch:3 Step:296 Training_loss:0.694808, Acc_avg:58.17% Training_loss_avg:0.680944\n",
            "Epoch:3 Step:304 Training_loss:0.731956, Acc_avg:57.92% Training_loss_avg:0.682375\n",
            "Epoch:3 Step:312 Training_loss:0.720057, Acc_avg:57.92% Training_loss_avg:0.682765\n",
            "Epoch:3 Step:320 Training_loss:0.684570, Acc_avg:58.17% Training_loss_avg:0.682517\n",
            "Epoch:3 Step:328 Training_loss:0.725796, Acc_avg:58.17% Training_loss_avg:0.682467\n",
            "Epoch:3 Step:336 Training_loss:0.621472, Acc_avg:58.42% Training_loss_avg:0.681541\n",
            "Epoch:3 Step:344 Training_loss:0.654097, Acc_avg:58.67% Training_loss_avg:0.680784\n",
            "Epoch:3 Step:352 Training_loss:0.740078, Acc_avg:58.17% Training_loss_avg:0.682421\n",
            "Epoch:3 Step:360 Training_loss:0.658116, Acc_avg:58.67% Training_loss_avg:0.681198\n",
            "Epoch:3 Step:368 Training_loss:0.630448, Acc_avg:59.17% Training_loss_avg:0.679745\n",
            "Epoch:3 Step:376 Training_loss:0.760160, Acc_avg:58.67% Training_loss_avg:0.681181\n",
            "Epoch:3 Step:384 Training_loss:0.657453, Acc_avg:59.42% Training_loss_avg:0.679453\n",
            "Epoch:3 Step:392 Training_loss:0.676022, Acc_avg:60.00% Training_loss_avg:0.678261\n",
            "Epoch:3 Step:400 Training_loss:0.718204, Acc_avg:59.25% Training_loss_avg:0.680939\n",
            "Epoch:3 Step:408 Training_loss:0.675440, Acc_avg:58.75% Training_loss_avg:0.681847\n",
            "Epoch:3 Step:416 Training_loss:0.607958, Acc_avg:59.00% Training_loss_avg:0.680682\n",
            "Epoch:3 Step:424 Training_loss:0.619782, Acc_avg:59.50% Training_loss_avg:0.678495\n",
            "Epoch:3 Step:432 Training_loss:0.726023, Acc_avg:59.00% Training_loss_avg:0.679450\n",
            "Epoch:3 Step:440 Training_loss:0.730653, Acc_avg:58.50% Training_loss_avg:0.681053\n",
            "Epoch:3 Step:448 Training_loss:0.738833, Acc_avg:57.75% Training_loss_avg:0.683418\n",
            "Epoch:3 Step:456 Training_loss:0.710575, Acc_avg:57.00% Training_loss_avg:0.685694\n",
            "Epoch:3 Step:464 Training_loss:0.596294, Acc_avg:57.25% Training_loss_avg:0.684560\n",
            "Epoch:3 Step:472 Training_loss:0.678927, Acc_avg:57.75% Training_loss_avg:0.682857\n",
            "Epoch:3 Step:480 Training_loss:0.703115, Acc_avg:57.50% Training_loss_avg:0.683952\n",
            "Epoch:3 Step:488 Training_loss:0.612561, Acc_avg:57.75% Training_loss_avg:0.683217\n",
            "Epoch:3 Step:496 Training_loss:0.695147, Acc_avg:57.50% Training_loss_avg:0.683914\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:496 Val_loss:0.690611, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:504 Training_loss:0.703544, Acc_avg:57.00% Training_loss_avg:0.685063\n",
            "Epoch:3 Step:512 Training_loss:0.675074, Acc_avg:57.00% Training_loss_avg:0.685577\n",
            "Epoch:3 Step:520 Training_loss:0.736357, Acc_avg:56.25% Training_loss_avg:0.688853\n",
            "Epoch:3 Step:528 Training_loss:0.675740, Acc_avg:56.25% Training_loss_avg:0.688936\n",
            "Epoch:3 Step:536 Training_loss:0.656375, Acc_avg:56.75% Training_loss_avg:0.687047\n",
            "Epoch:3 Step:544 Training_loss:0.783999, Acc_avg:56.75% Training_loss_avg:0.687293\n",
            "Epoch:3 Step:552 Training_loss:0.759366, Acc_avg:56.50% Training_loss_avg:0.688098\n",
            "Epoch:3 Step:560 Training_loss:0.647639, Acc_avg:56.50% Training_loss_avg:0.686690\n",
            "Epoch:3 Step:568 Training_loss:0.728012, Acc_avg:56.75% Training_loss_avg:0.684842\n",
            "Epoch:3 Step:576 Training_loss:0.747568, Acc_avg:56.75% Training_loss_avg:0.685249\n",
            "Epoch:3 Step:584 Training_loss:0.678482, Acc_avg:56.25% Training_loss_avg:0.687429\n",
            "Epoch:3 Step:592 Training_loss:0.622756, Acc_avg:56.75% Training_loss_avg:0.684653\n",
            "Epoch:3 Step:600 Training_loss:0.652587, Acc_avg:57.25% Training_loss_avg:0.683916\n",
            "Epoch:3 Step:608 Training_loss:0.716056, Acc_avg:56.75% Training_loss_avg:0.685014\n",
            "Epoch:3 Step:616 Training_loss:0.678872, Acc_avg:56.50% Training_loss_avg:0.685313\n",
            "Epoch:3 Step:624 Training_loss:0.645827, Acc_avg:56.50% Training_loss_avg:0.685570\n",
            "Epoch:3 Step:632 Training_loss:0.672911, Acc_avg:56.50% Training_loss_avg:0.684631\n",
            "Epoch:3 Step:640 Training_loss:0.632109, Acc_avg:57.00% Training_loss_avg:0.683721\n",
            "Epoch:3 Step:648 Training_loss:0.649506, Acc_avg:57.25% Training_loss_avg:0.683565\n",
            "Epoch:3 Step:656 Training_loss:0.718011, Acc_avg:56.75% Training_loss_avg:0.685299\n",
            "Epoch:3 Step:664 Training_loss:0.680591, Acc_avg:56.50% Training_loss_avg:0.685190\n",
            "Epoch:3 Step:672 Training_loss:0.703598, Acc_avg:56.75% Training_loss_avg:0.685344\n",
            "Epoch:3 Step:680 Training_loss:0.671511, Acc_avg:57.00% Training_loss_avg:0.684107\n",
            "Epoch:3 Step:688 Training_loss:0.661983, Acc_avg:56.50% Training_loss_avg:0.685340\n",
            "Epoch:3 Step:696 Training_loss:0.719079, Acc_avg:56.00% Training_loss_avg:0.685826\n",
            "Epoch:3 Step:704 Training_loss:0.681370, Acc_avg:56.25% Training_loss_avg:0.684814\n",
            "Epoch:3 Step:712 Training_loss:0.701902, Acc_avg:56.25% Training_loss_avg:0.684451\n",
            "Epoch:3 Step:720 Training_loss:0.603779, Acc_avg:56.75% Training_loss_avg:0.682835\n",
            "Epoch:3 Step:728 Training_loss:0.660965, Acc_avg:57.25% Training_loss_avg:0.681539\n",
            "Epoch:3 Step:736 Training_loss:0.691417, Acc_avg:56.75% Training_loss_avg:0.682937\n",
            "Epoch:3 Step:744 Training_loss:0.614005, Acc_avg:57.00% Training_loss_avg:0.682136\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:744 Val_loss:0.690208, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:752 Training_loss:0.705785, Acc_avg:57.25% Training_loss_avg:0.681450\n",
            "Epoch:3 Step:760 Training_loss:0.652038, Acc_avg:57.25% Training_loss_avg:0.681328\n",
            "Epoch:3 Step:768 Training_loss:0.702028, Acc_avg:56.75% Training_loss_avg:0.682760\n",
            "Epoch:3 Step:776 Training_loss:0.667649, Acc_avg:57.50% Training_loss_avg:0.680910\n",
            "Epoch:3 Step:784 Training_loss:0.741895, Acc_avg:56.75% Training_loss_avg:0.682598\n",
            "Epoch:3 Step:792 Training_loss:0.695778, Acc_avg:56.50% Training_loss_avg:0.682994\n",
            "Epoch:3 Step:800 Training_loss:0.780334, Acc_avg:56.25% Training_loss_avg:0.684236\n",
            "Epoch:3 Step:808 Training_loss:0.782824, Acc_avg:56.00% Training_loss_avg:0.686384\n",
            "Epoch:3 Step:816 Training_loss:0.686676, Acc_avg:55.75% Training_loss_avg:0.687958\n",
            "Epoch:3 Step:824 Training_loss:0.728668, Acc_avg:55.25% Training_loss_avg:0.690136\n",
            "Epoch:3 Step:832 Training_loss:0.788150, Acc_avg:55.25% Training_loss_avg:0.691378\n",
            "Epoch:3 Step:840 Training_loss:0.754899, Acc_avg:55.00% Training_loss_avg:0.691863\n",
            "Epoch:3 Step:848 Training_loss:0.664037, Acc_avg:55.25% Training_loss_avg:0.690367\n",
            "Epoch:3 Step:856 Training_loss:0.631944, Acc_avg:55.75% Training_loss_avg:0.688795\n",
            "Epoch:3 Step:864 Training_loss:0.678781, Acc_avg:55.25% Training_loss_avg:0.690445\n",
            "Epoch:3 Step:872 Training_loss:0.703613, Acc_avg:55.25% Training_loss_avg:0.690938\n",
            "Epoch:3 Step:880 Training_loss:0.657588, Acc_avg:55.50% Training_loss_avg:0.690028\n",
            "Epoch:3 Step:888 Training_loss:0.699428, Acc_avg:54.75% Training_loss_avg:0.691765\n",
            "Epoch:3 Step:896 Training_loss:0.678151, Acc_avg:55.00% Training_loss_avg:0.691425\n",
            "Epoch:3 Step:904 Training_loss:0.675573, Acc_avg:55.50% Training_loss_avg:0.690866\n",
            "Epoch:3 Step:912 Training_loss:0.729103, Acc_avg:55.00% Training_loss_avg:0.691946\n",
            "Epoch:3 Step:920 Training_loss:0.701672, Acc_avg:55.25% Training_loss_avg:0.691253\n",
            "Epoch:3 Step:928 Training_loss:0.760667, Acc_avg:54.25% Training_loss_avg:0.692951\n",
            "Epoch:3 Step:936 Training_loss:0.673124, Acc_avg:54.25% Training_loss_avg:0.693286\n",
            "Epoch:3 Step:944 Training_loss:0.704375, Acc_avg:54.50% Training_loss_avg:0.691694\n",
            "Epoch:3 Step:952 Training_loss:0.707207, Acc_avg:54.75% Training_loss_avg:0.690650\n",
            "Epoch:3 Step:960 Training_loss:0.672540, Acc_avg:55.00% Training_loss_avg:0.691149\n",
            "Epoch:3 Step:968 Training_loss:0.685391, Acc_avg:55.75% Training_loss_avg:0.690296\n",
            "Epoch:3 Step:976 Training_loss:0.654325, Acc_avg:56.50% Training_loss_avg:0.688431\n",
            "Epoch:3 Step:984 Training_loss:0.687241, Acc_avg:56.50% Training_loss_avg:0.688606\n",
            "Epoch:3 Step:992 Training_loss:0.694001, Acc_avg:56.25% Training_loss_avg:0.690031\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:992 Val_loss:0.690358, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:1000 Training_loss:0.681985, Acc_avg:56.00% Training_loss_avg:0.690619\n",
            "Epoch:3 Step:1008 Training_loss:0.714140, Acc_avg:56.00% Training_loss_avg:0.690581\n",
            "Epoch:3 Step:1016 Training_loss:0.717940, Acc_avg:55.50% Training_loss_avg:0.691362\n",
            "Epoch:3 Step:1024 Training_loss:0.705739, Acc_avg:55.00% Training_loss_avg:0.692561\n",
            "Epoch:3 Step:1032 Training_loss:0.678238, Acc_avg:55.25% Training_loss_avg:0.692667\n",
            "Epoch:3 Step:1040 Training_loss:0.676944, Acc_avg:55.00% Training_loss_avg:0.693564\n",
            "Epoch:3 Step:1048 Training_loss:0.693688, Acc_avg:54.50% Training_loss_avg:0.694447\n",
            "Epoch:3 Step:1056 Training_loss:0.653011, Acc_avg:55.00% Training_loss_avg:0.693147\n",
            "Epoch:3 Step:1064 Training_loss:0.682540, Acc_avg:55.00% Training_loss_avg:0.693186\n",
            "Epoch:3 Step:1072 Training_loss:0.686363, Acc_avg:55.25% Training_loss_avg:0.692842\n",
            "Epoch:3 Step:1080 Training_loss:0.703503, Acc_avg:54.75% Training_loss_avg:0.693482\n",
            "Epoch:3 Step:1088 Training_loss:0.718264, Acc_avg:54.00% Training_loss_avg:0.694607\n",
            "Epoch:3 Step:1096 Training_loss:0.681300, Acc_avg:54.75% Training_loss_avg:0.693852\n",
            "Epoch:3 Step:1104 Training_loss:0.669078, Acc_avg:55.25% Training_loss_avg:0.693606\n",
            "Epoch:3 Step:1112 Training_loss:0.720955, Acc_avg:54.75% Training_loss_avg:0.693987\n",
            "Epoch:3 Step:1120 Training_loss:0.663205, Acc_avg:54.50% Training_loss_avg:0.695175\n",
            "Epoch:3 Step:1128 Training_loss:0.713139, Acc_avg:54.25% Training_loss_avg:0.696219\n",
            "Epoch:3 Step:1136 Training_loss:0.653048, Acc_avg:55.00% Training_loss_avg:0.695451\n",
            "Epoch:3 Step:1144 Training_loss:0.729413, Acc_avg:54.00% Training_loss_avg:0.697760\n",
            "Epoch:3 Step:1152 Training_loss:0.720022, Acc_avg:54.00% Training_loss_avg:0.698044\n",
            "Epoch:3 Step:1160 Training_loss:0.660934, Acc_avg:54.25% Training_loss_avg:0.698222\n",
            "Epoch:3 Step:1168 Training_loss:0.653646, Acc_avg:54.75% Training_loss_avg:0.697255\n",
            "Epoch:3 Step:1176 Training_loss:0.674702, Acc_avg:54.50% Training_loss_avg:0.697396\n",
            "Epoch:3 Step:1184 Training_loss:0.714862, Acc_avg:54.50% Training_loss_avg:0.696855\n",
            "Epoch:3 Step:1192 Training_loss:0.639667, Acc_avg:55.00% Training_loss_avg:0.695733\n",
            "Epoch:3 Step:1200 Training_loss:0.794053, Acc_avg:54.50% Training_loss_avg:0.696007\n",
            "Epoch:3 Step:1208 Training_loss:0.662794, Acc_avg:55.00% Training_loss_avg:0.693607\n",
            "Epoch:3 Step:1216 Training_loss:0.676319, Acc_avg:55.00% Training_loss_avg:0.693399\n",
            "Epoch:3 Step:1224 Training_loss:0.635536, Acc_avg:55.75% Training_loss_avg:0.691537\n",
            "Epoch:3 Step:1232 Training_loss:0.672803, Acc_avg:56.25% Training_loss_avg:0.689230\n",
            "Epoch:3 Step:1240 Training_loss:0.688667, Acc_avg:56.50% Training_loss_avg:0.687905\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:1240 Val_loss:0.689660, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:1248 Training_loss:0.652982, Acc_avg:56.75% Training_loss_avg:0.687684\n",
            "Epoch:3 Step:1256 Training_loss:0.693119, Acc_avg:56.25% Training_loss_avg:0.688908\n",
            "Epoch:3 Step:1264 Training_loss:0.753968, Acc_avg:55.50% Training_loss_avg:0.690411\n",
            "Epoch:3 Step:1272 Training_loss:0.776992, Acc_avg:55.25% Training_loss_avg:0.691879\n",
            "Epoch:3 Step:1280 Training_loss:0.740736, Acc_avg:54.50% Training_loss_avg:0.693542\n",
            "Epoch:3 Step:1288 Training_loss:0.616984, Acc_avg:55.00% Training_loss_avg:0.691893\n",
            "Epoch:3 Step:1296 Training_loss:0.719599, Acc_avg:54.50% Training_loss_avg:0.692722\n",
            "Epoch:3 Step:1304 Training_loss:0.693692, Acc_avg:54.25% Training_loss_avg:0.693084\n",
            "Epoch:3 Step:1312 Training_loss:0.702029, Acc_avg:54.50% Training_loss_avg:0.692543\n",
            "Epoch:3 Step:1320 Training_loss:0.672356, Acc_avg:54.75% Training_loss_avg:0.691957\n",
            "Epoch:3 Step:1328 Training_loss:0.703767, Acc_avg:55.25% Training_loss_avg:0.690819\n",
            "Epoch:3 Step:1336 Training_loss:0.701131, Acc_avg:55.00% Training_loss_avg:0.691379\n",
            "Epoch:3 Step:1344 Training_loss:0.667420, Acc_avg:55.50% Training_loss_avg:0.690640\n",
            "Epoch:3 Step:1352 Training_loss:0.635366, Acc_avg:56.25% Training_loss_avg:0.689203\n",
            "Epoch:3 Step:1360 Training_loss:0.670185, Acc_avg:56.00% Training_loss_avg:0.689156\n",
            "Epoch:3 Step:1368 Training_loss:0.705015, Acc_avg:55.25% Training_loss_avg:0.689548\n",
            "Epoch:3 Step:1376 Training_loss:0.725371, Acc_avg:54.25% Training_loss_avg:0.690969\n",
            "Epoch:3 Step:1384 Training_loss:0.718185, Acc_avg:53.75% Training_loss_avg:0.691588\n",
            "Epoch:3 Step:1392 Training_loss:0.653612, Acc_avg:54.00% Training_loss_avg:0.690780\n",
            "Epoch:3 Step:1400 Training_loss:0.674605, Acc_avg:54.00% Training_loss_avg:0.690633\n",
            "Epoch:3 Step:1408 Training_loss:0.736671, Acc_avg:54.00% Training_loss_avg:0.691083\n",
            "Epoch:3 Step:1416 Training_loss:0.720943, Acc_avg:54.25% Training_loss_avg:0.691143\n",
            "Epoch:3 Step:1424 Training_loss:0.680342, Acc_avg:54.50% Training_loss_avg:0.690635\n",
            "Epoch:3 Step:1432 Training_loss:0.661963, Acc_avg:54.25% Training_loss_avg:0.690310\n",
            "Epoch:3 Step:1440 Training_loss:0.661268, Acc_avg:54.25% Training_loss_avg:0.689996\n",
            "Epoch:3 Step:1448 Training_loss:0.670405, Acc_avg:54.50% Training_loss_avg:0.689531\n",
            "Epoch:3 Step:1456 Training_loss:0.667066, Acc_avg:54.25% Training_loss_avg:0.689812\n",
            "Epoch:3 Step:1464 Training_loss:0.664814, Acc_avg:54.25% Training_loss_avg:0.689457\n",
            "Epoch:3 Step:1472 Training_loss:0.676635, Acc_avg:54.00% Training_loss_avg:0.689263\n",
            "Epoch:3 Step:1480 Training_loss:0.639392, Acc_avg:55.00% Training_loss_avg:0.687980\n",
            "Epoch:3 Step:1488 Training_loss:0.680001, Acc_avg:56.00% Training_loss_avg:0.687215\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:1488 Val_loss:0.689428, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:1496 Training_loss:0.615730, Acc_avg:56.25% Training_loss_avg:0.685904\n",
            "Epoch:3 Step:1504 Training_loss:0.678934, Acc_avg:55.75% Training_loss_avg:0.686101\n",
            "Epoch:3 Step:1512 Training_loss:0.689451, Acc_avg:56.25% Training_loss_avg:0.685471\n",
            "Epoch:3 Step:1520 Training_loss:0.708400, Acc_avg:56.00% Training_loss_avg:0.686375\n",
            "Epoch:3 Step:1528 Training_loss:0.673559, Acc_avg:56.25% Training_loss_avg:0.685583\n",
            "Epoch:3 Step:1536 Training_loss:0.696994, Acc_avg:55.50% Training_loss_avg:0.686462\n",
            "Epoch:3 Step:1544 Training_loss:0.687424, Acc_avg:56.00% Training_loss_avg:0.685622\n",
            "Epoch:3 Step:1552 Training_loss:0.626591, Acc_avg:56.25% Training_loss_avg:0.683754\n",
            "Epoch:3 Step:1560 Training_loss:0.696475, Acc_avg:55.75% Training_loss_avg:0.684464\n",
            "Epoch:3 Step:1568 Training_loss:0.656836, Acc_avg:55.50% Training_loss_avg:0.684528\n",
            "Epoch:3 Step:1576 Training_loss:0.710750, Acc_avg:55.25% Training_loss_avg:0.685249\n",
            "Epoch:3 Step:1584 Training_loss:0.731735, Acc_avg:55.25% Training_loss_avg:0.685587\n",
            "Epoch:3 Step:1592 Training_loss:0.701671, Acc_avg:54.75% Training_loss_avg:0.686827\n",
            "Epoch:3 Step:1600 Training_loss:0.739757, Acc_avg:55.25% Training_loss_avg:0.685741\n",
            "Epoch:3 Step:1608 Training_loss:0.700351, Acc_avg:55.00% Training_loss_avg:0.686492\n",
            "Epoch:3 Step:1616 Training_loss:0.679498, Acc_avg:54.75% Training_loss_avg:0.686556\n",
            "Epoch:3 Step:1624 Training_loss:0.669239, Acc_avg:54.50% Training_loss_avg:0.687230\n",
            "Epoch:3 Step:1632 Training_loss:0.677126, Acc_avg:54.25% Training_loss_avg:0.687316\n",
            "Epoch:3 Step:1640 Training_loss:0.672720, Acc_avg:54.75% Training_loss_avg:0.686997\n",
            "Epoch:3 Step:1648 Training_loss:0.674664, Acc_avg:54.50% Training_loss_avg:0.687431\n",
            "Epoch:3 Step:1656 Training_loss:0.675480, Acc_avg:54.50% Training_loss_avg:0.687078\n",
            "Epoch:3 Step:1664 Training_loss:0.615331, Acc_avg:55.50% Training_loss_avg:0.684305\n",
            "Epoch:3 Step:1672 Training_loss:0.604072, Acc_avg:56.50% Training_loss_avg:0.680847\n",
            "Epoch:3 Step:1680 Training_loss:0.705439, Acc_avg:57.00% Training_loss_avg:0.680141\n",
            "Epoch:3 Step:1688 Training_loss:0.813478, Acc_avg:56.00% Training_loss_avg:0.684071\n",
            "Epoch:3 Step:1696 Training_loss:0.712501, Acc_avg:56.50% Training_loss_avg:0.683929\n",
            "Epoch:3 Step:1704 Training_loss:0.580604, Acc_avg:57.25% Training_loss_avg:0.681667\n",
            "Epoch:3 Step:1712 Training_loss:0.661306, Acc_avg:57.50% Training_loss_avg:0.680853\n",
            "Epoch:3 Step:1720 Training_loss:0.704682, Acc_avg:57.00% Training_loss_avg:0.681499\n",
            "Epoch:3 Step:1728 Training_loss:0.836461, Acc_avg:56.50% Training_loss_avg:0.684153\n",
            "Epoch:3 Step:1736 Training_loss:0.781344, Acc_avg:56.50% Training_loss_avg:0.685757\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:1736 Val_loss:0.690490, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:1744 Training_loss:0.691545, Acc_avg:56.25% Training_loss_avg:0.686240\n",
            "Epoch:3 Step:1752 Training_loss:0.719655, Acc_avg:55.75% Training_loss_avg:0.687926\n",
            "Epoch:3 Step:1760 Training_loss:0.671464, Acc_avg:55.75% Training_loss_avg:0.687951\n",
            "Epoch:3 Step:1768 Training_loss:0.674624, Acc_avg:56.25% Training_loss_avg:0.687343\n",
            "Epoch:3 Step:1776 Training_loss:0.645742, Acc_avg:57.25% Training_loss_avg:0.685751\n",
            "Epoch:3 Step:1784 Training_loss:0.695296, Acc_avg:57.50% Training_loss_avg:0.685293\n",
            "Epoch:3 Step:1792 Training_loss:0.685401, Acc_avg:57.50% Training_loss_avg:0.685929\n",
            "Epoch:3 Step:1800 Training_loss:0.743634, Acc_avg:57.00% Training_loss_avg:0.687309\n",
            "Epoch:3 Step:1808 Training_loss:0.722251, Acc_avg:57.00% Training_loss_avg:0.687021\n",
            "Epoch:3 Step:1816 Training_loss:0.700707, Acc_avg:57.00% Training_loss_avg:0.686616\n",
            "Epoch:3 Step:1824 Training_loss:0.618289, Acc_avg:57.25% Training_loss_avg:0.685375\n",
            "Epoch:3 Step:1832 Training_loss:0.720127, Acc_avg:56.75% Training_loss_avg:0.686538\n",
            "Epoch:3 Step:1840 Training_loss:0.662592, Acc_avg:56.75% Training_loss_avg:0.686565\n",
            "Epoch:3 Step:1848 Training_loss:0.721124, Acc_avg:56.75% Training_loss_avg:0.687579\n",
            "Epoch:3 Step:1856 Training_loss:0.722439, Acc_avg:56.25% Training_loss_avg:0.688687\n",
            "Epoch:3 Step:1864 Training_loss:0.644111, Acc_avg:56.50% Training_loss_avg:0.688273\n",
            "Epoch:3 Step:1872 Training_loss:0.673720, Acc_avg:56.50% Training_loss_avg:0.688214\n",
            "Epoch:3 Step:1880 Training_loss:0.716984, Acc_avg:55.50% Training_loss_avg:0.689766\n",
            "Epoch:3 Step:1888 Training_loss:0.655864, Acc_avg:55.25% Training_loss_avg:0.689283\n",
            "Epoch:3 Step:1896 Training_loss:0.659418, Acc_avg:55.00% Training_loss_avg:0.690157\n",
            "Epoch:3 Step:1904 Training_loss:0.719408, Acc_avg:55.00% Training_loss_avg:0.690967\n",
            "Epoch:3 Step:1912 Training_loss:0.639932, Acc_avg:55.50% Training_loss_avg:0.689976\n",
            "Epoch:3 Step:1920 Training_loss:0.696055, Acc_avg:55.25% Training_loss_avg:0.689729\n",
            "Epoch:3 Step:1928 Training_loss:0.651990, Acc_avg:55.50% Training_loss_avg:0.689298\n",
            "Epoch:3 Step:1936 Training_loss:0.689751, Acc_avg:55.75% Training_loss_avg:0.689153\n",
            "Epoch:3 Step:1944 Training_loss:0.760494, Acc_avg:55.50% Training_loss_avg:0.690615\n",
            "Epoch:3 Step:1952 Training_loss:0.704047, Acc_avg:55.25% Training_loss_avg:0.692164\n",
            "Epoch:3 Step:1960 Training_loss:0.651404, Acc_avg:55.75% Training_loss_avg:0.691262\n",
            "Epoch:3 Step:1968 Training_loss:0.676710, Acc_avg:55.75% Training_loss_avg:0.691660\n",
            "Epoch:3 Step:1976 Training_loss:0.748432, Acc_avg:55.25% Training_loss_avg:0.692413\n",
            "Epoch:3 Step:1984 Training_loss:0.693346, Acc_avg:55.75% Training_loss_avg:0.691646\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:1984 Val_loss:0.689411, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:1992 Training_loss:0.697811, Acc_avg:55.75% Training_loss_avg:0.691568\n",
            "Epoch:3 Step:2000 Training_loss:0.676403, Acc_avg:56.25% Training_loss_avg:0.690301\n",
            "Epoch:3 Step:2008 Training_loss:0.667353, Acc_avg:56.50% Training_loss_avg:0.689641\n",
            "Epoch:3 Step:2016 Training_loss:0.730906, Acc_avg:56.25% Training_loss_avg:0.690670\n",
            "Epoch:3 Step:2024 Training_loss:0.771875, Acc_avg:55.25% Training_loss_avg:0.692722\n",
            "Epoch:3 Step:2032 Training_loss:0.708916, Acc_avg:55.00% Training_loss_avg:0.693358\n",
            "Epoch:3 Step:2040 Training_loss:0.669642, Acc_avg:55.00% Training_loss_avg:0.693296\n",
            "Epoch:3 Step:2048 Training_loss:0.678858, Acc_avg:55.00% Training_loss_avg:0.693380\n",
            "Epoch:3 Step:2056 Training_loss:0.675016, Acc_avg:55.25% Training_loss_avg:0.693371\n",
            "Epoch:3 Step:2064 Training_loss:0.672982, Acc_avg:55.25% Training_loss_avg:0.694524\n",
            "Epoch:3 Step:2072 Training_loss:0.693419, Acc_avg:54.50% Training_loss_avg:0.696311\n",
            "Epoch:3 Step:2080 Training_loss:0.704439, Acc_avg:54.25% Training_loss_avg:0.696291\n",
            "Epoch:3 Step:2088 Training_loss:0.700504, Acc_avg:55.00% Training_loss_avg:0.694032\n",
            "Epoch:3 Step:2096 Training_loss:0.641562, Acc_avg:55.25% Training_loss_avg:0.692613\n",
            "Epoch:3 Step:2104 Training_loss:0.713284, Acc_avg:54.25% Training_loss_avg:0.695266\n",
            "Epoch:3 Step:2112 Training_loss:0.672899, Acc_avg:54.25% Training_loss_avg:0.695498\n",
            "Epoch:3 Step:2120 Training_loss:0.650612, Acc_avg:55.25% Training_loss_avg:0.694417\n",
            "Epoch:3 Step:2128 Training_loss:0.647364, Acc_avg:56.75% Training_loss_avg:0.690635\n",
            "Epoch:3 Step:2136 Training_loss:0.703878, Acc_avg:56.75% Training_loss_avg:0.689086\n",
            "Epoch:3 Step:2144 Training_loss:0.669105, Acc_avg:57.00% Training_loss_avg:0.688637\n",
            "Epoch:3 Step:2152 Training_loss:0.711091, Acc_avg:56.75% Training_loss_avg:0.688465\n",
            "Epoch:3 Step:2160 Training_loss:0.775710, Acc_avg:55.75% Training_loss_avg:0.690550\n",
            "Epoch:3 Step:2168 Training_loss:0.731813, Acc_avg:55.25% Training_loss_avg:0.691694\n",
            "Epoch:3 Step:2176 Training_loss:0.682039, Acc_avg:55.00% Training_loss_avg:0.692420\n",
            "Epoch:3 Step:2184 Training_loss:0.693047, Acc_avg:55.25% Training_loss_avg:0.692375\n",
            "Epoch:3 Step:2192 Training_loss:0.667830, Acc_avg:55.00% Training_loss_avg:0.692024\n",
            "Epoch:3 Step:2200 Training_loss:0.683173, Acc_avg:55.50% Training_loss_avg:0.690814\n",
            "Epoch:3 Step:2208 Training_loss:0.647457, Acc_avg:56.50% Training_loss_avg:0.689319\n",
            "Epoch:3 Step:2216 Training_loss:0.695860, Acc_avg:56.50% Training_loss_avg:0.689222\n",
            "Epoch:3 Step:2224 Training_loss:0.708748, Acc_avg:56.00% Training_loss_avg:0.691031\n",
            "Epoch:3 Step:2232 Training_loss:0.727213, Acc_avg:55.75% Training_loss_avg:0.691173\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:2232 Val_loss:0.689412, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:2240 Training_loss:0.678548, Acc_avg:55.50% Training_loss_avg:0.691492\n",
            "Epoch:3 Step:2248 Training_loss:0.692757, Acc_avg:55.25% Training_loss_avg:0.690924\n",
            "Epoch:3 Step:2256 Training_loss:0.730642, Acc_avg:55.25% Training_loss_avg:0.691088\n",
            "Epoch:3 Step:2264 Training_loss:0.705993, Acc_avg:54.75% Training_loss_avg:0.692326\n",
            "Epoch:3 Step:2272 Training_loss:0.680440, Acc_avg:54.75% Training_loss_avg:0.692460\n",
            "Epoch:3 Step:2280 Training_loss:0.719911, Acc_avg:54.75% Training_loss_avg:0.692519\n",
            "Epoch:3 Step:2288 Training_loss:0.686763, Acc_avg:54.50% Training_loss_avg:0.693137\n",
            "Epoch:3 Step:2296 Training_loss:0.688715, Acc_avg:54.00% Training_loss_avg:0.693723\n",
            "Epoch:3 Step:2304 Training_loss:0.701177, Acc_avg:53.75% Training_loss_avg:0.693358\n",
            "Epoch:3 Step:2312 Training_loss:0.729655, Acc_avg:52.75% Training_loss_avg:0.695153\n",
            "Epoch:3 Step:2320 Training_loss:0.674218, Acc_avg:53.25% Training_loss_avg:0.694716\n",
            "Epoch:3 Step:2328 Training_loss:0.685112, Acc_avg:52.75% Training_loss_avg:0.695378\n",
            "Epoch:3 Step:2336 Training_loss:0.687640, Acc_avg:52.50% Training_loss_avg:0.695336\n",
            "Epoch:3 Step:2344 Training_loss:0.682560, Acc_avg:53.00% Training_loss_avg:0.693778\n",
            "Epoch:3 Step:2352 Training_loss:0.685803, Acc_avg:53.00% Training_loss_avg:0.693413\n",
            "Epoch:3 Step:2360 Training_loss:0.670685, Acc_avg:53.25% Training_loss_avg:0.693798\n",
            "Epoch:3 Step:2368 Training_loss:0.680064, Acc_avg:53.25% Training_loss_avg:0.693865\n",
            "Epoch:3 Step:2376 Training_loss:0.698430, Acc_avg:54.00% Training_loss_avg:0.692865\n",
            "Epoch:3 Step:2384 Training_loss:0.691839, Acc_avg:53.75% Training_loss_avg:0.692835\n",
            "Epoch:3 Step:2392 Training_loss:0.685650, Acc_avg:54.00% Training_loss_avg:0.692592\n",
            "Epoch:3 Step:2400 Training_loss:0.669464, Acc_avg:54.25% Training_loss_avg:0.692453\n",
            "Epoch:3 Step:2408 Training_loss:0.684423, Acc_avg:54.25% Training_loss_avg:0.692795\n",
            "Epoch:3 Step:2416 Training_loss:0.720448, Acc_avg:54.00% Training_loss_avg:0.692585\n",
            "Epoch:3 Step:2424 Training_loss:0.678055, Acc_avg:55.00% Training_loss_avg:0.690709\n",
            "Epoch:3 Step:2432 Training_loss:0.727036, Acc_avg:54.75% Training_loss_avg:0.691071\n",
            "Epoch:3 Step:2440 Training_loss:0.711625, Acc_avg:54.25% Training_loss_avg:0.691911\n",
            "Epoch:3 Step:2448 Training_loss:0.654871, Acc_avg:54.50% Training_loss_avg:0.691431\n",
            "Epoch:3 Step:2456 Training_loss:0.701833, Acc_avg:54.25% Training_loss_avg:0.691968\n",
            "Epoch:3 Step:2464 Training_loss:0.726232, Acc_avg:53.50% Training_loss_avg:0.693033\n",
            "Epoch:3 Step:2472 Training_loss:0.686234, Acc_avg:53.50% Training_loss_avg:0.692889\n",
            "Epoch:3 Step:2480 Training_loss:0.683114, Acc_avg:54.00% Training_loss_avg:0.692462\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:2480 Val_loss:0.689687, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:2488 Training_loss:0.692510, Acc_avg:54.00% Training_loss_avg:0.692303\n",
            "Epoch:3 Step:2496 Training_loss:0.703476, Acc_avg:53.50% Training_loss_avg:0.693541\n",
            "Epoch:3 Step:2504 Training_loss:0.690886, Acc_avg:53.75% Training_loss_avg:0.693093\n",
            "Epoch:3 Step:2512 Training_loss:0.657431, Acc_avg:54.25% Training_loss_avg:0.692784\n",
            "Epoch:3 Step:2520 Training_loss:0.706846, Acc_avg:53.50% Training_loss_avg:0.693908\n",
            "Epoch:3 Step:2528 Training_loss:0.651580, Acc_avg:53.25% Training_loss_avg:0.693993\n",
            "Epoch:3 Step:2536 Training_loss:0.665082, Acc_avg:53.75% Training_loss_avg:0.693217\n",
            "Epoch:3 Step:2544 Training_loss:0.675792, Acc_avg:53.75% Training_loss_avg:0.693350\n",
            "Epoch:3 Step:2552 Training_loss:0.642785, Acc_avg:54.50% Training_loss_avg:0.691984\n",
            "Epoch:3 Step:2560 Training_loss:0.706830, Acc_avg:55.25% Training_loss_avg:0.690607\n",
            "Epoch:3 Step:2568 Training_loss:0.675937, Acc_avg:55.75% Training_loss_avg:0.689489\n",
            "Epoch:3 Step:2576 Training_loss:0.648314, Acc_avg:56.00% Training_loss_avg:0.688815\n",
            "Epoch:3 Step:2584 Training_loss:0.697819, Acc_avg:55.75% Training_loss_avg:0.688910\n",
            "Epoch:3 Step:2592 Training_loss:0.715209, Acc_avg:55.25% Training_loss_avg:0.689858\n",
            "Epoch:3 Step:2600 Training_loss:0.759464, Acc_avg:54.50% Training_loss_avg:0.691384\n",
            "Epoch:3 Step:2608 Training_loss:0.703439, Acc_avg:53.75% Training_loss_avg:0.692503\n",
            "Epoch:3 Step:2616 Training_loss:0.716012, Acc_avg:53.75% Training_loss_avg:0.692906\n",
            "Epoch:3 Step:2624 Training_loss:0.693277, Acc_avg:53.75% Training_loss_avg:0.692597\n",
            "Epoch:3 Step:2632 Training_loss:0.735676, Acc_avg:54.00% Training_loss_avg:0.692766\n",
            "Epoch:3 Step:2640 Training_loss:0.722605, Acc_avg:53.75% Training_loss_avg:0.693647\n",
            "Epoch:3 Step:2648 Training_loss:0.668887, Acc_avg:54.00% Training_loss_avg:0.693170\n",
            "Epoch:3 Step:2656 Training_loss:0.727501, Acc_avg:54.00% Training_loss_avg:0.693107\n",
            "Epoch:3 Step:2664 Training_loss:0.655107, Acc_avg:54.25% Training_loss_avg:0.692089\n",
            "Epoch:3 Step:2672 Training_loss:0.737485, Acc_avg:53.75% Training_loss_avg:0.693230\n",
            "Epoch:3 Step:2680 Training_loss:0.710341, Acc_avg:53.75% Training_loss_avg:0.693039\n",
            "Epoch:3 Step:2688 Training_loss:0.694513, Acc_avg:54.00% Training_loss_avg:0.693194\n",
            "Epoch:3 Step:2696 Training_loss:0.661561, Acc_avg:54.50% Training_loss_avg:0.692651\n",
            "Epoch:3 Step:2704 Training_loss:0.727364, Acc_avg:54.50% Training_loss_avg:0.693174\n",
            "Epoch:3 Step:2712 Training_loss:0.656749, Acc_avg:55.50% Training_loss_avg:0.691716\n",
            "Epoch:3 Step:2720 Training_loss:0.610884, Acc_avg:55.75% Training_loss_avg:0.690450\n",
            "Epoch:3 Step:2728 Training_loss:0.709434, Acc_avg:55.75% Training_loss_avg:0.690936\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:2728 Val_loss:0.689405, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:2736 Training_loss:0.740482, Acc_avg:55.25% Training_loss_avg:0.691993\n",
            "Epoch:3 Step:2744 Training_loss:0.701060, Acc_avg:55.00% Training_loss_avg:0.692363\n",
            "Epoch:3 Step:2752 Training_loss:0.658580, Acc_avg:55.50% Training_loss_avg:0.691818\n",
            "Epoch:3 Step:2760 Training_loss:0.707368, Acc_avg:54.50% Training_loss_avg:0.692552\n",
            "Epoch:3 Step:2768 Training_loss:0.657230, Acc_avg:54.75% Training_loss_avg:0.692095\n",
            "Epoch:3 Step:2776 Training_loss:0.682133, Acc_avg:54.75% Training_loss_avg:0.691770\n",
            "Epoch:3 Step:2784 Training_loss:0.697859, Acc_avg:54.75% Training_loss_avg:0.691890\n",
            "Epoch:3 Step:2792 Training_loss:0.716793, Acc_avg:54.25% Training_loss_avg:0.692513\n",
            "Epoch:3 Step:2800 Training_loss:0.658253, Acc_avg:54.25% Training_loss_avg:0.692289\n",
            "Epoch:3 Step:2808 Training_loss:0.608660, Acc_avg:55.00% Training_loss_avg:0.690773\n",
            "Epoch:3 Step:2816 Training_loss:0.693535, Acc_avg:55.50% Training_loss_avg:0.690235\n",
            "Epoch:3 Step:2824 Training_loss:0.700943, Acc_avg:55.25% Training_loss_avg:0.690693\n",
            "Epoch:3 Step:2832 Training_loss:0.725512, Acc_avg:55.50% Training_loss_avg:0.690662\n",
            "Epoch:3 Step:2840 Training_loss:0.710591, Acc_avg:55.75% Training_loss_avg:0.690642\n",
            "Epoch:3 Step:2848 Training_loss:0.631420, Acc_avg:56.00% Training_loss_avg:0.690173\n",
            "Epoch:3 Step:2856 Training_loss:0.773493, Acc_avg:55.50% Training_loss_avg:0.691606\n",
            "Epoch:3 Step:2864 Training_loss:0.638245, Acc_avg:56.25% Training_loss_avg:0.689846\n",
            "Epoch:3 Step:2872 Training_loss:0.678136, Acc_avg:56.50% Training_loss_avg:0.689684\n",
            "Epoch:3 Step:2880 Training_loss:0.644258, Acc_avg:56.50% Training_loss_avg:0.688907\n",
            "Epoch:3 Step:2888 Training_loss:0.649265, Acc_avg:56.75% Training_loss_avg:0.688042\n",
            "Epoch:3 Step:2896 Training_loss:0.693130, Acc_avg:57.00% Training_loss_avg:0.687835\n",
            "Epoch:3 Step:2904 Training_loss:0.668890, Acc_avg:57.25% Training_loss_avg:0.687395\n",
            "Epoch:3 Step:2912 Training_loss:0.687573, Acc_avg:56.50% Training_loss_avg:0.687998\n",
            "Epoch:3 Step:2920 Training_loss:0.665558, Acc_avg:56.75% Training_loss_avg:0.687172\n",
            "Epoch:3 Step:2928 Training_loss:0.687525, Acc_avg:56.25% Training_loss_avg:0.687891\n",
            "Epoch:3 Step:2936 Training_loss:0.692385, Acc_avg:55.50% Training_loss_avg:0.688437\n",
            "Epoch:3 Step:2944 Training_loss:0.775010, Acc_avg:54.50% Training_loss_avg:0.690422\n",
            "Epoch:3 Step:2952 Training_loss:0.678040, Acc_avg:54.00% Training_loss_avg:0.691127\n",
            "Epoch:3 Step:2960 Training_loss:0.713705, Acc_avg:54.00% Training_loss_avg:0.691264\n",
            "Epoch:3 Step:2968 Training_loss:0.744997, Acc_avg:53.50% Training_loss_avg:0.692645\n",
            "Epoch:3 Step:2976 Training_loss:0.670059, Acc_avg:53.25% Training_loss_avg:0.693080\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:2976 Val_loss:0.689581, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:2984 Training_loss:0.785856, Acc_avg:52.50% Training_loss_avg:0.694841\n",
            "Epoch:3 Step:2992 Training_loss:0.656739, Acc_avg:53.25% Training_loss_avg:0.693672\n",
            "Epoch:3 Step:3000 Training_loss:0.729967, Acc_avg:53.50% Training_loss_avg:0.693082\n",
            "Epoch:3 Step:3008 Training_loss:0.644637, Acc_avg:54.00% Training_loss_avg:0.691906\n",
            "Epoch:3 Step:3016 Training_loss:0.691376, Acc_avg:54.00% Training_loss_avg:0.691413\n",
            "Epoch:3 Step:3024 Training_loss:0.705686, Acc_avg:54.00% Training_loss_avg:0.691661\n",
            "Epoch:3 Step:3032 Training_loss:0.685577, Acc_avg:54.25% Training_loss_avg:0.690659\n",
            "Epoch:3 Step:3040 Training_loss:0.676704, Acc_avg:54.75% Training_loss_avg:0.689741\n",
            "Epoch:3 Step:3048 Training_loss:0.720304, Acc_avg:54.25% Training_loss_avg:0.690769\n",
            "Epoch:3 Step:3056 Training_loss:0.625140, Acc_avg:55.00% Training_loss_avg:0.688722\n",
            "Epoch:3 Step:3064 Training_loss:0.690330, Acc_avg:54.50% Training_loss_avg:0.689427\n",
            "Epoch:3 Step:3072 Training_loss:0.708901, Acc_avg:54.50% Training_loss_avg:0.688855\n",
            "Epoch:3 Step:3080 Training_loss:0.712422, Acc_avg:54.50% Training_loss_avg:0.688897\n",
            "Epoch:3 Step:3088 Training_loss:0.710968, Acc_avg:54.00% Training_loss_avg:0.689226\n",
            "Epoch:3 Step:3096 Training_loss:0.664051, Acc_avg:54.00% Training_loss_avg:0.689276\n",
            "Epoch:3 Step:3104 Training_loss:0.663894, Acc_avg:54.75% Training_loss_avg:0.688006\n",
            "Epoch:3 Step:3112 Training_loss:0.681123, Acc_avg:54.25% Training_loss_avg:0.688494\n",
            "Epoch:3 Step:3120 Training_loss:0.680501, Acc_avg:53.75% Training_loss_avg:0.689886\n",
            "Epoch:3 Step:3128 Training_loss:0.697506, Acc_avg:53.75% Training_loss_avg:0.689647\n",
            "Epoch:3 Step:3136 Training_loss:0.729998, Acc_avg:53.75% Training_loss_avg:0.689438\n",
            "Epoch:3 Step:3144 Training_loss:0.657223, Acc_avg:54.00% Training_loss_avg:0.688561\n",
            "Epoch:3 Step:3152 Training_loss:0.694638, Acc_avg:53.50% Training_loss_avg:0.689282\n",
            "Epoch:3 Step:3160 Training_loss:0.698817, Acc_avg:53.75% Training_loss_avg:0.689111\n",
            "Epoch:3 Step:3168 Training_loss:0.692103, Acc_avg:53.25% Training_loss_avg:0.689809\n",
            "Epoch:3 Step:3176 Training_loss:0.702072, Acc_avg:53.00% Training_loss_avg:0.690207\n",
            "Epoch:3 Step:3184 Training_loss:0.695054, Acc_avg:53.00% Training_loss_avg:0.690151\n",
            "Epoch:3 Step:3192 Training_loss:0.694440, Acc_avg:52.75% Training_loss_avg:0.689704\n",
            "Epoch:3 Step:3200 Training_loss:0.662461, Acc_avg:52.50% Training_loss_avg:0.689788\n",
            "Epoch:3 Step:3208 Training_loss:0.733563, Acc_avg:50.75% Training_loss_avg:0.692286\n",
            "Epoch:3 Step:3216 Training_loss:0.738141, Acc_avg:50.50% Training_loss_avg:0.693179\n",
            "Epoch:3 Step:3224 Training_loss:0.677104, Acc_avg:50.75% Training_loss_avg:0.692702\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:3 Step:3224 Val_loss:0.689840, Val_Acc_avg:54.75%\n",
            "Epoch:3 Step:3232 Training_loss:0.714061, Acc_avg:50.75% Training_loss_avg:0.692473\n",
            "Epoch:3 Step:3240 Training_loss:0.710459, Acc_avg:50.50% Training_loss_avg:0.692470\n",
            "Epoch:3 Step:3248 Training_loss:0.695321, Acc_avg:50.00% Training_loss_avg:0.693748\n",
            "Epoch:3 Step:3256 Training_loss:0.671118, Acc_avg:51.00% Training_loss_avg:0.691701\n",
            "Epoch:3 Step:3264 Training_loss:0.705958, Acc_avg:50.25% Training_loss_avg:0.693055\n",
            "Epoch:3 Step:3272 Training_loss:0.713495, Acc_avg:49.75% Training_loss_avg:0.693762\n",
            "Epoch:3 Step:3280 Training_loss:0.701438, Acc_avg:49.25% Training_loss_avg:0.694906\n",
            "Epoch:3 Step:3288 Training_loss:0.662077, Acc_avg:49.25% Training_loss_avg:0.695162\n",
            "Epoch:3 Step:3296 Training_loss:0.709593, Acc_avg:49.25% Training_loss_avg:0.695491\n",
            "Epoch:3 Step:3304 Training_loss:0.679494, Acc_avg:49.50% Training_loss_avg:0.695703\n",
            "Epoch:3 Step:3312 Training_loss:0.691901, Acc_avg:49.25% Training_loss_avg:0.695790\n",
            "Epoch:3 Step:3320 Training_loss:0.683907, Acc_avg:49.50% Training_loss_avg:0.696157\n",
            "Epoch:3 Step:3328 Training_loss:0.667328, Acc_avg:49.83% Training_loss_avg:0.695753\n",
            "Epoch:4 Step:0 Training_loss:0.679278, Acc_avg:50.08% Training_loss_avg:0.695491\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:0 Val_loss:0.690375, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:8 Training_loss:0.694855, Acc_avg:50.83% Training_loss_avg:0.693888\n",
            "Epoch:4 Step:16 Training_loss:0.678773, Acc_avg:51.08% Training_loss_avg:0.693902\n",
            "Epoch:4 Step:24 Training_loss:0.698471, Acc_avg:51.58% Training_loss_avg:0.693598\n",
            "Epoch:4 Step:32 Training_loss:0.660385, Acc_avg:52.58% Training_loss_avg:0.691905\n",
            "Epoch:4 Step:40 Training_loss:0.704610, Acc_avg:52.08% Training_loss_avg:0.692596\n",
            "Epoch:4 Step:48 Training_loss:0.705973, Acc_avg:52.83% Training_loss_avg:0.690999\n",
            "Epoch:4 Step:56 Training_loss:0.696798, Acc_avg:52.58% Training_loss_avg:0.691800\n",
            "Epoch:4 Step:64 Training_loss:0.717039, Acc_avg:52.58% Training_loss_avg:0.691541\n",
            "Epoch:4 Step:72 Training_loss:0.711562, Acc_avg:51.83% Training_loss_avg:0.692880\n",
            "Epoch:4 Step:80 Training_loss:0.719542, Acc_avg:51.83% Training_loss_avg:0.693443\n",
            "Epoch:4 Step:88 Training_loss:0.747467, Acc_avg:51.33% Training_loss_avg:0.694279\n",
            "Epoch:4 Step:96 Training_loss:0.692326, Acc_avg:51.33% Training_loss_avg:0.694414\n",
            "Epoch:4 Step:104 Training_loss:0.706036, Acc_avg:50.83% Training_loss_avg:0.695000\n",
            "Epoch:4 Step:112 Training_loss:0.708092, Acc_avg:50.83% Training_loss_avg:0.694756\n",
            "Epoch:4 Step:120 Training_loss:0.660157, Acc_avg:51.08% Training_loss_avg:0.695456\n",
            "Epoch:4 Step:128 Training_loss:0.649904, Acc_avg:52.08% Training_loss_avg:0.694648\n",
            "Epoch:4 Step:136 Training_loss:0.658374, Acc_avg:53.08% Training_loss_avg:0.693637\n",
            "Epoch:4 Step:144 Training_loss:0.639436, Acc_avg:54.33% Training_loss_avg:0.692178\n",
            "Epoch:4 Step:152 Training_loss:0.698165, Acc_avg:54.58% Training_loss_avg:0.691922\n",
            "Epoch:4 Step:160 Training_loss:0.687433, Acc_avg:54.33% Training_loss_avg:0.692389\n",
            "Epoch:4 Step:168 Training_loss:0.682730, Acc_avg:53.83% Training_loss_avg:0.692766\n",
            "Epoch:4 Step:176 Training_loss:0.665437, Acc_avg:54.33% Training_loss_avg:0.692452\n",
            "Epoch:4 Step:184 Training_loss:0.731717, Acc_avg:53.58% Training_loss_avg:0.693477\n",
            "Epoch:4 Step:192 Training_loss:0.753312, Acc_avg:53.08% Training_loss_avg:0.694593\n",
            "Epoch:4 Step:200 Training_loss:0.715326, Acc_avg:53.33% Training_loss_avg:0.694299\n",
            "Epoch:4 Step:208 Training_loss:0.727171, Acc_avg:52.83% Training_loss_avg:0.695698\n",
            "Epoch:4 Step:216 Training_loss:0.701798, Acc_avg:52.83% Training_loss_avg:0.695841\n",
            "Epoch:4 Step:224 Training_loss:0.650914, Acc_avg:53.33% Training_loss_avg:0.694883\n",
            "Epoch:4 Step:232 Training_loss:0.708257, Acc_avg:53.08% Training_loss_avg:0.695206\n",
            "Epoch:4 Step:240 Training_loss:0.688464, Acc_avg:53.08% Training_loss_avg:0.694934\n",
            "Epoch:4 Step:248 Training_loss:0.770820, Acc_avg:52.08% Training_loss_avg:0.696450\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:248 Val_loss:0.689719, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:256 Training_loss:0.672037, Acc_avg:52.83% Training_loss_avg:0.696002\n",
            "Epoch:4 Step:264 Training_loss:0.670797, Acc_avg:52.83% Training_loss_avg:0.696168\n",
            "Epoch:4 Step:272 Training_loss:0.688460, Acc_avg:53.83% Training_loss_avg:0.695266\n",
            "Epoch:4 Step:280 Training_loss:0.712195, Acc_avg:53.83% Training_loss_avg:0.694747\n",
            "Epoch:4 Step:288 Training_loss:0.680958, Acc_avg:53.58% Training_loss_avg:0.694824\n",
            "Epoch:4 Step:296 Training_loss:0.658868, Acc_avg:54.33% Training_loss_avg:0.693720\n",
            "Epoch:4 Step:304 Training_loss:0.689574, Acc_avg:54.83% Training_loss_avg:0.693303\n",
            "Epoch:4 Step:312 Training_loss:0.688113, Acc_avg:54.83% Training_loss_avg:0.693159\n",
            "Epoch:4 Step:320 Training_loss:0.679645, Acc_avg:54.58% Training_loss_avg:0.693329\n",
            "Epoch:4 Step:328 Training_loss:0.682732, Acc_avg:55.08% Training_loss_avg:0.692865\n",
            "Epoch:4 Step:336 Training_loss:0.683326, Acc_avg:55.58% Training_loss_avg:0.692261\n",
            "Epoch:4 Step:344 Training_loss:0.672812, Acc_avg:56.08% Training_loss_avg:0.691689\n",
            "Epoch:4 Step:352 Training_loss:0.701215, Acc_avg:55.33% Training_loss_avg:0.692472\n",
            "Epoch:4 Step:360 Training_loss:0.699976, Acc_avg:55.33% Training_loss_avg:0.692279\n",
            "Epoch:4 Step:368 Training_loss:0.679286, Acc_avg:55.08% Training_loss_avg:0.692275\n",
            "Epoch:4 Step:376 Training_loss:0.632460, Acc_avg:56.33% Training_loss_avg:0.691086\n",
            "Epoch:4 Step:384 Training_loss:0.621545, Acc_avg:56.83% Training_loss_avg:0.689839\n",
            "Epoch:4 Step:392 Training_loss:0.658974, Acc_avg:56.75% Training_loss_avg:0.689672\n",
            "Epoch:4 Step:400 Training_loss:0.738641, Acc_avg:56.25% Training_loss_avg:0.690859\n",
            "Epoch:4 Step:408 Training_loss:0.699069, Acc_avg:56.25% Training_loss_avg:0.690943\n",
            "Epoch:4 Step:416 Training_loss:0.702783, Acc_avg:56.00% Training_loss_avg:0.691424\n",
            "Epoch:4 Step:424 Training_loss:0.723490, Acc_avg:55.25% Training_loss_avg:0.691924\n",
            "Epoch:4 Step:432 Training_loss:0.651013, Acc_avg:55.00% Training_loss_avg:0.691737\n",
            "Epoch:4 Step:440 Training_loss:0.727747, Acc_avg:54.75% Training_loss_avg:0.692199\n",
            "Epoch:4 Step:448 Training_loss:0.701509, Acc_avg:54.75% Training_loss_avg:0.692110\n",
            "Epoch:4 Step:456 Training_loss:0.619326, Acc_avg:55.25% Training_loss_avg:0.690561\n",
            "Epoch:4 Step:464 Training_loss:0.737336, Acc_avg:55.25% Training_loss_avg:0.690966\n",
            "Epoch:4 Step:472 Training_loss:0.652372, Acc_avg:56.00% Training_loss_avg:0.689783\n",
            "Epoch:4 Step:480 Training_loss:0.692532, Acc_avg:56.00% Training_loss_avg:0.689242\n",
            "Epoch:4 Step:488 Training_loss:0.624491, Acc_avg:56.75% Training_loss_avg:0.686783\n",
            "Epoch:4 Step:496 Training_loss:0.675189, Acc_avg:57.00% Training_loss_avg:0.686440\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:496 Val_loss:0.689810, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:504 Training_loss:0.802242, Acc_avg:57.00% Training_loss_avg:0.688364\n",
            "Epoch:4 Step:512 Training_loss:0.621690, Acc_avg:57.75% Training_loss_avg:0.686636\n",
            "Epoch:4 Step:520 Training_loss:0.659203, Acc_avg:57.25% Training_loss_avg:0.686617\n",
            "Epoch:4 Step:528 Training_loss:0.626494, Acc_avg:57.00% Training_loss_avg:0.686149\n",
            "Epoch:4 Step:536 Training_loss:0.744577, Acc_avg:55.75% Training_loss_avg:0.687873\n",
            "Epoch:4 Step:544 Training_loss:0.729626, Acc_avg:54.75% Training_loss_avg:0.689677\n",
            "Epoch:4 Step:552 Training_loss:0.734740, Acc_avg:54.75% Training_loss_avg:0.690408\n",
            "Epoch:4 Step:560 Training_loss:0.726444, Acc_avg:54.25% Training_loss_avg:0.691189\n",
            "Epoch:4 Step:568 Training_loss:0.675008, Acc_avg:54.50% Training_loss_avg:0.691034\n",
            "Epoch:4 Step:576 Training_loss:0.724053, Acc_avg:54.00% Training_loss_avg:0.692206\n",
            "Epoch:4 Step:584 Training_loss:0.710178, Acc_avg:54.25% Training_loss_avg:0.691776\n",
            "Epoch:4 Step:592 Training_loss:0.752692, Acc_avg:54.25% Training_loss_avg:0.691763\n",
            "Epoch:4 Step:600 Training_loss:0.649069, Acc_avg:55.00% Training_loss_avg:0.690438\n",
            "Epoch:4 Step:608 Training_loss:0.734989, Acc_avg:54.75% Training_loss_avg:0.690594\n",
            "Epoch:4 Step:616 Training_loss:0.767726, Acc_avg:54.00% Training_loss_avg:0.691913\n",
            "Epoch:4 Step:624 Training_loss:0.715188, Acc_avg:53.25% Training_loss_avg:0.693198\n",
            "Epoch:4 Step:632 Training_loss:0.740312, Acc_avg:53.25% Training_loss_avg:0.693840\n",
            "Epoch:4 Step:640 Training_loss:0.679608, Acc_avg:53.50% Training_loss_avg:0.693662\n",
            "Epoch:4 Step:648 Training_loss:0.704754, Acc_avg:54.25% Training_loss_avg:0.692341\n",
            "Epoch:4 Step:656 Training_loss:0.662640, Acc_avg:54.25% Training_loss_avg:0.692153\n",
            "Epoch:4 Step:664 Training_loss:0.676523, Acc_avg:54.25% Training_loss_avg:0.692268\n",
            "Epoch:4 Step:672 Training_loss:0.707648, Acc_avg:53.75% Training_loss_avg:0.692652\n",
            "Epoch:4 Step:680 Training_loss:0.658256, Acc_avg:54.75% Training_loss_avg:0.691573\n",
            "Epoch:4 Step:688 Training_loss:0.680197, Acc_avg:54.75% Training_loss_avg:0.691558\n",
            "Epoch:4 Step:696 Training_loss:0.683090, Acc_avg:54.50% Training_loss_avg:0.692042\n",
            "Epoch:4 Step:704 Training_loss:0.672690, Acc_avg:54.75% Training_loss_avg:0.691704\n",
            "Epoch:4 Step:712 Training_loss:0.748286, Acc_avg:53.75% Training_loss_avg:0.692908\n",
            "Epoch:4 Step:720 Training_loss:0.713124, Acc_avg:53.75% Training_loss_avg:0.693577\n",
            "Epoch:4 Step:728 Training_loss:0.720087, Acc_avg:53.25% Training_loss_avg:0.694324\n",
            "Epoch:4 Step:736 Training_loss:0.684463, Acc_avg:53.00% Training_loss_avg:0.694347\n",
            "Epoch:4 Step:744 Training_loss:0.693890, Acc_avg:53.00% Training_loss_avg:0.694769\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:744 Val_loss:0.690292, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:752 Training_loss:0.708905, Acc_avg:53.25% Training_loss_avg:0.694923\n",
            "Epoch:4 Step:760 Training_loss:0.709719, Acc_avg:52.75% Training_loss_avg:0.695117\n",
            "Epoch:4 Step:768 Training_loss:0.704650, Acc_avg:52.50% Training_loss_avg:0.695625\n",
            "Epoch:4 Step:776 Training_loss:0.677213, Acc_avg:52.00% Training_loss_avg:0.696520\n",
            "Epoch:4 Step:784 Training_loss:0.691638, Acc_avg:51.25% Training_loss_avg:0.697922\n",
            "Epoch:4 Step:792 Training_loss:0.678666, Acc_avg:51.50% Training_loss_avg:0.698315\n",
            "Epoch:4 Step:800 Training_loss:0.687287, Acc_avg:52.25% Training_loss_avg:0.697288\n",
            "Epoch:4 Step:808 Training_loss:0.686822, Acc_avg:52.50% Training_loss_avg:0.697043\n",
            "Epoch:4 Step:816 Training_loss:0.677978, Acc_avg:52.75% Training_loss_avg:0.696547\n",
            "Epoch:4 Step:824 Training_loss:0.683336, Acc_avg:53.25% Training_loss_avg:0.695744\n",
            "Epoch:4 Step:832 Training_loss:0.675266, Acc_avg:53.00% Training_loss_avg:0.696229\n",
            "Epoch:4 Step:840 Training_loss:0.693249, Acc_avg:53.75% Training_loss_avg:0.695539\n",
            "Epoch:4 Step:848 Training_loss:0.673261, Acc_avg:54.25% Training_loss_avg:0.694974\n",
            "Epoch:4 Step:856 Training_loss:0.695142, Acc_avg:53.50% Training_loss_avg:0.696491\n",
            "Epoch:4 Step:864 Training_loss:0.680959, Acc_avg:54.00% Training_loss_avg:0.695363\n",
            "Epoch:4 Step:872 Training_loss:0.678693, Acc_avg:53.75% Training_loss_avg:0.695890\n",
            "Epoch:4 Step:880 Training_loss:0.687703, Acc_avg:53.75% Training_loss_avg:0.695793\n",
            "Epoch:4 Step:888 Training_loss:0.669909, Acc_avg:54.00% Training_loss_avg:0.696701\n",
            "Epoch:4 Step:896 Training_loss:0.696679, Acc_avg:53.75% Training_loss_avg:0.697131\n",
            "Epoch:4 Step:904 Training_loss:0.694442, Acc_avg:53.75% Training_loss_avg:0.694975\n",
            "Epoch:4 Step:912 Training_loss:0.713554, Acc_avg:53.00% Training_loss_avg:0.696813\n",
            "Epoch:4 Step:920 Training_loss:0.697675, Acc_avg:52.75% Training_loss_avg:0.697582\n",
            "Epoch:4 Step:928 Training_loss:0.688292, Acc_avg:52.50% Training_loss_avg:0.698818\n",
            "Epoch:4 Step:936 Training_loss:0.656436, Acc_avg:53.75% Training_loss_avg:0.697055\n",
            "Epoch:4 Step:944 Training_loss:0.637715, Acc_avg:54.25% Training_loss_avg:0.695217\n",
            "Epoch:4 Step:952 Training_loss:0.652292, Acc_avg:54.50% Training_loss_avg:0.693568\n",
            "Epoch:4 Step:960 Training_loss:0.701957, Acc_avg:54.50% Training_loss_avg:0.693078\n",
            "Epoch:4 Step:968 Training_loss:0.682014, Acc_avg:54.50% Training_loss_avg:0.693218\n",
            "Epoch:4 Step:976 Training_loss:0.713833, Acc_avg:54.25% Training_loss_avg:0.693014\n",
            "Epoch:4 Step:984 Training_loss:0.658146, Acc_avg:55.00% Training_loss_avg:0.691973\n",
            "Epoch:4 Step:992 Training_loss:0.663674, Acc_avg:56.00% Training_loss_avg:0.690193\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:992 Val_loss:0.689410, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:1000 Training_loss:0.679050, Acc_avg:55.75% Training_loss_avg:0.690793\n",
            "Epoch:4 Step:1008 Training_loss:0.715491, Acc_avg:56.00% Training_loss_avg:0.690403\n",
            "Epoch:4 Step:1016 Training_loss:0.689743, Acc_avg:56.75% Training_loss_avg:0.688843\n",
            "Epoch:4 Step:1024 Training_loss:0.657060, Acc_avg:57.25% Training_loss_avg:0.687680\n",
            "Epoch:4 Step:1032 Training_loss:0.653703, Acc_avg:57.75% Training_loss_avg:0.685948\n",
            "Epoch:4 Step:1040 Training_loss:0.735508, Acc_avg:57.25% Training_loss_avg:0.687066\n",
            "Epoch:4 Step:1048 Training_loss:0.709926, Acc_avg:57.25% Training_loss_avg:0.687170\n",
            "Epoch:4 Step:1056 Training_loss:0.693217, Acc_avg:57.25% Training_loss_avg:0.687781\n",
            "Epoch:4 Step:1064 Training_loss:0.673693, Acc_avg:57.25% Training_loss_avg:0.687725\n",
            "Epoch:4 Step:1072 Training_loss:0.719850, Acc_avg:57.25% Training_loss_avg:0.687969\n",
            "Epoch:4 Step:1080 Training_loss:0.744043, Acc_avg:56.25% Training_loss_avg:0.689684\n",
            "Epoch:4 Step:1088 Training_loss:0.682135, Acc_avg:56.25% Training_loss_avg:0.689723\n",
            "Epoch:4 Step:1096 Training_loss:0.696345, Acc_avg:56.00% Training_loss_avg:0.689988\n",
            "Epoch:4 Step:1104 Training_loss:0.696831, Acc_avg:55.50% Training_loss_avg:0.690471\n",
            "Epoch:4 Step:1112 Training_loss:0.731806, Acc_avg:56.00% Training_loss_avg:0.690141\n",
            "Epoch:4 Step:1120 Training_loss:0.720988, Acc_avg:55.50% Training_loss_avg:0.690299\n",
            "Epoch:4 Step:1128 Training_loss:0.673794, Acc_avg:56.00% Training_loss_avg:0.689373\n",
            "Epoch:4 Step:1136 Training_loss:0.720492, Acc_avg:56.00% Training_loss_avg:0.690093\n",
            "Epoch:4 Step:1144 Training_loss:0.699226, Acc_avg:56.00% Training_loss_avg:0.690200\n",
            "Epoch:4 Step:1152 Training_loss:0.685860, Acc_avg:56.00% Training_loss_avg:0.689739\n",
            "Epoch:4 Step:1160 Training_loss:0.676279, Acc_avg:56.50% Training_loss_avg:0.689070\n",
            "Epoch:4 Step:1168 Training_loss:0.689140, Acc_avg:56.75% Training_loss_avg:0.688760\n",
            "Epoch:4 Step:1176 Training_loss:0.667604, Acc_avg:56.25% Training_loss_avg:0.688568\n",
            "Epoch:4 Step:1184 Training_loss:0.723832, Acc_avg:56.00% Training_loss_avg:0.689212\n",
            "Epoch:4 Step:1192 Training_loss:0.654888, Acc_avg:56.00% Training_loss_avg:0.688736\n",
            "Epoch:4 Step:1200 Training_loss:0.716332, Acc_avg:55.50% Training_loss_avg:0.689317\n",
            "Epoch:4 Step:1208 Training_loss:0.705789, Acc_avg:55.25% Training_loss_avg:0.689697\n",
            "Epoch:4 Step:1216 Training_loss:0.726117, Acc_avg:54.75% Training_loss_avg:0.690659\n",
            "Epoch:4 Step:1224 Training_loss:0.640777, Acc_avg:55.25% Training_loss_avg:0.689808\n",
            "Epoch:4 Step:1232 Training_loss:0.683208, Acc_avg:55.25% Training_loss_avg:0.689967\n",
            "Epoch:4 Step:1240 Training_loss:0.694018, Acc_avg:55.00% Training_loss_avg:0.689982\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:1240 Val_loss:0.689436, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:1248 Training_loss:0.653853, Acc_avg:55.00% Training_loss_avg:0.689594\n",
            "Epoch:4 Step:1256 Training_loss:0.711313, Acc_avg:55.00% Training_loss_avg:0.689918\n",
            "Epoch:4 Step:1264 Training_loss:0.666239, Acc_avg:55.00% Training_loss_avg:0.689623\n",
            "Epoch:4 Step:1272 Training_loss:0.705670, Acc_avg:54.50% Training_loss_avg:0.690163\n",
            "Epoch:4 Step:1280 Training_loss:0.634411, Acc_avg:55.25% Training_loss_avg:0.689097\n",
            "Epoch:4 Step:1288 Training_loss:0.684105, Acc_avg:54.75% Training_loss_avg:0.689381\n",
            "Epoch:4 Step:1296 Training_loss:0.654259, Acc_avg:55.25% Training_loss_avg:0.688533\n",
            "Epoch:4 Step:1304 Training_loss:0.662409, Acc_avg:55.75% Training_loss_avg:0.687892\n",
            "Epoch:4 Step:1312 Training_loss:0.690932, Acc_avg:56.00% Training_loss_avg:0.687439\n",
            "Epoch:4 Step:1320 Training_loss:0.668911, Acc_avg:56.25% Training_loss_avg:0.686864\n",
            "Epoch:4 Step:1328 Training_loss:0.661147, Acc_avg:56.25% Training_loss_avg:0.686321\n",
            "Epoch:4 Step:1336 Training_loss:0.680734, Acc_avg:55.75% Training_loss_avg:0.686807\n",
            "Epoch:4 Step:1344 Training_loss:0.702241, Acc_avg:55.25% Training_loss_avg:0.688098\n",
            "Epoch:4 Step:1352 Training_loss:0.646404, Acc_avg:55.25% Training_loss_avg:0.687980\n",
            "Epoch:4 Step:1360 Training_loss:0.727478, Acc_avg:55.25% Training_loss_avg:0.688490\n",
            "Epoch:4 Step:1368 Training_loss:0.632606, Acc_avg:55.50% Training_loss_avg:0.687502\n",
            "Epoch:4 Step:1376 Training_loss:0.732943, Acc_avg:55.75% Training_loss_avg:0.687884\n",
            "Epoch:4 Step:1384 Training_loss:0.756284, Acc_avg:54.75% Training_loss_avg:0.689847\n",
            "Epoch:4 Step:1392 Training_loss:0.673404, Acc_avg:54.50% Training_loss_avg:0.690042\n",
            "Epoch:4 Step:1400 Training_loss:0.677538, Acc_avg:54.25% Training_loss_avg:0.690012\n",
            "Epoch:4 Step:1408 Training_loss:0.578425, Acc_avg:55.25% Training_loss_avg:0.687270\n",
            "Epoch:4 Step:1416 Training_loss:0.671786, Acc_avg:55.25% Training_loss_avg:0.686911\n",
            "Epoch:4 Step:1424 Training_loss:0.687763, Acc_avg:55.25% Training_loss_avg:0.687525\n",
            "Epoch:4 Step:1432 Training_loss:0.755343, Acc_avg:54.50% Training_loss_avg:0.689558\n",
            "Epoch:4 Step:1440 Training_loss:0.657037, Acc_avg:55.00% Training_loss_avg:0.687989\n",
            "Epoch:4 Step:1448 Training_loss:0.638185, Acc_avg:55.75% Training_loss_avg:0.686554\n",
            "Epoch:4 Step:1456 Training_loss:0.685537, Acc_avg:55.75% Training_loss_avg:0.686400\n",
            "Epoch:4 Step:1464 Training_loss:0.715435, Acc_avg:55.75% Training_loss_avg:0.687235\n",
            "Epoch:4 Step:1472 Training_loss:0.859265, Acc_avg:55.25% Training_loss_avg:0.690023\n",
            "Epoch:4 Step:1480 Training_loss:0.615082, Acc_avg:56.25% Training_loss_avg:0.687444\n",
            "Epoch:4 Step:1488 Training_loss:0.734575, Acc_avg:56.25% Training_loss_avg:0.688493\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:1488 Val_loss:0.689995, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:1496 Training_loss:0.592583, Acc_avg:57.00% Training_loss_avg:0.686418\n",
            "Epoch:4 Step:1504 Training_loss:0.730320, Acc_avg:56.75% Training_loss_avg:0.687087\n",
            "Epoch:4 Step:1512 Training_loss:0.689353, Acc_avg:57.00% Training_loss_avg:0.686238\n",
            "Epoch:4 Step:1520 Training_loss:0.654617, Acc_avg:57.75% Training_loss_avg:0.684911\n",
            "Epoch:4 Step:1528 Training_loss:0.708563, Acc_avg:57.75% Training_loss_avg:0.685606\n",
            "Epoch:4 Step:1536 Training_loss:0.759779, Acc_avg:57.50% Training_loss_avg:0.686392\n",
            "Epoch:4 Step:1544 Training_loss:0.674044, Acc_avg:57.50% Training_loss_avg:0.685888\n",
            "Epoch:4 Step:1552 Training_loss:0.654699, Acc_avg:57.75% Training_loss_avg:0.685265\n",
            "Epoch:4 Step:1560 Training_loss:0.747890, Acc_avg:57.25% Training_loss_avg:0.686697\n",
            "Epoch:4 Step:1568 Training_loss:0.736326, Acc_avg:56.75% Training_loss_avg:0.687641\n",
            "Epoch:4 Step:1576 Training_loss:0.742995, Acc_avg:56.50% Training_loss_avg:0.689149\n",
            "Epoch:4 Step:1584 Training_loss:0.703072, Acc_avg:56.50% Training_loss_avg:0.688734\n",
            "Epoch:4 Step:1592 Training_loss:0.717034, Acc_avg:56.00% Training_loss_avg:0.689977\n",
            "Epoch:4 Step:1600 Training_loss:0.740845, Acc_avg:56.00% Training_loss_avg:0.690467\n",
            "Epoch:4 Step:1608 Training_loss:0.714861, Acc_avg:56.00% Training_loss_avg:0.690648\n",
            "Epoch:4 Step:1616 Training_loss:0.625111, Acc_avg:57.00% Training_loss_avg:0.688628\n",
            "Epoch:4 Step:1624 Training_loss:0.660787, Acc_avg:56.75% Training_loss_avg:0.689028\n",
            "Epoch:4 Step:1632 Training_loss:0.652064, Acc_avg:57.00% Training_loss_avg:0.688406\n",
            "Epoch:4 Step:1640 Training_loss:0.672792, Acc_avg:57.25% Training_loss_avg:0.687981\n",
            "Epoch:4 Step:1648 Training_loss:0.679058, Acc_avg:56.75% Training_loss_avg:0.688485\n",
            "Epoch:4 Step:1656 Training_loss:0.662634, Acc_avg:57.25% Training_loss_avg:0.687512\n",
            "Epoch:4 Step:1664 Training_loss:0.593430, Acc_avg:58.00% Training_loss_avg:0.686055\n",
            "Epoch:4 Step:1672 Training_loss:0.725325, Acc_avg:58.00% Training_loss_avg:0.686448\n",
            "Epoch:4 Step:1680 Training_loss:0.752721, Acc_avg:56.75% Training_loss_avg:0.688815\n",
            "Epoch:4 Step:1688 Training_loss:0.661106, Acc_avg:57.00% Training_loss_avg:0.688355\n",
            "Epoch:4 Step:1696 Training_loss:0.699750, Acc_avg:56.50% Training_loss_avg:0.689264\n",
            "Epoch:4 Step:1704 Training_loss:0.647236, Acc_avg:56.75% Training_loss_avg:0.688961\n",
            "Epoch:4 Step:1712 Training_loss:0.668873, Acc_avg:57.00% Training_loss_avg:0.688520\n",
            "Epoch:4 Step:1720 Training_loss:0.745946, Acc_avg:56.25% Training_loss_avg:0.690061\n",
            "Epoch:4 Step:1728 Training_loss:0.712258, Acc_avg:55.75% Training_loss_avg:0.691083\n",
            "Epoch:4 Step:1736 Training_loss:0.633343, Acc_avg:56.00% Training_loss_avg:0.690135\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:1736 Val_loss:0.689416, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:1744 Training_loss:0.717543, Acc_avg:55.75% Training_loss_avg:0.690441\n",
            "Epoch:4 Step:1752 Training_loss:0.635497, Acc_avg:56.00% Training_loss_avg:0.690223\n",
            "Epoch:4 Step:1760 Training_loss:0.622804, Acc_avg:56.75% Training_loss_avg:0.688129\n",
            "Epoch:4 Step:1768 Training_loss:0.635326, Acc_avg:57.00% Training_loss_avg:0.688184\n",
            "Epoch:4 Step:1776 Training_loss:0.681534, Acc_avg:57.25% Training_loss_avg:0.687156\n",
            "Epoch:4 Step:1784 Training_loss:0.661731, Acc_avg:58.00% Training_loss_avg:0.685265\n",
            "Epoch:4 Step:1792 Training_loss:0.710426, Acc_avg:57.50% Training_loss_avg:0.686005\n",
            "Epoch:4 Step:1800 Training_loss:0.668699, Acc_avg:57.75% Training_loss_avg:0.685828\n",
            "Epoch:4 Step:1808 Training_loss:0.735451, Acc_avg:57.00% Training_loss_avg:0.688969\n",
            "Epoch:4 Step:1816 Training_loss:0.658779, Acc_avg:57.25% Training_loss_avg:0.688709\n",
            "Epoch:4 Step:1824 Training_loss:0.669751, Acc_avg:57.25% Training_loss_avg:0.688348\n",
            "Epoch:4 Step:1832 Training_loss:0.689813, Acc_avg:57.75% Training_loss_avg:0.687038\n",
            "Epoch:4 Step:1840 Training_loss:0.748044, Acc_avg:57.50% Training_loss_avg:0.688858\n",
            "Epoch:4 Step:1848 Training_loss:0.728806, Acc_avg:57.00% Training_loss_avg:0.690670\n",
            "Epoch:4 Step:1856 Training_loss:0.620689, Acc_avg:57.25% Training_loss_avg:0.689373\n",
            "Epoch:4 Step:1864 Training_loss:0.761294, Acc_avg:56.50% Training_loss_avg:0.690291\n",
            "Epoch:4 Step:1872 Training_loss:0.726371, Acc_avg:57.00% Training_loss_avg:0.687633\n",
            "Epoch:4 Step:1880 Training_loss:0.640384, Acc_avg:56.75% Training_loss_avg:0.688139\n",
            "Epoch:4 Step:1888 Training_loss:0.747285, Acc_avg:56.50% Training_loss_avg:0.688393\n",
            "Epoch:4 Step:1896 Training_loss:0.634501, Acc_avg:56.25% Training_loss_avg:0.689231\n",
            "Epoch:4 Step:1904 Training_loss:0.612462, Acc_avg:57.25% Training_loss_avg:0.686874\n",
            "Epoch:4 Step:1912 Training_loss:0.693621, Acc_avg:57.00% Training_loss_avg:0.686959\n",
            "Epoch:4 Step:1920 Training_loss:0.637077, Acc_avg:56.75% Training_loss_avg:0.686609\n",
            "Epoch:4 Step:1928 Training_loss:0.622670, Acc_avg:56.75% Training_loss_avg:0.684891\n",
            "Epoch:4 Step:1936 Training_loss:0.733630, Acc_avg:56.75% Training_loss_avg:0.684368\n",
            "Epoch:4 Step:1944 Training_loss:0.730173, Acc_avg:56.25% Training_loss_avg:0.685490\n",
            "Epoch:4 Step:1952 Training_loss:0.711852, Acc_avg:55.75% Training_loss_avg:0.686633\n",
            "Epoch:4 Step:1960 Training_loss:0.613575, Acc_avg:56.25% Training_loss_avg:0.683947\n",
            "Epoch:4 Step:1968 Training_loss:0.761541, Acc_avg:56.00% Training_loss_avg:0.684451\n",
            "Epoch:4 Step:1976 Training_loss:0.756061, Acc_avg:56.00% Training_loss_avg:0.684713\n",
            "Epoch:4 Step:1984 Training_loss:0.665204, Acc_avg:56.25% Training_loss_avg:0.683955\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:1984 Val_loss:0.690133, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:1992 Training_loss:0.655764, Acc_avg:56.50% Training_loss_avg:0.682730\n",
            "Epoch:4 Step:2000 Training_loss:0.692039, Acc_avg:57.00% Training_loss_avg:0.681754\n",
            "Epoch:4 Step:2008 Training_loss:0.666187, Acc_avg:57.25% Training_loss_avg:0.680780\n",
            "Epoch:4 Step:2016 Training_loss:0.798554, Acc_avg:56.25% Training_loss_avg:0.684249\n",
            "Epoch:4 Step:2024 Training_loss:0.674103, Acc_avg:56.00% Training_loss_avg:0.684516\n",
            "Epoch:4 Step:2032 Training_loss:0.664924, Acc_avg:55.75% Training_loss_avg:0.684773\n",
            "Epoch:4 Step:2040 Training_loss:0.648409, Acc_avg:56.00% Training_loss_avg:0.684285\n",
            "Epoch:4 Step:2048 Training_loss:0.630550, Acc_avg:56.75% Training_loss_avg:0.683315\n",
            "Epoch:4 Step:2056 Training_loss:0.764830, Acc_avg:56.00% Training_loss_avg:0.685359\n",
            "Epoch:4 Step:2064 Training_loss:0.766002, Acc_avg:54.75% Training_loss_avg:0.688810\n",
            "Epoch:4 Step:2072 Training_loss:0.683634, Acc_avg:55.25% Training_loss_avg:0.687976\n",
            "Epoch:4 Step:2080 Training_loss:0.698833, Acc_avg:55.75% Training_loss_avg:0.686899\n",
            "Epoch:4 Step:2088 Training_loss:0.712794, Acc_avg:55.25% Training_loss_avg:0.687932\n",
            "Epoch:4 Step:2096 Training_loss:0.609540, Acc_avg:56.00% Training_loss_avg:0.686128\n",
            "Epoch:4 Step:2104 Training_loss:0.654092, Acc_avg:56.00% Training_loss_avg:0.686265\n",
            "Epoch:4 Step:2112 Training_loss:0.732479, Acc_avg:55.75% Training_loss_avg:0.687537\n",
            "Epoch:4 Step:2120 Training_loss:0.698388, Acc_avg:56.25% Training_loss_avg:0.686586\n",
            "Epoch:4 Step:2128 Training_loss:0.742947, Acc_avg:56.00% Training_loss_avg:0.687200\n",
            "Epoch:4 Step:2136 Training_loss:0.769260, Acc_avg:55.00% Training_loss_avg:0.689918\n",
            "Epoch:4 Step:2144 Training_loss:0.612628, Acc_avg:56.00% Training_loss_avg:0.687820\n",
            "Epoch:4 Step:2152 Training_loss:0.761290, Acc_avg:55.00% Training_loss_avg:0.690336\n",
            "Epoch:4 Step:2160 Training_loss:0.680077, Acc_avg:54.75% Training_loss_avg:0.691481\n",
            "Epoch:4 Step:2168 Training_loss:0.719954, Acc_avg:53.75% Training_loss_avg:0.693174\n",
            "Epoch:4 Step:2176 Training_loss:0.688576, Acc_avg:53.50% Training_loss_avg:0.693315\n",
            "Epoch:4 Step:2184 Training_loss:0.689142, Acc_avg:53.50% Training_loss_avg:0.693863\n",
            "Epoch:4 Step:2192 Training_loss:0.707292, Acc_avg:53.50% Training_loss_avg:0.693800\n",
            "Epoch:4 Step:2200 Training_loss:0.703278, Acc_avg:53.50% Training_loss_avg:0.694492\n",
            "Epoch:4 Step:2208 Training_loss:0.683373, Acc_avg:53.50% Training_loss_avg:0.693450\n",
            "Epoch:4 Step:2216 Training_loss:0.675659, Acc_avg:53.75% Training_loss_avg:0.693788\n",
            "Epoch:4 Step:2224 Training_loss:0.682758, Acc_avg:53.50% Training_loss_avg:0.694048\n",
            "Epoch:4 Step:2232 Training_loss:0.677919, Acc_avg:54.00% Training_loss_avg:0.693810\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:2232 Val_loss:0.691023, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:2240 Training_loss:0.677373, Acc_avg:54.00% Training_loss_avg:0.692397\n",
            "Epoch:4 Step:2248 Training_loss:0.693935, Acc_avg:53.75% Training_loss_avg:0.691700\n",
            "Epoch:4 Step:2256 Training_loss:0.716233, Acc_avg:52.75% Training_loss_avg:0.693610\n",
            "Epoch:4 Step:2264 Training_loss:0.685953, Acc_avg:53.25% Training_loss_avg:0.692104\n",
            "Epoch:4 Step:2272 Training_loss:0.714172, Acc_avg:53.00% Training_loss_avg:0.691860\n",
            "Epoch:4 Step:2280 Training_loss:0.672179, Acc_avg:53.00% Training_loss_avg:0.692495\n",
            "Epoch:4 Step:2288 Training_loss:0.683301, Acc_avg:53.50% Training_loss_avg:0.691216\n",
            "Epoch:4 Step:2296 Training_loss:0.705753, Acc_avg:52.75% Training_loss_avg:0.692641\n",
            "Epoch:4 Step:2304 Training_loss:0.686195, Acc_avg:52.25% Training_loss_avg:0.694115\n",
            "Epoch:4 Step:2312 Training_loss:0.667789, Acc_avg:53.00% Training_loss_avg:0.693599\n",
            "Epoch:4 Step:2320 Training_loss:0.676254, Acc_avg:53.00% Training_loss_avg:0.694382\n",
            "Epoch:4 Step:2328 Training_loss:0.675409, Acc_avg:53.25% Training_loss_avg:0.695437\n",
            "Epoch:4 Step:2336 Training_loss:0.710995, Acc_avg:53.25% Training_loss_avg:0.694984\n",
            "Epoch:4 Step:2344 Training_loss:0.710853, Acc_avg:53.25% Training_loss_avg:0.694598\n",
            "Epoch:4 Step:2352 Training_loss:0.684021, Acc_avg:53.75% Training_loss_avg:0.694041\n",
            "Epoch:4 Step:2360 Training_loss:0.701891, Acc_avg:53.25% Training_loss_avg:0.695808\n",
            "Epoch:4 Step:2368 Training_loss:0.697891, Acc_avg:53.75% Training_loss_avg:0.694535\n",
            "Epoch:4 Step:2376 Training_loss:0.670262, Acc_avg:54.25% Training_loss_avg:0.692819\n",
            "Epoch:4 Step:2384 Training_loss:0.713400, Acc_avg:53.75% Training_loss_avg:0.693783\n",
            "Epoch:4 Step:2392 Training_loss:0.712833, Acc_avg:53.50% Training_loss_avg:0.694924\n",
            "Epoch:4 Step:2400 Training_loss:0.655703, Acc_avg:53.50% Training_loss_avg:0.694197\n",
            "Epoch:4 Step:2408 Training_loss:0.720489, Acc_avg:52.75% Training_loss_avg:0.695283\n",
            "Epoch:4 Step:2416 Training_loss:0.677343, Acc_avg:53.25% Training_loss_avg:0.692859\n",
            "Epoch:4 Step:2424 Training_loss:0.709188, Acc_avg:52.75% Training_loss_avg:0.693561\n",
            "Epoch:4 Step:2432 Training_loss:0.748769, Acc_avg:52.25% Training_loss_avg:0.695238\n",
            "Epoch:4 Step:2440 Training_loss:0.693819, Acc_avg:51.75% Training_loss_avg:0.696146\n",
            "Epoch:4 Step:2448 Training_loss:0.710627, Acc_avg:50.75% Training_loss_avg:0.697748\n",
            "Epoch:4 Step:2456 Training_loss:0.661707, Acc_avg:51.50% Training_loss_avg:0.695685\n",
            "Epoch:4 Step:2464 Training_loss:0.686948, Acc_avg:52.25% Training_loss_avg:0.694104\n",
            "Epoch:4 Step:2472 Training_loss:0.647019, Acc_avg:52.75% Training_loss_avg:0.693372\n",
            "Epoch:4 Step:2480 Training_loss:0.674436, Acc_avg:53.00% Training_loss_avg:0.692884\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:2480 Val_loss:0.689569, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:2488 Training_loss:0.700303, Acc_avg:52.75% Training_loss_avg:0.692634\n",
            "Epoch:4 Step:2496 Training_loss:0.713639, Acc_avg:51.75% Training_loss_avg:0.694716\n",
            "Epoch:4 Step:2504 Training_loss:0.720093, Acc_avg:51.25% Training_loss_avg:0.696036\n",
            "Epoch:4 Step:2512 Training_loss:0.695885, Acc_avg:51.25% Training_loss_avg:0.695304\n",
            "Epoch:4 Step:2520 Training_loss:0.675602, Acc_avg:51.75% Training_loss_avg:0.694848\n",
            "Epoch:4 Step:2528 Training_loss:0.708439, Acc_avg:52.25% Training_loss_avg:0.694158\n",
            "Epoch:4 Step:2536 Training_loss:0.675104, Acc_avg:53.00% Training_loss_avg:0.692275\n",
            "Epoch:4 Step:2544 Training_loss:0.684001, Acc_avg:52.50% Training_loss_avg:0.693703\n",
            "Epoch:4 Step:2552 Training_loss:0.676045, Acc_avg:53.25% Training_loss_avg:0.691998\n",
            "Epoch:4 Step:2560 Training_loss:0.674200, Acc_avg:53.25% Training_loss_avg:0.691880\n",
            "Epoch:4 Step:2568 Training_loss:0.690082, Acc_avg:53.50% Training_loss_avg:0.691283\n",
            "Epoch:4 Step:2576 Training_loss:0.713156, Acc_avg:53.25% Training_loss_avg:0.691774\n",
            "Epoch:4 Step:2584 Training_loss:0.707551, Acc_avg:53.00% Training_loss_avg:0.692142\n",
            "Epoch:4 Step:2592 Training_loss:0.691213, Acc_avg:53.25% Training_loss_avg:0.691821\n",
            "Epoch:4 Step:2600 Training_loss:0.711462, Acc_avg:52.75% Training_loss_avg:0.691985\n",
            "Epoch:4 Step:2608 Training_loss:0.721023, Acc_avg:52.50% Training_loss_avg:0.692738\n",
            "Epoch:4 Step:2616 Training_loss:0.669755, Acc_avg:52.25% Training_loss_avg:0.692619\n",
            "Epoch:4 Step:2624 Training_loss:0.678045, Acc_avg:52.25% Training_loss_avg:0.692525\n",
            "Epoch:4 Step:2632 Training_loss:0.693115, Acc_avg:51.75% Training_loss_avg:0.692829\n",
            "Epoch:4 Step:2640 Training_loss:0.632622, Acc_avg:52.25% Training_loss_avg:0.691934\n",
            "Epoch:4 Step:2648 Training_loss:0.681957, Acc_avg:52.75% Training_loss_avg:0.691695\n",
            "Epoch:4 Step:2656 Training_loss:0.699597, Acc_avg:53.25% Training_loss_avg:0.691362\n",
            "Epoch:4 Step:2664 Training_loss:0.700346, Acc_avg:53.25% Training_loss_avg:0.691650\n",
            "Epoch:4 Step:2672 Training_loss:0.666627, Acc_avg:54.25% Training_loss_avg:0.690699\n",
            "Epoch:4 Step:2680 Training_loss:0.678375, Acc_avg:54.25% Training_loss_avg:0.690823\n",
            "Epoch:4 Step:2688 Training_loss:0.699532, Acc_avg:54.25% Training_loss_avg:0.691147\n",
            "Epoch:4 Step:2696 Training_loss:0.629873, Acc_avg:55.00% Training_loss_avg:0.689630\n",
            "Epoch:4 Step:2704 Training_loss:0.673060, Acc_avg:55.00% Training_loss_avg:0.689367\n",
            "Epoch:4 Step:2712 Training_loss:0.626290, Acc_avg:55.25% Training_loss_avg:0.688537\n",
            "Epoch:4 Step:2720 Training_loss:0.679154, Acc_avg:55.25% Training_loss_avg:0.688595\n",
            "Epoch:4 Step:2728 Training_loss:0.758460, Acc_avg:54.25% Training_loss_avg:0.690256\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:2728 Val_loss:0.689732, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:2736 Training_loss:0.661500, Acc_avg:54.75% Training_loss_avg:0.689266\n",
            "Epoch:4 Step:2744 Training_loss:0.698792, Acc_avg:55.00% Training_loss_avg:0.689025\n",
            "Epoch:4 Step:2752 Training_loss:0.696682, Acc_avg:54.75% Training_loss_avg:0.689278\n",
            "Epoch:4 Step:2760 Training_loss:0.684644, Acc_avg:55.00% Training_loss_avg:0.688933\n",
            "Epoch:4 Step:2768 Training_loss:0.649919, Acc_avg:55.25% Training_loss_avg:0.687974\n",
            "Epoch:4 Step:2776 Training_loss:0.658310, Acc_avg:55.00% Training_loss_avg:0.687735\n",
            "Epoch:4 Step:2784 Training_loss:0.664840, Acc_avg:55.50% Training_loss_avg:0.686763\n",
            "Epoch:4 Step:2792 Training_loss:0.681501, Acc_avg:55.75% Training_loss_avg:0.686137\n",
            "Epoch:4 Step:2800 Training_loss:0.767145, Acc_avg:55.00% Training_loss_avg:0.688366\n",
            "Epoch:4 Step:2808 Training_loss:0.858269, Acc_avg:54.75% Training_loss_avg:0.691121\n",
            "Epoch:4 Step:2816 Training_loss:0.642874, Acc_avg:55.00% Training_loss_avg:0.690432\n",
            "Epoch:4 Step:2824 Training_loss:0.616738, Acc_avg:56.00% Training_loss_avg:0.688583\n",
            "Epoch:4 Step:2832 Training_loss:0.704430, Acc_avg:56.25% Training_loss_avg:0.687696\n",
            "Epoch:4 Step:2840 Training_loss:0.685093, Acc_avg:56.25% Training_loss_avg:0.687522\n",
            "Epoch:4 Step:2848 Training_loss:0.672949, Acc_avg:56.75% Training_loss_avg:0.686768\n",
            "Epoch:4 Step:2856 Training_loss:0.752788, Acc_avg:56.00% Training_loss_avg:0.688590\n",
            "Epoch:4 Step:2864 Training_loss:0.657247, Acc_avg:55.75% Training_loss_avg:0.687996\n",
            "Epoch:4 Step:2872 Training_loss:0.628085, Acc_avg:55.50% Training_loss_avg:0.687617\n",
            "Epoch:4 Step:2880 Training_loss:0.695354, Acc_avg:55.50% Training_loss_avg:0.688035\n",
            "Epoch:4 Step:2888 Training_loss:0.723442, Acc_avg:55.75% Training_loss_avg:0.688498\n",
            "Epoch:4 Step:2896 Training_loss:0.675021, Acc_avg:56.25% Training_loss_avg:0.687726\n",
            "Epoch:4 Step:2904 Training_loss:0.738518, Acc_avg:56.00% Training_loss_avg:0.688094\n",
            "Epoch:4 Step:2912 Training_loss:0.662903, Acc_avg:56.25% Training_loss_avg:0.687435\n",
            "Epoch:4 Step:2920 Training_loss:0.641777, Acc_avg:56.25% Training_loss_avg:0.686758\n",
            "Epoch:4 Step:2928 Training_loss:0.688414, Acc_avg:56.50% Training_loss_avg:0.686358\n",
            "Epoch:4 Step:2936 Training_loss:0.742208, Acc_avg:56.00% Training_loss_avg:0.687700\n",
            "Epoch:4 Step:2944 Training_loss:0.750191, Acc_avg:55.25% Training_loss_avg:0.689024\n",
            "Epoch:4 Step:2952 Training_loss:0.631348, Acc_avg:55.50% Training_loss_avg:0.688130\n",
            "Epoch:4 Step:2960 Training_loss:0.767888, Acc_avg:55.00% Training_loss_avg:0.690003\n",
            "Epoch:4 Step:2968 Training_loss:0.750970, Acc_avg:54.75% Training_loss_avg:0.691221\n",
            "Epoch:4 Step:2976 Training_loss:0.676490, Acc_avg:55.25% Training_loss_avg:0.690488\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:2976 Val_loss:0.689415, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:2984 Training_loss:0.676128, Acc_avg:55.50% Training_loss_avg:0.689859\n",
            "Epoch:4 Step:2992 Training_loss:0.789602, Acc_avg:55.00% Training_loss_avg:0.691827\n",
            "Epoch:4 Step:3000 Training_loss:0.702376, Acc_avg:55.25% Training_loss_avg:0.691645\n",
            "Epoch:4 Step:3008 Training_loss:0.679447, Acc_avg:56.00% Training_loss_avg:0.690814\n",
            "Epoch:4 Step:3016 Training_loss:0.652764, Acc_avg:56.25% Training_loss_avg:0.690474\n",
            "Epoch:4 Step:3024 Training_loss:0.684437, Acc_avg:56.25% Training_loss_avg:0.690602\n",
            "Epoch:4 Step:3032 Training_loss:0.700319, Acc_avg:56.25% Training_loss_avg:0.690746\n",
            "Epoch:4 Step:3040 Training_loss:0.635938, Acc_avg:56.50% Training_loss_avg:0.690812\n",
            "Epoch:4 Step:3048 Training_loss:0.651998, Acc_avg:57.00% Training_loss_avg:0.690213\n",
            "Epoch:4 Step:3056 Training_loss:0.725900, Acc_avg:56.50% Training_loss_avg:0.690739\n",
            "Epoch:4 Step:3064 Training_loss:0.735718, Acc_avg:55.75% Training_loss_avg:0.691447\n",
            "Epoch:4 Step:3072 Training_loss:0.679930, Acc_avg:55.50% Training_loss_avg:0.691713\n",
            "Epoch:4 Step:3080 Training_loss:0.689067, Acc_avg:55.25% Training_loss_avg:0.691926\n",
            "Epoch:4 Step:3088 Training_loss:0.667024, Acc_avg:55.50% Training_loss_avg:0.691276\n",
            "Epoch:4 Step:3096 Training_loss:0.705886, Acc_avg:54.75% Training_loss_avg:0.692797\n",
            "Epoch:4 Step:3104 Training_loss:0.681510, Acc_avg:54.75% Training_loss_avg:0.692966\n",
            "Epoch:4 Step:3112 Training_loss:0.733572, Acc_avg:53.50% Training_loss_avg:0.695111\n",
            "Epoch:4 Step:3120 Training_loss:0.697199, Acc_avg:53.25% Training_loss_avg:0.695472\n",
            "Epoch:4 Step:3128 Training_loss:0.729290, Acc_avg:53.75% Training_loss_avg:0.694889\n",
            "Epoch:4 Step:3136 Training_loss:0.696402, Acc_avg:53.50% Training_loss_avg:0.695587\n",
            "Epoch:4 Step:3144 Training_loss:0.683654, Acc_avg:53.75% Training_loss_avg:0.695284\n",
            "Epoch:4 Step:3152 Training_loss:0.728442, Acc_avg:53.00% Training_loss_avg:0.695919\n",
            "Epoch:4 Step:3160 Training_loss:0.677925, Acc_avg:53.50% Training_loss_avg:0.695785\n",
            "Epoch:4 Step:3168 Training_loss:0.687200, Acc_avg:53.25% Training_loss_avg:0.696530\n",
            "Epoch:4 Step:3176 Training_loss:0.666844, Acc_avg:53.75% Training_loss_avg:0.696701\n",
            "Epoch:4 Step:3184 Training_loss:0.679796, Acc_avg:54.00% Training_loss_avg:0.697000\n",
            "Epoch:4 Step:3192 Training_loss:0.676152, Acc_avg:54.25% Training_loss_avg:0.696893\n",
            "Epoch:4 Step:3200 Training_loss:0.687377, Acc_avg:55.00% Training_loss_avg:0.695298\n",
            "Epoch:4 Step:3208 Training_loss:0.708190, Acc_avg:55.50% Training_loss_avg:0.692296\n",
            "Epoch:4 Step:3216 Training_loss:0.720346, Acc_avg:54.50% Training_loss_avg:0.693846\n",
            "Epoch:4 Step:3224 Training_loss:0.694939, Acc_avg:53.75% Training_loss_avg:0.695410\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:4 Step:3224 Val_loss:0.690396, Val_Acc_avg:54.75%\n",
            "Epoch:4 Step:3232 Training_loss:0.694982, Acc_avg:53.75% Training_loss_avg:0.695221\n",
            "Epoch:4 Step:3240 Training_loss:0.679275, Acc_avg:54.00% Training_loss_avg:0.695104\n",
            "Epoch:4 Step:3248 Training_loss:0.681982, Acc_avg:54.00% Training_loss_avg:0.695285\n",
            "Epoch:4 Step:3256 Training_loss:0.694223, Acc_avg:54.25% Training_loss_avg:0.694114\n",
            "Epoch:4 Step:3264 Training_loss:0.688099, Acc_avg:54.25% Training_loss_avg:0.694731\n",
            "Epoch:4 Step:3272 Training_loss:0.681785, Acc_avg:54.00% Training_loss_avg:0.695805\n",
            "Epoch:4 Step:3280 Training_loss:0.646374, Acc_avg:54.75% Training_loss_avg:0.694825\n",
            "Epoch:4 Step:3288 Training_loss:0.683718, Acc_avg:55.00% Training_loss_avg:0.694031\n",
            "Epoch:4 Step:3296 Training_loss:0.687078, Acc_avg:54.75% Training_loss_avg:0.694272\n",
            "Epoch:4 Step:3304 Training_loss:0.696507, Acc_avg:55.00% Training_loss_avg:0.693432\n",
            "Epoch:4 Step:3312 Training_loss:0.673314, Acc_avg:55.25% Training_loss_avg:0.693640\n",
            "Epoch:4 Step:3320 Training_loss:0.636332, Acc_avg:55.50% Training_loss_avg:0.693531\n",
            "Epoch:4 Step:3328 Training_loss:0.675075, Acc_avg:55.58% Training_loss_avg:0.693264\n",
            "Epoch:5 Step:0 Training_loss:0.678443, Acc_avg:56.08% Training_loss_avg:0.691989\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:0 Val_loss:0.689400, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:8 Training_loss:0.637885, Acc_avg:57.08% Training_loss_avg:0.689743\n",
            "Epoch:5 Step:16 Training_loss:0.746261, Acc_avg:56.58% Training_loss_avg:0.692041\n",
            "Epoch:5 Step:24 Training_loss:0.693920, Acc_avg:57.08% Training_loss_avg:0.690562\n",
            "Epoch:5 Step:32 Training_loss:0.711072, Acc_avg:57.33% Training_loss_avg:0.689764\n",
            "Epoch:5 Step:40 Training_loss:0.707648, Acc_avg:57.08% Training_loss_avg:0.690387\n",
            "Epoch:5 Step:48 Training_loss:0.769661, Acc_avg:56.33% Training_loss_avg:0.692258\n",
            "Epoch:5 Step:56 Training_loss:0.782958, Acc_avg:56.08% Training_loss_avg:0.692125\n",
            "Epoch:5 Step:64 Training_loss:0.681936, Acc_avg:56.33% Training_loss_avg:0.691716\n",
            "Epoch:5 Step:72 Training_loss:0.698592, Acc_avg:55.83% Training_loss_avg:0.692099\n",
            "Epoch:5 Step:80 Training_loss:0.719530, Acc_avg:55.08% Training_loss_avg:0.693434\n",
            "Epoch:5 Step:88 Training_loss:0.696806, Acc_avg:55.08% Training_loss_avg:0.693682\n",
            "Epoch:5 Step:96 Training_loss:0.594371, Acc_avg:56.08% Training_loss_avg:0.691563\n",
            "Epoch:5 Step:104 Training_loss:0.753102, Acc_avg:54.83% Training_loss_avg:0.693906\n",
            "Epoch:5 Step:112 Training_loss:0.685535, Acc_avg:54.08% Training_loss_avg:0.694577\n",
            "Epoch:5 Step:120 Training_loss:0.663905, Acc_avg:55.08% Training_loss_avg:0.693337\n",
            "Epoch:5 Step:128 Training_loss:0.714761, Acc_avg:55.83% Training_loss_avg:0.692918\n",
            "Epoch:5 Step:136 Training_loss:0.681582, Acc_avg:55.83% Training_loss_avg:0.692951\n",
            "Epoch:5 Step:144 Training_loss:0.703633, Acc_avg:55.58% Training_loss_avg:0.693242\n",
            "Epoch:5 Step:152 Training_loss:0.725503, Acc_avg:54.83% Training_loss_avg:0.694411\n",
            "Epoch:5 Step:160 Training_loss:0.684957, Acc_avg:55.08% Training_loss_avg:0.693993\n",
            "Epoch:5 Step:168 Training_loss:0.738489, Acc_avg:54.33% Training_loss_avg:0.695132\n",
            "Epoch:5 Step:176 Training_loss:0.673484, Acc_avg:55.08% Training_loss_avg:0.693931\n",
            "Epoch:5 Step:184 Training_loss:0.717065, Acc_avg:54.83% Training_loss_avg:0.694328\n",
            "Epoch:5 Step:192 Training_loss:0.672889, Acc_avg:55.08% Training_loss_avg:0.693200\n",
            "Epoch:5 Step:200 Training_loss:0.666983, Acc_avg:55.58% Training_loss_avg:0.692612\n",
            "Epoch:5 Step:208 Training_loss:0.657086, Acc_avg:55.83% Training_loss_avg:0.692080\n",
            "Epoch:5 Step:216 Training_loss:0.690322, Acc_avg:56.83% Training_loss_avg:0.691318\n",
            "Epoch:5 Step:224 Training_loss:0.695109, Acc_avg:56.33% Training_loss_avg:0.691662\n",
            "Epoch:5 Step:232 Training_loss:0.687447, Acc_avg:56.58% Training_loss_avg:0.691666\n",
            "Epoch:5 Step:240 Training_loss:0.682597, Acc_avg:56.33% Training_loss_avg:0.691982\n",
            "Epoch:5 Step:248 Training_loss:0.715767, Acc_avg:55.33% Training_loss_avg:0.692701\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:248 Val_loss:0.689861, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:256 Training_loss:0.666554, Acc_avg:55.33% Training_loss_avg:0.692509\n",
            "Epoch:5 Step:264 Training_loss:0.709725, Acc_avg:54.83% Training_loss_avg:0.692956\n",
            "Epoch:5 Step:272 Training_loss:0.677613, Acc_avg:55.33% Training_loss_avg:0.692344\n",
            "Epoch:5 Step:280 Training_loss:0.688305, Acc_avg:56.08% Training_loss_avg:0.691704\n",
            "Epoch:5 Step:288 Training_loss:0.715737, Acc_avg:55.58% Training_loss_avg:0.692120\n",
            "Epoch:5 Step:296 Training_loss:0.726997, Acc_avg:55.08% Training_loss_avg:0.692760\n",
            "Epoch:5 Step:304 Training_loss:0.685627, Acc_avg:55.08% Training_loss_avg:0.692887\n",
            "Epoch:5 Step:312 Training_loss:0.697523, Acc_avg:55.08% Training_loss_avg:0.693198\n",
            "Epoch:5 Step:320 Training_loss:0.688043, Acc_avg:55.08% Training_loss_avg:0.693074\n",
            "Epoch:5 Step:328 Training_loss:0.686056, Acc_avg:55.08% Training_loss_avg:0.693033\n",
            "Epoch:5 Step:336 Training_loss:0.695464, Acc_avg:54.83% Training_loss_avg:0.693307\n",
            "Epoch:5 Step:344 Training_loss:0.684759, Acc_avg:54.08% Training_loss_avg:0.694075\n",
            "Epoch:5 Step:352 Training_loss:0.682116, Acc_avg:54.58% Training_loss_avg:0.694042\n",
            "Epoch:5 Step:360 Training_loss:0.698647, Acc_avg:54.33% Training_loss_avg:0.694274\n",
            "Epoch:5 Step:368 Training_loss:0.693593, Acc_avg:54.33% Training_loss_avg:0.694216\n",
            "Epoch:5 Step:376 Training_loss:0.678500, Acc_avg:54.08% Training_loss_avg:0.694319\n",
            "Epoch:5 Step:384 Training_loss:0.691180, Acc_avg:53.33% Training_loss_avg:0.695416\n",
            "Epoch:5 Step:392 Training_loss:0.679276, Acc_avg:53.25% Training_loss_avg:0.695500\n",
            "Epoch:5 Step:400 Training_loss:0.705522, Acc_avg:52.75% Training_loss_avg:0.696042\n",
            "Epoch:5 Step:408 Training_loss:0.701470, Acc_avg:52.00% Training_loss_avg:0.697314\n",
            "Epoch:5 Step:416 Training_loss:0.692017, Acc_avg:52.00% Training_loss_avg:0.696229\n",
            "Epoch:5 Step:424 Training_loss:0.662482, Acc_avg:52.50% Training_loss_avg:0.695600\n",
            "Epoch:5 Step:432 Training_loss:0.702450, Acc_avg:52.25% Training_loss_avg:0.695427\n",
            "Epoch:5 Step:440 Training_loss:0.677550, Acc_avg:52.75% Training_loss_avg:0.694826\n",
            "Epoch:5 Step:448 Training_loss:0.695332, Acc_avg:53.25% Training_loss_avg:0.693339\n",
            "Epoch:5 Step:456 Training_loss:0.697232, Acc_avg:54.00% Training_loss_avg:0.691624\n",
            "Epoch:5 Step:464 Training_loss:0.680045, Acc_avg:54.00% Training_loss_avg:0.691587\n",
            "Epoch:5 Step:472 Training_loss:0.668794, Acc_avg:54.50% Training_loss_avg:0.690991\n",
            "Epoch:5 Step:480 Training_loss:0.662282, Acc_avg:55.25% Training_loss_avg:0.689846\n",
            "Epoch:5 Step:488 Training_loss:0.715592, Acc_avg:55.00% Training_loss_avg:0.690221\n",
            "Epoch:5 Step:496 Training_loss:0.662453, Acc_avg:54.50% Training_loss_avg:0.691583\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:496 Val_loss:0.689401, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:504 Training_loss:0.656176, Acc_avg:55.25% Training_loss_avg:0.689644\n",
            "Epoch:5 Step:512 Training_loss:0.757768, Acc_avg:54.75% Training_loss_avg:0.691089\n",
            "Epoch:5 Step:520 Training_loss:0.697069, Acc_avg:54.25% Training_loss_avg:0.691752\n",
            "Epoch:5 Step:528 Training_loss:0.713102, Acc_avg:54.00% Training_loss_avg:0.691719\n",
            "Epoch:5 Step:536 Training_loss:0.698771, Acc_avg:53.75% Training_loss_avg:0.692063\n",
            "Epoch:5 Step:544 Training_loss:0.711484, Acc_avg:53.50% Training_loss_avg:0.692220\n",
            "Epoch:5 Step:552 Training_loss:0.651579, Acc_avg:54.25% Training_loss_avg:0.690742\n",
            "Epoch:5 Step:560 Training_loss:0.697595, Acc_avg:54.25% Training_loss_avg:0.690994\n",
            "Epoch:5 Step:568 Training_loss:0.664106, Acc_avg:55.00% Training_loss_avg:0.689507\n",
            "Epoch:5 Step:576 Training_loss:0.770139, Acc_avg:54.25% Training_loss_avg:0.691440\n",
            "Epoch:5 Step:584 Training_loss:0.707061, Acc_avg:54.25% Training_loss_avg:0.691240\n",
            "Epoch:5 Step:592 Training_loss:0.709050, Acc_avg:53.75% Training_loss_avg:0.691963\n",
            "Epoch:5 Step:600 Training_loss:0.686044, Acc_avg:53.50% Training_loss_avg:0.692344\n",
            "Epoch:5 Step:608 Training_loss:0.698168, Acc_avg:53.00% Training_loss_avg:0.693166\n",
            "Epoch:5 Step:616 Training_loss:0.670111, Acc_avg:53.00% Training_loss_avg:0.692761\n",
            "Epoch:5 Step:624 Training_loss:0.682296, Acc_avg:53.25% Training_loss_avg:0.692505\n",
            "Epoch:5 Step:632 Training_loss:0.663502, Acc_avg:53.50% Training_loss_avg:0.692026\n",
            "Epoch:5 Step:640 Training_loss:0.689154, Acc_avg:53.25% Training_loss_avg:0.692157\n",
            "Epoch:5 Step:648 Training_loss:0.671322, Acc_avg:54.25% Training_loss_avg:0.691269\n",
            "Epoch:5 Step:656 Training_loss:0.705516, Acc_avg:53.50% Training_loss_avg:0.692048\n",
            "Epoch:5 Step:664 Training_loss:0.648944, Acc_avg:54.25% Training_loss_avg:0.690832\n",
            "Epoch:5 Step:672 Training_loss:0.654561, Acc_avg:54.25% Training_loss_avg:0.690371\n",
            "Epoch:5 Step:680 Training_loss:0.689938, Acc_avg:54.00% Training_loss_avg:0.690404\n",
            "Epoch:5 Step:688 Training_loss:0.695719, Acc_avg:54.75% Training_loss_avg:0.690003\n",
            "Epoch:5 Step:696 Training_loss:0.707234, Acc_avg:55.25% Training_loss_avg:0.689608\n",
            "Epoch:5 Step:704 Training_loss:0.703673, Acc_avg:54.75% Training_loss_avg:0.689969\n",
            "Epoch:5 Step:712 Training_loss:0.681738, Acc_avg:54.50% Training_loss_avg:0.689653\n",
            "Epoch:5 Step:720 Training_loss:0.675259, Acc_avg:55.00% Training_loss_avg:0.689398\n",
            "Epoch:5 Step:728 Training_loss:0.691777, Acc_avg:54.75% Training_loss_avg:0.689512\n",
            "Epoch:5 Step:736 Training_loss:0.643918, Acc_avg:55.25% Training_loss_avg:0.688481\n",
            "Epoch:5 Step:744 Training_loss:0.661886, Acc_avg:55.50% Training_loss_avg:0.688024\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:744 Val_loss:0.689449, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:752 Training_loss:0.661620, Acc_avg:55.50% Training_loss_avg:0.687614\n",
            "Epoch:5 Step:760 Training_loss:0.671688, Acc_avg:56.00% Training_loss_avg:0.687075\n",
            "Epoch:5 Step:768 Training_loss:0.696101, Acc_avg:56.25% Training_loss_avg:0.687125\n",
            "Epoch:5 Step:776 Training_loss:0.648116, Acc_avg:56.50% Training_loss_avg:0.686517\n",
            "Epoch:5 Step:784 Training_loss:0.720864, Acc_avg:56.25% Training_loss_avg:0.687111\n",
            "Epoch:5 Step:792 Training_loss:0.712674, Acc_avg:56.00% Training_loss_avg:0.687779\n",
            "Epoch:5 Step:800 Training_loss:0.675823, Acc_avg:56.50% Training_loss_avg:0.687185\n",
            "Epoch:5 Step:808 Training_loss:0.632066, Acc_avg:57.25% Training_loss_avg:0.685797\n",
            "Epoch:5 Step:816 Training_loss:0.657582, Acc_avg:57.75% Training_loss_avg:0.685108\n",
            "Epoch:5 Step:824 Training_loss:0.675563, Acc_avg:57.00% Training_loss_avg:0.685370\n",
            "Epoch:5 Step:832 Training_loss:0.680054, Acc_avg:57.50% Training_loss_avg:0.684922\n",
            "Epoch:5 Step:840 Training_loss:0.779651, Acc_avg:56.50% Training_loss_avg:0.686964\n",
            "Epoch:5 Step:848 Training_loss:0.631172, Acc_avg:57.25% Training_loss_avg:0.685681\n",
            "Epoch:5 Step:856 Training_loss:0.718488, Acc_avg:57.25% Training_loss_avg:0.686106\n",
            "Epoch:5 Step:864 Training_loss:0.637027, Acc_avg:57.50% Training_loss_avg:0.685245\n",
            "Epoch:5 Step:872 Training_loss:0.778493, Acc_avg:56.50% Training_loss_avg:0.687439\n",
            "Epoch:5 Step:880 Training_loss:0.580489, Acc_avg:56.75% Training_loss_avg:0.685803\n",
            "Epoch:5 Step:888 Training_loss:0.671717, Acc_avg:57.25% Training_loss_avg:0.684926\n",
            "Epoch:5 Step:896 Training_loss:0.732586, Acc_avg:56.50% Training_loss_avg:0.686329\n",
            "Epoch:5 Step:904 Training_loss:0.652926, Acc_avg:56.50% Training_loss_avg:0.686264\n",
            "Epoch:5 Step:912 Training_loss:0.674764, Acc_avg:57.25% Training_loss_avg:0.684603\n",
            "Epoch:5 Step:920 Training_loss:0.627637, Acc_avg:57.75% Training_loss_avg:0.683215\n",
            "Epoch:5 Step:928 Training_loss:0.744498, Acc_avg:57.75% Training_loss_avg:0.683843\n",
            "Epoch:5 Step:936 Training_loss:0.706966, Acc_avg:57.75% Training_loss_avg:0.684007\n",
            "Epoch:5 Step:944 Training_loss:0.648277, Acc_avg:58.25% Training_loss_avg:0.682743\n",
            "Epoch:5 Step:952 Training_loss:0.705394, Acc_avg:57.75% Training_loss_avg:0.683819\n",
            "Epoch:5 Step:960 Training_loss:0.657083, Acc_avg:58.00% Training_loss_avg:0.683009\n",
            "Epoch:5 Step:968 Training_loss:0.678826, Acc_avg:58.00% Training_loss_avg:0.683303\n",
            "Epoch:5 Step:976 Training_loss:0.679248, Acc_avg:58.75% Training_loss_avg:0.681485\n",
            "Epoch:5 Step:984 Training_loss:0.711400, Acc_avg:59.00% Training_loss_avg:0.681572\n",
            "Epoch:5 Step:992 Training_loss:0.669861, Acc_avg:59.50% Training_loss_avg:0.680788\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:992 Val_loss:0.691569, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:1000 Training_loss:0.643687, Acc_avg:59.50% Training_loss_avg:0.679941\n",
            "Epoch:5 Step:1008 Training_loss:0.597096, Acc_avg:60.25% Training_loss_avg:0.677920\n",
            "Epoch:5 Step:1016 Training_loss:0.733723, Acc_avg:60.00% Training_loss_avg:0.679192\n",
            "Epoch:5 Step:1024 Training_loss:0.532469, Acc_avg:60.75% Training_loss_avg:0.676195\n",
            "Epoch:5 Step:1032 Training_loss:0.714178, Acc_avg:60.25% Training_loss_avg:0.677209\n",
            "Epoch:5 Step:1040 Training_loss:0.774708, Acc_avg:60.00% Training_loss_avg:0.678920\n",
            "Epoch:5 Step:1048 Training_loss:0.706029, Acc_avg:59.50% Training_loss_avg:0.679614\n",
            "Epoch:5 Step:1056 Training_loss:0.637931, Acc_avg:60.00% Training_loss_avg:0.678262\n",
            "Epoch:5 Step:1064 Training_loss:0.666731, Acc_avg:59.75% Training_loss_avg:0.678618\n",
            "Epoch:5 Step:1072 Training_loss:0.612021, Acc_avg:60.00% Training_loss_avg:0.677767\n",
            "Epoch:5 Step:1080 Training_loss:0.671517, Acc_avg:60.25% Training_loss_avg:0.677399\n",
            "Epoch:5 Step:1088 Training_loss:0.707816, Acc_avg:60.00% Training_loss_avg:0.677641\n",
            "Epoch:5 Step:1096 Training_loss:0.807761, Acc_avg:59.50% Training_loss_avg:0.679651\n",
            "Epoch:5 Step:1104 Training_loss:0.771047, Acc_avg:59.50% Training_loss_avg:0.680999\n",
            "Epoch:5 Step:1112 Training_loss:0.651749, Acc_avg:59.75% Training_loss_avg:0.680399\n",
            "Epoch:5 Step:1120 Training_loss:0.745717, Acc_avg:59.00% Training_loss_avg:0.681808\n",
            "Epoch:5 Step:1128 Training_loss:0.788205, Acc_avg:58.50% Training_loss_avg:0.683737\n",
            "Epoch:5 Step:1136 Training_loss:0.715196, Acc_avg:57.75% Training_loss_avg:0.685162\n",
            "Epoch:5 Step:1144 Training_loss:0.709865, Acc_avg:57.25% Training_loss_avg:0.686122\n",
            "Epoch:5 Step:1152 Training_loss:0.690746, Acc_avg:56.75% Training_loss_avg:0.686705\n",
            "Epoch:5 Step:1160 Training_loss:0.676289, Acc_avg:56.75% Training_loss_avg:0.686797\n",
            "Epoch:5 Step:1168 Training_loss:0.685770, Acc_avg:56.50% Training_loss_avg:0.686590\n",
            "Epoch:5 Step:1176 Training_loss:0.685183, Acc_avg:56.25% Training_loss_avg:0.687331\n",
            "Epoch:5 Step:1184 Training_loss:0.684993, Acc_avg:56.75% Training_loss_avg:0.686614\n",
            "Epoch:5 Step:1192 Training_loss:0.683848, Acc_avg:57.00% Training_loss_avg:0.686037\n",
            "Epoch:5 Step:1200 Training_loss:0.669747, Acc_avg:57.50% Training_loss_avg:0.685916\n",
            "Epoch:5 Step:1208 Training_loss:0.680869, Acc_avg:57.25% Training_loss_avg:0.686892\n",
            "Epoch:5 Step:1216 Training_loss:0.699472, Acc_avg:56.50% Training_loss_avg:0.687730\n",
            "Epoch:5 Step:1224 Training_loss:0.699008, Acc_avg:56.50% Training_loss_avg:0.688199\n",
            "Epoch:5 Step:1232 Training_loss:0.704309, Acc_avg:56.25% Training_loss_avg:0.688684\n",
            "Epoch:5 Step:1240 Training_loss:0.676443, Acc_avg:57.00% Training_loss_avg:0.686620\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:1240 Val_loss:0.690260, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:1248 Training_loss:0.683569, Acc_avg:56.50% Training_loss_avg:0.687667\n",
            "Epoch:5 Step:1256 Training_loss:0.679958, Acc_avg:56.75% Training_loss_avg:0.686897\n",
            "Epoch:5 Step:1264 Training_loss:0.746372, Acc_avg:55.50% Training_loss_avg:0.689084\n",
            "Epoch:5 Step:1272 Training_loss:0.679908, Acc_avg:56.25% Training_loss_avg:0.687112\n",
            "Epoch:5 Step:1280 Training_loss:0.723005, Acc_avg:55.25% Training_loss_avg:0.689962\n",
            "Epoch:5 Step:1288 Training_loss:0.703128, Acc_avg:55.00% Training_loss_avg:0.690591\n",
            "Epoch:5 Step:1296 Training_loss:0.662508, Acc_avg:56.00% Training_loss_avg:0.689189\n",
            "Epoch:5 Step:1304 Training_loss:0.679871, Acc_avg:56.00% Training_loss_avg:0.689728\n",
            "Epoch:5 Step:1312 Training_loss:0.676311, Acc_avg:56.25% Training_loss_avg:0.689759\n",
            "Epoch:5 Step:1320 Training_loss:0.687947, Acc_avg:55.75% Training_loss_avg:0.690965\n",
            "Epoch:5 Step:1328 Training_loss:0.683248, Acc_avg:56.25% Training_loss_avg:0.689740\n",
            "Epoch:5 Step:1336 Training_loss:0.667234, Acc_avg:56.75% Training_loss_avg:0.688945\n",
            "Epoch:5 Step:1344 Training_loss:0.697546, Acc_avg:56.50% Training_loss_avg:0.689931\n",
            "Epoch:5 Step:1352 Training_loss:0.739316, Acc_avg:56.00% Training_loss_avg:0.690609\n",
            "Epoch:5 Step:1360 Training_loss:0.686013, Acc_avg:56.00% Training_loss_avg:0.691188\n",
            "Epoch:5 Step:1368 Training_loss:0.665541, Acc_avg:56.00% Training_loss_avg:0.690922\n",
            "Epoch:5 Step:1376 Training_loss:0.629312, Acc_avg:56.75% Training_loss_avg:0.689923\n",
            "Epoch:5 Step:1384 Training_loss:0.695115, Acc_avg:56.75% Training_loss_avg:0.689598\n",
            "Epoch:5 Step:1392 Training_loss:0.767076, Acc_avg:55.75% Training_loss_avg:0.691542\n",
            "Epoch:5 Step:1400 Training_loss:0.685660, Acc_avg:55.75% Training_loss_avg:0.692381\n",
            "Epoch:5 Step:1408 Training_loss:0.718234, Acc_avg:54.75% Training_loss_avg:0.694804\n",
            "Epoch:5 Step:1416 Training_loss:0.681773, Acc_avg:55.00% Training_loss_avg:0.693765\n",
            "Epoch:5 Step:1424 Training_loss:0.670463, Acc_avg:54.25% Training_loss_avg:0.696525\n",
            "Epoch:5 Step:1432 Training_loss:0.730307, Acc_avg:54.00% Training_loss_avg:0.696848\n",
            "Epoch:5 Step:1440 Training_loss:0.664264, Acc_avg:54.75% Training_loss_avg:0.694639\n",
            "Epoch:5 Step:1448 Training_loss:0.661737, Acc_avg:55.25% Training_loss_avg:0.693753\n",
            "Epoch:5 Step:1456 Training_loss:0.692841, Acc_avg:55.00% Training_loss_avg:0.694851\n",
            "Epoch:5 Step:1464 Training_loss:0.691660, Acc_avg:54.75% Training_loss_avg:0.695350\n",
            "Epoch:5 Step:1472 Training_loss:0.659909, Acc_avg:54.75% Training_loss_avg:0.696307\n",
            "Epoch:5 Step:1480 Training_loss:0.643717, Acc_avg:55.00% Training_loss_avg:0.695751\n",
            "Epoch:5 Step:1488 Training_loss:0.677530, Acc_avg:55.25% Training_loss_avg:0.695146\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:1488 Val_loss:0.689433, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:1496 Training_loss:0.647760, Acc_avg:56.25% Training_loss_avg:0.691946\n",
            "Epoch:5 Step:1504 Training_loss:0.722348, Acc_avg:56.25% Training_loss_avg:0.690972\n",
            "Epoch:5 Step:1512 Training_loss:0.699694, Acc_avg:56.00% Training_loss_avg:0.691931\n",
            "Epoch:5 Step:1520 Training_loss:0.672891, Acc_avg:56.50% Training_loss_avg:0.690474\n",
            "Epoch:5 Step:1528 Training_loss:0.695436, Acc_avg:57.00% Training_loss_avg:0.688619\n",
            "Epoch:5 Step:1536 Training_loss:0.760157, Acc_avg:56.75% Training_loss_avg:0.689518\n",
            "Epoch:5 Step:1544 Training_loss:0.642868, Acc_avg:57.25% Training_loss_avg:0.688178\n",
            "Epoch:5 Step:1552 Training_loss:0.640379, Acc_avg:57.75% Training_loss_avg:0.687171\n",
            "Epoch:5 Step:1560 Training_loss:0.731011, Acc_avg:57.25% Training_loss_avg:0.688265\n",
            "Epoch:5 Step:1568 Training_loss:0.717601, Acc_avg:57.25% Training_loss_avg:0.688902\n",
            "Epoch:5 Step:1576 Training_loss:0.662507, Acc_avg:57.25% Training_loss_avg:0.688448\n",
            "Epoch:5 Step:1584 Training_loss:0.709258, Acc_avg:57.00% Training_loss_avg:0.688934\n",
            "Epoch:5 Step:1592 Training_loss:0.736994, Acc_avg:56.50% Training_loss_avg:0.689996\n",
            "Epoch:5 Step:1600 Training_loss:0.726857, Acc_avg:55.50% Training_loss_avg:0.691139\n",
            "Epoch:5 Step:1608 Training_loss:0.760119, Acc_avg:54.75% Training_loss_avg:0.692724\n",
            "Epoch:5 Step:1616 Training_loss:0.673981, Acc_avg:55.25% Training_loss_avg:0.692214\n",
            "Epoch:5 Step:1624 Training_loss:0.749572, Acc_avg:54.75% Training_loss_avg:0.693225\n",
            "Epoch:5 Step:1632 Training_loss:0.695522, Acc_avg:54.75% Training_loss_avg:0.693049\n",
            "Epoch:5 Step:1640 Training_loss:0.699199, Acc_avg:54.50% Training_loss_avg:0.693505\n",
            "Epoch:5 Step:1648 Training_loss:0.751377, Acc_avg:53.50% Training_loss_avg:0.694861\n",
            "Epoch:5 Step:1656 Training_loss:0.683791, Acc_avg:53.50% Training_loss_avg:0.694937\n",
            "Epoch:5 Step:1664 Training_loss:0.685145, Acc_avg:54.50% Training_loss_avg:0.693713\n",
            "Epoch:5 Step:1672 Training_loss:0.679573, Acc_avg:54.50% Training_loss_avg:0.693706\n",
            "Epoch:5 Step:1680 Training_loss:0.702036, Acc_avg:54.50% Training_loss_avg:0.693287\n",
            "Epoch:5 Step:1688 Training_loss:0.672368, Acc_avg:55.00% Training_loss_avg:0.692672\n",
            "Epoch:5 Step:1696 Training_loss:0.686350, Acc_avg:54.50% Training_loss_avg:0.693148\n",
            "Epoch:5 Step:1704 Training_loss:0.682269, Acc_avg:54.50% Training_loss_avg:0.693196\n",
            "Epoch:5 Step:1712 Training_loss:0.681310, Acc_avg:54.25% Training_loss_avg:0.693296\n",
            "Epoch:5 Step:1720 Training_loss:0.707487, Acc_avg:54.00% Training_loss_avg:0.693687\n",
            "Epoch:5 Step:1728 Training_loss:0.697252, Acc_avg:53.75% Training_loss_avg:0.693967\n",
            "Epoch:5 Step:1736 Training_loss:0.683730, Acc_avg:53.50% Training_loss_avg:0.694297\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:1736 Val_loss:0.690714, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:1744 Training_loss:0.666356, Acc_avg:54.25% Training_loss_avg:0.693673\n",
            "Epoch:5 Step:1752 Training_loss:0.709818, Acc_avg:54.50% Training_loss_avg:0.693083\n",
            "Epoch:5 Step:1760 Training_loss:0.687423, Acc_avg:54.25% Training_loss_avg:0.693112\n",
            "Epoch:5 Step:1768 Training_loss:0.676742, Acc_avg:54.50% Training_loss_avg:0.693336\n",
            "Epoch:5 Step:1776 Training_loss:0.713363, Acc_avg:53.25% Training_loss_avg:0.695017\n",
            "Epoch:5 Step:1784 Training_loss:0.690560, Acc_avg:53.25% Training_loss_avg:0.694925\n",
            "Epoch:5 Step:1792 Training_loss:0.676678, Acc_avg:54.25% Training_loss_avg:0.693118\n",
            "Epoch:5 Step:1800 Training_loss:0.707926, Acc_avg:53.75% Training_loss_avg:0.693563\n",
            "Epoch:5 Step:1808 Training_loss:0.671136, Acc_avg:54.50% Training_loss_avg:0.692621\n",
            "Epoch:5 Step:1816 Training_loss:0.720429, Acc_avg:53.75% Training_loss_avg:0.693394\n",
            "Epoch:5 Step:1824 Training_loss:0.699008, Acc_avg:53.50% Training_loss_avg:0.693965\n",
            "Epoch:5 Step:1832 Training_loss:0.673063, Acc_avg:54.25% Training_loss_avg:0.692820\n",
            "Epoch:5 Step:1840 Training_loss:0.718916, Acc_avg:53.25% Training_loss_avg:0.693913\n",
            "Epoch:5 Step:1848 Training_loss:0.668202, Acc_avg:53.25% Training_loss_avg:0.694042\n",
            "Epoch:5 Step:1856 Training_loss:0.683702, Acc_avg:53.50% Training_loss_avg:0.693860\n",
            "Epoch:5 Step:1864 Training_loss:0.708939, Acc_avg:53.25% Training_loss_avg:0.694205\n",
            "Epoch:5 Step:1872 Training_loss:0.691813, Acc_avg:52.75% Training_loss_avg:0.694843\n",
            "Epoch:5 Step:1880 Training_loss:0.735516, Acc_avg:51.75% Training_loss_avg:0.696679\n",
            "Epoch:5 Step:1888 Training_loss:0.631971, Acc_avg:52.25% Training_loss_avg:0.695768\n",
            "Epoch:5 Step:1896 Training_loss:0.724078, Acc_avg:51.50% Training_loss_avg:0.697294\n",
            "Epoch:5 Step:1904 Training_loss:0.680938, Acc_avg:52.00% Training_loss_avg:0.696466\n",
            "Epoch:5 Step:1912 Training_loss:0.666155, Acc_avg:52.25% Training_loss_avg:0.695795\n",
            "Epoch:5 Step:1920 Training_loss:0.695116, Acc_avg:52.00% Training_loss_avg:0.696240\n",
            "Epoch:5 Step:1928 Training_loss:0.680265, Acc_avg:52.00% Training_loss_avg:0.695936\n",
            "Epoch:5 Step:1936 Training_loss:0.673670, Acc_avg:52.75% Training_loss_avg:0.694207\n",
            "Epoch:5 Step:1944 Training_loss:0.704250, Acc_avg:52.25% Training_loss_avg:0.695434\n",
            "Epoch:5 Step:1952 Training_loss:0.707643, Acc_avg:51.50% Training_loss_avg:0.696780\n",
            "Epoch:5 Step:1960 Training_loss:0.741447, Acc_avg:51.50% Training_loss_avg:0.696988\n",
            "Epoch:5 Step:1968 Training_loss:0.714169, Acc_avg:51.50% Training_loss_avg:0.696920\n",
            "Epoch:5 Step:1976 Training_loss:0.682658, Acc_avg:51.50% Training_loss_avg:0.697323\n",
            "Epoch:5 Step:1984 Training_loss:0.666905, Acc_avg:52.00% Training_loss_avg:0.696476\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:1984 Val_loss:0.689438, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:1992 Training_loss:0.644122, Acc_avg:53.00% Training_loss_avg:0.694618\n",
            "Epoch:5 Step:2000 Training_loss:0.700789, Acc_avg:53.25% Training_loss_avg:0.694097\n",
            "Epoch:5 Step:2008 Training_loss:0.697660, Acc_avg:53.75% Training_loss_avg:0.692848\n",
            "Epoch:5 Step:2016 Training_loss:0.723055, Acc_avg:53.25% Training_loss_avg:0.693829\n",
            "Epoch:5 Step:2024 Training_loss:0.660684, Acc_avg:54.25% Training_loss_avg:0.692051\n",
            "Epoch:5 Step:2032 Training_loss:0.695355, Acc_avg:54.25% Training_loss_avg:0.692048\n",
            "Epoch:5 Step:2040 Training_loss:0.700945, Acc_avg:54.00% Training_loss_avg:0.692083\n",
            "Epoch:5 Step:2048 Training_loss:0.700443, Acc_avg:54.75% Training_loss_avg:0.691064\n",
            "Epoch:5 Step:2056 Training_loss:0.640258, Acc_avg:55.25% Training_loss_avg:0.690194\n",
            "Epoch:5 Step:2064 Training_loss:0.635742, Acc_avg:55.75% Training_loss_avg:0.689206\n",
            "Epoch:5 Step:2072 Training_loss:0.678477, Acc_avg:55.75% Training_loss_avg:0.689184\n",
            "Epoch:5 Step:2080 Training_loss:0.661912, Acc_avg:56.50% Training_loss_avg:0.688381\n",
            "Epoch:5 Step:2088 Training_loss:0.683868, Acc_avg:56.00% Training_loss_avg:0.688611\n",
            "Epoch:5 Step:2096 Training_loss:0.704934, Acc_avg:55.75% Training_loss_avg:0.688983\n",
            "Epoch:5 Step:2104 Training_loss:0.657432, Acc_avg:56.00% Training_loss_avg:0.688486\n",
            "Epoch:5 Step:2112 Training_loss:0.679643, Acc_avg:56.00% Training_loss_avg:0.688453\n",
            "Epoch:5 Step:2120 Training_loss:0.768900, Acc_avg:55.75% Training_loss_avg:0.689681\n",
            "Epoch:5 Step:2128 Training_loss:0.655923, Acc_avg:56.25% Training_loss_avg:0.688855\n",
            "Epoch:5 Step:2136 Training_loss:0.654795, Acc_avg:56.25% Training_loss_avg:0.688276\n",
            "Epoch:5 Step:2144 Training_loss:0.718930, Acc_avg:55.50% Training_loss_avg:0.689327\n",
            "Epoch:5 Step:2152 Training_loss:0.621356, Acc_avg:56.50% Training_loss_avg:0.687558\n",
            "Epoch:5 Step:2160 Training_loss:0.721814, Acc_avg:56.25% Training_loss_avg:0.688246\n",
            "Epoch:5 Step:2168 Training_loss:0.726001, Acc_avg:55.50% Training_loss_avg:0.689231\n",
            "Epoch:5 Step:2176 Training_loss:0.725466, Acc_avg:55.50% Training_loss_avg:0.689473\n",
            "Epoch:5 Step:2184 Training_loss:0.756915, Acc_avg:55.25% Training_loss_avg:0.690800\n",
            "Epoch:5 Step:2192 Training_loss:0.688143, Acc_avg:55.00% Training_loss_avg:0.691029\n",
            "Epoch:5 Step:2200 Training_loss:0.617679, Acc_avg:55.75% Training_loss_avg:0.689225\n",
            "Epoch:5 Step:2208 Training_loss:0.687400, Acc_avg:55.50% Training_loss_avg:0.689550\n",
            "Epoch:5 Step:2216 Training_loss:0.698081, Acc_avg:56.00% Training_loss_avg:0.689103\n",
            "Epoch:5 Step:2224 Training_loss:0.682397, Acc_avg:56.00% Training_loss_avg:0.688771\n",
            "Epoch:5 Step:2232 Training_loss:0.672930, Acc_avg:55.75% Training_loss_avg:0.688768\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:2232 Val_loss:0.690255, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:2240 Training_loss:0.632030, Acc_avg:56.75% Training_loss_avg:0.687030\n",
            "Epoch:5 Step:2248 Training_loss:0.648343, Acc_avg:56.75% Training_loss_avg:0.686633\n",
            "Epoch:5 Step:2256 Training_loss:0.620142, Acc_avg:57.25% Training_loss_avg:0.685362\n",
            "Epoch:5 Step:2264 Training_loss:0.666644, Acc_avg:57.50% Training_loss_avg:0.684516\n",
            "Epoch:5 Step:2272 Training_loss:0.718586, Acc_avg:57.25% Training_loss_avg:0.685051\n",
            "Epoch:5 Step:2280 Training_loss:0.658331, Acc_avg:58.00% Training_loss_avg:0.683508\n",
            "Epoch:5 Step:2288 Training_loss:0.719877, Acc_avg:57.25% Training_loss_avg:0.685266\n",
            "Epoch:5 Step:2296 Training_loss:0.665342, Acc_avg:57.75% Training_loss_avg:0.684091\n",
            "Epoch:5 Step:2304 Training_loss:0.646256, Acc_avg:58.00% Training_loss_avg:0.683398\n",
            "Epoch:5 Step:2312 Training_loss:0.753131, Acc_avg:57.50% Training_loss_avg:0.685137\n",
            "Epoch:5 Step:2320 Training_loss:0.732944, Acc_avg:57.50% Training_loss_avg:0.685894\n",
            "Epoch:5 Step:2328 Training_loss:0.711577, Acc_avg:57.50% Training_loss_avg:0.686520\n",
            "Epoch:5 Step:2336 Training_loss:0.691002, Acc_avg:57.50% Training_loss_avg:0.686867\n",
            "Epoch:5 Step:2344 Training_loss:0.674761, Acc_avg:57.75% Training_loss_avg:0.686277\n",
            "Epoch:5 Step:2352 Training_loss:0.633754, Acc_avg:58.50% Training_loss_avg:0.684799\n",
            "Epoch:5 Step:2360 Training_loss:0.726237, Acc_avg:58.75% Training_loss_avg:0.684495\n",
            "Epoch:5 Step:2368 Training_loss:0.677567, Acc_avg:59.00% Training_loss_avg:0.683763\n",
            "Epoch:5 Step:2376 Training_loss:0.646370, Acc_avg:59.00% Training_loss_avg:0.683037\n",
            "Epoch:5 Step:2384 Training_loss:0.742545, Acc_avg:58.25% Training_loss_avg:0.684550\n",
            "Epoch:5 Step:2392 Training_loss:0.696192, Acc_avg:57.50% Training_loss_avg:0.685591\n",
            "Epoch:5 Step:2400 Training_loss:0.598035, Acc_avg:58.25% Training_loss_avg:0.683536\n",
            "Epoch:5 Step:2408 Training_loss:0.653268, Acc_avg:58.50% Training_loss_avg:0.682648\n",
            "Epoch:5 Step:2416 Training_loss:0.679296, Acc_avg:59.00% Training_loss_avg:0.681773\n",
            "Epoch:5 Step:2424 Training_loss:0.698739, Acc_avg:58.50% Training_loss_avg:0.682534\n",
            "Epoch:5 Step:2432 Training_loss:0.652359, Acc_avg:58.75% Training_loss_avg:0.681674\n",
            "Epoch:5 Step:2440 Training_loss:0.699701, Acc_avg:59.00% Training_loss_avg:0.681649\n",
            "Epoch:5 Step:2448 Training_loss:0.666259, Acc_avg:59.25% Training_loss_avg:0.680966\n",
            "Epoch:5 Step:2456 Training_loss:0.676447, Acc_avg:58.75% Training_loss_avg:0.681689\n",
            "Epoch:5 Step:2464 Training_loss:0.737286, Acc_avg:57.75% Training_loss_avg:0.683720\n",
            "Epoch:5 Step:2472 Training_loss:0.632784, Acc_avg:58.00% Training_loss_avg:0.682806\n",
            "Epoch:5 Step:2480 Training_loss:0.632405, Acc_avg:58.00% Training_loss_avg:0.682216\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:2480 Val_loss:0.691848, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:2488 Training_loss:0.762089, Acc_avg:57.50% Training_loss_avg:0.683781\n",
            "Epoch:5 Step:2496 Training_loss:0.629293, Acc_avg:58.00% Training_loss_avg:0.682268\n",
            "Epoch:5 Step:2504 Training_loss:0.847270, Acc_avg:56.50% Training_loss_avg:0.686065\n",
            "Epoch:5 Step:2512 Training_loss:0.725591, Acc_avg:56.25% Training_loss_avg:0.686984\n",
            "Epoch:5 Step:2520 Training_loss:0.650635, Acc_avg:57.25% Training_loss_avg:0.684618\n",
            "Epoch:5 Step:2528 Training_loss:0.665257, Acc_avg:57.00% Training_loss_avg:0.684805\n",
            "Epoch:5 Step:2536 Training_loss:0.759067, Acc_avg:56.25% Training_loss_avg:0.686890\n",
            "Epoch:5 Step:2544 Training_loss:0.651701, Acc_avg:56.75% Training_loss_avg:0.685546\n",
            "Epoch:5 Step:2552 Training_loss:0.662092, Acc_avg:56.25% Training_loss_avg:0.686361\n",
            "Epoch:5 Step:2560 Training_loss:0.762917, Acc_avg:56.25% Training_loss_avg:0.687183\n",
            "Epoch:5 Step:2568 Training_loss:0.617310, Acc_avg:57.25% Training_loss_avg:0.685009\n",
            "Epoch:5 Step:2576 Training_loss:0.675817, Acc_avg:57.75% Training_loss_avg:0.684016\n",
            "Epoch:5 Step:2584 Training_loss:0.649359, Acc_avg:58.50% Training_loss_avg:0.681865\n",
            "Epoch:5 Step:2592 Training_loss:0.671259, Acc_avg:58.75% Training_loss_avg:0.681527\n",
            "Epoch:5 Step:2600 Training_loss:0.680438, Acc_avg:58.50% Training_loss_avg:0.682782\n",
            "Epoch:5 Step:2608 Training_loss:0.675335, Acc_avg:58.50% Training_loss_avg:0.682541\n",
            "Epoch:5 Step:2616 Training_loss:0.783401, Acc_avg:57.75% Training_loss_avg:0.684247\n",
            "Epoch:5 Step:2624 Training_loss:0.721460, Acc_avg:57.50% Training_loss_avg:0.685029\n",
            "Epoch:5 Step:2632 Training_loss:0.697879, Acc_avg:57.25% Training_loss_avg:0.685528\n",
            "Epoch:5 Step:2640 Training_loss:0.708028, Acc_avg:56.75% Training_loss_avg:0.687048\n",
            "Epoch:5 Step:2648 Training_loss:0.698052, Acc_avg:56.25% Training_loss_avg:0.688042\n",
            "Epoch:5 Step:2656 Training_loss:0.625819, Acc_avg:56.25% Training_loss_avg:0.688155\n",
            "Epoch:5 Step:2664 Training_loss:0.674698, Acc_avg:56.50% Training_loss_avg:0.688316\n",
            "Epoch:5 Step:2672 Training_loss:0.718459, Acc_avg:56.50% Training_loss_avg:0.688314\n",
            "Epoch:5 Step:2680 Training_loss:0.669518, Acc_avg:56.50% Training_loss_avg:0.688538\n",
            "Epoch:5 Step:2688 Training_loss:0.695845, Acc_avg:56.75% Training_loss_avg:0.688057\n",
            "Epoch:5 Step:2696 Training_loss:0.725102, Acc_avg:56.25% Training_loss_avg:0.689252\n",
            "Epoch:5 Step:2704 Training_loss:0.696005, Acc_avg:55.75% Training_loss_avg:0.690247\n",
            "Epoch:5 Step:2712 Training_loss:0.676114, Acc_avg:56.25% Training_loss_avg:0.688707\n",
            "Epoch:5 Step:2720 Training_loss:0.722594, Acc_avg:56.00% Training_loss_avg:0.688500\n",
            "Epoch:5 Step:2728 Training_loss:0.739539, Acc_avg:55.50% Training_loss_avg:0.689059\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:2728 Val_loss:0.689466, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:2736 Training_loss:0.655579, Acc_avg:55.75% Training_loss_avg:0.688351\n",
            "Epoch:5 Step:2744 Training_loss:0.681576, Acc_avg:55.50% Training_loss_avg:0.688487\n",
            "Epoch:5 Step:2752 Training_loss:0.676788, Acc_avg:55.25% Training_loss_avg:0.689348\n",
            "Epoch:5 Step:2760 Training_loss:0.648466, Acc_avg:56.00% Training_loss_avg:0.687792\n",
            "Epoch:5 Step:2768 Training_loss:0.707605, Acc_avg:55.50% Training_loss_avg:0.688393\n",
            "Epoch:5 Step:2776 Training_loss:0.677506, Acc_avg:55.50% Training_loss_avg:0.689016\n",
            "Epoch:5 Step:2784 Training_loss:0.645991, Acc_avg:56.50% Training_loss_avg:0.687084\n",
            "Epoch:5 Step:2792 Training_loss:0.671507, Acc_avg:56.75% Training_loss_avg:0.686591\n",
            "Epoch:5 Step:2800 Training_loss:0.659041, Acc_avg:56.50% Training_loss_avg:0.687811\n",
            "Epoch:5 Step:2808 Training_loss:0.710238, Acc_avg:56.00% Training_loss_avg:0.688950\n",
            "Epoch:5 Step:2816 Training_loss:0.671346, Acc_avg:56.00% Training_loss_avg:0.688791\n",
            "Epoch:5 Step:2824 Training_loss:0.679923, Acc_avg:56.25% Training_loss_avg:0.688415\n",
            "Epoch:5 Step:2832 Training_loss:0.674521, Acc_avg:56.25% Training_loss_avg:0.688858\n",
            "Epoch:5 Step:2840 Training_loss:0.745881, Acc_avg:55.75% Training_loss_avg:0.689782\n",
            "Epoch:5 Step:2848 Training_loss:0.653379, Acc_avg:56.00% Training_loss_avg:0.689524\n",
            "Epoch:5 Step:2856 Training_loss:0.685479, Acc_avg:55.75% Training_loss_avg:0.689705\n",
            "Epoch:5 Step:2864 Training_loss:0.752575, Acc_avg:55.50% Training_loss_avg:0.690011\n",
            "Epoch:5 Step:2872 Training_loss:0.657337, Acc_avg:55.25% Training_loss_avg:0.690502\n",
            "Epoch:5 Step:2880 Training_loss:0.667668, Acc_avg:55.00% Training_loss_avg:0.691207\n",
            "Epoch:5 Step:2888 Training_loss:0.684619, Acc_avg:55.50% Training_loss_avg:0.689658\n",
            "Epoch:5 Step:2896 Training_loss:0.649639, Acc_avg:55.50% Training_loss_avg:0.690065\n",
            "Epoch:5 Step:2904 Training_loss:0.729414, Acc_avg:56.25% Training_loss_avg:0.687707\n",
            "Epoch:5 Step:2912 Training_loss:0.727086, Acc_avg:56.00% Training_loss_avg:0.687737\n",
            "Epoch:5 Step:2920 Training_loss:0.650244, Acc_avg:56.00% Training_loss_avg:0.687729\n",
            "Epoch:5 Step:2928 Training_loss:0.661058, Acc_avg:56.00% Training_loss_avg:0.687645\n",
            "Epoch:5 Step:2936 Training_loss:0.681873, Acc_avg:56.75% Training_loss_avg:0.686102\n",
            "Epoch:5 Step:2944 Training_loss:0.668927, Acc_avg:56.50% Training_loss_avg:0.686446\n",
            "Epoch:5 Step:2952 Training_loss:0.674645, Acc_avg:56.50% Training_loss_avg:0.686697\n",
            "Epoch:5 Step:2960 Training_loss:0.651617, Acc_avg:57.00% Training_loss_avg:0.684471\n",
            "Epoch:5 Step:2968 Training_loss:0.720599, Acc_avg:56.25% Training_loss_avg:0.686537\n",
            "Epoch:5 Step:2976 Training_loss:0.659837, Acc_avg:56.25% Training_loss_avg:0.686217\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:2976 Val_loss:0.690284, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:2984 Training_loss:0.668178, Acc_avg:56.00% Training_loss_avg:0.686594\n",
            "Epoch:5 Step:2992 Training_loss:0.673589, Acc_avg:56.00% Training_loss_avg:0.686640\n",
            "Epoch:5 Step:3000 Training_loss:0.755895, Acc_avg:55.25% Training_loss_avg:0.688150\n",
            "Epoch:5 Step:3008 Training_loss:0.667498, Acc_avg:55.25% Training_loss_avg:0.687993\n",
            "Epoch:5 Step:3016 Training_loss:0.658008, Acc_avg:56.25% Training_loss_avg:0.685485\n",
            "Epoch:5 Step:3024 Training_loss:0.595222, Acc_avg:57.25% Training_loss_avg:0.682960\n",
            "Epoch:5 Step:3032 Training_loss:0.739820, Acc_avg:57.00% Training_loss_avg:0.683799\n",
            "Epoch:5 Step:3040 Training_loss:0.779657, Acc_avg:56.50% Training_loss_avg:0.685232\n",
            "Epoch:5 Step:3048 Training_loss:0.664533, Acc_avg:56.75% Training_loss_avg:0.684561\n",
            "Epoch:5 Step:3056 Training_loss:0.765029, Acc_avg:55.50% Training_loss_avg:0.687345\n",
            "Epoch:5 Step:3064 Training_loss:0.733528, Acc_avg:55.00% Training_loss_avg:0.688522\n",
            "Epoch:5 Step:3072 Training_loss:0.669670, Acc_avg:55.50% Training_loss_avg:0.687546\n",
            "Epoch:5 Step:3080 Training_loss:0.679323, Acc_avg:55.50% Training_loss_avg:0.687742\n",
            "Epoch:5 Step:3088 Training_loss:0.711015, Acc_avg:55.25% Training_loss_avg:0.688046\n",
            "Epoch:5 Step:3096 Training_loss:0.669831, Acc_avg:55.75% Training_loss_avg:0.686940\n",
            "Epoch:5 Step:3104 Training_loss:0.718777, Acc_avg:55.50% Training_loss_avg:0.687396\n",
            "Epoch:5 Step:3112 Training_loss:0.652424, Acc_avg:55.75% Training_loss_avg:0.686922\n",
            "Epoch:5 Step:3120 Training_loss:0.699702, Acc_avg:56.00% Training_loss_avg:0.686464\n",
            "Epoch:5 Step:3128 Training_loss:0.690556, Acc_avg:56.50% Training_loss_avg:0.685484\n",
            "Epoch:5 Step:3136 Training_loss:0.696618, Acc_avg:56.00% Training_loss_avg:0.686305\n",
            "Epoch:5 Step:3144 Training_loss:0.708897, Acc_avg:56.00% Training_loss_avg:0.686852\n",
            "Epoch:5 Step:3152 Training_loss:0.730187, Acc_avg:55.25% Training_loss_avg:0.687920\n",
            "Epoch:5 Step:3160 Training_loss:0.691458, Acc_avg:54.50% Training_loss_avg:0.688779\n",
            "Epoch:5 Step:3168 Training_loss:0.691654, Acc_avg:54.75% Training_loss_avg:0.688460\n",
            "Epoch:5 Step:3176 Training_loss:0.680815, Acc_avg:54.75% Training_loss_avg:0.688527\n",
            "Epoch:5 Step:3184 Training_loss:0.687192, Acc_avg:54.25% Training_loss_avg:0.689351\n",
            "Epoch:5 Step:3192 Training_loss:0.693862, Acc_avg:54.00% Training_loss_avg:0.689798\n",
            "Epoch:5 Step:3200 Training_loss:0.702469, Acc_avg:53.50% Training_loss_avg:0.690666\n",
            "Epoch:5 Step:3208 Training_loss:0.690508, Acc_avg:53.75% Training_loss_avg:0.690272\n",
            "Epoch:5 Step:3216 Training_loss:0.702022, Acc_avg:53.50% Training_loss_avg:0.690885\n",
            "Epoch:5 Step:3224 Training_loss:0.696362, Acc_avg:53.25% Training_loss_avg:0.691214\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:5 Step:3224 Val_loss:0.690282, Val_Acc_avg:54.75%\n",
            "Epoch:5 Step:3232 Training_loss:0.707884, Acc_avg:52.75% Training_loss_avg:0.691881\n",
            "Epoch:5 Step:3240 Training_loss:0.711275, Acc_avg:53.00% Training_loss_avg:0.691189\n",
            "Epoch:5 Step:3248 Training_loss:0.680233, Acc_avg:52.75% Training_loss_avg:0.691726\n",
            "Epoch:5 Step:3256 Training_loss:0.686758, Acc_avg:53.00% Training_loss_avg:0.691752\n",
            "Epoch:5 Step:3264 Training_loss:0.694003, Acc_avg:53.50% Training_loss_avg:0.690580\n",
            "Epoch:5 Step:3272 Training_loss:0.683234, Acc_avg:53.50% Training_loss_avg:0.691098\n",
            "Epoch:5 Step:3280 Training_loss:0.694953, Acc_avg:53.25% Training_loss_avg:0.691644\n",
            "Epoch:5 Step:3288 Training_loss:0.684156, Acc_avg:53.25% Training_loss_avg:0.691635\n",
            "Epoch:5 Step:3296 Training_loss:0.705938, Acc_avg:52.75% Training_loss_avg:0.692761\n",
            "Epoch:5 Step:3304 Training_loss:0.710930, Acc_avg:52.50% Training_loss_avg:0.692391\n",
            "Epoch:5 Step:3312 Training_loss:0.706021, Acc_avg:52.75% Training_loss_avg:0.691970\n",
            "Epoch:5 Step:3320 Training_loss:0.693764, Acc_avg:52.25% Training_loss_avg:0.692840\n",
            "Epoch:5 Step:3328 Training_loss:0.661617, Acc_avg:52.33% Training_loss_avg:0.692851\n",
            "Epoch:6 Step:0 Training_loss:0.661905, Acc_avg:52.58% Training_loss_avg:0.692452\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:0 Val_loss:0.690305, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:8 Training_loss:0.704515, Acc_avg:52.08% Training_loss_avg:0.693164\n",
            "Epoch:6 Step:16 Training_loss:0.689471, Acc_avg:52.08% Training_loss_avg:0.693460\n",
            "Epoch:6 Step:24 Training_loss:0.678916, Acc_avg:51.83% Training_loss_avg:0.694006\n",
            "Epoch:6 Step:32 Training_loss:0.692030, Acc_avg:51.83% Training_loss_avg:0.693435\n",
            "Epoch:6 Step:40 Training_loss:0.703372, Acc_avg:51.58% Training_loss_avg:0.694305\n",
            "Epoch:6 Step:48 Training_loss:0.680287, Acc_avg:51.58% Training_loss_avg:0.694548\n",
            "Epoch:6 Step:56 Training_loss:0.700102, Acc_avg:51.33% Training_loss_avg:0.695078\n",
            "Epoch:6 Step:64 Training_loss:0.755700, Acc_avg:50.83% Training_loss_avg:0.695074\n",
            "Epoch:6 Step:72 Training_loss:0.697697, Acc_avg:50.33% Training_loss_avg:0.695678\n",
            "Epoch:6 Step:80 Training_loss:0.679056, Acc_avg:50.58% Training_loss_avg:0.696099\n",
            "Epoch:6 Step:88 Training_loss:0.720382, Acc_avg:49.33% Training_loss_avg:0.698602\n",
            "Epoch:6 Step:96 Training_loss:0.700430, Acc_avg:49.33% Training_loss_avg:0.697814\n",
            "Epoch:6 Step:104 Training_loss:0.678800, Acc_avg:50.08% Training_loss_avg:0.695797\n",
            "Epoch:6 Step:112 Training_loss:0.689736, Acc_avg:50.08% Training_loss_avg:0.696301\n",
            "Epoch:6 Step:120 Training_loss:0.698845, Acc_avg:50.58% Training_loss_avg:0.694978\n",
            "Epoch:6 Step:128 Training_loss:0.700341, Acc_avg:50.58% Training_loss_avg:0.694314\n",
            "Epoch:6 Step:136 Training_loss:0.689507, Acc_avg:50.58% Training_loss_avg:0.694711\n",
            "Epoch:6 Step:144 Training_loss:0.688333, Acc_avg:50.58% Training_loss_avg:0.694891\n",
            "Epoch:6 Step:152 Training_loss:0.699018, Acc_avg:50.58% Training_loss_avg:0.694651\n",
            "Epoch:6 Step:160 Training_loss:0.695688, Acc_avg:50.33% Training_loss_avg:0.695168\n",
            "Epoch:6 Step:168 Training_loss:0.701328, Acc_avg:50.33% Training_loss_avg:0.694819\n",
            "Epoch:6 Step:176 Training_loss:0.690244, Acc_avg:50.08% Training_loss_avg:0.695575\n",
            "Epoch:6 Step:184 Training_loss:0.699821, Acc_avg:49.58% Training_loss_avg:0.695578\n",
            "Epoch:6 Step:192 Training_loss:0.707766, Acc_avg:49.58% Training_loss_avg:0.695922\n",
            "Epoch:6 Step:200 Training_loss:0.698135, Acc_avg:49.83% Training_loss_avg:0.695952\n",
            "Epoch:6 Step:208 Training_loss:0.678899, Acc_avg:50.08% Training_loss_avg:0.695352\n",
            "Epoch:6 Step:216 Training_loss:0.682888, Acc_avg:51.08% Training_loss_avg:0.694406\n",
            "Epoch:6 Step:224 Training_loss:0.692999, Acc_avg:51.08% Training_loss_avg:0.694437\n",
            "Epoch:6 Step:232 Training_loss:0.673549, Acc_avg:51.58% Training_loss_avg:0.694075\n",
            "Epoch:6 Step:240 Training_loss:0.686940, Acc_avg:51.58% Training_loss_avg:0.694198\n",
            "Epoch:6 Step:248 Training_loss:0.694155, Acc_avg:51.58% Training_loss_avg:0.694337\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:248 Val_loss:0.690584, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:256 Training_loss:0.680991, Acc_avg:52.08% Training_loss_avg:0.694079\n",
            "Epoch:6 Step:264 Training_loss:0.699528, Acc_avg:52.08% Training_loss_avg:0.694021\n",
            "Epoch:6 Step:272 Training_loss:0.681596, Acc_avg:52.33% Training_loss_avg:0.693842\n",
            "Epoch:6 Step:280 Training_loss:0.675236, Acc_avg:52.58% Training_loss_avg:0.693307\n",
            "Epoch:6 Step:288 Training_loss:0.689647, Acc_avg:52.83% Training_loss_avg:0.693172\n",
            "Epoch:6 Step:296 Training_loss:0.717406, Acc_avg:52.83% Training_loss_avg:0.693363\n",
            "Epoch:6 Step:304 Training_loss:0.671923, Acc_avg:53.33% Training_loss_avg:0.692576\n",
            "Epoch:6 Step:312 Training_loss:0.660521, Acc_avg:53.58% Training_loss_avg:0.692182\n",
            "Epoch:6 Step:320 Training_loss:0.699222, Acc_avg:53.33% Training_loss_avg:0.692431\n",
            "Epoch:6 Step:328 Training_loss:0.661701, Acc_avg:53.58% Training_loss_avg:0.691785\n",
            "Epoch:6 Step:336 Training_loss:0.632917, Acc_avg:54.08% Training_loss_avg:0.690778\n",
            "Epoch:6 Step:344 Training_loss:0.690452, Acc_avg:54.08% Training_loss_avg:0.690688\n",
            "Epoch:6 Step:352 Training_loss:0.600819, Acc_avg:54.83% Training_loss_avg:0.689022\n",
            "Epoch:6 Step:360 Training_loss:0.727414, Acc_avg:54.83% Training_loss_avg:0.689451\n",
            "Epoch:6 Step:368 Training_loss:0.731255, Acc_avg:55.08% Training_loss_avg:0.689858\n",
            "Epoch:6 Step:376 Training_loss:0.736018, Acc_avg:54.83% Training_loss_avg:0.690458\n",
            "Epoch:6 Step:384 Training_loss:0.691962, Acc_avg:55.08% Training_loss_avg:0.690422\n",
            "Epoch:6 Step:392 Training_loss:0.726996, Acc_avg:54.75% Training_loss_avg:0.691729\n",
            "Epoch:6 Step:400 Training_loss:0.757702, Acc_avg:54.00% Training_loss_avg:0.693645\n",
            "Epoch:6 Step:408 Training_loss:0.689075, Acc_avg:54.25% Training_loss_avg:0.693336\n",
            "Epoch:6 Step:416 Training_loss:0.645132, Acc_avg:54.50% Training_loss_avg:0.692449\n",
            "Epoch:6 Step:424 Training_loss:0.644203, Acc_avg:55.00% Training_loss_avg:0.691755\n",
            "Epoch:6 Step:432 Training_loss:0.669522, Acc_avg:55.25% Training_loss_avg:0.691305\n",
            "Epoch:6 Step:440 Training_loss:0.741593, Acc_avg:55.00% Training_loss_avg:0.692069\n",
            "Epoch:6 Step:448 Training_loss:0.717045, Acc_avg:54.75% Training_loss_avg:0.692805\n",
            "Epoch:6 Step:456 Training_loss:0.673209, Acc_avg:55.00% Training_loss_avg:0.692267\n",
            "Epoch:6 Step:464 Training_loss:0.634018, Acc_avg:56.50% Training_loss_avg:0.689833\n",
            "Epoch:6 Step:472 Training_loss:0.750108, Acc_avg:56.25% Training_loss_avg:0.690881\n",
            "Epoch:6 Step:480 Training_loss:0.678971, Acc_avg:56.00% Training_loss_avg:0.690880\n",
            "Epoch:6 Step:488 Training_loss:0.755668, Acc_avg:56.00% Training_loss_avg:0.691585\n",
            "Epoch:6 Step:496 Training_loss:0.638041, Acc_avg:56.75% Training_loss_avg:0.690338\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:496 Val_loss:0.689931, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:504 Training_loss:0.739670, Acc_avg:56.25% Training_loss_avg:0.691555\n",
            "Epoch:6 Step:512 Training_loss:0.673064, Acc_avg:56.25% Training_loss_avg:0.691222\n",
            "Epoch:6 Step:520 Training_loss:0.648439, Acc_avg:56.75% Training_loss_avg:0.690213\n",
            "Epoch:6 Step:528 Training_loss:0.648111, Acc_avg:57.50% Training_loss_avg:0.689169\n",
            "Epoch:6 Step:536 Training_loss:0.661219, Acc_avg:57.50% Training_loss_avg:0.688603\n",
            "Epoch:6 Step:544 Training_loss:0.695492, Acc_avg:57.25% Training_loss_avg:0.688746\n",
            "Epoch:6 Step:552 Training_loss:0.673633, Acc_avg:57.50% Training_loss_avg:0.688239\n",
            "Epoch:6 Step:560 Training_loss:0.732551, Acc_avg:57.25% Training_loss_avg:0.688976\n",
            "Epoch:6 Step:568 Training_loss:0.794089, Acc_avg:56.75% Training_loss_avg:0.690831\n",
            "Epoch:6 Step:576 Training_loss:0.726267, Acc_avg:56.25% Training_loss_avg:0.691551\n",
            "Epoch:6 Step:584 Training_loss:0.701137, Acc_avg:56.75% Training_loss_avg:0.691578\n",
            "Epoch:6 Step:592 Training_loss:0.694502, Acc_avg:56.75% Training_loss_avg:0.691313\n",
            "Epoch:6 Step:600 Training_loss:0.718468, Acc_avg:56.25% Training_loss_avg:0.691719\n",
            "Epoch:6 Step:608 Training_loss:0.675996, Acc_avg:56.25% Training_loss_avg:0.691661\n",
            "Epoch:6 Step:616 Training_loss:0.700864, Acc_avg:55.75% Training_loss_avg:0.692021\n",
            "Epoch:6 Step:624 Training_loss:0.702034, Acc_avg:55.75% Training_loss_avg:0.692201\n",
            "Epoch:6 Step:632 Training_loss:0.660113, Acc_avg:55.75% Training_loss_avg:0.691933\n",
            "Epoch:6 Step:640 Training_loss:0.652621, Acc_avg:56.00% Training_loss_avg:0.691246\n",
            "Epoch:6 Step:648 Training_loss:0.625232, Acc_avg:56.50% Training_loss_avg:0.689868\n",
            "Epoch:6 Step:656 Training_loss:0.687506, Acc_avg:56.25% Training_loss_avg:0.689998\n",
            "Epoch:6 Step:664 Training_loss:0.654911, Acc_avg:56.75% Training_loss_avg:0.689106\n",
            "Epoch:6 Step:672 Training_loss:0.662110, Acc_avg:56.75% Training_loss_avg:0.688716\n",
            "Epoch:6 Step:680 Training_loss:0.672573, Acc_avg:56.75% Training_loss_avg:0.688663\n",
            "Epoch:6 Step:688 Training_loss:0.740097, Acc_avg:56.00% Training_loss_avg:0.689672\n",
            "Epoch:6 Step:696 Training_loss:0.646594, Acc_avg:56.75% Training_loss_avg:0.688256\n",
            "Epoch:6 Step:704 Training_loss:0.673396, Acc_avg:56.75% Training_loss_avg:0.688285\n",
            "Epoch:6 Step:712 Training_loss:0.700087, Acc_avg:56.25% Training_loss_avg:0.689076\n",
            "Epoch:6 Step:720 Training_loss:0.737117, Acc_avg:56.00% Training_loss_avg:0.689834\n",
            "Epoch:6 Step:728 Training_loss:0.670049, Acc_avg:56.25% Training_loss_avg:0.690001\n",
            "Epoch:6 Step:736 Training_loss:0.683101, Acc_avg:55.75% Training_loss_avg:0.691005\n",
            "Epoch:6 Step:744 Training_loss:0.736719, Acc_avg:55.50% Training_loss_avg:0.691930\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:744 Val_loss:0.689591, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:752 Training_loss:0.678239, Acc_avg:55.00% Training_loss_avg:0.693479\n",
            "Epoch:6 Step:760 Training_loss:0.698531, Acc_avg:55.00% Training_loss_avg:0.692901\n",
            "Epoch:6 Step:768 Training_loss:0.671430, Acc_avg:55.50% Training_loss_avg:0.691705\n",
            "Epoch:6 Step:776 Training_loss:0.628169, Acc_avg:56.50% Training_loss_avg:0.689548\n",
            "Epoch:6 Step:784 Training_loss:0.683353, Acc_avg:56.50% Training_loss_avg:0.689375\n",
            "Epoch:6 Step:792 Training_loss:0.668713, Acc_avg:56.75% Training_loss_avg:0.688210\n",
            "Epoch:6 Step:800 Training_loss:0.672128, Acc_avg:57.25% Training_loss_avg:0.686498\n",
            "Epoch:6 Step:808 Training_loss:0.750598, Acc_avg:56.75% Training_loss_avg:0.687729\n",
            "Epoch:6 Step:816 Training_loss:0.716037, Acc_avg:56.00% Training_loss_avg:0.689147\n",
            "Epoch:6 Step:824 Training_loss:0.638806, Acc_avg:56.00% Training_loss_avg:0.689039\n",
            "Epoch:6 Step:832 Training_loss:0.680298, Acc_avg:56.00% Training_loss_avg:0.689254\n",
            "Epoch:6 Step:840 Training_loss:0.618035, Acc_avg:57.00% Training_loss_avg:0.686783\n",
            "Epoch:6 Step:848 Training_loss:0.698882, Acc_avg:57.00% Training_loss_avg:0.686420\n",
            "Epoch:6 Step:856 Training_loss:0.695417, Acc_avg:56.75% Training_loss_avg:0.686864\n",
            "Epoch:6 Step:864 Training_loss:0.698562, Acc_avg:56.25% Training_loss_avg:0.688155\n",
            "Epoch:6 Step:872 Training_loss:0.625473, Acc_avg:57.25% Training_loss_avg:0.685662\n",
            "Epoch:6 Step:880 Training_loss:0.603012, Acc_avg:57.75% Training_loss_avg:0.684143\n",
            "Epoch:6 Step:888 Training_loss:0.705408, Acc_avg:58.25% Training_loss_avg:0.683138\n",
            "Epoch:6 Step:896 Training_loss:0.705365, Acc_avg:57.75% Training_loss_avg:0.684484\n",
            "Epoch:6 Step:904 Training_loss:0.688572, Acc_avg:58.00% Training_loss_avg:0.683462\n",
            "Epoch:6 Step:912 Training_loss:0.773455, Acc_avg:57.25% Training_loss_avg:0.685470\n",
            "Epoch:6 Step:920 Training_loss:0.668145, Acc_avg:57.00% Training_loss_avg:0.685864\n",
            "Epoch:6 Step:928 Training_loss:0.705418, Acc_avg:56.50% Training_loss_avg:0.687011\n",
            "Epoch:6 Step:936 Training_loss:0.661163, Acc_avg:56.50% Training_loss_avg:0.687009\n",
            "Epoch:6 Step:944 Training_loss:0.668568, Acc_avg:56.75% Training_loss_avg:0.686471\n",
            "Epoch:6 Step:952 Training_loss:0.720612, Acc_avg:56.50% Training_loss_avg:0.687411\n",
            "Epoch:6 Step:960 Training_loss:0.651798, Acc_avg:57.00% Training_loss_avg:0.685795\n",
            "Epoch:6 Step:968 Training_loss:0.554375, Acc_avg:58.75% Training_loss_avg:0.681001\n",
            "Epoch:6 Step:976 Training_loss:0.709897, Acc_avg:59.00% Training_loss_avg:0.680674\n",
            "Epoch:6 Step:984 Training_loss:0.702664, Acc_avg:59.00% Training_loss_avg:0.680704\n",
            "Epoch:6 Step:992 Training_loss:0.629809, Acc_avg:59.50% Training_loss_avg:0.679410\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:992 Val_loss:0.692488, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:1000 Training_loss:0.763833, Acc_avg:59.50% Training_loss_avg:0.680318\n",
            "Epoch:6 Step:1008 Training_loss:0.618070, Acc_avg:59.75% Training_loss_avg:0.679159\n",
            "Epoch:6 Step:1016 Training_loss:0.732981, Acc_avg:59.75% Training_loss_avg:0.679802\n",
            "Epoch:6 Step:1024 Training_loss:0.780513, Acc_avg:59.25% Training_loss_avg:0.681371\n",
            "Epoch:6 Step:1032 Training_loss:0.674082, Acc_avg:59.00% Training_loss_avg:0.681651\n",
            "Epoch:6 Step:1040 Training_loss:0.737434, Acc_avg:58.25% Training_loss_avg:0.683347\n",
            "Epoch:6 Step:1048 Training_loss:0.786158, Acc_avg:57.00% Training_loss_avg:0.686565\n",
            "Epoch:6 Step:1056 Training_loss:0.703981, Acc_avg:57.00% Training_loss_avg:0.686895\n",
            "Epoch:6 Step:1064 Training_loss:0.755516, Acc_avg:56.50% Training_loss_avg:0.688907\n",
            "Epoch:6 Step:1072 Training_loss:0.691178, Acc_avg:56.25% Training_loss_avg:0.689488\n",
            "Epoch:6 Step:1080 Training_loss:0.624308, Acc_avg:56.50% Training_loss_avg:0.688523\n",
            "Epoch:6 Step:1088 Training_loss:0.754726, Acc_avg:56.50% Training_loss_avg:0.688816\n",
            "Epoch:6 Step:1096 Training_loss:0.703824, Acc_avg:56.00% Training_loss_avg:0.689960\n",
            "Epoch:6 Step:1104 Training_loss:0.711746, Acc_avg:55.50% Training_loss_avg:0.690727\n",
            "Epoch:6 Step:1112 Training_loss:0.693663, Acc_avg:55.50% Training_loss_avg:0.690599\n",
            "Epoch:6 Step:1120 Training_loss:0.701215, Acc_avg:55.75% Training_loss_avg:0.689881\n",
            "Epoch:6 Step:1128 Training_loss:0.701306, Acc_avg:55.00% Training_loss_avg:0.690506\n",
            "Epoch:6 Step:1136 Training_loss:0.637948, Acc_avg:55.25% Training_loss_avg:0.689603\n",
            "Epoch:6 Step:1144 Training_loss:0.698092, Acc_avg:55.50% Training_loss_avg:0.688830\n",
            "Epoch:6 Step:1152 Training_loss:0.680653, Acc_avg:55.50% Training_loss_avg:0.688878\n",
            "Epoch:6 Step:1160 Training_loss:0.647193, Acc_avg:55.75% Training_loss_avg:0.687852\n",
            "Epoch:6 Step:1168 Training_loss:0.742954, Acc_avg:55.00% Training_loss_avg:0.689282\n",
            "Epoch:6 Step:1176 Training_loss:0.716033, Acc_avg:54.25% Training_loss_avg:0.691039\n",
            "Epoch:6 Step:1184 Training_loss:0.664679, Acc_avg:54.50% Training_loss_avg:0.690666\n",
            "Epoch:6 Step:1192 Training_loss:0.722046, Acc_avg:53.75% Training_loss_avg:0.691733\n",
            "Epoch:6 Step:1200 Training_loss:0.655261, Acc_avg:54.00% Training_loss_avg:0.691395\n",
            "Epoch:6 Step:1208 Training_loss:0.642072, Acc_avg:55.25% Training_loss_avg:0.689225\n",
            "Epoch:6 Step:1216 Training_loss:0.719145, Acc_avg:55.25% Training_loss_avg:0.689287\n",
            "Epoch:6 Step:1224 Training_loss:0.694514, Acc_avg:54.50% Training_loss_avg:0.690401\n",
            "Epoch:6 Step:1232 Training_loss:0.731916, Acc_avg:53.75% Training_loss_avg:0.691433\n",
            "Epoch:6 Step:1240 Training_loss:0.686473, Acc_avg:53.25% Training_loss_avg:0.692802\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:1240 Val_loss:0.689445, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:1248 Training_loss:0.672142, Acc_avg:53.50% Training_loss_avg:0.692267\n",
            "Epoch:6 Step:1256 Training_loss:0.698383, Acc_avg:53.75% Training_loss_avg:0.692327\n",
            "Epoch:6 Step:1264 Training_loss:0.679933, Acc_avg:53.75% Training_loss_avg:0.691954\n",
            "Epoch:6 Step:1272 Training_loss:0.660291, Acc_avg:53.50% Training_loss_avg:0.692650\n",
            "Epoch:6 Step:1280 Training_loss:0.662450, Acc_avg:53.00% Training_loss_avg:0.693839\n",
            "Epoch:6 Step:1288 Training_loss:0.739631, Acc_avg:52.75% Training_loss_avg:0.694524\n",
            "Epoch:6 Step:1296 Training_loss:0.748376, Acc_avg:52.25% Training_loss_avg:0.695384\n",
            "Epoch:6 Step:1304 Training_loss:0.655323, Acc_avg:53.00% Training_loss_avg:0.694719\n",
            "Epoch:6 Step:1312 Training_loss:0.702066, Acc_avg:53.25% Training_loss_avg:0.693291\n",
            "Epoch:6 Step:1320 Training_loss:0.641074, Acc_avg:53.75% Training_loss_avg:0.692750\n",
            "Epoch:6 Step:1328 Training_loss:0.710461, Acc_avg:53.75% Training_loss_avg:0.692851\n",
            "Epoch:6 Step:1336 Training_loss:0.687551, Acc_avg:53.50% Training_loss_avg:0.693378\n",
            "Epoch:6 Step:1344 Training_loss:0.646825, Acc_avg:54.00% Training_loss_avg:0.692943\n",
            "Epoch:6 Step:1352 Training_loss:0.721440, Acc_avg:53.75% Training_loss_avg:0.692960\n",
            "Epoch:6 Step:1360 Training_loss:0.697261, Acc_avg:53.50% Training_loss_avg:0.693869\n",
            "Epoch:6 Step:1368 Training_loss:0.725052, Acc_avg:52.00% Training_loss_avg:0.697283\n",
            "Epoch:6 Step:1376 Training_loss:0.692221, Acc_avg:52.00% Training_loss_avg:0.696929\n",
            "Epoch:6 Step:1384 Training_loss:0.663020, Acc_avg:52.25% Training_loss_avg:0.696136\n",
            "Epoch:6 Step:1392 Training_loss:0.711882, Acc_avg:51.50% Training_loss_avg:0.697778\n",
            "Epoch:6 Step:1400 Training_loss:0.703202, Acc_avg:51.50% Training_loss_avg:0.696565\n",
            "Epoch:6 Step:1408 Training_loss:0.688749, Acc_avg:51.00% Training_loss_avg:0.697979\n",
            "Epoch:6 Step:1416 Training_loss:0.700351, Acc_avg:51.00% Training_loss_avg:0.697326\n",
            "Epoch:6 Step:1424 Training_loss:0.662739, Acc_avg:52.00% Training_loss_avg:0.694971\n",
            "Epoch:6 Step:1432 Training_loss:0.698970, Acc_avg:51.75% Training_loss_avg:0.695469\n",
            "Epoch:6 Step:1440 Training_loss:0.699339, Acc_avg:52.00% Training_loss_avg:0.694707\n",
            "Epoch:6 Step:1448 Training_loss:0.716123, Acc_avg:52.25% Training_loss_avg:0.693306\n",
            "Epoch:6 Step:1456 Training_loss:0.677518, Acc_avg:52.25% Training_loss_avg:0.692777\n",
            "Epoch:6 Step:1464 Training_loss:0.676428, Acc_avg:52.50% Training_loss_avg:0.691195\n",
            "Epoch:6 Step:1472 Training_loss:0.682414, Acc_avg:52.75% Training_loss_avg:0.691020\n",
            "Epoch:6 Step:1480 Training_loss:0.691976, Acc_avg:52.25% Training_loss_avg:0.692373\n",
            "Epoch:6 Step:1488 Training_loss:0.718374, Acc_avg:52.25% Training_loss_avg:0.691646\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:1488 Val_loss:0.689918, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:1496 Training_loss:0.667809, Acc_avg:52.50% Training_loss_avg:0.690926\n",
            "Epoch:6 Step:1504 Training_loss:0.700712, Acc_avg:52.75% Training_loss_avg:0.690705\n",
            "Epoch:6 Step:1512 Training_loss:0.697443, Acc_avg:52.75% Training_loss_avg:0.690781\n",
            "Epoch:6 Step:1520 Training_loss:0.698910, Acc_avg:52.75% Training_loss_avg:0.690734\n",
            "Epoch:6 Step:1528 Training_loss:0.679854, Acc_avg:53.25% Training_loss_avg:0.690305\n",
            "Epoch:6 Step:1536 Training_loss:0.708493, Acc_avg:52.50% Training_loss_avg:0.691716\n",
            "Epoch:6 Step:1544 Training_loss:0.693096, Acc_avg:52.50% Training_loss_avg:0.691616\n",
            "Epoch:6 Step:1552 Training_loss:0.698854, Acc_avg:52.25% Training_loss_avg:0.691980\n",
            "Epoch:6 Step:1560 Training_loss:0.671202, Acc_avg:52.00% Training_loss_avg:0.692461\n",
            "Epoch:6 Step:1568 Training_loss:0.695209, Acc_avg:52.50% Training_loss_avg:0.691506\n",
            "Epoch:6 Step:1576 Training_loss:0.700912, Acc_avg:52.50% Training_loss_avg:0.691203\n",
            "Epoch:6 Step:1584 Training_loss:0.664471, Acc_avg:52.75% Training_loss_avg:0.691199\n",
            "Epoch:6 Step:1592 Training_loss:0.670612, Acc_avg:53.75% Training_loss_avg:0.690170\n",
            "Epoch:6 Step:1600 Training_loss:0.667467, Acc_avg:53.75% Training_loss_avg:0.690415\n",
            "Epoch:6 Step:1608 Training_loss:0.669870, Acc_avg:53.50% Training_loss_avg:0.690971\n",
            "Epoch:6 Step:1616 Training_loss:0.662139, Acc_avg:54.25% Training_loss_avg:0.689830\n",
            "Epoch:6 Step:1624 Training_loss:0.734247, Acc_avg:54.00% Training_loss_avg:0.690625\n",
            "Epoch:6 Step:1632 Training_loss:0.707249, Acc_avg:54.25% Training_loss_avg:0.690132\n",
            "Epoch:6 Step:1640 Training_loss:0.697546, Acc_avg:54.00% Training_loss_avg:0.690353\n",
            "Epoch:6 Step:1648 Training_loss:0.695603, Acc_avg:53.75% Training_loss_avg:0.690822\n",
            "Epoch:6 Step:1656 Training_loss:0.677356, Acc_avg:53.50% Training_loss_avg:0.690402\n",
            "Epoch:6 Step:1664 Training_loss:0.709647, Acc_avg:53.25% Training_loss_avg:0.690996\n",
            "Epoch:6 Step:1672 Training_loss:0.665491, Acc_avg:53.50% Training_loss_avg:0.691100\n",
            "Epoch:6 Step:1680 Training_loss:0.657201, Acc_avg:53.75% Training_loss_avg:0.690995\n",
            "Epoch:6 Step:1688 Training_loss:0.726748, Acc_avg:53.50% Training_loss_avg:0.690738\n",
            "Epoch:6 Step:1696 Training_loss:0.713395, Acc_avg:54.00% Training_loss_avg:0.690038\n",
            "Epoch:6 Step:1704 Training_loss:0.671649, Acc_avg:53.75% Training_loss_avg:0.690364\n",
            "Epoch:6 Step:1712 Training_loss:0.606723, Acc_avg:54.75% Training_loss_avg:0.688458\n",
            "Epoch:6 Step:1720 Training_loss:0.673756, Acc_avg:54.50% Training_loss_avg:0.689111\n",
            "Epoch:6 Step:1728 Training_loss:0.750389, Acc_avg:54.00% Training_loss_avg:0.689910\n",
            "Epoch:6 Step:1736 Training_loss:0.673329, Acc_avg:54.00% Training_loss_avg:0.689625\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:1736 Val_loss:0.689431, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:1744 Training_loss:0.674637, Acc_avg:53.50% Training_loss_avg:0.690182\n",
            "Epoch:6 Step:1752 Training_loss:0.680103, Acc_avg:54.00% Training_loss_avg:0.689355\n",
            "Epoch:6 Step:1760 Training_loss:0.694052, Acc_avg:54.00% Training_loss_avg:0.689291\n",
            "Epoch:6 Step:1768 Training_loss:0.700522, Acc_avg:54.50% Training_loss_avg:0.688800\n",
            "Epoch:6 Step:1776 Training_loss:0.673206, Acc_avg:54.75% Training_loss_avg:0.688420\n",
            "Epoch:6 Step:1784 Training_loss:0.681803, Acc_avg:54.75% Training_loss_avg:0.688795\n",
            "Epoch:6 Step:1792 Training_loss:0.682465, Acc_avg:55.25% Training_loss_avg:0.688207\n",
            "Epoch:6 Step:1800 Training_loss:0.695404, Acc_avg:55.75% Training_loss_avg:0.688051\n",
            "Epoch:6 Step:1808 Training_loss:0.722373, Acc_avg:55.50% Training_loss_avg:0.688724\n",
            "Epoch:6 Step:1816 Training_loss:0.719157, Acc_avg:55.25% Training_loss_avg:0.689100\n",
            "Epoch:6 Step:1824 Training_loss:0.740513, Acc_avg:54.50% Training_loss_avg:0.690655\n",
            "Epoch:6 Step:1832 Training_loss:0.743498, Acc_avg:54.00% Training_loss_avg:0.691546\n",
            "Epoch:6 Step:1840 Training_loss:0.695799, Acc_avg:54.00% Training_loss_avg:0.691475\n",
            "Epoch:6 Step:1848 Training_loss:0.617614, Acc_avg:55.00% Training_loss_avg:0.689505\n",
            "Epoch:6 Step:1856 Training_loss:0.696940, Acc_avg:54.75% Training_loss_avg:0.689893\n",
            "Epoch:6 Step:1864 Training_loss:0.740865, Acc_avg:54.25% Training_loss_avg:0.691182\n",
            "Epoch:6 Step:1872 Training_loss:0.657470, Acc_avg:54.50% Training_loss_avg:0.690683\n",
            "Epoch:6 Step:1880 Training_loss:0.655990, Acc_avg:55.00% Training_loss_avg:0.689963\n",
            "Epoch:6 Step:1888 Training_loss:0.693577, Acc_avg:55.50% Training_loss_avg:0.689467\n",
            "Epoch:6 Step:1896 Training_loss:0.720436, Acc_avg:55.00% Training_loss_avg:0.690520\n",
            "Epoch:6 Step:1904 Training_loss:0.673791, Acc_avg:55.25% Training_loss_avg:0.689981\n",
            "Epoch:6 Step:1912 Training_loss:0.730789, Acc_avg:55.00% Training_loss_avg:0.690648\n",
            "Epoch:6 Step:1920 Training_loss:0.718526, Acc_avg:54.75% Training_loss_avg:0.691041\n",
            "Epoch:6 Step:1928 Training_loss:0.738135, Acc_avg:54.25% Training_loss_avg:0.692206\n",
            "Epoch:6 Step:1936 Training_loss:0.720858, Acc_avg:54.25% Training_loss_avg:0.692454\n",
            "Epoch:6 Step:1944 Training_loss:0.700450, Acc_avg:54.00% Training_loss_avg:0.692601\n",
            "Epoch:6 Step:1952 Training_loss:0.730724, Acc_avg:53.75% Training_loss_avg:0.693238\n",
            "Epoch:6 Step:1960 Training_loss:0.695851, Acc_avg:53.75% Training_loss_avg:0.693731\n",
            "Epoch:6 Step:1968 Training_loss:0.674635, Acc_avg:54.25% Training_loss_avg:0.693320\n",
            "Epoch:6 Step:1976 Training_loss:0.695019, Acc_avg:54.25% Training_loss_avg:0.693202\n",
            "Epoch:6 Step:1984 Training_loss:0.677097, Acc_avg:54.00% Training_loss_avg:0.693454\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:1984 Val_loss:0.690576, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:1992 Training_loss:0.694337, Acc_avg:53.50% Training_loss_avg:0.693929\n",
            "Epoch:6 Step:2000 Training_loss:0.678336, Acc_avg:53.25% Training_loss_avg:0.694146\n",
            "Epoch:6 Step:2008 Training_loss:0.699611, Acc_avg:52.25% Training_loss_avg:0.694741\n",
            "Epoch:6 Step:2016 Training_loss:0.680806, Acc_avg:52.00% Training_loss_avg:0.695114\n",
            "Epoch:6 Step:2024 Training_loss:0.673449, Acc_avg:53.00% Training_loss_avg:0.693898\n",
            "Epoch:6 Step:2032 Training_loss:0.701510, Acc_avg:53.00% Training_loss_avg:0.693784\n",
            "Epoch:6 Step:2040 Training_loss:0.691630, Acc_avg:53.00% Training_loss_avg:0.693665\n",
            "Epoch:6 Step:2048 Training_loss:0.687823, Acc_avg:53.00% Training_loss_avg:0.693510\n",
            "Epoch:6 Step:2056 Training_loss:0.672489, Acc_avg:53.75% Training_loss_avg:0.693412\n",
            "Epoch:6 Step:2064 Training_loss:0.702964, Acc_avg:54.00% Training_loss_avg:0.693279\n",
            "Epoch:6 Step:2072 Training_loss:0.696542, Acc_avg:53.50% Training_loss_avg:0.693900\n",
            "Epoch:6 Step:2080 Training_loss:0.701205, Acc_avg:52.50% Training_loss_avg:0.694780\n",
            "Epoch:6 Step:2088 Training_loss:0.707033, Acc_avg:52.75% Training_loss_avg:0.694385\n",
            "Epoch:6 Step:2096 Training_loss:0.686755, Acc_avg:52.75% Training_loss_avg:0.693853\n",
            "Epoch:6 Step:2104 Training_loss:0.692860, Acc_avg:52.25% Training_loss_avg:0.694277\n",
            "Epoch:6 Step:2112 Training_loss:0.677833, Acc_avg:51.75% Training_loss_avg:0.695699\n",
            "Epoch:6 Step:2120 Training_loss:0.681667, Acc_avg:51.75% Training_loss_avg:0.695857\n",
            "Epoch:6 Step:2128 Training_loss:0.699703, Acc_avg:52.50% Training_loss_avg:0.694844\n",
            "Epoch:6 Step:2136 Training_loss:0.664102, Acc_avg:53.00% Training_loss_avg:0.694659\n",
            "Epoch:6 Step:2144 Training_loss:0.697459, Acc_avg:52.50% Training_loss_avg:0.695115\n",
            "Epoch:6 Step:2152 Training_loss:0.697343, Acc_avg:52.25% Training_loss_avg:0.695460\n",
            "Epoch:6 Step:2160 Training_loss:0.668982, Acc_avg:52.75% Training_loss_avg:0.694959\n",
            "Epoch:6 Step:2168 Training_loss:0.708265, Acc_avg:52.50% Training_loss_avg:0.695114\n",
            "Epoch:6 Step:2176 Training_loss:0.696721, Acc_avg:52.00% Training_loss_avg:0.695584\n",
            "Epoch:6 Step:2184 Training_loss:0.704552, Acc_avg:51.50% Training_loss_avg:0.696039\n",
            "Epoch:6 Step:2192 Training_loss:0.657626, Acc_avg:52.00% Training_loss_avg:0.695542\n",
            "Epoch:6 Step:2200 Training_loss:0.680099, Acc_avg:52.00% Training_loss_avg:0.695236\n",
            "Epoch:6 Step:2208 Training_loss:0.709607, Acc_avg:52.00% Training_loss_avg:0.694981\n",
            "Epoch:6 Step:2216 Training_loss:0.700290, Acc_avg:52.25% Training_loss_avg:0.694603\n",
            "Epoch:6 Step:2224 Training_loss:0.705643, Acc_avg:52.50% Training_loss_avg:0.693906\n",
            "Epoch:6 Step:2232 Training_loss:0.666200, Acc_avg:53.25% Training_loss_avg:0.692360\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:2232 Val_loss:0.689566, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:2240 Training_loss:0.741322, Acc_avg:52.75% Training_loss_avg:0.693271\n",
            "Epoch:6 Step:2248 Training_loss:0.634469, Acc_avg:53.00% Training_loss_avg:0.693608\n",
            "Epoch:6 Step:2256 Training_loss:0.699026, Acc_avg:53.00% Training_loss_avg:0.693649\n",
            "Epoch:6 Step:2264 Training_loss:0.670497, Acc_avg:53.25% Training_loss_avg:0.692242\n",
            "Epoch:6 Step:2272 Training_loss:0.670402, Acc_avg:53.00% Training_loss_avg:0.692501\n",
            "Epoch:6 Step:2280 Training_loss:0.727460, Acc_avg:52.25% Training_loss_avg:0.693930\n",
            "Epoch:6 Step:2288 Training_loss:0.682500, Acc_avg:52.50% Training_loss_avg:0.693708\n",
            "Epoch:6 Step:2296 Training_loss:0.664862, Acc_avg:53.00% Training_loss_avg:0.692597\n",
            "Epoch:6 Step:2304 Training_loss:0.692960, Acc_avg:52.50% Training_loss_avg:0.692980\n",
            "Epoch:6 Step:2312 Training_loss:0.653602, Acc_avg:53.25% Training_loss_avg:0.691437\n",
            "Epoch:6 Step:2320 Training_loss:0.682481, Acc_avg:53.75% Training_loss_avg:0.690716\n",
            "Epoch:6 Step:2328 Training_loss:0.711737, Acc_avg:54.00% Training_loss_avg:0.690188\n",
            "Epoch:6 Step:2336 Training_loss:0.607350, Acc_avg:55.00% Training_loss_avg:0.687918\n",
            "Epoch:6 Step:2344 Training_loss:0.713780, Acc_avg:55.00% Training_loss_avg:0.688184\n",
            "Epoch:6 Step:2352 Training_loss:0.670383, Acc_avg:55.50% Training_loss_avg:0.686977\n",
            "Epoch:6 Step:2360 Training_loss:0.719547, Acc_avg:55.50% Training_loss_avg:0.687451\n",
            "Epoch:6 Step:2368 Training_loss:0.644402, Acc_avg:55.50% Training_loss_avg:0.686847\n",
            "Epoch:6 Step:2376 Training_loss:0.661662, Acc_avg:56.00% Training_loss_avg:0.686180\n",
            "Epoch:6 Step:2384 Training_loss:0.663324, Acc_avg:56.00% Training_loss_avg:0.685904\n",
            "Epoch:6 Step:2392 Training_loss:0.665538, Acc_avg:56.25% Training_loss_avg:0.685328\n",
            "Epoch:6 Step:2400 Training_loss:0.717023, Acc_avg:56.00% Training_loss_avg:0.686102\n",
            "Epoch:6 Step:2408 Training_loss:0.728064, Acc_avg:56.25% Training_loss_avg:0.686671\n",
            "Epoch:6 Step:2416 Training_loss:0.753107, Acc_avg:55.75% Training_loss_avg:0.688117\n",
            "Epoch:6 Step:2424 Training_loss:0.780779, Acc_avg:54.75% Training_loss_avg:0.690264\n",
            "Epoch:6 Step:2432 Training_loss:0.626292, Acc_avg:55.50% Training_loss_avg:0.688759\n",
            "Epoch:6 Step:2440 Training_loss:0.758432, Acc_avg:55.25% Training_loss_avg:0.690095\n",
            "Epoch:6 Step:2448 Training_loss:0.653811, Acc_avg:55.75% Training_loss_avg:0.689415\n",
            "Epoch:6 Step:2456 Training_loss:0.667112, Acc_avg:55.25% Training_loss_avg:0.689307\n",
            "Epoch:6 Step:2464 Training_loss:0.720341, Acc_avg:55.00% Training_loss_avg:0.689655\n",
            "Epoch:6 Step:2472 Training_loss:0.736202, Acc_avg:54.75% Training_loss_avg:0.690448\n",
            "Epoch:6 Step:2480 Training_loss:0.736294, Acc_avg:55.00% Training_loss_avg:0.691150\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:2480 Val_loss:0.689744, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:2488 Training_loss:0.642682, Acc_avg:55.75% Training_loss_avg:0.689863\n",
            "Epoch:6 Step:2496 Training_loss:0.672854, Acc_avg:56.00% Training_loss_avg:0.689585\n",
            "Epoch:6 Step:2504 Training_loss:0.715383, Acc_avg:55.75% Training_loss_avg:0.690035\n",
            "Epoch:6 Step:2512 Training_loss:0.734552, Acc_avg:55.25% Training_loss_avg:0.691170\n",
            "Epoch:6 Step:2520 Training_loss:0.637979, Acc_avg:55.25% Training_loss_avg:0.690296\n",
            "Epoch:6 Step:2528 Training_loss:0.741109, Acc_avg:54.50% Training_loss_avg:0.691124\n",
            "Epoch:6 Step:2536 Training_loss:0.678145, Acc_avg:54.25% Training_loss_avg:0.691405\n",
            "Epoch:6 Step:2544 Training_loss:0.726055, Acc_avg:54.00% Training_loss_avg:0.691977\n",
            "Epoch:6 Step:2552 Training_loss:0.659681, Acc_avg:54.50% Training_loss_avg:0.691224\n",
            "Epoch:6 Step:2560 Training_loss:0.708124, Acc_avg:53.75% Training_loss_avg:0.692007\n",
            "Epoch:6 Step:2568 Training_loss:0.674216, Acc_avg:54.25% Training_loss_avg:0.691326\n",
            "Epoch:6 Step:2576 Training_loss:0.667395, Acc_avg:55.00% Training_loss_avg:0.690739\n",
            "Epoch:6 Step:2584 Training_loss:0.688046, Acc_avg:55.25% Training_loss_avg:0.690409\n",
            "Epoch:6 Step:2592 Training_loss:0.694365, Acc_avg:54.50% Training_loss_avg:0.691144\n",
            "Epoch:6 Step:2600 Training_loss:0.682421, Acc_avg:54.50% Training_loss_avg:0.691190\n",
            "Epoch:6 Step:2608 Training_loss:0.682739, Acc_avg:55.00% Training_loss_avg:0.690653\n",
            "Epoch:6 Step:2616 Training_loss:0.695466, Acc_avg:55.00% Training_loss_avg:0.690556\n",
            "Epoch:6 Step:2624 Training_loss:0.669046, Acc_avg:55.50% Training_loss_avg:0.689824\n",
            "Epoch:6 Step:2632 Training_loss:0.692270, Acc_avg:55.25% Training_loss_avg:0.690346\n",
            "Epoch:6 Step:2640 Training_loss:0.696628, Acc_avg:55.75% Training_loss_avg:0.689452\n",
            "Epoch:6 Step:2648 Training_loss:0.684667, Acc_avg:55.00% Training_loss_avg:0.690456\n",
            "Epoch:6 Step:2656 Training_loss:0.658528, Acc_avg:55.50% Training_loss_avg:0.689646\n",
            "Epoch:6 Step:2664 Training_loss:0.694649, Acc_avg:55.50% Training_loss_avg:0.690129\n",
            "Epoch:6 Step:2672 Training_loss:0.680915, Acc_avg:55.50% Training_loss_avg:0.690339\n",
            "Epoch:6 Step:2680 Training_loss:0.696963, Acc_avg:55.75% Training_loss_avg:0.689729\n",
            "Epoch:6 Step:2688 Training_loss:0.684549, Acc_avg:55.75% Training_loss_avg:0.689770\n",
            "Epoch:6 Step:2696 Training_loss:0.677434, Acc_avg:55.75% Training_loss_avg:0.690022\n",
            "Epoch:6 Step:2704 Training_loss:0.679038, Acc_avg:56.25% Training_loss_avg:0.689743\n",
            "Epoch:6 Step:2712 Training_loss:0.695984, Acc_avg:55.75% Training_loss_avg:0.690591\n",
            "Epoch:6 Step:2720 Training_loss:0.682094, Acc_avg:55.75% Training_loss_avg:0.690583\n",
            "Epoch:6 Step:2728 Training_loss:0.670458, Acc_avg:56.00% Training_loss_avg:0.689758\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:2728 Val_loss:0.689439, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:2736 Training_loss:0.699883, Acc_avg:55.25% Training_loss_avg:0.691608\n",
            "Epoch:6 Step:2744 Training_loss:0.643961, Acc_avg:56.25% Training_loss_avg:0.690212\n",
            "Epoch:6 Step:2752 Training_loss:0.725640, Acc_avg:55.75% Training_loss_avg:0.691317\n",
            "Epoch:6 Step:2760 Training_loss:0.669744, Acc_avg:56.00% Training_loss_avg:0.690321\n",
            "Epoch:6 Step:2768 Training_loss:0.651225, Acc_avg:56.00% Training_loss_avg:0.690457\n",
            "Epoch:6 Step:2776 Training_loss:0.657787, Acc_avg:55.75% Training_loss_avg:0.690380\n",
            "Epoch:6 Step:2784 Training_loss:0.587198, Acc_avg:56.25% Training_loss_avg:0.688857\n",
            "Epoch:6 Step:2792 Training_loss:0.694926, Acc_avg:56.00% Training_loss_avg:0.689445\n",
            "Epoch:6 Step:2800 Training_loss:0.674176, Acc_avg:56.25% Training_loss_avg:0.688588\n",
            "Epoch:6 Step:2808 Training_loss:0.599233, Acc_avg:57.25% Training_loss_avg:0.686012\n",
            "Epoch:6 Step:2816 Training_loss:0.572201, Acc_avg:58.50% Training_loss_avg:0.682393\n",
            "Epoch:6 Step:2824 Training_loss:0.625423, Acc_avg:59.50% Training_loss_avg:0.679286\n",
            "Epoch:6 Step:2832 Training_loss:0.745791, Acc_avg:58.75% Training_loss_avg:0.681676\n",
            "Epoch:6 Step:2840 Training_loss:0.666598, Acc_avg:59.25% Training_loss_avg:0.679840\n",
            "Epoch:6 Step:2848 Training_loss:0.552046, Acc_avg:59.50% Training_loss_avg:0.677804\n",
            "Epoch:6 Step:2856 Training_loss:0.760707, Acc_avg:59.25% Training_loss_avg:0.679676\n",
            "Epoch:6 Step:2864 Training_loss:0.671286, Acc_avg:59.75% Training_loss_avg:0.678695\n",
            "Epoch:6 Step:2872 Training_loss:0.548021, Acc_avg:60.75% Training_loss_avg:0.674931\n",
            "Epoch:6 Step:2880 Training_loss:0.775073, Acc_avg:60.75% Training_loss_avg:0.675707\n",
            "Epoch:6 Step:2888 Training_loss:0.613922, Acc_avg:60.75% Training_loss_avg:0.675132\n",
            "Epoch:6 Step:2896 Training_loss:0.658416, Acc_avg:60.75% Training_loss_avg:0.674843\n",
            "Epoch:6 Step:2904 Training_loss:0.846046, Acc_avg:60.50% Training_loss_avg:0.677456\n",
            "Epoch:6 Step:2912 Training_loss:0.735542, Acc_avg:60.75% Training_loss_avg:0.677476\n",
            "Epoch:6 Step:2920 Training_loss:0.824441, Acc_avg:60.00% Training_loss_avg:0.681205\n",
            "Epoch:6 Step:2928 Training_loss:0.823250, Acc_avg:60.25% Training_loss_avg:0.682848\n",
            "Epoch:6 Step:2936 Training_loss:0.582911, Acc_avg:60.50% Training_loss_avg:0.680944\n",
            "Epoch:6 Step:2944 Training_loss:0.828323, Acc_avg:60.50% Training_loss_avg:0.682989\n",
            "Epoch:6 Step:2952 Training_loss:0.807246, Acc_avg:59.75% Training_loss_avg:0.685940\n",
            "Epoch:6 Step:2960 Training_loss:0.740850, Acc_avg:59.75% Training_loss_avg:0.686595\n",
            "Epoch:6 Step:2968 Training_loss:0.684049, Acc_avg:59.75% Training_loss_avg:0.686791\n",
            "Epoch:6 Step:2976 Training_loss:0.742100, Acc_avg:59.25% Training_loss_avg:0.688286\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:2976 Val_loss:0.691668, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:2984 Training_loss:0.662016, Acc_avg:59.50% Training_loss_avg:0.687765\n",
            "Epoch:6 Step:2992 Training_loss:0.742159, Acc_avg:59.25% Training_loss_avg:0.688721\n",
            "Epoch:6 Step:3000 Training_loss:0.653962, Acc_avg:59.25% Training_loss_avg:0.688152\n",
            "Epoch:6 Step:3008 Training_loss:0.696451, Acc_avg:59.00% Training_loss_avg:0.688426\n",
            "Epoch:6 Step:3016 Training_loss:0.765579, Acc_avg:58.50% Training_loss_avg:0.689828\n",
            "Epoch:6 Step:3024 Training_loss:0.727302, Acc_avg:57.75% Training_loss_avg:0.690993\n",
            "Epoch:6 Step:3032 Training_loss:0.732758, Acc_avg:57.50% Training_loss_avg:0.691803\n",
            "Epoch:6 Step:3040 Training_loss:0.656382, Acc_avg:58.00% Training_loss_avg:0.690998\n",
            "Epoch:6 Step:3048 Training_loss:0.671699, Acc_avg:58.00% Training_loss_avg:0.690739\n",
            "Epoch:6 Step:3056 Training_loss:0.653422, Acc_avg:58.00% Training_loss_avg:0.690637\n",
            "Epoch:6 Step:3064 Training_loss:0.733722, Acc_avg:57.50% Training_loss_avg:0.691418\n",
            "Epoch:6 Step:3072 Training_loss:0.692851, Acc_avg:57.25% Training_loss_avg:0.691657\n",
            "Epoch:6 Step:3080 Training_loss:0.654969, Acc_avg:58.00% Training_loss_avg:0.690817\n",
            "Epoch:6 Step:3088 Training_loss:0.694018, Acc_avg:57.75% Training_loss_avg:0.691006\n",
            "Epoch:6 Step:3096 Training_loss:0.705358, Acc_avg:57.50% Training_loss_avg:0.691565\n",
            "Epoch:6 Step:3104 Training_loss:0.700923, Acc_avg:57.00% Training_loss_avg:0.692002\n",
            "Epoch:6 Step:3112 Training_loss:0.698393, Acc_avg:57.00% Training_loss_avg:0.692051\n",
            "Epoch:6 Step:3120 Training_loss:0.710696, Acc_avg:56.50% Training_loss_avg:0.692623\n",
            "Epoch:6 Step:3128 Training_loss:0.681695, Acc_avg:56.50% Training_loss_avg:0.692847\n",
            "Epoch:6 Step:3136 Training_loss:0.700160, Acc_avg:56.50% Training_loss_avg:0.692853\n",
            "Epoch:6 Step:3144 Training_loss:0.693456, Acc_avg:55.75% Training_loss_avg:0.693843\n",
            "Epoch:6 Step:3152 Training_loss:0.672585, Acc_avg:56.50% Training_loss_avg:0.692782\n",
            "Epoch:6 Step:3160 Training_loss:0.704925, Acc_avg:55.75% Training_loss_avg:0.693485\n",
            "Epoch:6 Step:3168 Training_loss:0.704401, Acc_avg:55.00% Training_loss_avg:0.694549\n",
            "Epoch:6 Step:3176 Training_loss:0.678411, Acc_avg:55.00% Training_loss_avg:0.694961\n",
            "Epoch:6 Step:3184 Training_loss:0.671647, Acc_avg:54.50% Training_loss_avg:0.696650\n",
            "Epoch:6 Step:3192 Training_loss:0.680317, Acc_avg:55.00% Training_loss_avg:0.696358\n",
            "Epoch:6 Step:3200 Training_loss:0.687437, Acc_avg:54.75% Training_loss_avg:0.696623\n",
            "Epoch:6 Step:3208 Training_loss:0.683972, Acc_avg:54.00% Training_loss_avg:0.698318\n",
            "Epoch:6 Step:3216 Training_loss:0.658232, Acc_avg:53.75% Training_loss_avg:0.700039\n",
            "Epoch:6 Step:3224 Training_loss:0.665558, Acc_avg:53.75% Training_loss_avg:0.700841\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:6 Step:3224 Val_loss:0.689622, Val_Acc_avg:54.75%\n",
            "Epoch:6 Step:3232 Training_loss:0.668353, Acc_avg:54.25% Training_loss_avg:0.699293\n",
            "Epoch:6 Step:3240 Training_loss:0.718677, Acc_avg:53.75% Training_loss_avg:0.700334\n",
            "Epoch:6 Step:3248 Training_loss:0.717984, Acc_avg:52.50% Training_loss_avg:0.703653\n",
            "Epoch:6 Step:3256 Training_loss:0.694270, Acc_avg:52.50% Training_loss_avg:0.702324\n",
            "Epoch:6 Step:3264 Training_loss:0.693174, Acc_avg:52.50% Training_loss_avg:0.702762\n",
            "Epoch:6 Step:3272 Training_loss:0.636539, Acc_avg:52.50% Training_loss_avg:0.704532\n",
            "Epoch:6 Step:3280 Training_loss:0.711876, Acc_avg:52.75% Training_loss_avg:0.703268\n",
            "Epoch:6 Step:3288 Training_loss:0.773368, Acc_avg:51.50% Training_loss_avg:0.706457\n",
            "Epoch:6 Step:3296 Training_loss:0.710118, Acc_avg:51.00% Training_loss_avg:0.707491\n",
            "Epoch:6 Step:3304 Training_loss:0.676663, Acc_avg:51.75% Training_loss_avg:0.704104\n",
            "Epoch:6 Step:3312 Training_loss:0.640793, Acc_avg:52.25% Training_loss_avg:0.702209\n",
            "Epoch:6 Step:3320 Training_loss:0.710633, Acc_avg:52.50% Training_loss_avg:0.699933\n",
            "Epoch:6 Step:3328 Training_loss:0.772932, Acc_avg:52.42% Training_loss_avg:0.698926\n",
            "Epoch:7 Step:0 Training_loss:0.633416, Acc_avg:52.42% Training_loss_avg:0.699936\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:0 Val_loss:0.689401, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:8 Training_loss:0.658186, Acc_avg:53.42% Training_loss_avg:0.696534\n",
            "Epoch:7 Step:16 Training_loss:0.723897, Acc_avg:53.42% Training_loss_avg:0.694867\n",
            "Epoch:7 Step:24 Training_loss:0.699128, Acc_avg:53.67% Training_loss_avg:0.694032\n",
            "Epoch:7 Step:32 Training_loss:0.671460, Acc_avg:53.67% Training_loss_avg:0.693780\n",
            "Epoch:7 Step:40 Training_loss:0.677963, Acc_avg:53.92% Training_loss_avg:0.692498\n",
            "Epoch:7 Step:48 Training_loss:0.725701, Acc_avg:53.42% Training_loss_avg:0.693771\n",
            "Epoch:7 Step:56 Training_loss:0.760549, Acc_avg:53.17% Training_loss_avg:0.694139\n",
            "Epoch:7 Step:64 Training_loss:0.716480, Acc_avg:52.92% Training_loss_avg:0.695390\n",
            "Epoch:7 Step:72 Training_loss:0.653828, Acc_avg:53.17% Training_loss_avg:0.694537\n",
            "Epoch:7 Step:80 Training_loss:0.694888, Acc_avg:53.67% Training_loss_avg:0.693123\n",
            "Epoch:7 Step:88 Training_loss:0.717418, Acc_avg:53.67% Training_loss_avg:0.692926\n",
            "Epoch:7 Step:96 Training_loss:0.656812, Acc_avg:54.67% Training_loss_avg:0.691407\n",
            "Epoch:7 Step:104 Training_loss:0.679497, Acc_avg:54.42% Training_loss_avg:0.691869\n",
            "Epoch:7 Step:112 Training_loss:0.729217, Acc_avg:53.67% Training_loss_avg:0.693019\n",
            "Epoch:7 Step:120 Training_loss:0.697524, Acc_avg:53.17% Training_loss_avg:0.693901\n",
            "Epoch:7 Step:128 Training_loss:0.666901, Acc_avg:54.17% Training_loss_avg:0.692565\n",
            "Epoch:7 Step:136 Training_loss:0.719402, Acc_avg:53.92% Training_loss_avg:0.693096\n",
            "Epoch:7 Step:144 Training_loss:0.708685, Acc_avg:52.92% Training_loss_avg:0.694170\n",
            "Epoch:7 Step:152 Training_loss:0.708235, Acc_avg:52.67% Training_loss_avg:0.694455\n",
            "Epoch:7 Step:160 Training_loss:0.679324, Acc_avg:52.92% Training_loss_avg:0.693934\n",
            "Epoch:7 Step:168 Training_loss:0.692173, Acc_avg:53.42% Training_loss_avg:0.693759\n",
            "Epoch:7 Step:176 Training_loss:0.681015, Acc_avg:53.67% Training_loss_avg:0.693411\n",
            "Epoch:7 Step:184 Training_loss:0.694709, Acc_avg:53.92% Training_loss_avg:0.693092\n",
            "Epoch:7 Step:192 Training_loss:0.716846, Acc_avg:53.17% Training_loss_avg:0.693795\n",
            "Epoch:7 Step:200 Training_loss:0.675392, Acc_avg:53.67% Training_loss_avg:0.693299\n",
            "Epoch:7 Step:208 Training_loss:0.687180, Acc_avg:53.92% Training_loss_avg:0.693174\n",
            "Epoch:7 Step:216 Training_loss:0.710533, Acc_avg:52.92% Training_loss_avg:0.693933\n",
            "Epoch:7 Step:224 Training_loss:0.686632, Acc_avg:53.67% Training_loss_avg:0.693567\n",
            "Epoch:7 Step:232 Training_loss:0.656464, Acc_avg:54.67% Training_loss_avg:0.692608\n",
            "Epoch:7 Step:240 Training_loss:0.706559, Acc_avg:54.17% Training_loss_avg:0.693171\n",
            "Epoch:7 Step:248 Training_loss:0.702348, Acc_avg:53.42% Training_loss_avg:0.693785\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:248 Val_loss:0.690291, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:256 Training_loss:0.684975, Acc_avg:53.17% Training_loss_avg:0.693878\n",
            "Epoch:7 Step:264 Training_loss:0.668187, Acc_avg:53.67% Training_loss_avg:0.693493\n",
            "Epoch:7 Step:272 Training_loss:0.669133, Acc_avg:54.17% Training_loss_avg:0.693197\n",
            "Epoch:7 Step:280 Training_loss:0.726578, Acc_avg:52.92% Training_loss_avg:0.694563\n",
            "Epoch:7 Step:288 Training_loss:0.699839, Acc_avg:52.42% Training_loss_avg:0.695249\n",
            "Epoch:7 Step:296 Training_loss:0.682223, Acc_avg:52.42% Training_loss_avg:0.695526\n",
            "Epoch:7 Step:304 Training_loss:0.689094, Acc_avg:52.67% Training_loss_avg:0.694935\n",
            "Epoch:7 Step:312 Training_loss:0.747525, Acc_avg:52.42% Training_loss_avg:0.695526\n",
            "Epoch:7 Step:320 Training_loss:0.662831, Acc_avg:52.92% Training_loss_avg:0.694897\n",
            "Epoch:7 Step:328 Training_loss:0.662748, Acc_avg:53.17% Training_loss_avg:0.694288\n",
            "Epoch:7 Step:336 Training_loss:0.645633, Acc_avg:52.92% Training_loss_avg:0.694470\n",
            "Epoch:7 Step:344 Training_loss:0.682165, Acc_avg:53.17% Training_loss_avg:0.693876\n",
            "Epoch:7 Step:352 Training_loss:0.672383, Acc_avg:54.17% Training_loss_avg:0.691856\n",
            "Epoch:7 Step:360 Training_loss:0.647604, Acc_avg:55.17% Training_loss_avg:0.690606\n",
            "Epoch:7 Step:368 Training_loss:0.670565, Acc_avg:55.17% Training_loss_avg:0.690484\n",
            "Epoch:7 Step:376 Training_loss:0.711066, Acc_avg:54.67% Training_loss_avg:0.691890\n",
            "Epoch:7 Step:384 Training_loss:0.716961, Acc_avg:54.67% Training_loss_avg:0.692016\n",
            "Epoch:7 Step:392 Training_loss:0.713051, Acc_avg:54.75% Training_loss_avg:0.690818\n",
            "Epoch:7 Step:400 Training_loss:0.668299, Acc_avg:54.50% Training_loss_avg:0.691516\n",
            "Epoch:7 Step:408 Training_loss:0.632648, Acc_avg:54.25% Training_loss_avg:0.691005\n",
            "Epoch:7 Step:416 Training_loss:0.704838, Acc_avg:54.50% Training_loss_avg:0.690624\n",
            "Epoch:7 Step:424 Training_loss:0.719820, Acc_avg:54.25% Training_loss_avg:0.691038\n",
            "Epoch:7 Step:432 Training_loss:0.747790, Acc_avg:53.50% Training_loss_avg:0.692565\n",
            "Epoch:7 Step:440 Training_loss:0.717571, Acc_avg:53.00% Training_loss_avg:0.693357\n",
            "Epoch:7 Step:448 Training_loss:0.719969, Acc_avg:53.00% Training_loss_avg:0.693242\n",
            "Epoch:7 Step:456 Training_loss:0.721024, Acc_avg:53.75% Training_loss_avg:0.692452\n",
            "Epoch:7 Step:464 Training_loss:0.680331, Acc_avg:54.00% Training_loss_avg:0.691729\n",
            "Epoch:7 Step:472 Training_loss:0.664048, Acc_avg:54.00% Training_loss_avg:0.691933\n",
            "Epoch:7 Step:480 Training_loss:0.616815, Acc_avg:54.75% Training_loss_avg:0.690372\n",
            "Epoch:7 Step:488 Training_loss:0.761951, Acc_avg:54.50% Training_loss_avg:0.691262\n",
            "Epoch:7 Step:496 Training_loss:0.702319, Acc_avg:53.75% Training_loss_avg:0.692172\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:496 Val_loss:0.689417, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:504 Training_loss:0.651284, Acc_avg:54.00% Training_loss_avg:0.691608\n",
            "Epoch:7 Step:512 Training_loss:0.650618, Acc_avg:55.00% Training_loss_avg:0.690036\n",
            "Epoch:7 Step:520 Training_loss:0.666453, Acc_avg:55.25% Training_loss_avg:0.689415\n",
            "Epoch:7 Step:528 Training_loss:0.699447, Acc_avg:54.75% Training_loss_avg:0.690066\n",
            "Epoch:7 Step:536 Training_loss:0.692584, Acc_avg:55.00% Training_loss_avg:0.689529\n",
            "Epoch:7 Step:544 Training_loss:0.664305, Acc_avg:55.50% Training_loss_avg:0.688642\n",
            "Epoch:7 Step:552 Training_loss:0.660435, Acc_avg:56.25% Training_loss_avg:0.687686\n",
            "Epoch:7 Step:560 Training_loss:0.686312, Acc_avg:56.25% Training_loss_avg:0.687825\n",
            "Epoch:7 Step:568 Training_loss:0.747856, Acc_avg:55.75% Training_loss_avg:0.688939\n",
            "Epoch:7 Step:576 Training_loss:0.760606, Acc_avg:55.25% Training_loss_avg:0.690531\n",
            "Epoch:7 Step:584 Training_loss:0.719222, Acc_avg:55.00% Training_loss_avg:0.691021\n",
            "Epoch:7 Step:592 Training_loss:0.659882, Acc_avg:56.00% Training_loss_avg:0.689882\n",
            "Epoch:7 Step:600 Training_loss:0.642730, Acc_avg:56.00% Training_loss_avg:0.689229\n",
            "Epoch:7 Step:608 Training_loss:0.713574, Acc_avg:55.50% Training_loss_avg:0.689757\n",
            "Epoch:7 Step:616 Training_loss:0.677266, Acc_avg:56.25% Training_loss_avg:0.689091\n",
            "Epoch:7 Step:624 Training_loss:0.657872, Acc_avg:56.25% Training_loss_avg:0.688516\n",
            "Epoch:7 Step:632 Training_loss:0.706666, Acc_avg:55.50% Training_loss_avg:0.689520\n",
            "Epoch:7 Step:640 Training_loss:0.702864, Acc_avg:55.75% Training_loss_avg:0.689446\n",
            "Epoch:7 Step:648 Training_loss:0.690462, Acc_avg:56.00% Training_loss_avg:0.689208\n",
            "Epoch:7 Step:656 Training_loss:0.727654, Acc_avg:55.50% Training_loss_avg:0.690062\n",
            "Epoch:7 Step:664 Training_loss:0.682954, Acc_avg:55.00% Training_loss_avg:0.690357\n",
            "Epoch:7 Step:672 Training_loss:0.646028, Acc_avg:55.00% Training_loss_avg:0.689895\n",
            "Epoch:7 Step:680 Training_loss:0.695893, Acc_avg:55.50% Training_loss_avg:0.689282\n",
            "Epoch:7 Step:688 Training_loss:0.695490, Acc_avg:55.50% Training_loss_avg:0.689195\n",
            "Epoch:7 Step:696 Training_loss:0.643523, Acc_avg:55.75% Training_loss_avg:0.688421\n",
            "Epoch:7 Step:704 Training_loss:0.707972, Acc_avg:55.50% Training_loss_avg:0.688798\n",
            "Epoch:7 Step:712 Training_loss:0.675186, Acc_avg:56.50% Training_loss_avg:0.687351\n",
            "Epoch:7 Step:720 Training_loss:0.711102, Acc_avg:55.75% Training_loss_avg:0.688317\n",
            "Epoch:7 Step:728 Training_loss:0.708031, Acc_avg:55.00% Training_loss_avg:0.689222\n",
            "Epoch:7 Step:736 Training_loss:0.713552, Acc_avg:54.25% Training_loss_avg:0.690581\n",
            "Epoch:7 Step:744 Training_loss:0.654634, Acc_avg:54.50% Training_loss_avg:0.690030\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:744 Val_loss:0.689400, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:752 Training_loss:0.704409, Acc_avg:54.00% Training_loss_avg:0.690671\n",
            "Epoch:7 Step:760 Training_loss:0.685958, Acc_avg:53.25% Training_loss_avg:0.691438\n",
            "Epoch:7 Step:768 Training_loss:0.746265, Acc_avg:52.75% Training_loss_avg:0.692952\n",
            "Epoch:7 Step:776 Training_loss:0.685577, Acc_avg:52.75% Training_loss_avg:0.692442\n",
            "Epoch:7 Step:784 Training_loss:0.644257, Acc_avg:53.50% Training_loss_avg:0.690988\n",
            "Epoch:7 Step:792 Training_loss:0.699224, Acc_avg:53.75% Training_loss_avg:0.690711\n",
            "Epoch:7 Step:800 Training_loss:0.703758, Acc_avg:53.50% Training_loss_avg:0.691421\n",
            "Epoch:7 Step:808 Training_loss:0.632242, Acc_avg:54.00% Training_loss_avg:0.691413\n",
            "Epoch:7 Step:816 Training_loss:0.705179, Acc_avg:53.75% Training_loss_avg:0.691419\n",
            "Epoch:7 Step:824 Training_loss:0.701325, Acc_avg:53.75% Training_loss_avg:0.691049\n",
            "Epoch:7 Step:832 Training_loss:0.624015, Acc_avg:55.00% Training_loss_avg:0.688574\n",
            "Epoch:7 Step:840 Training_loss:0.706199, Acc_avg:55.25% Training_loss_avg:0.688347\n",
            "Epoch:7 Step:848 Training_loss:0.658104, Acc_avg:55.75% Training_loss_avg:0.687109\n",
            "Epoch:7 Step:856 Training_loss:0.730974, Acc_avg:55.25% Training_loss_avg:0.687308\n",
            "Epoch:7 Step:864 Training_loss:0.617852, Acc_avg:55.75% Training_loss_avg:0.686059\n",
            "Epoch:7 Step:872 Training_loss:0.696052, Acc_avg:55.50% Training_loss_avg:0.686699\n",
            "Epoch:7 Step:880 Training_loss:0.672844, Acc_avg:55.00% Training_loss_avg:0.687819\n",
            "Epoch:7 Step:888 Training_loss:0.686622, Acc_avg:55.50% Training_loss_avg:0.686313\n",
            "Epoch:7 Step:896 Training_loss:0.638485, Acc_avg:56.00% Training_loss_avg:0.685036\n",
            "Epoch:7 Step:904 Training_loss:0.691407, Acc_avg:55.50% Training_loss_avg:0.685838\n",
            "Epoch:7 Step:912 Training_loss:0.681163, Acc_avg:55.25% Training_loss_avg:0.686449\n",
            "Epoch:7 Step:920 Training_loss:0.672001, Acc_avg:55.25% Training_loss_avg:0.686560\n",
            "Epoch:7 Step:928 Training_loss:0.687423, Acc_avg:55.50% Training_loss_avg:0.686320\n",
            "Epoch:7 Step:936 Training_loss:0.747020, Acc_avg:55.25% Training_loss_avg:0.687409\n",
            "Epoch:7 Step:944 Training_loss:0.683670, Acc_avg:55.00% Training_loss_avg:0.687796\n",
            "Epoch:7 Step:952 Training_loss:0.637137, Acc_avg:54.75% Training_loss_avg:0.687330\n",
            "Epoch:7 Step:960 Training_loss:0.704297, Acc_avg:54.50% Training_loss_avg:0.687690\n",
            "Epoch:7 Step:968 Training_loss:0.707544, Acc_avg:54.75% Training_loss_avg:0.686883\n",
            "Epoch:7 Step:976 Training_loss:0.675428, Acc_avg:55.25% Training_loss_avg:0.685180\n",
            "Epoch:7 Step:984 Training_loss:0.652815, Acc_avg:55.75% Training_loss_avg:0.683852\n",
            "Epoch:7 Step:992 Training_loss:0.656100, Acc_avg:55.50% Training_loss_avg:0.683776\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:992 Val_loss:0.690630, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:1000 Training_loss:0.694106, Acc_avg:55.50% Training_loss_avg:0.684804\n",
            "Epoch:7 Step:1008 Training_loss:0.599906, Acc_avg:56.25% Training_loss_avg:0.682530\n",
            "Epoch:7 Step:1016 Training_loss:0.747642, Acc_avg:55.75% Training_loss_avg:0.683938\n",
            "Epoch:7 Step:1024 Training_loss:0.747263, Acc_avg:55.25% Training_loss_avg:0.685726\n",
            "Epoch:7 Step:1032 Training_loss:0.576450, Acc_avg:56.00% Training_loss_avg:0.683121\n",
            "Epoch:7 Step:1040 Training_loss:0.602855, Acc_avg:56.50% Training_loss_avg:0.681121\n",
            "Epoch:7 Step:1048 Training_loss:0.679739, Acc_avg:56.75% Training_loss_avg:0.680907\n",
            "Epoch:7 Step:1056 Training_loss:0.586316, Acc_avg:57.75% Training_loss_avg:0.678080\n",
            "Epoch:7 Step:1064 Training_loss:0.659253, Acc_avg:58.00% Training_loss_avg:0.677606\n",
            "Epoch:7 Step:1072 Training_loss:0.666361, Acc_avg:57.75% Training_loss_avg:0.678013\n",
            "Epoch:7 Step:1080 Training_loss:0.669592, Acc_avg:58.00% Training_loss_avg:0.677486\n",
            "Epoch:7 Step:1088 Training_loss:0.631537, Acc_avg:58.50% Training_loss_avg:0.676207\n",
            "Epoch:7 Step:1096 Training_loss:0.620994, Acc_avg:58.50% Training_loss_avg:0.675757\n",
            "Epoch:7 Step:1104 Training_loss:0.562608, Acc_avg:59.50% Training_loss_avg:0.672850\n",
            "Epoch:7 Step:1112 Training_loss:0.650783, Acc_avg:59.50% Training_loss_avg:0.672361\n",
            "Epoch:7 Step:1120 Training_loss:0.712355, Acc_avg:59.75% Training_loss_avg:0.672387\n",
            "Epoch:7 Step:1128 Training_loss:0.842887, Acc_avg:59.50% Training_loss_avg:0.675084\n",
            "Epoch:7 Step:1136 Training_loss:0.829391, Acc_avg:59.50% Training_loss_avg:0.677400\n",
            "Epoch:7 Step:1144 Training_loss:0.816259, Acc_avg:58.50% Training_loss_avg:0.680633\n",
            "Epoch:7 Step:1152 Training_loss:0.708122, Acc_avg:59.00% Training_loss_avg:0.680707\n",
            "Epoch:7 Step:1160 Training_loss:0.750866, Acc_avg:58.75% Training_loss_avg:0.682005\n",
            "Epoch:7 Step:1168 Training_loss:0.458802, Acc_avg:60.00% Training_loss_avg:0.676256\n",
            "Epoch:7 Step:1176 Training_loss:0.572846, Acc_avg:60.75% Training_loss_avg:0.674001\n",
            "Epoch:7 Step:1184 Training_loss:0.679890, Acc_avg:60.25% Training_loss_avg:0.674714\n",
            "Epoch:7 Step:1192 Training_loss:0.832717, Acc_avg:60.00% Training_loss_avg:0.677384\n",
            "Epoch:7 Step:1200 Training_loss:0.856660, Acc_avg:59.50% Training_loss_avg:0.680442\n",
            "Epoch:7 Step:1208 Training_loss:0.676563, Acc_avg:59.00% Training_loss_avg:0.681328\n",
            "Epoch:7 Step:1216 Training_loss:0.712692, Acc_avg:59.25% Training_loss_avg:0.681479\n",
            "Epoch:7 Step:1224 Training_loss:0.678624, Acc_avg:59.75% Training_loss_avg:0.681025\n",
            "Epoch:7 Step:1232 Training_loss:0.662455, Acc_avg:59.25% Training_loss_avg:0.681793\n",
            "Epoch:7 Step:1240 Training_loss:0.697153, Acc_avg:59.25% Training_loss_avg:0.681613\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:1240 Val_loss:0.691555, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:1248 Training_loss:0.757620, Acc_avg:58.75% Training_loss_avg:0.683603\n",
            "Epoch:7 Step:1256 Training_loss:0.627487, Acc_avg:59.50% Training_loss_avg:0.681533\n",
            "Epoch:7 Step:1264 Training_loss:0.615762, Acc_avg:59.25% Training_loss_avg:0.681491\n",
            "Epoch:7 Step:1272 Training_loss:0.675329, Acc_avg:59.50% Training_loss_avg:0.681077\n",
            "Epoch:7 Step:1280 Training_loss:0.638956, Acc_avg:59.75% Training_loss_avg:0.680399\n",
            "Epoch:7 Step:1288 Training_loss:0.592329, Acc_avg:60.50% Training_loss_avg:0.678513\n",
            "Epoch:7 Step:1296 Training_loss:0.715490, Acc_avg:60.00% Training_loss_avg:0.680053\n",
            "Epoch:7 Step:1304 Training_loss:0.637450, Acc_avg:60.25% Training_loss_avg:0.678974\n",
            "Epoch:7 Step:1312 Training_loss:0.634765, Acc_avg:60.25% Training_loss_avg:0.678046\n",
            "Epoch:7 Step:1320 Training_loss:0.744059, Acc_avg:59.75% Training_loss_avg:0.679487\n",
            "Epoch:7 Step:1328 Training_loss:0.675673, Acc_avg:59.75% Training_loss_avg:0.679252\n",
            "Epoch:7 Step:1336 Training_loss:0.690807, Acc_avg:60.25% Training_loss_avg:0.678128\n",
            "Epoch:7 Step:1344 Training_loss:0.672360, Acc_avg:60.25% Training_loss_avg:0.677902\n",
            "Epoch:7 Step:1352 Training_loss:0.717918, Acc_avg:60.00% Training_loss_avg:0.679518\n",
            "Epoch:7 Step:1360 Training_loss:0.820292, Acc_avg:59.25% Training_loss_avg:0.681837\n",
            "Epoch:7 Step:1368 Training_loss:0.625841, Acc_avg:59.75% Training_loss_avg:0.680203\n",
            "Epoch:7 Step:1376 Training_loss:0.721967, Acc_avg:59.25% Training_loss_avg:0.681134\n",
            "Epoch:7 Step:1384 Training_loss:0.637410, Acc_avg:59.50% Training_loss_avg:0.680826\n",
            "Epoch:7 Step:1392 Training_loss:0.659255, Acc_avg:59.50% Training_loss_avg:0.680889\n",
            "Epoch:7 Step:1400 Training_loss:0.666603, Acc_avg:59.25% Training_loss_avg:0.680339\n",
            "Epoch:7 Step:1408 Training_loss:0.637540, Acc_avg:59.25% Training_loss_avg:0.681092\n",
            "Epoch:7 Step:1416 Training_loss:0.671715, Acc_avg:59.75% Training_loss_avg:0.679573\n",
            "Epoch:7 Step:1424 Training_loss:0.872307, Acc_avg:59.00% Training_loss_avg:0.682074\n",
            "Epoch:7 Step:1432 Training_loss:0.728400, Acc_avg:58.25% Training_loss_avg:0.685113\n",
            "Epoch:7 Step:1440 Training_loss:0.658792, Acc_avg:58.00% Training_loss_avg:0.686232\n",
            "Epoch:7 Step:1448 Training_loss:0.634106, Acc_avg:58.25% Training_loss_avg:0.685319\n",
            "Epoch:7 Step:1456 Training_loss:0.641689, Acc_avg:58.00% Training_loss_avg:0.686427\n",
            "Epoch:7 Step:1464 Training_loss:0.625845, Acc_avg:58.25% Training_loss_avg:0.685758\n",
            "Epoch:7 Step:1472 Training_loss:0.717801, Acc_avg:58.00% Training_loss_avg:0.686787\n",
            "Epoch:7 Step:1480 Training_loss:0.746554, Acc_avg:57.50% Training_loss_avg:0.688327\n",
            "Epoch:7 Step:1488 Training_loss:0.775314, Acc_avg:56.75% Training_loss_avg:0.691202\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:1488 Val_loss:0.690182, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:1496 Training_loss:0.679728, Acc_avg:56.25% Training_loss_avg:0.692377\n",
            "Epoch:7 Step:1504 Training_loss:0.757376, Acc_avg:55.25% Training_loss_avg:0.696272\n",
            "Epoch:7 Step:1512 Training_loss:0.670391, Acc_avg:55.25% Training_loss_avg:0.696664\n",
            "Epoch:7 Step:1520 Training_loss:0.729235, Acc_avg:55.00% Training_loss_avg:0.697002\n",
            "Epoch:7 Step:1528 Training_loss:0.705801, Acc_avg:55.50% Training_loss_avg:0.694260\n",
            "Epoch:7 Step:1536 Training_loss:0.778536, Acc_avg:55.00% Training_loss_avg:0.693243\n",
            "Epoch:7 Step:1544 Training_loss:0.717031, Acc_avg:55.25% Training_loss_avg:0.691258\n",
            "Epoch:7 Step:1552 Training_loss:0.617213, Acc_avg:56.00% Training_loss_avg:0.689440\n",
            "Epoch:7 Step:1560 Training_loss:0.655866, Acc_avg:56.75% Training_loss_avg:0.687540\n",
            "Epoch:7 Step:1568 Training_loss:0.688854, Acc_avg:56.00% Training_loss_avg:0.692141\n",
            "Epoch:7 Step:1576 Training_loss:0.638887, Acc_avg:56.00% Training_loss_avg:0.693462\n",
            "Epoch:7 Step:1584 Training_loss:0.718959, Acc_avg:55.50% Training_loss_avg:0.694244\n",
            "Epoch:7 Step:1592 Training_loss:0.721086, Acc_avg:55.50% Training_loss_avg:0.692011\n",
            "Epoch:7 Step:1600 Training_loss:0.639619, Acc_avg:56.75% Training_loss_avg:0.687670\n",
            "Epoch:7 Step:1608 Training_loss:0.763351, Acc_avg:55.50% Training_loss_avg:0.689406\n",
            "Epoch:7 Step:1616 Training_loss:0.711212, Acc_avg:55.25% Training_loss_avg:0.689376\n",
            "Epoch:7 Step:1624 Training_loss:0.720187, Acc_avg:54.50% Training_loss_avg:0.690208\n",
            "Epoch:7 Step:1632 Training_loss:0.683466, Acc_avg:54.50% Training_loss_avg:0.690628\n",
            "Epoch:7 Step:1640 Training_loss:0.661466, Acc_avg:55.00% Training_loss_avg:0.689914\n",
            "Epoch:7 Step:1648 Training_loss:0.693676, Acc_avg:55.25% Training_loss_avg:0.688635\n",
            "Epoch:7 Step:1656 Training_loss:0.668877, Acc_avg:55.25% Training_loss_avg:0.689463\n",
            "Epoch:7 Step:1664 Training_loss:0.710305, Acc_avg:54.50% Training_loss_avg:0.691354\n",
            "Epoch:7 Step:1672 Training_loss:0.710382, Acc_avg:54.00% Training_loss_avg:0.692055\n",
            "Epoch:7 Step:1680 Training_loss:0.641816, Acc_avg:54.50% Training_loss_avg:0.692112\n",
            "Epoch:7 Step:1688 Training_loss:0.692427, Acc_avg:53.75% Training_loss_avg:0.694114\n",
            "Epoch:7 Step:1696 Training_loss:0.725575, Acc_avg:53.25% Training_loss_avg:0.694316\n",
            "Epoch:7 Step:1704 Training_loss:0.701588, Acc_avg:52.75% Training_loss_avg:0.695598\n",
            "Epoch:7 Step:1712 Training_loss:0.679607, Acc_avg:52.75% Training_loss_avg:0.696495\n",
            "Epoch:7 Step:1720 Training_loss:0.715450, Acc_avg:52.50% Training_loss_avg:0.695923\n",
            "Epoch:7 Step:1728 Training_loss:0.692576, Acc_avg:52.25% Training_loss_avg:0.696261\n",
            "Epoch:7 Step:1736 Training_loss:0.670743, Acc_avg:52.75% Training_loss_avg:0.695860\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:1736 Val_loss:0.690483, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:1744 Training_loss:0.687988, Acc_avg:53.00% Training_loss_avg:0.696173\n",
            "Epoch:7 Step:1752 Training_loss:0.702081, Acc_avg:52.75% Training_loss_avg:0.695856\n",
            "Epoch:7 Step:1760 Training_loss:0.725583, Acc_avg:52.75% Training_loss_avg:0.693962\n",
            "Epoch:7 Step:1768 Training_loss:0.682802, Acc_avg:52.50% Training_loss_avg:0.695101\n",
            "Epoch:7 Step:1776 Training_loss:0.703833, Acc_avg:52.50% Training_loss_avg:0.694738\n",
            "Epoch:7 Step:1784 Training_loss:0.690155, Acc_avg:52.25% Training_loss_avg:0.695793\n",
            "Epoch:7 Step:1792 Training_loss:0.679011, Acc_avg:52.50% Training_loss_avg:0.696188\n",
            "Epoch:7 Step:1800 Training_loss:0.684050, Acc_avg:52.50% Training_loss_avg:0.696537\n",
            "Epoch:7 Step:1808 Training_loss:0.692687, Acc_avg:52.25% Training_loss_avg:0.697640\n",
            "Epoch:7 Step:1816 Training_loss:0.701494, Acc_avg:51.75% Training_loss_avg:0.698236\n",
            "Epoch:7 Step:1824 Training_loss:0.697496, Acc_avg:52.75% Training_loss_avg:0.694739\n",
            "Epoch:7 Step:1832 Training_loss:0.702241, Acc_avg:52.50% Training_loss_avg:0.694216\n",
            "Epoch:7 Step:1840 Training_loss:0.678943, Acc_avg:52.75% Training_loss_avg:0.694619\n",
            "Epoch:7 Step:1848 Training_loss:0.678539, Acc_avg:52.50% Training_loss_avg:0.695508\n",
            "Epoch:7 Step:1856 Training_loss:0.688522, Acc_avg:52.25% Training_loss_avg:0.696444\n",
            "Epoch:7 Step:1864 Training_loss:0.703750, Acc_avg:51.50% Training_loss_avg:0.698003\n",
            "Epoch:7 Step:1872 Training_loss:0.670486, Acc_avg:51.75% Training_loss_avg:0.697056\n",
            "Epoch:7 Step:1880 Training_loss:0.673619, Acc_avg:52.50% Training_loss_avg:0.695598\n",
            "Epoch:7 Step:1888 Training_loss:0.692685, Acc_avg:52.75% Training_loss_avg:0.693945\n",
            "Epoch:7 Step:1896 Training_loss:0.692440, Acc_avg:52.75% Training_loss_avg:0.694199\n",
            "Epoch:7 Step:1904 Training_loss:0.666284, Acc_avg:53.50% Training_loss_avg:0.692377\n",
            "Epoch:7 Step:1912 Training_loss:0.707646, Acc_avg:53.25% Training_loss_avg:0.693123\n",
            "Epoch:7 Step:1920 Training_loss:0.657528, Acc_avg:54.00% Training_loss_avg:0.691688\n",
            "Epoch:7 Step:1928 Training_loss:0.693219, Acc_avg:54.25% Training_loss_avg:0.691437\n",
            "Epoch:7 Step:1936 Training_loss:0.717580, Acc_avg:54.75% Training_loss_avg:0.690218\n",
            "Epoch:7 Step:1944 Training_loss:0.695325, Acc_avg:55.00% Training_loss_avg:0.689783\n",
            "Epoch:7 Step:1952 Training_loss:0.707154, Acc_avg:53.75% Training_loss_avg:0.691582\n",
            "Epoch:7 Step:1960 Training_loss:0.737516, Acc_avg:52.75% Training_loss_avg:0.693215\n",
            "Epoch:7 Step:1968 Training_loss:0.698408, Acc_avg:52.50% Training_loss_avg:0.693406\n",
            "Epoch:7 Step:1976 Training_loss:0.742941, Acc_avg:51.25% Training_loss_avg:0.695487\n",
            "Epoch:7 Step:1984 Training_loss:0.669667, Acc_avg:52.00% Training_loss_avg:0.694502\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:1984 Val_loss:0.689484, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:1992 Training_loss:0.723821, Acc_avg:52.00% Training_loss_avg:0.694556\n",
            "Epoch:7 Step:2000 Training_loss:0.676028, Acc_avg:51.50% Training_loss_avg:0.695285\n",
            "Epoch:7 Step:2008 Training_loss:0.718494, Acc_avg:52.00% Training_loss_avg:0.694387\n",
            "Epoch:7 Step:2016 Training_loss:0.676599, Acc_avg:52.50% Training_loss_avg:0.693695\n",
            "Epoch:7 Step:2024 Training_loss:0.657258, Acc_avg:53.75% Training_loss_avg:0.692437\n",
            "Epoch:7 Step:2032 Training_loss:0.659026, Acc_avg:54.00% Training_loss_avg:0.691948\n",
            "Epoch:7 Step:2040 Training_loss:0.688830, Acc_avg:53.50% Training_loss_avg:0.692495\n",
            "Epoch:7 Step:2048 Training_loss:0.677396, Acc_avg:53.75% Training_loss_avg:0.692169\n",
            "Epoch:7 Step:2056 Training_loss:0.663799, Acc_avg:53.75% Training_loss_avg:0.692068\n",
            "Epoch:7 Step:2064 Training_loss:0.662336, Acc_avg:54.50% Training_loss_avg:0.691108\n",
            "Epoch:7 Step:2072 Training_loss:0.652948, Acc_avg:55.25% Training_loss_avg:0.689960\n",
            "Epoch:7 Step:2080 Training_loss:0.735318, Acc_avg:53.75% Training_loss_avg:0.691830\n",
            "Epoch:7 Step:2088 Training_loss:0.722437, Acc_avg:53.50% Training_loss_avg:0.692430\n",
            "Epoch:7 Step:2096 Training_loss:0.696265, Acc_avg:54.00% Training_loss_avg:0.691844\n",
            "Epoch:7 Step:2104 Training_loss:0.719276, Acc_avg:54.00% Training_loss_avg:0.692198\n",
            "Epoch:7 Step:2112 Training_loss:0.652014, Acc_avg:54.25% Training_loss_avg:0.691646\n",
            "Epoch:7 Step:2120 Training_loss:0.713125, Acc_avg:54.50% Training_loss_avg:0.691599\n",
            "Epoch:7 Step:2128 Training_loss:0.719911, Acc_avg:54.25% Training_loss_avg:0.692146\n",
            "Epoch:7 Step:2136 Training_loss:0.727148, Acc_avg:53.25% Training_loss_avg:0.693274\n",
            "Epoch:7 Step:2144 Training_loss:0.692498, Acc_avg:53.25% Training_loss_avg:0.693364\n",
            "Epoch:7 Step:2152 Training_loss:0.652354, Acc_avg:54.00% Training_loss_avg:0.692370\n",
            "Epoch:7 Step:2160 Training_loss:0.668990, Acc_avg:55.00% Training_loss_avg:0.691238\n",
            "Epoch:7 Step:2168 Training_loss:0.630038, Acc_avg:55.50% Training_loss_avg:0.690183\n",
            "Epoch:7 Step:2176 Training_loss:0.702234, Acc_avg:56.00% Training_loss_avg:0.690151\n",
            "Epoch:7 Step:2184 Training_loss:0.634927, Acc_avg:56.50% Training_loss_avg:0.689046\n",
            "Epoch:7 Step:2192 Training_loss:0.674728, Acc_avg:56.25% Training_loss_avg:0.688960\n",
            "Epoch:7 Step:2200 Training_loss:0.726764, Acc_avg:55.75% Training_loss_avg:0.689815\n",
            "Epoch:7 Step:2208 Training_loss:0.716111, Acc_avg:55.25% Training_loss_avg:0.690283\n",
            "Epoch:7 Step:2216 Training_loss:0.653358, Acc_avg:56.00% Training_loss_avg:0.689320\n",
            "Epoch:7 Step:2224 Training_loss:0.719058, Acc_avg:55.75% Training_loss_avg:0.689752\n",
            "Epoch:7 Step:2232 Training_loss:0.715702, Acc_avg:55.75% Training_loss_avg:0.690021\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:2232 Val_loss:0.689583, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:2240 Training_loss:0.649497, Acc_avg:55.75% Training_loss_avg:0.689432\n",
            "Epoch:7 Step:2248 Training_loss:0.663352, Acc_avg:55.75% Training_loss_avg:0.689128\n",
            "Epoch:7 Step:2256 Training_loss:0.699146, Acc_avg:55.50% Training_loss_avg:0.689341\n",
            "Epoch:7 Step:2264 Training_loss:0.677968, Acc_avg:56.00% Training_loss_avg:0.688825\n",
            "Epoch:7 Step:2272 Training_loss:0.742408, Acc_avg:55.25% Training_loss_avg:0.690263\n",
            "Epoch:7 Step:2280 Training_loss:0.637419, Acc_avg:55.25% Training_loss_avg:0.689539\n",
            "Epoch:7 Step:2288 Training_loss:0.758717, Acc_avg:54.75% Training_loss_avg:0.690860\n",
            "Epoch:7 Step:2296 Training_loss:0.635222, Acc_avg:55.25% Training_loss_avg:0.689716\n",
            "Epoch:7 Step:2304 Training_loss:0.753676, Acc_avg:54.25% Training_loss_avg:0.691464\n",
            "Epoch:7 Step:2312 Training_loss:0.647937, Acc_avg:54.75% Training_loss_avg:0.690269\n",
            "Epoch:7 Step:2320 Training_loss:0.662927, Acc_avg:54.50% Training_loss_avg:0.690377\n",
            "Epoch:7 Step:2328 Training_loss:0.687543, Acc_avg:54.50% Training_loss_avg:0.690264\n",
            "Epoch:7 Step:2336 Training_loss:0.683920, Acc_avg:55.00% Training_loss_avg:0.689591\n",
            "Epoch:7 Step:2344 Training_loss:0.658450, Acc_avg:55.25% Training_loss_avg:0.688853\n",
            "Epoch:7 Step:2352 Training_loss:0.671751, Acc_avg:55.75% Training_loss_avg:0.688145\n",
            "Epoch:7 Step:2360 Training_loss:0.665618, Acc_avg:56.50% Training_loss_avg:0.686707\n",
            "Epoch:7 Step:2368 Training_loss:0.673664, Acc_avg:56.75% Training_loss_avg:0.686212\n",
            "Epoch:7 Step:2376 Training_loss:0.685588, Acc_avg:57.25% Training_loss_avg:0.685065\n",
            "Epoch:7 Step:2384 Training_loss:0.720711, Acc_avg:56.75% Training_loss_avg:0.686086\n",
            "Epoch:7 Step:2392 Training_loss:0.679841, Acc_avg:57.25% Training_loss_avg:0.685206\n",
            "Epoch:7 Step:2400 Training_loss:0.649954, Acc_avg:57.25% Training_loss_avg:0.684685\n",
            "Epoch:7 Step:2408 Training_loss:0.702191, Acc_avg:57.75% Training_loss_avg:0.684359\n",
            "Epoch:7 Step:2416 Training_loss:0.624447, Acc_avg:58.00% Training_loss_avg:0.683316\n",
            "Epoch:7 Step:2424 Training_loss:0.617291, Acc_avg:57.75% Training_loss_avg:0.682516\n",
            "Epoch:7 Step:2432 Training_loss:0.821249, Acc_avg:56.25% Training_loss_avg:0.685761\n",
            "Epoch:7 Step:2440 Training_loss:0.693464, Acc_avg:56.25% Training_loss_avg:0.685854\n",
            "Epoch:7 Step:2448 Training_loss:0.668018, Acc_avg:56.25% Training_loss_avg:0.685666\n",
            "Epoch:7 Step:2456 Training_loss:0.792935, Acc_avg:55.25% Training_loss_avg:0.688249\n",
            "Epoch:7 Step:2464 Training_loss:0.562441, Acc_avg:55.75% Training_loss_avg:0.686251\n",
            "Epoch:7 Step:2472 Training_loss:0.639185, Acc_avg:55.75% Training_loss_avg:0.685976\n",
            "Epoch:7 Step:2480 Training_loss:0.648717, Acc_avg:56.50% Training_loss_avg:0.684244\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:2480 Val_loss:0.690828, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:2488 Training_loss:0.777964, Acc_avg:56.25% Training_loss_avg:0.685354\n",
            "Epoch:7 Step:2496 Training_loss:0.750136, Acc_avg:56.00% Training_loss_avg:0.686432\n",
            "Epoch:7 Step:2504 Training_loss:0.680927, Acc_avg:56.50% Training_loss_avg:0.685665\n",
            "Epoch:7 Step:2512 Training_loss:0.701896, Acc_avg:56.00% Training_loss_avg:0.686662\n",
            "Epoch:7 Step:2520 Training_loss:0.631181, Acc_avg:56.75% Training_loss_avg:0.685023\n",
            "Epoch:7 Step:2528 Training_loss:0.633230, Acc_avg:57.50% Training_loss_avg:0.683290\n",
            "Epoch:7 Step:2536 Training_loss:0.699443, Acc_avg:57.75% Training_loss_avg:0.682736\n",
            "Epoch:7 Step:2544 Training_loss:0.712535, Acc_avg:57.50% Training_loss_avg:0.683136\n",
            "Epoch:7 Step:2552 Training_loss:0.662854, Acc_avg:57.25% Training_loss_avg:0.683346\n",
            "Epoch:7 Step:2560 Training_loss:0.727429, Acc_avg:56.75% Training_loss_avg:0.684515\n",
            "Epoch:7 Step:2568 Training_loss:0.674460, Acc_avg:56.25% Training_loss_avg:0.685404\n",
            "Epoch:7 Step:2576 Training_loss:0.669535, Acc_avg:56.25% Training_loss_avg:0.684750\n",
            "Epoch:7 Step:2584 Training_loss:0.648901, Acc_avg:56.00% Training_loss_avg:0.685029\n",
            "Epoch:7 Step:2592 Training_loss:0.595687, Acc_avg:56.50% Training_loss_avg:0.683448\n",
            "Epoch:7 Step:2600 Training_loss:0.628223, Acc_avg:57.25% Training_loss_avg:0.681477\n",
            "Epoch:7 Step:2608 Training_loss:0.748806, Acc_avg:57.25% Training_loss_avg:0.682131\n",
            "Epoch:7 Step:2616 Training_loss:0.711539, Acc_avg:56.75% Training_loss_avg:0.683295\n",
            "Epoch:7 Step:2624 Training_loss:0.675094, Acc_avg:57.25% Training_loss_avg:0.682416\n",
            "Epoch:7 Step:2632 Training_loss:0.679703, Acc_avg:57.50% Training_loss_avg:0.681696\n",
            "Epoch:7 Step:2640 Training_loss:0.761684, Acc_avg:56.75% Training_loss_avg:0.683939\n",
            "Epoch:7 Step:2648 Training_loss:0.789422, Acc_avg:56.00% Training_loss_avg:0.686461\n",
            "Epoch:7 Step:2656 Training_loss:0.679885, Acc_avg:56.25% Training_loss_avg:0.686076\n",
            "Epoch:7 Step:2664 Training_loss:0.719732, Acc_avg:55.75% Training_loss_avg:0.686911\n",
            "Epoch:7 Step:2672 Training_loss:0.673310, Acc_avg:56.50% Training_loss_avg:0.685529\n",
            "Epoch:7 Step:2680 Training_loss:0.655168, Acc_avg:56.25% Training_loss_avg:0.685884\n",
            "Epoch:7 Step:2688 Training_loss:0.718683, Acc_avg:56.75% Training_loss_avg:0.685083\n",
            "Epoch:7 Step:2696 Training_loss:0.629490, Acc_avg:56.75% Training_loss_avg:0.684969\n",
            "Epoch:7 Step:2704 Training_loss:0.670857, Acc_avg:57.50% Training_loss_avg:0.683312\n",
            "Epoch:7 Step:2712 Training_loss:0.613219, Acc_avg:57.75% Training_loss_avg:0.682618\n",
            "Epoch:7 Step:2720 Training_loss:0.704262, Acc_avg:57.50% Training_loss_avg:0.683445\n",
            "Epoch:7 Step:2728 Training_loss:0.657006, Acc_avg:57.50% Training_loss_avg:0.682834\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:2728 Val_loss:0.690110, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:2736 Training_loss:0.746992, Acc_avg:57.00% Training_loss_avg:0.684095\n",
            "Epoch:7 Step:2744 Training_loss:0.671959, Acc_avg:57.00% Training_loss_avg:0.684365\n",
            "Epoch:7 Step:2752 Training_loss:0.637741, Acc_avg:57.25% Training_loss_avg:0.683685\n",
            "Epoch:7 Step:2760 Training_loss:0.794415, Acc_avg:56.25% Training_loss_avg:0.686261\n",
            "Epoch:7 Step:2768 Training_loss:0.666456, Acc_avg:56.25% Training_loss_avg:0.686117\n",
            "Epoch:7 Step:2776 Training_loss:0.695430, Acc_avg:56.25% Training_loss_avg:0.686314\n",
            "Epoch:7 Step:2784 Training_loss:0.654564, Acc_avg:56.75% Training_loss_avg:0.684991\n",
            "Epoch:7 Step:2792 Training_loss:0.639398, Acc_avg:57.00% Training_loss_avg:0.684182\n",
            "Epoch:7 Step:2800 Training_loss:0.715142, Acc_avg:56.75% Training_loss_avg:0.685486\n",
            "Epoch:7 Step:2808 Training_loss:0.644653, Acc_avg:57.25% Training_loss_avg:0.684335\n",
            "Epoch:7 Step:2816 Training_loss:0.738728, Acc_avg:56.25% Training_loss_avg:0.686621\n",
            "Epoch:7 Step:2824 Training_loss:0.628575, Acc_avg:56.25% Training_loss_avg:0.686846\n",
            "Epoch:7 Step:2832 Training_loss:0.771868, Acc_avg:56.75% Training_loss_avg:0.685859\n",
            "Epoch:7 Step:2840 Training_loss:0.743912, Acc_avg:56.50% Training_loss_avg:0.686868\n",
            "Epoch:7 Step:2848 Training_loss:0.643135, Acc_avg:56.75% Training_loss_avg:0.686370\n",
            "Epoch:7 Step:2856 Training_loss:0.693824, Acc_avg:57.25% Training_loss_avg:0.684388\n",
            "Epoch:7 Step:2864 Training_loss:0.702149, Acc_avg:56.25% Training_loss_avg:0.687182\n",
            "Epoch:7 Step:2872 Training_loss:0.783046, Acc_avg:55.00% Training_loss_avg:0.690059\n",
            "Epoch:7 Step:2880 Training_loss:0.629494, Acc_avg:55.25% Training_loss_avg:0.689675\n",
            "Epoch:7 Step:2888 Training_loss:0.701509, Acc_avg:55.75% Training_loss_avg:0.688146\n",
            "Epoch:7 Step:2896 Training_loss:0.617370, Acc_avg:56.75% Training_loss_avg:0.685490\n",
            "Epoch:7 Step:2904 Training_loss:0.723912, Acc_avg:56.25% Training_loss_avg:0.686350\n",
            "Epoch:7 Step:2912 Training_loss:0.672149, Acc_avg:56.50% Training_loss_avg:0.685755\n",
            "Epoch:7 Step:2920 Training_loss:0.648540, Acc_avg:56.50% Training_loss_avg:0.686102\n",
            "Epoch:7 Step:2928 Training_loss:0.639885, Acc_avg:56.50% Training_loss_avg:0.686236\n",
            "Epoch:7 Step:2936 Training_loss:0.646077, Acc_avg:57.00% Training_loss_avg:0.685168\n",
            "Epoch:7 Step:2944 Training_loss:0.705549, Acc_avg:57.00% Training_loss_avg:0.685029\n",
            "Epoch:7 Step:2952 Training_loss:0.741019, Acc_avg:56.50% Training_loss_avg:0.686592\n",
            "Epoch:7 Step:2960 Training_loss:0.683229, Acc_avg:56.75% Training_loss_avg:0.685708\n",
            "Epoch:7 Step:2968 Training_loss:0.663227, Acc_avg:57.00% Training_loss_avg:0.685483\n",
            "Epoch:7 Step:2976 Training_loss:0.677056, Acc_avg:57.00% Training_loss_avg:0.685634\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:2976 Val_loss:0.690088, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:2984 Training_loss:0.717635, Acc_avg:56.25% Training_loss_avg:0.687008\n",
            "Epoch:7 Step:2992 Training_loss:0.742499, Acc_avg:55.25% Training_loss_avg:0.689944\n",
            "Epoch:7 Step:3000 Training_loss:0.769182, Acc_avg:54.25% Training_loss_avg:0.692764\n",
            "Epoch:7 Step:3008 Training_loss:0.708095, Acc_avg:54.50% Training_loss_avg:0.691949\n",
            "Epoch:7 Step:3016 Training_loss:0.677610, Acc_avg:54.75% Training_loss_avg:0.691271\n",
            "Epoch:7 Step:3024 Training_loss:0.686732, Acc_avg:54.50% Training_loss_avg:0.691504\n",
            "Epoch:7 Step:3032 Training_loss:0.760245, Acc_avg:54.00% Training_loss_avg:0.693114\n",
            "Epoch:7 Step:3040 Training_loss:0.656445, Acc_avg:54.50% Training_loss_avg:0.691010\n",
            "Epoch:7 Step:3048 Training_loss:0.663727, Acc_avg:55.50% Training_loss_avg:0.688496\n",
            "Epoch:7 Step:3056 Training_loss:0.707756, Acc_avg:55.00% Training_loss_avg:0.689053\n",
            "Epoch:7 Step:3064 Training_loss:0.683452, Acc_avg:55.50% Training_loss_avg:0.688328\n",
            "Epoch:7 Step:3072 Training_loss:0.676966, Acc_avg:55.25% Training_loss_avg:0.688401\n",
            "Epoch:7 Step:3080 Training_loss:0.628045, Acc_avg:55.75% Training_loss_avg:0.687858\n",
            "Epoch:7 Step:3088 Training_loss:0.709956, Acc_avg:55.50% Training_loss_avg:0.687684\n",
            "Epoch:7 Step:3096 Training_loss:0.644422, Acc_avg:55.50% Training_loss_avg:0.687982\n",
            "Epoch:7 Step:3104 Training_loss:0.634941, Acc_avg:56.00% Training_loss_avg:0.687264\n",
            "Epoch:7 Step:3112 Training_loss:0.684473, Acc_avg:55.25% Training_loss_avg:0.688689\n",
            "Epoch:7 Step:3120 Training_loss:0.661816, Acc_avg:55.50% Training_loss_avg:0.687840\n",
            "Epoch:7 Step:3128 Training_loss:0.767893, Acc_avg:54.75% Training_loss_avg:0.690058\n",
            "Epoch:7 Step:3136 Training_loss:0.710317, Acc_avg:54.75% Training_loss_avg:0.689324\n",
            "Epoch:7 Step:3144 Training_loss:0.650926, Acc_avg:54.75% Training_loss_avg:0.688904\n",
            "Epoch:7 Step:3152 Training_loss:0.676679, Acc_avg:54.50% Training_loss_avg:0.689682\n",
            "Epoch:7 Step:3160 Training_loss:0.753751, Acc_avg:54.75% Training_loss_avg:0.688869\n",
            "Epoch:7 Step:3168 Training_loss:0.704186, Acc_avg:54.50% Training_loss_avg:0.689624\n",
            "Epoch:7 Step:3176 Training_loss:0.658150, Acc_avg:55.00% Training_loss_avg:0.688878\n",
            "Epoch:7 Step:3184 Training_loss:0.759891, Acc_avg:54.00% Training_loss_avg:0.690985\n",
            "Epoch:7 Step:3192 Training_loss:0.692618, Acc_avg:53.50% Training_loss_avg:0.692049\n",
            "Epoch:7 Step:3200 Training_loss:0.707378, Acc_avg:53.50% Training_loss_avg:0.691894\n",
            "Epoch:7 Step:3208 Training_loss:0.689261, Acc_avg:53.00% Training_loss_avg:0.692786\n",
            "Epoch:7 Step:3216 Training_loss:0.694954, Acc_avg:53.50% Training_loss_avg:0.691911\n",
            "Epoch:7 Step:3224 Training_loss:0.707266, Acc_avg:52.75% Training_loss_avg:0.693484\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:7 Step:3224 Val_loss:0.689407, Val_Acc_avg:54.75%\n",
            "Epoch:7 Step:3232 Training_loss:0.694049, Acc_avg:53.25% Training_loss_avg:0.691928\n",
            "Epoch:7 Step:3240 Training_loss:0.658499, Acc_avg:54.00% Training_loss_avg:0.690220\n",
            "Epoch:7 Step:3248 Training_loss:0.729454, Acc_avg:53.25% Training_loss_avg:0.691946\n",
            "Epoch:7 Step:3256 Training_loss:0.720271, Acc_avg:52.75% Training_loss_avg:0.692475\n",
            "Epoch:7 Step:3264 Training_loss:0.738060, Acc_avg:52.25% Training_loss_avg:0.693193\n",
            "Epoch:7 Step:3272 Training_loss:0.703121, Acc_avg:53.00% Training_loss_avg:0.691595\n",
            "Epoch:7 Step:3280 Training_loss:0.693232, Acc_avg:52.50% Training_loss_avg:0.692870\n",
            "Epoch:7 Step:3288 Training_loss:0.682893, Acc_avg:52.50% Training_loss_avg:0.692497\n",
            "Epoch:7 Step:3296 Training_loss:0.653565, Acc_avg:52.50% Training_loss_avg:0.693221\n",
            "Epoch:7 Step:3304 Training_loss:0.691230, Acc_avg:52.75% Training_loss_avg:0.692567\n",
            "Epoch:7 Step:3312 Training_loss:0.677226, Acc_avg:52.75% Training_loss_avg:0.692669\n",
            "Epoch:7 Step:3320 Training_loss:0.683489, Acc_avg:52.50% Training_loss_avg:0.693368\n",
            "Epoch:7 Step:3328 Training_loss:0.702986, Acc_avg:51.67% Training_loss_avg:0.694630\n",
            "Epoch:8 Step:0 Training_loss:0.697867, Acc_avg:51.42% Training_loss_avg:0.695666\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:0 Val_loss:0.690026, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:8 Training_loss:0.685742, Acc_avg:51.42% Training_loss_avg:0.695270\n",
            "Epoch:8 Step:16 Training_loss:0.680030, Acc_avg:51.67% Training_loss_avg:0.694050\n",
            "Epoch:8 Step:24 Training_loss:0.651590, Acc_avg:52.42% Training_loss_avg:0.693417\n",
            "Epoch:8 Step:32 Training_loss:0.677089, Acc_avg:52.17% Training_loss_avg:0.693694\n",
            "Epoch:8 Step:40 Training_loss:0.670797, Acc_avg:52.17% Training_loss_avg:0.693569\n",
            "Epoch:8 Step:48 Training_loss:0.699262, Acc_avg:52.17% Training_loss_avg:0.693202\n",
            "Epoch:8 Step:56 Training_loss:0.700690, Acc_avg:52.42% Training_loss_avg:0.692365\n",
            "Epoch:8 Step:64 Training_loss:0.706718, Acc_avg:52.92% Training_loss_avg:0.691116\n",
            "Epoch:8 Step:72 Training_loss:0.716280, Acc_avg:52.92% Training_loss_avg:0.691280\n",
            "Epoch:8 Step:80 Training_loss:0.713704, Acc_avg:52.42% Training_loss_avg:0.692002\n",
            "Epoch:8 Step:88 Training_loss:0.724826, Acc_avg:51.92% Training_loss_avg:0.692764\n",
            "Epoch:8 Step:96 Training_loss:0.711940, Acc_avg:52.17% Training_loss_avg:0.691798\n",
            "Epoch:8 Step:104 Training_loss:0.718305, Acc_avg:51.67% Training_loss_avg:0.693035\n",
            "Epoch:8 Step:112 Training_loss:0.674810, Acc_avg:51.67% Training_loss_avg:0.693256\n",
            "Epoch:8 Step:120 Training_loss:0.707250, Acc_avg:51.67% Training_loss_avg:0.693246\n",
            "Epoch:8 Step:128 Training_loss:0.686378, Acc_avg:51.67% Training_loss_avg:0.693305\n",
            "Epoch:8 Step:136 Training_loss:0.690653, Acc_avg:51.67% Training_loss_avg:0.693579\n",
            "Epoch:8 Step:144 Training_loss:0.685573, Acc_avg:50.92% Training_loss_avg:0.694729\n",
            "Epoch:8 Step:152 Training_loss:0.696471, Acc_avg:51.17% Training_loss_avg:0.694459\n",
            "Epoch:8 Step:160 Training_loss:0.669404, Acc_avg:51.17% Training_loss_avg:0.694959\n",
            "Epoch:8 Step:168 Training_loss:0.684039, Acc_avg:50.42% Training_loss_avg:0.695941\n",
            "Epoch:8 Step:176 Training_loss:0.689274, Acc_avg:50.67% Training_loss_avg:0.696037\n",
            "Epoch:8 Step:184 Training_loss:0.698414, Acc_avg:50.17% Training_loss_avg:0.696769\n",
            "Epoch:8 Step:192 Training_loss:0.693560, Acc_avg:50.42% Training_loss_avg:0.695282\n",
            "Epoch:8 Step:200 Training_loss:0.683259, Acc_avg:50.92% Training_loss_avg:0.694741\n",
            "Epoch:8 Step:208 Training_loss:0.708869, Acc_avg:50.67% Training_loss_avg:0.695900\n",
            "Epoch:8 Step:216 Training_loss:0.691724, Acc_avg:50.42% Training_loss_avg:0.696201\n",
            "Epoch:8 Step:224 Training_loss:0.718490, Acc_avg:50.67% Training_loss_avg:0.695496\n",
            "Epoch:8 Step:232 Training_loss:0.710770, Acc_avg:50.42% Training_loss_avg:0.695627\n",
            "Epoch:8 Step:240 Training_loss:0.690529, Acc_avg:50.17% Training_loss_avg:0.696275\n",
            "Epoch:8 Step:248 Training_loss:0.685422, Acc_avg:50.92% Training_loss_avg:0.694786\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:248 Val_loss:0.689959, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:256 Training_loss:0.724909, Acc_avg:50.42% Training_loss_avg:0.695431\n",
            "Epoch:8 Step:264 Training_loss:0.691580, Acc_avg:50.42% Training_loss_avg:0.695115\n",
            "Epoch:8 Step:272 Training_loss:0.668189, Acc_avg:50.92% Training_loss_avg:0.694694\n",
            "Epoch:8 Step:280 Training_loss:0.653804, Acc_avg:51.67% Training_loss_avg:0.693871\n",
            "Epoch:8 Step:288 Training_loss:0.672726, Acc_avg:52.42% Training_loss_avg:0.693180\n",
            "Epoch:8 Step:296 Training_loss:0.684027, Acc_avg:52.67% Training_loss_avg:0.692980\n",
            "Epoch:8 Step:304 Training_loss:0.713894, Acc_avg:51.92% Training_loss_avg:0.694088\n",
            "Epoch:8 Step:312 Training_loss:0.714212, Acc_avg:51.92% Training_loss_avg:0.693783\n",
            "Epoch:8 Step:320 Training_loss:0.680341, Acc_avg:52.67% Training_loss_avg:0.692984\n",
            "Epoch:8 Step:328 Training_loss:0.654421, Acc_avg:53.67% Training_loss_avg:0.691311\n",
            "Epoch:8 Step:336 Training_loss:0.697550, Acc_avg:53.67% Training_loss_avg:0.691200\n",
            "Epoch:8 Step:344 Training_loss:0.666392, Acc_avg:54.17% Training_loss_avg:0.690663\n",
            "Epoch:8 Step:352 Training_loss:0.719905, Acc_avg:53.92% Training_loss_avg:0.691403\n",
            "Epoch:8 Step:360 Training_loss:0.680898, Acc_avg:53.42% Training_loss_avg:0.691950\n",
            "Epoch:8 Step:368 Training_loss:0.744316, Acc_avg:52.67% Training_loss_avg:0.693012\n",
            "Epoch:8 Step:376 Training_loss:0.674880, Acc_avg:52.67% Training_loss_avg:0.692965\n",
            "Epoch:8 Step:384 Training_loss:0.669214, Acc_avg:52.67% Training_loss_avg:0.692679\n",
            "Epoch:8 Step:392 Training_loss:0.653364, Acc_avg:53.50% Training_loss_avg:0.691687\n",
            "Epoch:8 Step:400 Training_loss:0.709557, Acc_avg:53.00% Training_loss_avg:0.691921\n",
            "Epoch:8 Step:408 Training_loss:0.725542, Acc_avg:52.50% Training_loss_avg:0.692717\n",
            "Epoch:8 Step:416 Training_loss:0.680145, Acc_avg:52.75% Training_loss_avg:0.692719\n",
            "Epoch:8 Step:424 Training_loss:0.733741, Acc_avg:51.75% Training_loss_avg:0.694362\n",
            "Epoch:8 Step:432 Training_loss:0.685106, Acc_avg:51.75% Training_loss_avg:0.694522\n",
            "Epoch:8 Step:440 Training_loss:0.663652, Acc_avg:52.00% Training_loss_avg:0.694379\n",
            "Epoch:8 Step:448 Training_loss:0.705671, Acc_avg:52.25% Training_loss_avg:0.694508\n",
            "Epoch:8 Step:456 Training_loss:0.675683, Acc_avg:52.50% Training_loss_avg:0.694008\n",
            "Epoch:8 Step:464 Training_loss:0.666299, Acc_avg:53.00% Training_loss_avg:0.693199\n",
            "Epoch:8 Step:472 Training_loss:0.697119, Acc_avg:53.00% Training_loss_avg:0.692816\n",
            "Epoch:8 Step:480 Training_loss:0.682224, Acc_avg:53.25% Training_loss_avg:0.692186\n",
            "Epoch:8 Step:488 Training_loss:0.670353, Acc_avg:54.25% Training_loss_avg:0.691097\n",
            "Epoch:8 Step:496 Training_loss:0.631620, Acc_avg:55.25% Training_loss_avg:0.689490\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:496 Val_loss:0.689735, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:504 Training_loss:0.631299, Acc_avg:56.50% Training_loss_avg:0.687750\n",
            "Epoch:8 Step:512 Training_loss:0.679510, Acc_avg:56.25% Training_loss_avg:0.687844\n",
            "Epoch:8 Step:520 Training_loss:0.696019, Acc_avg:56.75% Training_loss_avg:0.687620\n",
            "Epoch:8 Step:528 Training_loss:0.715862, Acc_avg:56.50% Training_loss_avg:0.688209\n",
            "Epoch:8 Step:536 Training_loss:0.699864, Acc_avg:56.50% Training_loss_avg:0.688394\n",
            "Epoch:8 Step:544 Training_loss:0.664161, Acc_avg:56.75% Training_loss_avg:0.687965\n",
            "Epoch:8 Step:552 Training_loss:0.727047, Acc_avg:56.50% Training_loss_avg:0.688577\n",
            "Epoch:8 Step:560 Training_loss:0.677862, Acc_avg:56.25% Training_loss_avg:0.688746\n",
            "Epoch:8 Step:568 Training_loss:0.723515, Acc_avg:56.25% Training_loss_avg:0.689536\n",
            "Epoch:8 Step:576 Training_loss:0.694190, Acc_avg:56.00% Training_loss_avg:0.689634\n",
            "Epoch:8 Step:584 Training_loss:0.692908, Acc_avg:56.25% Training_loss_avg:0.689524\n",
            "Epoch:8 Step:592 Training_loss:0.777365, Acc_avg:56.00% Training_loss_avg:0.691200\n",
            "Epoch:8 Step:600 Training_loss:0.673871, Acc_avg:56.00% Training_loss_avg:0.691012\n",
            "Epoch:8 Step:608 Training_loss:0.629829, Acc_avg:56.75% Training_loss_avg:0.689431\n",
            "Epoch:8 Step:616 Training_loss:0.662362, Acc_avg:57.25% Training_loss_avg:0.688844\n",
            "Epoch:8 Step:624 Training_loss:0.675869, Acc_avg:57.75% Training_loss_avg:0.687992\n",
            "Epoch:8 Step:632 Training_loss:0.684133, Acc_avg:58.00% Training_loss_avg:0.687459\n",
            "Epoch:8 Step:640 Training_loss:0.669955, Acc_avg:58.00% Training_loss_avg:0.687047\n",
            "Epoch:8 Step:648 Training_loss:0.667868, Acc_avg:58.00% Training_loss_avg:0.686696\n",
            "Epoch:8 Step:656 Training_loss:0.684103, Acc_avg:58.75% Training_loss_avg:0.685880\n",
            "Epoch:8 Step:664 Training_loss:0.703920, Acc_avg:58.75% Training_loss_avg:0.686127\n",
            "Epoch:8 Step:672 Training_loss:0.651621, Acc_avg:58.75% Training_loss_avg:0.685796\n",
            "Epoch:8 Step:680 Training_loss:0.726806, Acc_avg:57.75% Training_loss_avg:0.687256\n",
            "Epoch:8 Step:688 Training_loss:0.631756, Acc_avg:57.75% Training_loss_avg:0.686436\n",
            "Epoch:8 Step:696 Training_loss:0.681190, Acc_avg:57.75% Training_loss_avg:0.686380\n",
            "Epoch:8 Step:704 Training_loss:0.706499, Acc_avg:58.00% Training_loss_avg:0.686232\n",
            "Epoch:8 Step:712 Training_loss:0.757756, Acc_avg:58.00% Training_loss_avg:0.687103\n",
            "Epoch:8 Step:720 Training_loss:0.801735, Acc_avg:57.25% Training_loss_avg:0.689531\n",
            "Epoch:8 Step:728 Training_loss:0.711793, Acc_avg:56.75% Training_loss_avg:0.690678\n",
            "Epoch:8 Step:736 Training_loss:0.659112, Acc_avg:57.25% Training_loss_avg:0.689909\n",
            "Epoch:8 Step:744 Training_loss:0.644091, Acc_avg:57.25% Training_loss_avg:0.689463\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:744 Val_loss:0.689553, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:752 Training_loss:0.685815, Acc_avg:57.50% Training_loss_avg:0.688781\n",
            "Epoch:8 Step:760 Training_loss:0.671864, Acc_avg:57.50% Training_loss_avg:0.688601\n",
            "Epoch:8 Step:768 Training_loss:0.731718, Acc_avg:58.00% Training_loss_avg:0.688349\n",
            "Epoch:8 Step:776 Training_loss:0.714312, Acc_avg:57.50% Training_loss_avg:0.689137\n",
            "Epoch:8 Step:784 Training_loss:0.611276, Acc_avg:58.25% Training_loss_avg:0.687979\n",
            "Epoch:8 Step:792 Training_loss:0.654668, Acc_avg:58.25% Training_loss_avg:0.688005\n",
            "Epoch:8 Step:800 Training_loss:0.665988, Acc_avg:58.75% Training_loss_avg:0.687133\n",
            "Epoch:8 Step:808 Training_loss:0.627913, Acc_avg:60.00% Training_loss_avg:0.685181\n",
            "Epoch:8 Step:816 Training_loss:0.678853, Acc_avg:60.00% Training_loss_avg:0.685155\n",
            "Epoch:8 Step:824 Training_loss:0.670970, Acc_avg:60.50% Training_loss_avg:0.683899\n",
            "Epoch:8 Step:832 Training_loss:0.658192, Acc_avg:60.50% Training_loss_avg:0.683361\n",
            "Epoch:8 Step:840 Training_loss:0.656576, Acc_avg:60.25% Training_loss_avg:0.683220\n",
            "Epoch:8 Step:848 Training_loss:0.684646, Acc_avg:60.25% Training_loss_avg:0.682799\n",
            "Epoch:8 Step:856 Training_loss:0.634851, Acc_avg:60.50% Training_loss_avg:0.681983\n",
            "Epoch:8 Step:864 Training_loss:0.667741, Acc_avg:60.25% Training_loss_avg:0.682011\n",
            "Epoch:8 Step:872 Training_loss:0.582106, Acc_avg:61.00% Training_loss_avg:0.679711\n",
            "Epoch:8 Step:880 Training_loss:0.733409, Acc_avg:61.00% Training_loss_avg:0.680735\n",
            "Epoch:8 Step:888 Training_loss:0.809559, Acc_avg:60.00% Training_loss_avg:0.683519\n",
            "Epoch:8 Step:896 Training_loss:0.763234, Acc_avg:59.00% Training_loss_avg:0.686151\n",
            "Epoch:8 Step:904 Training_loss:0.719148, Acc_avg:58.00% Training_loss_avg:0.687908\n",
            "Epoch:8 Step:912 Training_loss:0.728787, Acc_avg:57.50% Training_loss_avg:0.688894\n",
            "Epoch:8 Step:920 Training_loss:0.610501, Acc_avg:57.75% Training_loss_avg:0.687183\n",
            "Epoch:8 Step:928 Training_loss:0.729577, Acc_avg:57.50% Training_loss_avg:0.687458\n",
            "Epoch:8 Step:936 Training_loss:0.763202, Acc_avg:57.25% Training_loss_avg:0.688724\n",
            "Epoch:8 Step:944 Training_loss:0.625641, Acc_avg:57.50% Training_loss_avg:0.687954\n",
            "Epoch:8 Step:952 Training_loss:0.592750, Acc_avg:58.50% Training_loss_avg:0.685268\n",
            "Epoch:8 Step:960 Training_loss:0.723708, Acc_avg:58.00% Training_loss_avg:0.686185\n",
            "Epoch:8 Step:968 Training_loss:0.632259, Acc_avg:58.50% Training_loss_avg:0.684360\n",
            "Epoch:8 Step:976 Training_loss:0.703249, Acc_avg:58.50% Training_loss_avg:0.684541\n",
            "Epoch:8 Step:984 Training_loss:0.616796, Acc_avg:59.00% Training_loss_avg:0.683019\n",
            "Epoch:8 Step:992 Training_loss:0.658131, Acc_avg:59.75% Training_loss_avg:0.680634\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:992 Val_loss:0.692041, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:1000 Training_loss:0.709122, Acc_avg:59.50% Training_loss_avg:0.681339\n",
            "Epoch:8 Step:1008 Training_loss:0.675416, Acc_avg:59.00% Training_loss_avg:0.682251\n",
            "Epoch:8 Step:1016 Training_loss:0.734848, Acc_avg:58.50% Training_loss_avg:0.683701\n",
            "Epoch:8 Step:1024 Training_loss:0.726401, Acc_avg:58.25% Training_loss_avg:0.684711\n",
            "Epoch:8 Step:1032 Training_loss:0.578673, Acc_avg:59.00% Training_loss_avg:0.682602\n",
            "Epoch:8 Step:1040 Training_loss:0.749155, Acc_avg:58.50% Training_loss_avg:0.684186\n",
            "Epoch:8 Step:1048 Training_loss:0.661862, Acc_avg:58.50% Training_loss_avg:0.684066\n",
            "Epoch:8 Step:1056 Training_loss:0.633204, Acc_avg:58.50% Training_loss_avg:0.683048\n",
            "Epoch:8 Step:1064 Training_loss:0.645877, Acc_avg:58.75% Training_loss_avg:0.681887\n",
            "Epoch:8 Step:1072 Training_loss:0.604130, Acc_avg:59.00% Training_loss_avg:0.680937\n",
            "Epoch:8 Step:1080 Training_loss:0.681964, Acc_avg:59.50% Training_loss_avg:0.680040\n",
            "Epoch:8 Step:1088 Training_loss:0.795301, Acc_avg:58.50% Training_loss_avg:0.683311\n",
            "Epoch:8 Step:1096 Training_loss:0.663303, Acc_avg:58.50% Training_loss_avg:0.682954\n",
            "Epoch:8 Step:1104 Training_loss:0.686814, Acc_avg:58.75% Training_loss_avg:0.682560\n",
            "Epoch:8 Step:1112 Training_loss:0.654513, Acc_avg:59.50% Training_loss_avg:0.680495\n",
            "Epoch:8 Step:1120 Training_loss:0.742243, Acc_avg:59.75% Training_loss_avg:0.679305\n",
            "Epoch:8 Step:1128 Training_loss:0.662193, Acc_avg:60.00% Training_loss_avg:0.678313\n",
            "Epoch:8 Step:1136 Training_loss:0.704781, Acc_avg:59.50% Training_loss_avg:0.679227\n",
            "Epoch:8 Step:1144 Training_loss:0.636428, Acc_avg:59.50% Training_loss_avg:0.679073\n",
            "Epoch:8 Step:1152 Training_loss:0.739830, Acc_avg:59.25% Training_loss_avg:0.680154\n",
            "Epoch:8 Step:1160 Training_loss:0.612292, Acc_avg:59.75% Training_loss_avg:0.678962\n",
            "Epoch:8 Step:1168 Training_loss:0.716000, Acc_avg:60.00% Training_loss_avg:0.678648\n",
            "Epoch:8 Step:1176 Training_loss:0.690422, Acc_avg:60.25% Training_loss_avg:0.678170\n",
            "Epoch:8 Step:1184 Training_loss:0.618067, Acc_avg:59.75% Training_loss_avg:0.678306\n",
            "Epoch:8 Step:1192 Training_loss:0.798499, Acc_avg:58.50% Training_loss_avg:0.681182\n",
            "Epoch:8 Step:1200 Training_loss:0.781737, Acc_avg:57.75% Training_loss_avg:0.683497\n",
            "Epoch:8 Step:1208 Training_loss:0.716145, Acc_avg:57.00% Training_loss_avg:0.685262\n",
            "Epoch:8 Step:1216 Training_loss:0.644943, Acc_avg:57.25% Training_loss_avg:0.684584\n",
            "Epoch:8 Step:1224 Training_loss:0.677288, Acc_avg:57.25% Training_loss_avg:0.684710\n",
            "Epoch:8 Step:1232 Training_loss:0.616591, Acc_avg:57.75% Training_loss_avg:0.683878\n",
            "Epoch:8 Step:1240 Training_loss:0.725197, Acc_avg:57.25% Training_loss_avg:0.685251\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:1240 Val_loss:0.689508, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:1248 Training_loss:0.670365, Acc_avg:57.50% Training_loss_avg:0.684965\n",
            "Epoch:8 Step:1256 Training_loss:0.737139, Acc_avg:56.75% Training_loss_avg:0.687011\n",
            "Epoch:8 Step:1264 Training_loss:0.676351, Acc_avg:56.75% Training_loss_avg:0.687183\n",
            "Epoch:8 Step:1272 Training_loss:0.677096, Acc_avg:56.25% Training_loss_avg:0.689083\n",
            "Epoch:8 Step:1280 Training_loss:0.664535, Acc_avg:56.50% Training_loss_avg:0.687705\n",
            "Epoch:8 Step:1288 Training_loss:0.654121, Acc_avg:57.50% Training_loss_avg:0.684597\n",
            "Epoch:8 Step:1296 Training_loss:0.676708, Acc_avg:58.00% Training_loss_avg:0.682866\n",
            "Epoch:8 Step:1304 Training_loss:0.745822, Acc_avg:57.50% Training_loss_avg:0.683400\n",
            "Epoch:8 Step:1312 Training_loss:0.653183, Acc_avg:58.25% Training_loss_avg:0.681887\n",
            "Epoch:8 Step:1320 Training_loss:0.732762, Acc_avg:57.25% Training_loss_avg:0.684333\n",
            "Epoch:8 Step:1328 Training_loss:0.686209, Acc_avg:57.75% Training_loss_avg:0.683465\n",
            "Epoch:8 Step:1336 Training_loss:0.663679, Acc_avg:58.50% Training_loss_avg:0.681475\n",
            "Epoch:8 Step:1344 Training_loss:0.711957, Acc_avg:57.75% Training_loss_avg:0.683201\n",
            "Epoch:8 Step:1352 Training_loss:0.630238, Acc_avg:58.00% Training_loss_avg:0.683951\n",
            "Epoch:8 Step:1360 Training_loss:0.692986, Acc_avg:58.25% Training_loss_avg:0.683337\n",
            "Epoch:8 Step:1368 Training_loss:0.703276, Acc_avg:57.75% Training_loss_avg:0.684757\n",
            "Epoch:8 Step:1376 Training_loss:0.716074, Acc_avg:57.50% Training_loss_avg:0.685013\n",
            "Epoch:8 Step:1384 Training_loss:0.743644, Acc_avg:56.50% Training_loss_avg:0.687550\n",
            "Epoch:8 Step:1392 Training_loss:0.710624, Acc_avg:56.00% Training_loss_avg:0.688600\n",
            "Epoch:8 Step:1400 Training_loss:0.724628, Acc_avg:55.50% Training_loss_avg:0.688910\n",
            "Epoch:8 Step:1408 Training_loss:0.700973, Acc_avg:55.25% Training_loss_avg:0.689421\n",
            "Epoch:8 Step:1416 Training_loss:0.689231, Acc_avg:55.50% Training_loss_avg:0.688509\n",
            "Epoch:8 Step:1424 Training_loss:0.681704, Acc_avg:55.75% Training_loss_avg:0.687615\n",
            "Epoch:8 Step:1432 Training_loss:0.663316, Acc_avg:55.75% Training_loss_avg:0.689308\n",
            "Epoch:8 Step:1440 Training_loss:0.701259, Acc_avg:55.75% Training_loss_avg:0.688350\n",
            "Epoch:8 Step:1448 Training_loss:0.700039, Acc_avg:55.25% Training_loss_avg:0.689114\n",
            "Epoch:8 Step:1456 Training_loss:0.676921, Acc_avg:55.25% Training_loss_avg:0.689988\n",
            "Epoch:8 Step:1464 Training_loss:0.693404, Acc_avg:55.25% Training_loss_avg:0.690939\n",
            "Epoch:8 Step:1472 Training_loss:0.670101, Acc_avg:55.00% Training_loss_avg:0.692258\n",
            "Epoch:8 Step:1480 Training_loss:0.698768, Acc_avg:54.50% Training_loss_avg:0.692594\n",
            "Epoch:8 Step:1488 Training_loss:0.709257, Acc_avg:54.75% Training_loss_avg:0.690873\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:1488 Val_loss:0.690095, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:1496 Training_loss:0.707947, Acc_avg:54.25% Training_loss_avg:0.691766\n",
            "Epoch:8 Step:1504 Training_loss:0.678881, Acc_avg:54.50% Training_loss_avg:0.691607\n",
            "Epoch:8 Step:1512 Training_loss:0.678480, Acc_avg:54.25% Training_loss_avg:0.692087\n",
            "Epoch:8 Step:1520 Training_loss:0.670797, Acc_avg:55.00% Training_loss_avg:0.690658\n",
            "Epoch:8 Step:1528 Training_loss:0.742379, Acc_avg:54.00% Training_loss_avg:0.692262\n",
            "Epoch:8 Step:1536 Training_loss:0.686991, Acc_avg:54.00% Training_loss_avg:0.691906\n",
            "Epoch:8 Step:1544 Training_loss:0.721647, Acc_avg:53.00% Training_loss_avg:0.693610\n",
            "Epoch:8 Step:1552 Training_loss:0.680160, Acc_avg:53.50% Training_loss_avg:0.692417\n",
            "Epoch:8 Step:1560 Training_loss:0.684329, Acc_avg:53.00% Training_loss_avg:0.693857\n",
            "Epoch:8 Step:1568 Training_loss:0.694699, Acc_avg:52.75% Training_loss_avg:0.693431\n",
            "Epoch:8 Step:1576 Training_loss:0.678746, Acc_avg:53.00% Training_loss_avg:0.693198\n",
            "Epoch:8 Step:1584 Training_loss:0.710770, Acc_avg:52.25% Training_loss_avg:0.695052\n",
            "Epoch:8 Step:1592 Training_loss:0.672122, Acc_avg:53.50% Training_loss_avg:0.692524\n",
            "Epoch:8 Step:1600 Training_loss:0.678683, Acc_avg:54.25% Training_loss_avg:0.690463\n",
            "Epoch:8 Step:1608 Training_loss:0.709506, Acc_avg:54.00% Training_loss_avg:0.690331\n",
            "Epoch:8 Step:1616 Training_loss:0.672202, Acc_avg:54.00% Training_loss_avg:0.690876\n",
            "Epoch:8 Step:1624 Training_loss:0.721671, Acc_avg:53.50% Training_loss_avg:0.691763\n",
            "Epoch:8 Step:1632 Training_loss:0.709241, Acc_avg:52.50% Training_loss_avg:0.693616\n",
            "Epoch:8 Step:1640 Training_loss:0.666133, Acc_avg:53.25% Training_loss_avg:0.692435\n",
            "Epoch:8 Step:1648 Training_loss:0.705956, Acc_avg:52.75% Training_loss_avg:0.693147\n",
            "Epoch:8 Step:1656 Training_loss:0.702318, Acc_avg:52.75% Training_loss_avg:0.692451\n",
            "Epoch:8 Step:1664 Training_loss:0.704703, Acc_avg:52.00% Training_loss_avg:0.693018\n",
            "Epoch:8 Step:1672 Training_loss:0.684855, Acc_avg:52.00% Training_loss_avg:0.693173\n",
            "Epoch:8 Step:1680 Training_loss:0.668180, Acc_avg:52.25% Training_loss_avg:0.693246\n",
            "Epoch:8 Step:1688 Training_loss:0.679020, Acc_avg:52.50% Training_loss_avg:0.693744\n",
            "Epoch:8 Step:1696 Training_loss:0.676896, Acc_avg:52.75% Training_loss_avg:0.693747\n",
            "Epoch:8 Step:1704 Training_loss:0.693706, Acc_avg:53.00% Training_loss_avg:0.692705\n",
            "Epoch:8 Step:1712 Training_loss:0.673806, Acc_avg:53.00% Training_loss_avg:0.693118\n",
            "Epoch:8 Step:1720 Training_loss:0.665849, Acc_avg:54.00% Training_loss_avg:0.691779\n",
            "Epoch:8 Step:1728 Training_loss:0.710375, Acc_avg:53.50% Training_loss_avg:0.692263\n",
            "Epoch:8 Step:1736 Training_loss:0.687975, Acc_avg:53.25% Training_loss_avg:0.692748\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:1736 Val_loss:0.689938, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:1744 Training_loss:0.727596, Acc_avg:53.00% Training_loss_avg:0.693061\n",
            "Epoch:8 Step:1752 Training_loss:0.704970, Acc_avg:51.75% Training_loss_avg:0.694556\n",
            "Epoch:8 Step:1760 Training_loss:0.684636, Acc_avg:51.75% Training_loss_avg:0.694389\n",
            "Epoch:8 Step:1768 Training_loss:0.716540, Acc_avg:51.50% Training_loss_avg:0.694654\n",
            "Epoch:8 Step:1776 Training_loss:0.693490, Acc_avg:51.75% Training_loss_avg:0.694203\n",
            "Epoch:8 Step:1784 Training_loss:0.688756, Acc_avg:52.50% Training_loss_avg:0.693105\n",
            "Epoch:8 Step:1792 Training_loss:0.683467, Acc_avg:52.75% Training_loss_avg:0.692562\n",
            "Epoch:8 Step:1800 Training_loss:0.681397, Acc_avg:53.25% Training_loss_avg:0.691697\n",
            "Epoch:8 Step:1808 Training_loss:0.696405, Acc_avg:53.25% Training_loss_avg:0.691606\n",
            "Epoch:8 Step:1816 Training_loss:0.710213, Acc_avg:52.75% Training_loss_avg:0.692025\n",
            "Epoch:8 Step:1824 Training_loss:0.700056, Acc_avg:52.25% Training_loss_avg:0.692392\n",
            "Epoch:8 Step:1832 Training_loss:0.738353, Acc_avg:50.50% Training_loss_avg:0.693893\n",
            "Epoch:8 Step:1840 Training_loss:0.687517, Acc_avg:50.75% Training_loss_avg:0.693618\n",
            "Epoch:8 Step:1848 Training_loss:0.709145, Acc_avg:50.75% Training_loss_avg:0.693800\n",
            "Epoch:8 Step:1856 Training_loss:0.724442, Acc_avg:50.00% Training_loss_avg:0.694751\n",
            "Epoch:8 Step:1864 Training_loss:0.700981, Acc_avg:49.25% Training_loss_avg:0.694902\n",
            "Epoch:8 Step:1872 Training_loss:0.671974, Acc_avg:49.50% Training_loss_avg:0.694940\n",
            "Epoch:8 Step:1880 Training_loss:0.692788, Acc_avg:50.00% Training_loss_avg:0.694820\n",
            "Epoch:8 Step:1888 Training_loss:0.697874, Acc_avg:50.25% Training_loss_avg:0.694593\n",
            "Epoch:8 Step:1896 Training_loss:0.695663, Acc_avg:50.25% Training_loss_avg:0.694347\n",
            "Epoch:8 Step:1904 Training_loss:0.692213, Acc_avg:49.75% Training_loss_avg:0.694613\n",
            "Epoch:8 Step:1912 Training_loss:0.672276, Acc_avg:50.00% Training_loss_avg:0.694489\n",
            "Epoch:8 Step:1920 Training_loss:0.706501, Acc_avg:49.50% Training_loss_avg:0.695203\n",
            "Epoch:8 Step:1928 Training_loss:0.681419, Acc_avg:50.50% Training_loss_avg:0.693984\n",
            "Epoch:8 Step:1936 Training_loss:0.674569, Acc_avg:50.75% Training_loss_avg:0.693736\n",
            "Epoch:8 Step:1944 Training_loss:0.686852, Acc_avg:51.50% Training_loss_avg:0.693040\n",
            "Epoch:8 Step:1952 Training_loss:0.681142, Acc_avg:51.50% Training_loss_avg:0.693060\n",
            "Epoch:8 Step:1960 Training_loss:0.704234, Acc_avg:51.00% Training_loss_avg:0.693458\n",
            "Epoch:8 Step:1968 Training_loss:0.654051, Acc_avg:51.75% Training_loss_avg:0.692645\n",
            "Epoch:8 Step:1976 Training_loss:0.645597, Acc_avg:52.00% Training_loss_avg:0.691982\n",
            "Epoch:8 Step:1984 Training_loss:0.711410, Acc_avg:52.25% Training_loss_avg:0.691995\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:1984 Val_loss:0.690113, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:1992 Training_loss:0.700934, Acc_avg:51.75% Training_loss_avg:0.692571\n",
            "Epoch:8 Step:2000 Training_loss:0.704454, Acc_avg:51.50% Training_loss_avg:0.693086\n",
            "Epoch:8 Step:2008 Training_loss:0.624038, Acc_avg:52.25% Training_loss_avg:0.691377\n",
            "Epoch:8 Step:2016 Training_loss:0.722284, Acc_avg:51.75% Training_loss_avg:0.692378\n",
            "Epoch:8 Step:2024 Training_loss:0.741313, Acc_avg:51.75% Training_loss_avg:0.692771\n",
            "Epoch:8 Step:2032 Training_loss:0.703286, Acc_avg:52.00% Training_loss_avg:0.692652\n",
            "Epoch:8 Step:2040 Training_loss:0.803146, Acc_avg:51.00% Training_loss_avg:0.695392\n",
            "Epoch:8 Step:2048 Training_loss:0.712012, Acc_avg:51.25% Training_loss_avg:0.695514\n",
            "Epoch:8 Step:2056 Training_loss:0.716611, Acc_avg:51.50% Training_loss_avg:0.695799\n",
            "Epoch:8 Step:2064 Training_loss:0.704525, Acc_avg:52.00% Training_loss_avg:0.695796\n",
            "Epoch:8 Step:2072 Training_loss:0.708125, Acc_avg:51.75% Training_loss_avg:0.696261\n",
            "Epoch:8 Step:2080 Training_loss:0.722965, Acc_avg:51.00% Training_loss_avg:0.697357\n",
            "Epoch:8 Step:2088 Training_loss:0.751736, Acc_avg:49.75% Training_loss_avg:0.698811\n",
            "Epoch:8 Step:2096 Training_loss:0.699829, Acc_avg:49.25% Training_loss_avg:0.699270\n",
            "Epoch:8 Step:2104 Training_loss:0.652444, Acc_avg:50.00% Training_loss_avg:0.698445\n",
            "Epoch:8 Step:2112 Training_loss:0.693421, Acc_avg:49.50% Training_loss_avg:0.698837\n",
            "Epoch:8 Step:2120 Training_loss:0.674985, Acc_avg:49.25% Training_loss_avg:0.699020\n",
            "Epoch:8 Step:2128 Training_loss:0.702016, Acc_avg:49.50% Training_loss_avg:0.698853\n",
            "Epoch:8 Step:2136 Training_loss:0.724773, Acc_avg:48.75% Training_loss_avg:0.699588\n",
            "Epoch:8 Step:2144 Training_loss:0.693311, Acc_avg:49.00% Training_loss_avg:0.698903\n",
            "Epoch:8 Step:2152 Training_loss:0.725184, Acc_avg:48.50% Training_loss_avg:0.699307\n",
            "Epoch:8 Step:2160 Training_loss:0.694261, Acc_avg:48.50% Training_loss_avg:0.699500\n",
            "Epoch:8 Step:2168 Training_loss:0.706861, Acc_avg:48.50% Training_loss_avg:0.699306\n",
            "Epoch:8 Step:2176 Training_loss:0.676626, Acc_avg:48.75% Training_loss_avg:0.698969\n",
            "Epoch:8 Step:2184 Training_loss:0.695972, Acc_avg:48.50% Training_loss_avg:0.699113\n",
            "Epoch:8 Step:2192 Training_loss:0.684614, Acc_avg:48.50% Training_loss_avg:0.699136\n",
            "Epoch:8 Step:2200 Training_loss:0.671247, Acc_avg:48.75% Training_loss_avg:0.698933\n",
            "Epoch:8 Step:2208 Training_loss:0.704046, Acc_avg:48.25% Training_loss_avg:0.699086\n",
            "Epoch:8 Step:2216 Training_loss:0.684742, Acc_avg:48.75% Training_loss_avg:0.698576\n",
            "Epoch:8 Step:2224 Training_loss:0.687254, Acc_avg:49.00% Training_loss_avg:0.698320\n",
            "Epoch:8 Step:2232 Training_loss:0.692193, Acc_avg:49.75% Training_loss_avg:0.697397\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:2232 Val_loss:0.695831, Val_Acc_avg:45.25%\n",
            "Epoch:8 Step:2240 Training_loss:0.682861, Acc_avg:50.00% Training_loss_avg:0.697304\n",
            "Epoch:8 Step:2248 Training_loss:0.700192, Acc_avg:50.00% Training_loss_avg:0.697125\n",
            "Epoch:8 Step:2256 Training_loss:0.708575, Acc_avg:50.00% Training_loss_avg:0.696808\n",
            "Epoch:8 Step:2264 Training_loss:0.672581, Acc_avg:50.25% Training_loss_avg:0.696240\n",
            "Epoch:8 Step:2272 Training_loss:0.735511, Acc_avg:48.75% Training_loss_avg:0.697510\n",
            "Epoch:8 Step:2280 Training_loss:0.688308, Acc_avg:48.50% Training_loss_avg:0.697421\n",
            "Epoch:8 Step:2288 Training_loss:0.691241, Acc_avg:48.00% Training_loss_avg:0.697288\n",
            "Epoch:8 Step:2296 Training_loss:0.713173, Acc_avg:48.00% Training_loss_avg:0.697638\n",
            "Epoch:8 Step:2304 Training_loss:0.690279, Acc_avg:47.75% Training_loss_avg:0.697600\n",
            "Epoch:8 Step:2312 Training_loss:0.679083, Acc_avg:47.50% Training_loss_avg:0.697736\n",
            "Epoch:8 Step:2320 Training_loss:0.690671, Acc_avg:47.75% Training_loss_avg:0.697419\n",
            "Epoch:8 Step:2328 Training_loss:0.710123, Acc_avg:47.25% Training_loss_avg:0.697993\n",
            "Epoch:8 Step:2336 Training_loss:0.696551, Acc_avg:47.00% Training_loss_avg:0.698433\n",
            "Epoch:8 Step:2344 Training_loss:0.665585, Acc_avg:47.00% Training_loss_avg:0.698008\n",
            "Epoch:8 Step:2352 Training_loss:0.686531, Acc_avg:46.75% Training_loss_avg:0.698115\n",
            "Epoch:8 Step:2360 Training_loss:0.710755, Acc_avg:46.50% Training_loss_avg:0.698246\n",
            "Epoch:8 Step:2368 Training_loss:0.685175, Acc_avg:46.75% Training_loss_avg:0.698868\n",
            "Epoch:8 Step:2376 Training_loss:0.682244, Acc_avg:46.75% Training_loss_avg:0.699601\n",
            "Epoch:8 Step:2384 Training_loss:0.683595, Acc_avg:47.25% Training_loss_avg:0.699045\n",
            "Epoch:8 Step:2392 Training_loss:0.676101, Acc_avg:47.50% Training_loss_avg:0.698548\n",
            "Epoch:8 Step:2400 Training_loss:0.698051, Acc_avg:47.25% Training_loss_avg:0.698420\n",
            "Epoch:8 Step:2408 Training_loss:0.687633, Acc_avg:47.00% Training_loss_avg:0.699692\n",
            "Epoch:8 Step:2416 Training_loss:0.701689, Acc_avg:47.00% Training_loss_avg:0.699280\n",
            "Epoch:8 Step:2424 Training_loss:0.677669, Acc_avg:47.75% Training_loss_avg:0.698007\n",
            "Epoch:8 Step:2432 Training_loss:0.672149, Acc_avg:48.25% Training_loss_avg:0.697385\n",
            "Epoch:8 Step:2440 Training_loss:0.703105, Acc_avg:48.50% Training_loss_avg:0.695384\n",
            "Epoch:8 Step:2448 Training_loss:0.666534, Acc_avg:49.00% Training_loss_avg:0.694474\n",
            "Epoch:8 Step:2456 Training_loss:0.680477, Acc_avg:49.25% Training_loss_avg:0.693751\n",
            "Epoch:8 Step:2464 Training_loss:0.715987, Acc_avg:49.00% Training_loss_avg:0.693981\n",
            "Epoch:8 Step:2472 Training_loss:0.671514, Acc_avg:49.50% Training_loss_avg:0.693248\n",
            "Epoch:8 Step:2480 Training_loss:0.682523, Acc_avg:50.00% Training_loss_avg:0.692440\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:2480 Val_loss:0.689562, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:2488 Training_loss:0.687269, Acc_avg:50.50% Training_loss_avg:0.691150\n",
            "Epoch:8 Step:2496 Training_loss:0.663880, Acc_avg:51.00% Training_loss_avg:0.690431\n",
            "Epoch:8 Step:2504 Training_loss:0.695827, Acc_avg:50.50% Training_loss_avg:0.691299\n",
            "Epoch:8 Step:2512 Training_loss:0.723901, Acc_avg:50.00% Training_loss_avg:0.691909\n",
            "Epoch:8 Step:2520 Training_loss:0.652437, Acc_avg:50.25% Training_loss_avg:0.691458\n",
            "Epoch:8 Step:2528 Training_loss:0.681842, Acc_avg:50.25% Training_loss_avg:0.691054\n",
            "Epoch:8 Step:2536 Training_loss:0.652033, Acc_avg:51.25% Training_loss_avg:0.689599\n",
            "Epoch:8 Step:2544 Training_loss:0.644429, Acc_avg:52.00% Training_loss_avg:0.688622\n",
            "Epoch:8 Step:2552 Training_loss:0.693533, Acc_avg:52.75% Training_loss_avg:0.687989\n",
            "Epoch:8 Step:2560 Training_loss:0.652039, Acc_avg:53.25% Training_loss_avg:0.687144\n",
            "Epoch:8 Step:2568 Training_loss:0.704728, Acc_avg:53.25% Training_loss_avg:0.687102\n",
            "Epoch:8 Step:2576 Training_loss:0.727113, Acc_avg:52.75% Training_loss_avg:0.688111\n",
            "Epoch:8 Step:2584 Training_loss:0.786982, Acc_avg:52.00% Training_loss_avg:0.689932\n",
            "Epoch:8 Step:2592 Training_loss:0.637186, Acc_avg:52.50% Training_loss_avg:0.688983\n",
            "Epoch:8 Step:2600 Training_loss:0.611924, Acc_avg:52.75% Training_loss_avg:0.687797\n",
            "Epoch:8 Step:2608 Training_loss:0.697498, Acc_avg:53.25% Training_loss_avg:0.687666\n",
            "Epoch:8 Step:2616 Training_loss:0.680640, Acc_avg:53.25% Training_loss_avg:0.687584\n",
            "Epoch:8 Step:2624 Training_loss:0.744439, Acc_avg:52.75% Training_loss_avg:0.688727\n",
            "Epoch:8 Step:2632 Training_loss:0.627689, Acc_avg:53.50% Training_loss_avg:0.687437\n",
            "Epoch:8 Step:2640 Training_loss:0.648766, Acc_avg:53.50% Training_loss_avg:0.686755\n",
            "Epoch:8 Step:2648 Training_loss:0.684306, Acc_avg:54.00% Training_loss_avg:0.686438\n",
            "Epoch:8 Step:2656 Training_loss:0.751953, Acc_avg:54.25% Training_loss_avg:0.687305\n",
            "Epoch:8 Step:2664 Training_loss:0.672864, Acc_avg:54.75% Training_loss_avg:0.687311\n",
            "Epoch:8 Step:2672 Training_loss:0.760395, Acc_avg:55.25% Training_loss_avg:0.687808\n",
            "Epoch:8 Step:2680 Training_loss:0.660682, Acc_avg:55.50% Training_loss_avg:0.687256\n",
            "Epoch:8 Step:2688 Training_loss:0.608880, Acc_avg:56.50% Training_loss_avg:0.685609\n",
            "Epoch:8 Step:2696 Training_loss:0.648493, Acc_avg:57.25% Training_loss_avg:0.684315\n",
            "Epoch:8 Step:2704 Training_loss:0.631929, Acc_avg:58.00% Training_loss_avg:0.683148\n",
            "Epoch:8 Step:2712 Training_loss:0.643101, Acc_avg:58.00% Training_loss_avg:0.682428\n",
            "Epoch:8 Step:2720 Training_loss:0.682699, Acc_avg:58.00% Training_loss_avg:0.682269\n",
            "Epoch:8 Step:2728 Training_loss:0.703210, Acc_avg:58.25% Training_loss_avg:0.682131\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:2728 Val_loss:0.692947, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:2736 Training_loss:0.643880, Acc_avg:58.75% Training_loss_avg:0.681077\n",
            "Epoch:8 Step:2744 Training_loss:0.598397, Acc_avg:59.00% Training_loss_avg:0.679734\n",
            "Epoch:8 Step:2752 Training_loss:0.673991, Acc_avg:59.50% Training_loss_avg:0.679483\n",
            "Epoch:8 Step:2760 Training_loss:0.781927, Acc_avg:59.50% Training_loss_avg:0.680906\n",
            "Epoch:8 Step:2768 Training_loss:0.753119, Acc_avg:58.50% Training_loss_avg:0.682265\n",
            "Epoch:8 Step:2776 Training_loss:0.674689, Acc_avg:58.25% Training_loss_avg:0.682114\n",
            "Epoch:8 Step:2784 Training_loss:0.842756, Acc_avg:57.25% Training_loss_avg:0.685297\n",
            "Epoch:8 Step:2792 Training_loss:0.630923, Acc_avg:57.25% Training_loss_avg:0.684394\n",
            "Epoch:8 Step:2800 Training_loss:0.692086, Acc_avg:57.50% Training_loss_avg:0.684274\n",
            "Epoch:8 Step:2808 Training_loss:0.619174, Acc_avg:57.75% Training_loss_avg:0.682905\n",
            "Epoch:8 Step:2816 Training_loss:0.664782, Acc_avg:58.00% Training_loss_avg:0.682167\n",
            "Epoch:8 Step:2824 Training_loss:0.624225, Acc_avg:58.00% Training_loss_avg:0.681098\n",
            "Epoch:8 Step:2832 Training_loss:0.654783, Acc_avg:57.75% Training_loss_avg:0.680751\n",
            "Epoch:8 Step:2840 Training_loss:0.695003, Acc_avg:58.00% Training_loss_avg:0.680589\n",
            "Epoch:8 Step:2848 Training_loss:0.571101, Acc_avg:58.25% Training_loss_avg:0.678680\n",
            "Epoch:8 Step:2856 Training_loss:0.656594, Acc_avg:58.25% Training_loss_avg:0.678202\n",
            "Epoch:8 Step:2864 Training_loss:0.720512, Acc_avg:58.25% Training_loss_avg:0.678293\n",
            "Epoch:8 Step:2872 Training_loss:0.683297, Acc_avg:57.75% Training_loss_avg:0.678529\n",
            "Epoch:8 Step:2880 Training_loss:0.703176, Acc_avg:57.50% Training_loss_avg:0.678942\n",
            "Epoch:8 Step:2888 Training_loss:0.735396, Acc_avg:57.25% Training_loss_avg:0.679904\n",
            "Epoch:8 Step:2896 Training_loss:0.736435, Acc_avg:56.75% Training_loss_avg:0.681355\n",
            "Epoch:8 Step:2904 Training_loss:0.620628, Acc_avg:57.25% Training_loss_avg:0.679851\n",
            "Epoch:8 Step:2912 Training_loss:0.789529, Acc_avg:57.50% Training_loss_avg:0.681164\n",
            "Epoch:8 Step:2920 Training_loss:0.724139, Acc_avg:57.00% Training_loss_avg:0.682598\n",
            "Epoch:8 Step:2928 Training_loss:0.624451, Acc_avg:57.50% Training_loss_avg:0.681450\n",
            "Epoch:8 Step:2936 Training_loss:0.743238, Acc_avg:56.75% Training_loss_avg:0.683274\n",
            "Epoch:8 Step:2944 Training_loss:0.634495, Acc_avg:56.50% Training_loss_avg:0.683076\n",
            "Epoch:8 Step:2952 Training_loss:0.689159, Acc_avg:56.50% Training_loss_avg:0.682988\n",
            "Epoch:8 Step:2960 Training_loss:0.608604, Acc_avg:56.75% Training_loss_avg:0.682119\n",
            "Epoch:8 Step:2968 Training_loss:0.621547, Acc_avg:57.50% Training_loss_avg:0.680456\n",
            "Epoch:8 Step:2976 Training_loss:0.627276, Acc_avg:58.25% Training_loss_avg:0.678459\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:2976 Val_loss:0.691622, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:2984 Training_loss:0.671188, Acc_avg:59.25% Training_loss_avg:0.676143\n",
            "Epoch:8 Step:2992 Training_loss:0.646977, Acc_avg:59.00% Training_loss_avg:0.676339\n",
            "Epoch:8 Step:3000 Training_loss:0.703522, Acc_avg:58.50% Training_loss_avg:0.678171\n",
            "Epoch:8 Step:3008 Training_loss:0.756201, Acc_avg:58.25% Training_loss_avg:0.679345\n",
            "Epoch:8 Step:3016 Training_loss:0.618556, Acc_avg:58.50% Training_loss_avg:0.678103\n",
            "Epoch:8 Step:3024 Training_loss:0.720559, Acc_avg:59.00% Training_loss_avg:0.677626\n",
            "Epoch:8 Step:3032 Training_loss:0.781327, Acc_avg:58.00% Training_loss_avg:0.680698\n",
            "Epoch:8 Step:3040 Training_loss:0.713029, Acc_avg:57.75% Training_loss_avg:0.681984\n",
            "Epoch:8 Step:3048 Training_loss:0.691182, Acc_avg:57.50% Training_loss_avg:0.682121\n",
            "Epoch:8 Step:3056 Training_loss:0.742351, Acc_avg:57.50% Training_loss_avg:0.681929\n",
            "Epoch:8 Step:3064 Training_loss:0.661731, Acc_avg:57.50% Training_loss_avg:0.681706\n",
            "Epoch:8 Step:3072 Training_loss:0.751917, Acc_avg:57.50% Training_loss_avg:0.681537\n",
            "Epoch:8 Step:3080 Training_loss:0.633328, Acc_avg:57.75% Training_loss_avg:0.680990\n",
            "Epoch:8 Step:3088 Training_loss:0.760700, Acc_avg:57.00% Training_loss_avg:0.684026\n",
            "Epoch:8 Step:3096 Training_loss:0.632713, Acc_avg:57.00% Training_loss_avg:0.683711\n",
            "Epoch:8 Step:3104 Training_loss:0.658005, Acc_avg:57.00% Training_loss_avg:0.684232\n",
            "Epoch:8 Step:3112 Training_loss:0.642613, Acc_avg:57.25% Training_loss_avg:0.684222\n",
            "Epoch:8 Step:3120 Training_loss:0.670429, Acc_avg:57.25% Training_loss_avg:0.683977\n",
            "Epoch:8 Step:3128 Training_loss:0.692956, Acc_avg:57.25% Training_loss_avg:0.683772\n",
            "Epoch:8 Step:3136 Training_loss:0.699744, Acc_avg:57.00% Training_loss_avg:0.684889\n",
            "Epoch:8 Step:3144 Training_loss:0.740636, Acc_avg:56.25% Training_loss_avg:0.687734\n",
            "Epoch:8 Step:3152 Training_loss:0.676723, Acc_avg:55.75% Training_loss_avg:0.687789\n",
            "Epoch:8 Step:3160 Training_loss:0.595688, Acc_avg:57.00% Training_loss_avg:0.684064\n",
            "Epoch:8 Step:3168 Training_loss:0.623801, Acc_avg:58.00% Training_loss_avg:0.681477\n",
            "Epoch:8 Step:3176 Training_loss:0.762764, Acc_avg:57.25% Training_loss_avg:0.683239\n",
            "Epoch:8 Step:3184 Training_loss:0.647787, Acc_avg:58.25% Training_loss_avg:0.679340\n",
            "Epoch:8 Step:3192 Training_loss:0.721657, Acc_avg:58.00% Training_loss_avg:0.681154\n",
            "Epoch:8 Step:3200 Training_loss:0.732222, Acc_avg:57.75% Training_loss_avg:0.681957\n",
            "Epoch:8 Step:3208 Training_loss:0.715243, Acc_avg:57.00% Training_loss_avg:0.683878\n",
            "Epoch:8 Step:3216 Training_loss:0.583350, Acc_avg:57.75% Training_loss_avg:0.682250\n",
            "Epoch:8 Step:3224 Training_loss:0.648848, Acc_avg:57.50% Training_loss_avg:0.682742\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:8 Step:3224 Val_loss:0.690454, Val_Acc_avg:54.75%\n",
            "Epoch:8 Step:3232 Training_loss:0.744037, Acc_avg:57.00% Training_loss_avg:0.684527\n",
            "Epoch:8 Step:3240 Training_loss:0.660452, Acc_avg:57.25% Training_loss_avg:0.683836\n",
            "Epoch:8 Step:3248 Training_loss:0.672057, Acc_avg:56.75% Training_loss_avg:0.685855\n",
            "Epoch:8 Step:3256 Training_loss:0.685065, Acc_avg:56.75% Training_loss_avg:0.686425\n",
            "Epoch:8 Step:3264 Training_loss:0.677957, Acc_avg:57.25% Training_loss_avg:0.685574\n",
            "Epoch:8 Step:3272 Training_loss:0.740389, Acc_avg:57.00% Training_loss_avg:0.686716\n",
            "Epoch:8 Step:3280 Training_loss:0.740234, Acc_avg:56.75% Training_loss_avg:0.687457\n",
            "Epoch:8 Step:3288 Training_loss:0.734196, Acc_avg:56.75% Training_loss_avg:0.687433\n",
            "Epoch:8 Step:3296 Training_loss:0.696483, Acc_avg:56.75% Training_loss_avg:0.686634\n",
            "Epoch:8 Step:3304 Training_loss:0.673614, Acc_avg:56.50% Training_loss_avg:0.687693\n",
            "Epoch:8 Step:3312 Training_loss:0.758565, Acc_avg:56.25% Training_loss_avg:0.687074\n",
            "Epoch:8 Step:3320 Training_loss:0.722840, Acc_avg:56.00% Training_loss_avg:0.687048\n",
            "Epoch:8 Step:3328 Training_loss:0.668951, Acc_avg:55.83% Training_loss_avg:0.687938\n",
            "Epoch:9 Step:0 Training_loss:0.667844, Acc_avg:56.33% Training_loss_avg:0.686430\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:0 Val_loss:0.689973, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:8 Training_loss:0.707327, Acc_avg:56.08% Training_loss_avg:0.687887\n",
            "Epoch:9 Step:16 Training_loss:0.653261, Acc_avg:56.58% Training_loss_avg:0.687169\n",
            "Epoch:9 Step:24 Training_loss:0.654355, Acc_avg:56.33% Training_loss_avg:0.688084\n",
            "Epoch:9 Step:32 Training_loss:0.610029, Acc_avg:56.58% Training_loss_avg:0.687854\n",
            "Epoch:9 Step:40 Training_loss:0.682662, Acc_avg:56.33% Training_loss_avg:0.688961\n",
            "Epoch:9 Step:48 Training_loss:0.727052, Acc_avg:56.08% Training_loss_avg:0.690079\n",
            "Epoch:9 Step:56 Training_loss:0.776273, Acc_avg:55.58% Training_loss_avg:0.692665\n",
            "Epoch:9 Step:64 Training_loss:0.675668, Acc_avg:55.83% Training_loss_avg:0.692108\n",
            "Epoch:9 Step:72 Training_loss:0.652545, Acc_avg:56.33% Training_loss_avg:0.690034\n",
            "Epoch:9 Step:80 Training_loss:0.723568, Acc_avg:55.58% Training_loss_avg:0.692135\n",
            "Epoch:9 Step:88 Training_loss:0.642205, Acc_avg:56.08% Training_loss_avg:0.690568\n",
            "Epoch:9 Step:96 Training_loss:0.771283, Acc_avg:55.83% Training_loss_avg:0.690367\n",
            "Epoch:9 Step:104 Training_loss:0.742460, Acc_avg:55.33% Training_loss_avg:0.690955\n",
            "Epoch:9 Step:112 Training_loss:0.697784, Acc_avg:55.33% Training_loss_avg:0.691087\n",
            "Epoch:9 Step:120 Training_loss:0.687331, Acc_avg:55.58% Training_loss_avg:0.689987\n",
            "Epoch:9 Step:128 Training_loss:0.709925, Acc_avg:55.08% Training_loss_avg:0.690951\n",
            "Epoch:9 Step:136 Training_loss:0.684180, Acc_avg:55.58% Training_loss_avg:0.689596\n",
            "Epoch:9 Step:144 Training_loss:0.709447, Acc_avg:54.83% Training_loss_avg:0.691118\n",
            "Epoch:9 Step:152 Training_loss:0.728374, Acc_avg:54.58% Training_loss_avg:0.690472\n",
            "Epoch:9 Step:160 Training_loss:0.681619, Acc_avg:54.33% Training_loss_avg:0.691450\n",
            "Epoch:9 Step:168 Training_loss:0.681874, Acc_avg:54.33% Training_loss_avg:0.691927\n",
            "Epoch:9 Step:176 Training_loss:0.692147, Acc_avg:53.83% Training_loss_avg:0.692918\n",
            "Epoch:9 Step:184 Training_loss:0.689214, Acc_avg:53.58% Training_loss_avg:0.693294\n",
            "Epoch:9 Step:192 Training_loss:0.690363, Acc_avg:53.33% Training_loss_avg:0.693242\n",
            "Epoch:9 Step:200 Training_loss:0.673603, Acc_avg:53.58% Training_loss_avg:0.692719\n",
            "Epoch:9 Step:208 Training_loss:0.710439, Acc_avg:53.33% Training_loss_avg:0.692115\n",
            "Epoch:9 Step:216 Training_loss:0.705739, Acc_avg:52.83% Training_loss_avg:0.692696\n",
            "Epoch:9 Step:224 Training_loss:0.679648, Acc_avg:52.58% Training_loss_avg:0.694375\n",
            "Epoch:9 Step:232 Training_loss:0.694324, Acc_avg:51.83% Training_loss_avg:0.695785\n",
            "Epoch:9 Step:240 Training_loss:0.703354, Acc_avg:52.08% Training_loss_avg:0.694597\n",
            "Epoch:9 Step:248 Training_loss:0.708631, Acc_avg:51.08% Training_loss_avg:0.695814\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:248 Val_loss:0.691097, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:256 Training_loss:0.701209, Acc_avg:50.83% Training_loss_avg:0.695405\n",
            "Epoch:9 Step:264 Training_loss:0.705450, Acc_avg:50.83% Training_loss_avg:0.694869\n",
            "Epoch:9 Step:272 Training_loss:0.690616, Acc_avg:51.08% Training_loss_avg:0.694377\n",
            "Epoch:9 Step:280 Training_loss:0.702305, Acc_avg:49.83% Training_loss_avg:0.696756\n",
            "Epoch:9 Step:288 Training_loss:0.693543, Acc_avg:49.58% Training_loss_avg:0.697650\n",
            "Epoch:9 Step:296 Training_loss:0.701992, Acc_avg:49.58% Training_loss_avg:0.696809\n",
            "Epoch:9 Step:304 Training_loss:0.697890, Acc_avg:49.08% Training_loss_avg:0.697558\n",
            "Epoch:9 Step:312 Training_loss:0.690485, Acc_avg:49.08% Training_loss_avg:0.697926\n",
            "Epoch:9 Step:320 Training_loss:0.689591, Acc_avg:49.08% Training_loss_avg:0.698017\n",
            "Epoch:9 Step:328 Training_loss:0.671369, Acc_avg:49.58% Training_loss_avg:0.697885\n",
            "Epoch:9 Step:336 Training_loss:0.685032, Acc_avg:50.08% Training_loss_avg:0.696778\n",
            "Epoch:9 Step:344 Training_loss:0.682846, Acc_avg:50.58% Training_loss_avg:0.695630\n",
            "Epoch:9 Step:352 Training_loss:0.700637, Acc_avg:50.58% Training_loss_avg:0.694959\n",
            "Epoch:9 Step:360 Training_loss:0.700367, Acc_avg:50.33% Training_loss_avg:0.695037\n",
            "Epoch:9 Step:368 Training_loss:0.680737, Acc_avg:50.33% Training_loss_avg:0.695179\n",
            "Epoch:9 Step:376 Training_loss:0.674692, Acc_avg:51.08% Training_loss_avg:0.693502\n",
            "Epoch:9 Step:384 Training_loss:0.715875, Acc_avg:50.83% Training_loss_avg:0.693362\n",
            "Epoch:9 Step:392 Training_loss:0.651897, Acc_avg:51.25% Training_loss_avg:0.693021\n",
            "Epoch:9 Step:400 Training_loss:0.690081, Acc_avg:51.00% Training_loss_avg:0.693466\n",
            "Epoch:9 Step:408 Training_loss:0.675994, Acc_avg:51.25% Training_loss_avg:0.692839\n",
            "Epoch:9 Step:416 Training_loss:0.713714, Acc_avg:50.50% Training_loss_avg:0.694048\n",
            "Epoch:9 Step:424 Training_loss:0.710643, Acc_avg:49.75% Training_loss_avg:0.695174\n",
            "Epoch:9 Step:432 Training_loss:0.647059, Acc_avg:49.75% Training_loss_avg:0.695915\n",
            "Epoch:9 Step:440 Training_loss:0.634137, Acc_avg:50.50% Training_loss_avg:0.694944\n",
            "Epoch:9 Step:448 Training_loss:0.687946, Acc_avg:50.75% Training_loss_avg:0.694162\n",
            "Epoch:9 Step:456 Training_loss:0.714724, Acc_avg:50.75% Training_loss_avg:0.692931\n",
            "Epoch:9 Step:464 Training_loss:0.737772, Acc_avg:50.00% Training_loss_avg:0.694173\n",
            "Epoch:9 Step:472 Training_loss:0.767130, Acc_avg:49.00% Training_loss_avg:0.696465\n",
            "Epoch:9 Step:480 Training_loss:0.632869, Acc_avg:50.00% Training_loss_avg:0.694651\n",
            "Epoch:9 Step:488 Training_loss:0.701744, Acc_avg:49.50% Training_loss_avg:0.695842\n",
            "Epoch:9 Step:496 Training_loss:0.637150, Acc_avg:51.00% Training_loss_avg:0.693159\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:496 Val_loss:0.689444, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:504 Training_loss:0.639935, Acc_avg:52.25% Training_loss_avg:0.691109\n",
            "Epoch:9 Step:512 Training_loss:0.667359, Acc_avg:52.50% Training_loss_avg:0.690500\n",
            "Epoch:9 Step:520 Training_loss:0.727423, Acc_avg:52.50% Training_loss_avg:0.691302\n",
            "Epoch:9 Step:528 Training_loss:0.699761, Acc_avg:52.75% Training_loss_avg:0.691099\n",
            "Epoch:9 Step:536 Training_loss:0.669860, Acc_avg:52.75% Training_loss_avg:0.690812\n",
            "Epoch:9 Step:544 Training_loss:0.725532, Acc_avg:53.00% Training_loss_avg:0.691134\n",
            "Epoch:9 Step:552 Training_loss:0.702268, Acc_avg:53.50% Training_loss_avg:0.690612\n",
            "Epoch:9 Step:560 Training_loss:0.738350, Acc_avg:53.00% Training_loss_avg:0.691746\n",
            "Epoch:9 Step:568 Training_loss:0.635721, Acc_avg:53.00% Training_loss_avg:0.690823\n",
            "Epoch:9 Step:576 Training_loss:0.689734, Acc_avg:53.00% Training_loss_avg:0.690775\n",
            "Epoch:9 Step:584 Training_loss:0.670141, Acc_avg:53.25% Training_loss_avg:0.690394\n",
            "Epoch:9 Step:592 Training_loss:0.668210, Acc_avg:53.75% Training_loss_avg:0.689951\n",
            "Epoch:9 Step:600 Training_loss:0.644281, Acc_avg:53.75% Training_loss_avg:0.689364\n",
            "Epoch:9 Step:608 Training_loss:0.670394, Acc_avg:54.50% Training_loss_avg:0.688563\n",
            "Epoch:9 Step:616 Training_loss:0.602593, Acc_avg:55.75% Training_loss_avg:0.686500\n",
            "Epoch:9 Step:624 Training_loss:0.651213, Acc_avg:55.50% Training_loss_avg:0.685932\n",
            "Epoch:9 Step:632 Training_loss:0.679434, Acc_avg:55.75% Training_loss_avg:0.685634\n",
            "Epoch:9 Step:640 Training_loss:0.746346, Acc_avg:55.75% Training_loss_avg:0.686494\n",
            "Epoch:9 Step:648 Training_loss:0.655037, Acc_avg:56.50% Training_loss_avg:0.685422\n",
            "Epoch:9 Step:656 Training_loss:0.727499, Acc_avg:56.75% Training_loss_avg:0.685948\n",
            "Epoch:9 Step:664 Training_loss:0.726615, Acc_avg:56.75% Training_loss_avg:0.686371\n",
            "Epoch:9 Step:672 Training_loss:0.690163, Acc_avg:57.00% Training_loss_avg:0.686362\n",
            "Epoch:9 Step:680 Training_loss:0.798962, Acc_avg:56.50% Training_loss_avg:0.688295\n",
            "Epoch:9 Step:688 Training_loss:0.776894, Acc_avg:56.00% Training_loss_avg:0.689962\n",
            "Epoch:9 Step:696 Training_loss:0.707178, Acc_avg:56.25% Training_loss_avg:0.690066\n",
            "Epoch:9 Step:704 Training_loss:0.718079, Acc_avg:56.50% Training_loss_avg:0.690469\n",
            "Epoch:9 Step:712 Training_loss:0.707173, Acc_avg:56.25% Training_loss_avg:0.690803\n",
            "Epoch:9 Step:720 Training_loss:0.635233, Acc_avg:56.50% Training_loss_avg:0.689716\n",
            "Epoch:9 Step:728 Training_loss:0.682707, Acc_avg:56.00% Training_loss_avg:0.689943\n",
            "Epoch:9 Step:736 Training_loss:0.684954, Acc_avg:55.75% Training_loss_avg:0.689941\n",
            "Epoch:9 Step:744 Training_loss:0.646818, Acc_avg:56.00% Training_loss_avg:0.689221\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:744 Val_loss:0.689771, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:752 Training_loss:0.734547, Acc_avg:56.00% Training_loss_avg:0.689899\n",
            "Epoch:9 Step:760 Training_loss:0.632547, Acc_avg:56.75% Training_loss_avg:0.688543\n",
            "Epoch:9 Step:768 Training_loss:0.648839, Acc_avg:57.00% Training_loss_avg:0.687905\n",
            "Epoch:9 Step:776 Training_loss:0.707595, Acc_avg:56.75% Training_loss_avg:0.688563\n",
            "Epoch:9 Step:784 Training_loss:0.642489, Acc_avg:57.75% Training_loss_avg:0.687095\n",
            "Epoch:9 Step:792 Training_loss:0.643626, Acc_avg:57.50% Training_loss_avg:0.686929\n",
            "Epoch:9 Step:800 Training_loss:0.673836, Acc_avg:57.75% Training_loss_avg:0.686605\n",
            "Epoch:9 Step:808 Training_loss:0.677770, Acc_avg:57.75% Training_loss_avg:0.686640\n",
            "Epoch:9 Step:816 Training_loss:0.689952, Acc_avg:58.25% Training_loss_avg:0.686165\n",
            "Epoch:9 Step:824 Training_loss:0.711713, Acc_avg:58.50% Training_loss_avg:0.686186\n",
            "Epoch:9 Step:832 Training_loss:0.741264, Acc_avg:57.50% Training_loss_avg:0.688070\n",
            "Epoch:9 Step:840 Training_loss:0.765531, Acc_avg:56.00% Training_loss_avg:0.690698\n",
            "Epoch:9 Step:848 Training_loss:0.765511, Acc_avg:55.25% Training_loss_avg:0.692250\n",
            "Epoch:9 Step:856 Training_loss:0.709786, Acc_avg:55.25% Training_loss_avg:0.692151\n",
            "Epoch:9 Step:864 Training_loss:0.701564, Acc_avg:55.75% Training_loss_avg:0.691427\n",
            "Epoch:9 Step:872 Training_loss:0.719121, Acc_avg:56.25% Training_loss_avg:0.690466\n",
            "Epoch:9 Step:880 Training_loss:0.692807, Acc_avg:55.50% Training_loss_avg:0.691665\n",
            "Epoch:9 Step:888 Training_loss:0.714538, Acc_avg:55.25% Training_loss_avg:0.691921\n",
            "Epoch:9 Step:896 Training_loss:0.721011, Acc_avg:54.25% Training_loss_avg:0.693598\n",
            "Epoch:9 Step:904 Training_loss:0.692358, Acc_avg:53.50% Training_loss_avg:0.694647\n",
            "Epoch:9 Step:912 Training_loss:0.691738, Acc_avg:53.50% Training_loss_avg:0.695134\n",
            "Epoch:9 Step:920 Training_loss:0.666498, Acc_avg:54.00% Training_loss_avg:0.693916\n",
            "Epoch:9 Step:928 Training_loss:0.687728, Acc_avg:54.25% Training_loss_avg:0.693675\n",
            "Epoch:9 Step:936 Training_loss:0.696944, Acc_avg:53.75% Training_loss_avg:0.694217\n",
            "Epoch:9 Step:944 Training_loss:0.686939, Acc_avg:53.75% Training_loss_avg:0.693445\n",
            "Epoch:9 Step:952 Training_loss:0.689294, Acc_avg:53.75% Training_loss_avg:0.693186\n",
            "Epoch:9 Step:960 Training_loss:0.704281, Acc_avg:54.00% Training_loss_avg:0.692504\n",
            "Epoch:9 Step:968 Training_loss:0.701404, Acc_avg:53.25% Training_loss_avg:0.693818\n",
            "Epoch:9 Step:976 Training_loss:0.679171, Acc_avg:53.75% Training_loss_avg:0.693607\n",
            "Epoch:9 Step:984 Training_loss:0.696281, Acc_avg:53.75% Training_loss_avg:0.694129\n",
            "Epoch:9 Step:992 Training_loss:0.675957, Acc_avg:54.00% Training_loss_avg:0.694284\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:992 Val_loss:0.691613, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:1000 Training_loss:0.695082, Acc_avg:53.50% Training_loss_avg:0.695300\n",
            "Epoch:9 Step:1008 Training_loss:0.700089, Acc_avg:53.25% Training_loss_avg:0.695894\n",
            "Epoch:9 Step:1016 Training_loss:0.717997, Acc_avg:52.50% Training_loss_avg:0.698202\n",
            "Epoch:9 Step:1024 Training_loss:0.683255, Acc_avg:52.75% Training_loss_avg:0.698843\n",
            "Epoch:9 Step:1032 Training_loss:0.710275, Acc_avg:52.00% Training_loss_avg:0.699460\n",
            "Epoch:9 Step:1040 Training_loss:0.690466, Acc_avg:52.50% Training_loss_avg:0.698342\n",
            "Epoch:9 Step:1048 Training_loss:0.701171, Acc_avg:52.25% Training_loss_avg:0.699265\n",
            "Epoch:9 Step:1056 Training_loss:0.724703, Acc_avg:51.75% Training_loss_avg:0.699209\n",
            "Epoch:9 Step:1064 Training_loss:0.681997, Acc_avg:52.25% Training_loss_avg:0.698317\n",
            "Epoch:9 Step:1072 Training_loss:0.672078, Acc_avg:52.75% Training_loss_avg:0.697955\n",
            "Epoch:9 Step:1080 Training_loss:0.693727, Acc_avg:53.50% Training_loss_avg:0.695850\n",
            "Epoch:9 Step:1088 Training_loss:0.679268, Acc_avg:54.25% Training_loss_avg:0.693898\n",
            "Epoch:9 Step:1096 Training_loss:0.721485, Acc_avg:53.75% Training_loss_avg:0.694184\n",
            "Epoch:9 Step:1104 Training_loss:0.685297, Acc_avg:53.75% Training_loss_avg:0.693528\n",
            "Epoch:9 Step:1112 Training_loss:0.680873, Acc_avg:54.00% Training_loss_avg:0.693002\n",
            "Epoch:9 Step:1120 Training_loss:0.699233, Acc_avg:53.50% Training_loss_avg:0.694282\n",
            "Epoch:9 Step:1128 Training_loss:0.687317, Acc_avg:53.25% Training_loss_avg:0.694375\n",
            "Epoch:9 Step:1136 Training_loss:0.677345, Acc_avg:53.50% Training_loss_avg:0.694222\n",
            "Epoch:9 Step:1144 Training_loss:0.683604, Acc_avg:53.25% Training_loss_avg:0.694958\n",
            "Epoch:9 Step:1152 Training_loss:0.701753, Acc_avg:53.50% Training_loss_avg:0.694302\n",
            "Epoch:9 Step:1160 Training_loss:0.668581, Acc_avg:53.50% Training_loss_avg:0.695023\n",
            "Epoch:9 Step:1168 Training_loss:0.714661, Acc_avg:52.75% Training_loss_avg:0.696339\n",
            "Epoch:9 Step:1176 Training_loss:0.703299, Acc_avg:52.50% Training_loss_avg:0.696253\n",
            "Epoch:9 Step:1184 Training_loss:0.679916, Acc_avg:52.25% Training_loss_avg:0.697002\n",
            "Epoch:9 Step:1192 Training_loss:0.712383, Acc_avg:51.50% Training_loss_avg:0.698377\n",
            "Epoch:9 Step:1200 Training_loss:0.687832, Acc_avg:51.25% Training_loss_avg:0.698657\n",
            "Epoch:9 Step:1208 Training_loss:0.672337, Acc_avg:51.50% Training_loss_avg:0.698548\n",
            "Epoch:9 Step:1216 Training_loss:0.648161, Acc_avg:52.00% Training_loss_avg:0.697712\n",
            "Epoch:9 Step:1224 Training_loss:0.734271, Acc_avg:51.25% Training_loss_avg:0.698164\n",
            "Epoch:9 Step:1232 Training_loss:0.701453, Acc_avg:51.25% Training_loss_avg:0.697367\n",
            "Epoch:9 Step:1240 Training_loss:0.674548, Acc_avg:52.00% Training_loss_avg:0.695548\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:1240 Val_loss:0.689523, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:1248 Training_loss:0.687447, Acc_avg:52.50% Training_loss_avg:0.693986\n",
            "Epoch:9 Step:1256 Training_loss:0.709269, Acc_avg:52.50% Training_loss_avg:0.693976\n",
            "Epoch:9 Step:1264 Training_loss:0.694745, Acc_avg:52.50% Training_loss_avg:0.693840\n",
            "Epoch:9 Step:1272 Training_loss:0.666400, Acc_avg:53.25% Training_loss_avg:0.692785\n",
            "Epoch:9 Step:1280 Training_loss:0.680983, Acc_avg:53.50% Training_loss_avg:0.692549\n",
            "Epoch:9 Step:1288 Training_loss:0.706534, Acc_avg:53.75% Training_loss_avg:0.692389\n",
            "Epoch:9 Step:1296 Training_loss:0.696756, Acc_avg:54.00% Training_loss_avg:0.691904\n",
            "Epoch:9 Step:1304 Training_loss:0.649828, Acc_avg:54.75% Training_loss_avg:0.691053\n",
            "Epoch:9 Step:1312 Training_loss:0.647127, Acc_avg:55.25% Training_loss_avg:0.690161\n",
            "Epoch:9 Step:1320 Training_loss:0.680531, Acc_avg:55.00% Training_loss_avg:0.690442\n",
            "Epoch:9 Step:1328 Training_loss:0.717228, Acc_avg:54.50% Training_loss_avg:0.691032\n",
            "Epoch:9 Step:1336 Training_loss:0.715422, Acc_avg:54.50% Training_loss_avg:0.691401\n",
            "Epoch:9 Step:1344 Training_loss:0.778269, Acc_avg:53.75% Training_loss_avg:0.693228\n",
            "Epoch:9 Step:1352 Training_loss:0.632144, Acc_avg:54.25% Training_loss_avg:0.692085\n",
            "Epoch:9 Step:1360 Training_loss:0.692766, Acc_avg:54.25% Training_loss_avg:0.691854\n",
            "Epoch:9 Step:1368 Training_loss:0.658618, Acc_avg:55.00% Training_loss_avg:0.690999\n",
            "Epoch:9 Step:1376 Training_loss:0.670888, Acc_avg:54.75% Training_loss_avg:0.690833\n",
            "Epoch:9 Step:1384 Training_loss:0.766183, Acc_avg:54.00% Training_loss_avg:0.692231\n",
            "Epoch:9 Step:1392 Training_loss:0.697889, Acc_avg:53.50% Training_loss_avg:0.692670\n",
            "Epoch:9 Step:1400 Training_loss:0.748081, Acc_avg:53.25% Training_loss_avg:0.693730\n",
            "Epoch:9 Step:1408 Training_loss:0.684305, Acc_avg:53.25% Training_loss_avg:0.693414\n",
            "Epoch:9 Step:1416 Training_loss:0.654618, Acc_avg:53.75% Training_loss_avg:0.692146\n",
            "Epoch:9 Step:1424 Training_loss:0.694287, Acc_avg:53.25% Training_loss_avg:0.692367\n",
            "Epoch:9 Step:1432 Training_loss:0.708168, Acc_avg:53.50% Training_loss_avg:0.692325\n",
            "Epoch:9 Step:1440 Training_loss:0.711796, Acc_avg:53.25% Training_loss_avg:0.692751\n",
            "Epoch:9 Step:1448 Training_loss:0.650235, Acc_avg:53.75% Training_loss_avg:0.691733\n",
            "Epoch:9 Step:1456 Training_loss:0.691318, Acc_avg:54.25% Training_loss_avg:0.691065\n",
            "Epoch:9 Step:1464 Training_loss:0.688591, Acc_avg:54.00% Training_loss_avg:0.691197\n",
            "Epoch:9 Step:1472 Training_loss:0.683010, Acc_avg:53.50% Training_loss_avg:0.691416\n",
            "Epoch:9 Step:1480 Training_loss:0.753941, Acc_avg:53.00% Training_loss_avg:0.692620\n",
            "Epoch:9 Step:1488 Training_loss:0.654480, Acc_avg:53.25% Training_loss_avg:0.692124\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:1488 Val_loss:0.689427, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:1496 Training_loss:0.703973, Acc_avg:53.75% Training_loss_avg:0.691774\n",
            "Epoch:9 Step:1504 Training_loss:0.681993, Acc_avg:54.00% Training_loss_avg:0.691708\n",
            "Epoch:9 Step:1512 Training_loss:0.673537, Acc_avg:54.00% Training_loss_avg:0.691561\n",
            "Epoch:9 Step:1520 Training_loss:0.665082, Acc_avg:54.50% Training_loss_avg:0.690878\n",
            "Epoch:9 Step:1528 Training_loss:0.686146, Acc_avg:54.75% Training_loss_avg:0.690855\n",
            "Epoch:9 Step:1536 Training_loss:0.679373, Acc_avg:54.75% Training_loss_avg:0.690895\n",
            "Epoch:9 Step:1544 Training_loss:0.729993, Acc_avg:54.00% Training_loss_avg:0.691823\n",
            "Epoch:9 Step:1552 Training_loss:0.692591, Acc_avg:54.00% Training_loss_avg:0.691640\n",
            "Epoch:9 Step:1560 Training_loss:0.677305, Acc_avg:53.75% Training_loss_avg:0.691814\n",
            "Epoch:9 Step:1568 Training_loss:0.682169, Acc_avg:54.25% Training_loss_avg:0.691164\n",
            "Epoch:9 Step:1576 Training_loss:0.710611, Acc_avg:54.25% Training_loss_avg:0.691311\n",
            "Epoch:9 Step:1584 Training_loss:0.713523, Acc_avg:53.75% Training_loss_avg:0.691983\n",
            "Epoch:9 Step:1592 Training_loss:0.691655, Acc_avg:54.00% Training_loss_avg:0.691568\n",
            "Epoch:9 Step:1600 Training_loss:0.697241, Acc_avg:54.00% Training_loss_avg:0.691756\n",
            "Epoch:9 Step:1608 Training_loss:0.672559, Acc_avg:53.75% Training_loss_avg:0.691761\n",
            "Epoch:9 Step:1616 Training_loss:0.688875, Acc_avg:53.25% Training_loss_avg:0.692575\n",
            "Epoch:9 Step:1624 Training_loss:0.697546, Acc_avg:54.00% Training_loss_avg:0.691841\n",
            "Epoch:9 Step:1632 Training_loss:0.706154, Acc_avg:54.00% Training_loss_avg:0.691935\n",
            "Epoch:9 Step:1640 Training_loss:0.666963, Acc_avg:54.25% Training_loss_avg:0.691783\n",
            "Epoch:9 Step:1648 Training_loss:0.686736, Acc_avg:54.25% Training_loss_avg:0.691769\n",
            "Epoch:9 Step:1656 Training_loss:0.681736, Acc_avg:54.75% Training_loss_avg:0.691218\n",
            "Epoch:9 Step:1664 Training_loss:0.667629, Acc_avg:55.25% Training_loss_avg:0.690676\n",
            "Epoch:9 Step:1672 Training_loss:0.664306, Acc_avg:55.25% Training_loss_avg:0.690634\n",
            "Epoch:9 Step:1680 Training_loss:0.674465, Acc_avg:55.25% Training_loss_avg:0.690504\n",
            "Epoch:9 Step:1688 Training_loss:0.691355, Acc_avg:55.50% Training_loss_avg:0.690200\n",
            "Epoch:9 Step:1696 Training_loss:0.657420, Acc_avg:56.00% Training_loss_avg:0.689413\n",
            "Epoch:9 Step:1704 Training_loss:0.724381, Acc_avg:54.75% Training_loss_avg:0.690904\n",
            "Epoch:9 Step:1712 Training_loss:0.641405, Acc_avg:54.75% Training_loss_avg:0.690790\n",
            "Epoch:9 Step:1720 Training_loss:0.666008, Acc_avg:55.00% Training_loss_avg:0.690499\n",
            "Epoch:9 Step:1728 Training_loss:0.646301, Acc_avg:55.75% Training_loss_avg:0.689081\n",
            "Epoch:9 Step:1736 Training_loss:0.698935, Acc_avg:56.00% Training_loss_avg:0.688751\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:1736 Val_loss:0.689410, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:1744 Training_loss:0.677053, Acc_avg:57.00% Training_loss_avg:0.686727\n",
            "Epoch:9 Step:1752 Training_loss:0.676037, Acc_avg:56.75% Training_loss_avg:0.687605\n",
            "Epoch:9 Step:1760 Training_loss:0.704995, Acc_avg:56.75% Training_loss_avg:0.687849\n",
            "Epoch:9 Step:1768 Training_loss:0.669798, Acc_avg:56.50% Training_loss_avg:0.688073\n",
            "Epoch:9 Step:1776 Training_loss:0.661855, Acc_avg:56.50% Training_loss_avg:0.687892\n",
            "Epoch:9 Step:1784 Training_loss:0.578650, Acc_avg:58.00% Training_loss_avg:0.684141\n",
            "Epoch:9 Step:1792 Training_loss:0.664192, Acc_avg:58.25% Training_loss_avg:0.683468\n",
            "Epoch:9 Step:1800 Training_loss:0.710696, Acc_avg:58.50% Training_loss_avg:0.682720\n",
            "Epoch:9 Step:1808 Training_loss:0.596258, Acc_avg:59.25% Training_loss_avg:0.680959\n",
            "Epoch:9 Step:1816 Training_loss:0.635166, Acc_avg:59.25% Training_loss_avg:0.680570\n",
            "Epoch:9 Step:1824 Training_loss:0.734635, Acc_avg:59.25% Training_loss_avg:0.681377\n",
            "Epoch:9 Step:1832 Training_loss:0.662424, Acc_avg:59.75% Training_loss_avg:0.680462\n",
            "Epoch:9 Step:1840 Training_loss:0.622859, Acc_avg:60.25% Training_loss_avg:0.678683\n",
            "Epoch:9 Step:1848 Training_loss:0.635968, Acc_avg:60.00% Training_loss_avg:0.678398\n",
            "Epoch:9 Step:1856 Training_loss:0.674549, Acc_avg:60.25% Training_loss_avg:0.678062\n",
            "Epoch:9 Step:1864 Training_loss:0.689921, Acc_avg:60.50% Training_loss_avg:0.678089\n",
            "Epoch:9 Step:1872 Training_loss:0.706768, Acc_avg:60.50% Training_loss_avg:0.678564\n",
            "Epoch:9 Step:1880 Training_loss:0.681807, Acc_avg:61.00% Training_loss_avg:0.677122\n",
            "Epoch:9 Step:1888 Training_loss:0.682794, Acc_avg:60.75% Training_loss_avg:0.677688\n",
            "Epoch:9 Step:1896 Training_loss:0.673984, Acc_avg:61.00% Training_loss_avg:0.677088\n",
            "Epoch:9 Step:1904 Training_loss:0.765628, Acc_avg:60.50% Training_loss_avg:0.678761\n",
            "Epoch:9 Step:1912 Training_loss:0.747589, Acc_avg:60.00% Training_loss_avg:0.680242\n",
            "Epoch:9 Step:1920 Training_loss:0.598185, Acc_avg:60.25% Training_loss_avg:0.678904\n",
            "Epoch:9 Step:1928 Training_loss:0.761050, Acc_avg:59.75% Training_loss_avg:0.680402\n",
            "Epoch:9 Step:1936 Training_loss:0.617993, Acc_avg:60.00% Training_loss_avg:0.679174\n",
            "Epoch:9 Step:1944 Training_loss:0.789035, Acc_avg:60.00% Training_loss_avg:0.680355\n",
            "Epoch:9 Step:1952 Training_loss:0.648231, Acc_avg:60.25% Training_loss_avg:0.679468\n",
            "Epoch:9 Step:1960 Training_loss:0.888118, Acc_avg:59.50% Training_loss_avg:0.683684\n",
            "Epoch:9 Step:1968 Training_loss:0.760902, Acc_avg:59.00% Training_loss_avg:0.685259\n",
            "Epoch:9 Step:1976 Training_loss:0.777950, Acc_avg:59.00% Training_loss_avg:0.686606\n",
            "Epoch:9 Step:1984 Training_loss:0.658480, Acc_avg:59.50% Training_loss_avg:0.685505\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:1984 Val_loss:0.692162, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:1992 Training_loss:0.649598, Acc_avg:59.75% Training_loss_avg:0.684664\n",
            "Epoch:9 Step:2000 Training_loss:0.688427, Acc_avg:59.75% Training_loss_avg:0.684487\n",
            "Epoch:9 Step:2008 Training_loss:0.736455, Acc_avg:59.25% Training_loss_avg:0.685765\n",
            "Epoch:9 Step:2016 Training_loss:0.775360, Acc_avg:58.50% Training_loss_avg:0.687495\n",
            "Epoch:9 Step:2024 Training_loss:0.596103, Acc_avg:59.25% Training_loss_avg:0.685466\n",
            "Epoch:9 Step:2032 Training_loss:0.665385, Acc_avg:59.75% Training_loss_avg:0.684651\n",
            "Epoch:9 Step:2040 Training_loss:0.696241, Acc_avg:59.50% Training_loss_avg:0.685236\n",
            "Epoch:9 Step:2048 Training_loss:0.628442, Acc_avg:60.00% Training_loss_avg:0.684070\n",
            "Epoch:9 Step:2056 Training_loss:0.657543, Acc_avg:60.00% Training_loss_avg:0.683587\n",
            "Epoch:9 Step:2064 Training_loss:0.684032, Acc_avg:59.50% Training_loss_avg:0.683915\n",
            "Epoch:9 Step:2072 Training_loss:0.712869, Acc_avg:59.00% Training_loss_avg:0.684886\n",
            "Epoch:9 Step:2080 Training_loss:0.704727, Acc_avg:58.75% Training_loss_avg:0.685491\n",
            "Epoch:9 Step:2088 Training_loss:0.703399, Acc_avg:58.50% Training_loss_avg:0.685732\n",
            "Epoch:9 Step:2096 Training_loss:0.635248, Acc_avg:58.50% Training_loss_avg:0.685289\n",
            "Epoch:9 Step:2104 Training_loss:0.691681, Acc_avg:59.00% Training_loss_avg:0.684635\n",
            "Epoch:9 Step:2112 Training_loss:0.740848, Acc_avg:58.00% Training_loss_avg:0.686623\n",
            "Epoch:9 Step:2120 Training_loss:0.637285, Acc_avg:58.00% Training_loss_avg:0.686049\n",
            "Epoch:9 Step:2128 Training_loss:0.674934, Acc_avg:57.75% Training_loss_avg:0.686622\n",
            "Epoch:9 Step:2136 Training_loss:0.663712, Acc_avg:58.00% Training_loss_avg:0.685917\n",
            "Epoch:9 Step:2144 Training_loss:0.722993, Acc_avg:57.50% Training_loss_avg:0.686836\n",
            "Epoch:9 Step:2152 Training_loss:0.688659, Acc_avg:57.25% Training_loss_avg:0.687088\n",
            "Epoch:9 Step:2160 Training_loss:0.668467, Acc_avg:57.50% Training_loss_avg:0.686358\n",
            "Epoch:9 Step:2168 Training_loss:0.649032, Acc_avg:57.75% Training_loss_avg:0.685943\n",
            "Epoch:9 Step:2176 Training_loss:0.650826, Acc_avg:58.00% Training_loss_avg:0.685722\n",
            "Epoch:9 Step:2184 Training_loss:0.616037, Acc_avg:57.75% Training_loss_avg:0.686470\n",
            "Epoch:9 Step:2192 Training_loss:0.730254, Acc_avg:57.25% Training_loss_avg:0.687791\n",
            "Epoch:9 Step:2200 Training_loss:0.631911, Acc_avg:57.75% Training_loss_avg:0.686215\n",
            "Epoch:9 Step:2208 Training_loss:0.706635, Acc_avg:57.00% Training_loss_avg:0.688423\n",
            "Epoch:9 Step:2216 Training_loss:0.661038, Acc_avg:57.00% Training_loss_avg:0.688940\n",
            "Epoch:9 Step:2224 Training_loss:0.673848, Acc_avg:57.25% Training_loss_avg:0.687724\n",
            "Epoch:9 Step:2232 Training_loss:0.697505, Acc_avg:57.00% Training_loss_avg:0.688426\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:2232 Val_loss:0.690906, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:2240 Training_loss:0.751940, Acc_avg:56.25% Training_loss_avg:0.691008\n",
            "Epoch:9 Step:2248 Training_loss:0.733130, Acc_avg:55.75% Training_loss_avg:0.692951\n",
            "Epoch:9 Step:2256 Training_loss:0.690095, Acc_avg:55.50% Training_loss_avg:0.693262\n",
            "Epoch:9 Step:2264 Training_loss:0.683122, Acc_avg:55.50% Training_loss_avg:0.693126\n",
            "Epoch:9 Step:2272 Training_loss:0.657397, Acc_avg:55.75% Training_loss_avg:0.692139\n",
            "Epoch:9 Step:2280 Training_loss:0.626525, Acc_avg:56.25% Training_loss_avg:0.691033\n",
            "Epoch:9 Step:2288 Training_loss:0.770622, Acc_avg:55.75% Training_loss_avg:0.692789\n",
            "Epoch:9 Step:2296 Training_loss:0.630632, Acc_avg:56.00% Training_loss_avg:0.691922\n",
            "Epoch:9 Step:2304 Training_loss:0.678150, Acc_avg:56.50% Training_loss_avg:0.690173\n",
            "Epoch:9 Step:2312 Training_loss:0.672472, Acc_avg:57.00% Training_loss_avg:0.688671\n",
            "Epoch:9 Step:2320 Training_loss:0.753351, Acc_avg:56.00% Training_loss_avg:0.691774\n",
            "Epoch:9 Step:2328 Training_loss:0.689514, Acc_avg:56.25% Training_loss_avg:0.690343\n",
            "Epoch:9 Step:2336 Training_loss:0.714996, Acc_avg:55.75% Training_loss_avg:0.692283\n",
            "Epoch:9 Step:2344 Training_loss:0.658955, Acc_avg:56.50% Training_loss_avg:0.689682\n",
            "Epoch:9 Step:2352 Training_loss:0.748261, Acc_avg:56.00% Training_loss_avg:0.691682\n",
            "Epoch:9 Step:2360 Training_loss:0.719083, Acc_avg:56.25% Training_loss_avg:0.688301\n",
            "Epoch:9 Step:2368 Training_loss:0.681395, Acc_avg:56.75% Training_loss_avg:0.686711\n",
            "Epoch:9 Step:2376 Training_loss:0.708306, Acc_avg:57.00% Training_loss_avg:0.685318\n",
            "Epoch:9 Step:2384 Training_loss:0.655584, Acc_avg:57.25% Training_loss_avg:0.685261\n",
            "Epoch:9 Step:2392 Training_loss:0.668336, Acc_avg:57.25% Training_loss_avg:0.685635\n",
            "Epoch:9 Step:2400 Training_loss:0.640578, Acc_avg:57.75% Training_loss_avg:0.684678\n",
            "Epoch:9 Step:2408 Training_loss:0.677067, Acc_avg:58.25% Training_loss_avg:0.683491\n",
            "Epoch:9 Step:2416 Training_loss:0.702916, Acc_avg:58.75% Training_loss_avg:0.682042\n",
            "Epoch:9 Step:2424 Training_loss:0.670758, Acc_avg:58.25% Training_loss_avg:0.683535\n",
            "Epoch:9 Step:2432 Training_loss:0.719739, Acc_avg:57.75% Training_loss_avg:0.684622\n",
            "Epoch:9 Step:2440 Training_loss:0.729584, Acc_avg:57.25% Training_loss_avg:0.685289\n",
            "Epoch:9 Step:2448 Training_loss:0.772989, Acc_avg:56.00% Training_loss_avg:0.688180\n",
            "Epoch:9 Step:2456 Training_loss:0.731589, Acc_avg:55.50% Training_loss_avg:0.689661\n",
            "Epoch:9 Step:2464 Training_loss:0.619655, Acc_avg:56.25% Training_loss_avg:0.688373\n",
            "Epoch:9 Step:2472 Training_loss:0.692292, Acc_avg:56.25% Training_loss_avg:0.687961\n",
            "Epoch:9 Step:2480 Training_loss:0.651403, Acc_avg:56.75% Training_loss_avg:0.686895\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:2480 Val_loss:0.689596, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:2488 Training_loss:0.706381, Acc_avg:56.75% Training_loss_avg:0.686955\n",
            "Epoch:9 Step:2496 Training_loss:0.727949, Acc_avg:56.00% Training_loss_avg:0.688809\n",
            "Epoch:9 Step:2504 Training_loss:0.694187, Acc_avg:56.00% Training_loss_avg:0.688859\n",
            "Epoch:9 Step:2512 Training_loss:0.692580, Acc_avg:56.25% Training_loss_avg:0.687893\n",
            "Epoch:9 Step:2520 Training_loss:0.668771, Acc_avg:56.00% Training_loss_avg:0.688523\n",
            "Epoch:9 Step:2528 Training_loss:0.643654, Acc_avg:56.25% Training_loss_avg:0.687898\n",
            "Epoch:9 Step:2536 Training_loss:0.668360, Acc_avg:56.25% Training_loss_avg:0.687990\n",
            "Epoch:9 Step:2544 Training_loss:0.667980, Acc_avg:56.75% Training_loss_avg:0.686890\n",
            "Epoch:9 Step:2552 Training_loss:0.699458, Acc_avg:56.75% Training_loss_avg:0.687106\n",
            "Epoch:9 Step:2560 Training_loss:0.646799, Acc_avg:57.00% Training_loss_avg:0.686673\n",
            "Epoch:9 Step:2568 Training_loss:0.708381, Acc_avg:56.25% Training_loss_avg:0.687860\n",
            "Epoch:9 Step:2576 Training_loss:0.730358, Acc_avg:55.50% Training_loss_avg:0.689450\n",
            "Epoch:9 Step:2584 Training_loss:0.672226, Acc_avg:55.00% Training_loss_avg:0.690574\n",
            "Epoch:9 Step:2592 Training_loss:0.686929, Acc_avg:55.25% Training_loss_avg:0.689708\n",
            "Epoch:9 Step:2600 Training_loss:0.666814, Acc_avg:55.25% Training_loss_avg:0.690406\n",
            "Epoch:9 Step:2608 Training_loss:0.710404, Acc_avg:55.25% Training_loss_avg:0.690481\n",
            "Epoch:9 Step:2616 Training_loss:0.680708, Acc_avg:55.00% Training_loss_avg:0.690875\n",
            "Epoch:9 Step:2624 Training_loss:0.720432, Acc_avg:54.50% Training_loss_avg:0.691806\n",
            "Epoch:9 Step:2632 Training_loss:0.726950, Acc_avg:54.25% Training_loss_avg:0.692395\n",
            "Epoch:9 Step:2640 Training_loss:0.719506, Acc_avg:54.25% Training_loss_avg:0.691746\n",
            "Epoch:9 Step:2648 Training_loss:0.671412, Acc_avg:54.75% Training_loss_avg:0.690512\n",
            "Epoch:9 Step:2656 Training_loss:0.668638, Acc_avg:55.00% Training_loss_avg:0.690083\n",
            "Epoch:9 Step:2664 Training_loss:0.684430, Acc_avg:54.75% Training_loss_avg:0.690109\n",
            "Epoch:9 Step:2672 Training_loss:0.689638, Acc_avg:54.50% Training_loss_avg:0.690754\n",
            "Epoch:9 Step:2680 Training_loss:0.696047, Acc_avg:54.00% Training_loss_avg:0.692144\n",
            "Epoch:9 Step:2688 Training_loss:0.665119, Acc_avg:54.50% Training_loss_avg:0.690034\n",
            "Epoch:9 Step:2696 Training_loss:0.706410, Acc_avg:54.00% Training_loss_avg:0.691550\n",
            "Epoch:9 Step:2704 Training_loss:0.660698, Acc_avg:54.00% Training_loss_avg:0.691201\n",
            "Epoch:9 Step:2712 Training_loss:0.681124, Acc_avg:54.00% Training_loss_avg:0.691374\n",
            "Epoch:9 Step:2720 Training_loss:0.622826, Acc_avg:55.00% Training_loss_avg:0.688763\n",
            "Epoch:9 Step:2728 Training_loss:0.765735, Acc_avg:54.25% Training_loss_avg:0.690288\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:2728 Val_loss:0.689596, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:2736 Training_loss:0.656586, Acc_avg:54.50% Training_loss_avg:0.689120\n",
            "Epoch:9 Step:2744 Training_loss:0.700729, Acc_avg:54.25% Training_loss_avg:0.689955\n",
            "Epoch:9 Step:2752 Training_loss:0.655735, Acc_avg:55.00% Training_loss_avg:0.688105\n",
            "Epoch:9 Step:2760 Training_loss:0.691632, Acc_avg:55.25% Training_loss_avg:0.687556\n",
            "Epoch:9 Step:2768 Training_loss:0.712603, Acc_avg:54.75% Training_loss_avg:0.688180\n",
            "Epoch:9 Step:2776 Training_loss:0.693379, Acc_avg:54.75% Training_loss_avg:0.687881\n",
            "Epoch:9 Step:2784 Training_loss:0.677631, Acc_avg:54.50% Training_loss_avg:0.688322\n",
            "Epoch:9 Step:2792 Training_loss:0.706849, Acc_avg:54.25% Training_loss_avg:0.689092\n",
            "Epoch:9 Step:2800 Training_loss:0.655943, Acc_avg:54.25% Training_loss_avg:0.689400\n",
            "Epoch:9 Step:2808 Training_loss:0.697871, Acc_avg:54.25% Training_loss_avg:0.689816\n",
            "Epoch:9 Step:2816 Training_loss:0.757730, Acc_avg:53.75% Training_loss_avg:0.690912\n",
            "Epoch:9 Step:2824 Training_loss:0.701399, Acc_avg:53.25% Training_loss_avg:0.691525\n",
            "Epoch:9 Step:2832 Training_loss:0.710010, Acc_avg:53.50% Training_loss_avg:0.691330\n",
            "Epoch:9 Step:2840 Training_loss:0.676812, Acc_avg:54.00% Training_loss_avg:0.690275\n",
            "Epoch:9 Step:2848 Training_loss:0.627988, Acc_avg:55.50% Training_loss_avg:0.687375\n",
            "Epoch:9 Step:2856 Training_loss:0.696936, Acc_avg:55.75% Training_loss_avg:0.686682\n",
            "Epoch:9 Step:2864 Training_loss:0.627727, Acc_avg:55.50% Training_loss_avg:0.686843\n",
            "Epoch:9 Step:2872 Training_loss:0.706920, Acc_avg:55.25% Training_loss_avg:0.687136\n",
            "Epoch:9 Step:2880 Training_loss:0.763370, Acc_avg:54.00% Training_loss_avg:0.689375\n",
            "Epoch:9 Step:2888 Training_loss:0.700455, Acc_avg:54.00% Training_loss_avg:0.689257\n",
            "Epoch:9 Step:2896 Training_loss:0.696131, Acc_avg:54.25% Training_loss_avg:0.688620\n",
            "Epoch:9 Step:2904 Training_loss:0.619352, Acc_avg:55.00% Training_loss_avg:0.687124\n",
            "Epoch:9 Step:2912 Training_loss:0.697334, Acc_avg:55.00% Training_loss_avg:0.687219\n",
            "Epoch:9 Step:2920 Training_loss:0.690856, Acc_avg:54.75% Training_loss_avg:0.687660\n",
            "Epoch:9 Step:2928 Training_loss:0.618921, Acc_avg:55.00% Training_loss_avg:0.687166\n",
            "Epoch:9 Step:2936 Training_loss:0.700151, Acc_avg:54.75% Training_loss_avg:0.687801\n",
            "Epoch:9 Step:2944 Training_loss:0.689781, Acc_avg:54.75% Training_loss_avg:0.688237\n",
            "Epoch:9 Step:2952 Training_loss:0.728338, Acc_avg:54.50% Training_loss_avg:0.688815\n",
            "Epoch:9 Step:2960 Training_loss:0.677051, Acc_avg:54.25% Training_loss_avg:0.689420\n",
            "Epoch:9 Step:2968 Training_loss:0.643062, Acc_avg:55.00% Training_loss_avg:0.688114\n",
            "Epoch:9 Step:2976 Training_loss:0.697773, Acc_avg:55.25% Training_loss_avg:0.687462\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:2976 Val_loss:0.689839, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:2984 Training_loss:0.740160, Acc_avg:54.50% Training_loss_avg:0.688821\n",
            "Epoch:9 Step:2992 Training_loss:0.689277, Acc_avg:54.50% Training_loss_avg:0.688868\n",
            "Epoch:9 Step:3000 Training_loss:0.706044, Acc_avg:54.00% Training_loss_avg:0.689652\n",
            "Epoch:9 Step:3008 Training_loss:0.749133, Acc_avg:53.75% Training_loss_avg:0.690427\n",
            "Epoch:9 Step:3016 Training_loss:0.731846, Acc_avg:53.25% Training_loss_avg:0.691450\n",
            "Epoch:9 Step:3024 Training_loss:0.708987, Acc_avg:53.50% Training_loss_avg:0.691221\n",
            "Epoch:9 Step:3032 Training_loss:0.701116, Acc_avg:53.50% Training_loss_avg:0.690704\n",
            "Epoch:9 Step:3040 Training_loss:0.670277, Acc_avg:54.00% Training_loss_avg:0.689719\n",
            "Epoch:9 Step:3048 Training_loss:0.720085, Acc_avg:53.50% Training_loss_avg:0.690693\n",
            "Epoch:9 Step:3056 Training_loss:0.642970, Acc_avg:53.75% Training_loss_avg:0.690180\n",
            "Epoch:9 Step:3064 Training_loss:0.708984, Acc_avg:53.75% Training_loss_avg:0.690671\n",
            "Epoch:9 Step:3072 Training_loss:0.658169, Acc_avg:54.00% Training_loss_avg:0.690041\n",
            "Epoch:9 Step:3080 Training_loss:0.687004, Acc_avg:54.25% Training_loss_avg:0.689860\n",
            "Epoch:9 Step:3088 Training_loss:0.690018, Acc_avg:54.00% Training_loss_avg:0.690358\n",
            "Epoch:9 Step:3096 Training_loss:0.700513, Acc_avg:54.00% Training_loss_avg:0.690240\n",
            "Epoch:9 Step:3104 Training_loss:0.681585, Acc_avg:53.75% Training_loss_avg:0.690658\n",
            "Epoch:9 Step:3112 Training_loss:0.686076, Acc_avg:53.50% Training_loss_avg:0.690757\n",
            "Epoch:9 Step:3120 Training_loss:0.646815, Acc_avg:53.50% Training_loss_avg:0.691237\n",
            "Epoch:9 Step:3128 Training_loss:0.717117, Acc_avg:53.75% Training_loss_avg:0.690265\n",
            "Epoch:9 Step:3136 Training_loss:0.721075, Acc_avg:53.00% Training_loss_avg:0.691554\n",
            "Epoch:9 Step:3144 Training_loss:0.689702, Acc_avg:53.25% Training_loss_avg:0.691334\n",
            "Epoch:9 Step:3152 Training_loss:0.703455, Acc_avg:52.50% Training_loss_avg:0.692288\n",
            "Epoch:9 Step:3160 Training_loss:0.719951, Acc_avg:52.00% Training_loss_avg:0.692855\n",
            "Epoch:9 Step:3168 Training_loss:0.696152, Acc_avg:52.25% Training_loss_avg:0.692526\n",
            "Epoch:9 Step:3176 Training_loss:0.702044, Acc_avg:52.00% Training_loss_avg:0.692699\n",
            "Epoch:9 Step:3184 Training_loss:0.713321, Acc_avg:51.50% Training_loss_avg:0.693413\n",
            "Epoch:9 Step:3192 Training_loss:0.691441, Acc_avg:51.50% Training_loss_avg:0.693105\n",
            "Epoch:9 Step:3200 Training_loss:0.694239, Acc_avg:51.25% Training_loss_avg:0.693871\n",
            "Epoch:9 Step:3208 Training_loss:0.691636, Acc_avg:51.25% Training_loss_avg:0.693746\n",
            "Epoch:9 Step:3216 Training_loss:0.706978, Acc_avg:52.00% Training_loss_avg:0.692731\n",
            "Epoch:9 Step:3224 Training_loss:0.692011, Acc_avg:52.25% Training_loss_avg:0.692543\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "52it [00:07,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:9 Step:3224 Val_loss:0.692773, Val_Acc_avg:54.75%\n",
            "Epoch:9 Step:3232 Training_loss:0.704064, Acc_avg:52.25% Training_loss_avg:0.692424\n",
            "Epoch:9 Step:3240 Training_loss:0.720836, Acc_avg:52.00% Training_loss_avg:0.693305\n",
            "Epoch:9 Step:3248 Training_loss:0.687531, Acc_avg:51.25% Training_loss_avg:0.694495\n",
            "Epoch:9 Step:3256 Training_loss:0.676797, Acc_avg:51.50% Training_loss_avg:0.694093\n",
            "Epoch:9 Step:3264 Training_loss:0.682843, Acc_avg:51.00% Training_loss_avg:0.695195\n",
            "Epoch:9 Step:3272 Training_loss:0.679375, Acc_avg:52.00% Training_loss_avg:0.694644\n",
            "Epoch:9 Step:3280 Training_loss:0.697114, Acc_avg:52.75% Training_loss_avg:0.693319\n",
            "Epoch:9 Step:3288 Training_loss:0.703511, Acc_avg:52.50% Training_loss_avg:0.693380\n",
            "Epoch:9 Step:3296 Training_loss:0.661961, Acc_avg:53.25% Training_loss_avg:0.692697\n",
            "Epoch:9 Step:3304 Training_loss:0.681081, Acc_avg:52.75% Training_loss_avg:0.693931\n",
            "Epoch:9 Step:3312 Training_loss:0.706295, Acc_avg:52.50% Training_loss_avg:0.694110\n",
            "Epoch:9 Step:3320 Training_loss:0.662265, Acc_avg:53.25% Training_loss_avg:0.693539\n",
            "Epoch:9 Step:3328 Training_loss:0.701145, Acc_avg:52.17% Training_loss_avg:0.695183\n"
          ]
        }
      ]
    }
  ]
}